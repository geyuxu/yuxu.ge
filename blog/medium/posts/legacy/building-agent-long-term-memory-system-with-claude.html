<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j</title>
    <style>
        body { font-family: Georgia, serif; max-width: 700px; margin: 2rem auto; padding: 0 1rem; line-height: 1.7; color: #333; }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        h2 { font-size: 1.4rem; margin-top: 2rem; }
        pre { background: #f4f4f4; padding: 1rem; overflow-x: auto; border-radius: 4px; }
        code { font-family: Menlo, Monaco, monospace; font-size: 0.9em; }
        p code { background: #f4f4f4; padding: 0.2em 0.4em; border-radius: 3px; }
        img { max-width: 100%; }
        blockquote { border-left: 3px solid #ddd; margin-left: 0; padding-left: 1rem; color: #666; }
        ul { padding-left: 1.5rem; }
        hr { border: none; border-top: 1px solid #ddd; margin: 2rem 0; }
        a { color: #1a8917; }
    </style>
</head>
<body>
<hr>
<h2>date: 2025-07-23
tags: [ai]
legacy: true</h2>
<h1>Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j</h1>
<p>Below is a summary of the installation and configuration process based on practice:</p>
<ol>
<li>Install Neo4j Desktop: Download and install Neo4j Desktop from the official Neo4j website. Neo4j Desktop provides an intuitive interface to manage local databases, which is very suitable for getting started. Start Neo4j Desktop after installation is complete.</li>
<li>Create a database instance and set password: Create a new local graph database in Neo4j Desktop (version needs to be 5.x or higher). When starting the database for the first time, you will be asked to set a password. Please set a password for the Neo4j user (default username is neo4j) and remember this information. By default, Neo4j&#39;s Bolt connection URI is bolt://localhost:7687, and Graphiti will connect to the database through this URI later.</li>
<li>Clone the Graphiti repository and configure the environment: Open terminal, clone the Graphiti source code repository and enter the directory:</li>
</ol>
<blockquote><code>git clone https://github.com/getzep/graphiti.git</code><br>
<code>cd graphiti/mcp_server</code></blockquote><p>The repository provides a .env.example template file. Copy one as .env and fill in Neo4j and OpenAI configurations according to actual conditions:</p>
<blockquote><code>OPENAI_API_KEY=&lt;your OpenAI API key&gt;</code><br>
<code>MODEL_NAME=gpt-4.1-mini        # Specify LLM model name, such as OpenAI&#039;s GPT-4 mini version</code><br>
<code>NEO4J_URI=bolt://localhost:7687</code><br>
<code>NEO4J_USER=neo4j</code><br>
<code>NEO4J_PASSWORD=&lt;your Neo4j password&gt;</code></blockquote><p>Where OPENAI_API_KEY is the key used by Graphiti to call the OpenAI interface for LLM inference and embeddings, MODEL_NAME can specify OpenAI models (such as gpt-3.5-turbo or gpt-4 series, the default example uses GPT-4.1 mini model), and the Neo4j section fills in the connection information and credentials for the database just created.</p>
<ol start="4">
<li>Install required tools (uv, uvicorn, claude-cli):</li>
</ol>
<ul>
<li>uv: Graphiti recommends using the uv tool developed by Astral to manage Python environments and dependencies. First install uv through pip install uv. Then execute uv sync in the graphiti/mcp_server directory, this command will install the required Python packages according to the project&#39;s lock file. uv is similar to pip but can synchronize dependencies faster. If not using uv, you can also manually create a virtual environment and use pip install -r requirements.txt to install dependencies.</li>
<li>uvicorn: If you plan to run the service through HTTP SSE, you need to install the ASGI server uvicorn (usually already in dependencies). Make sure uvicorn can be called from the command line (e.g., pip install uvicorn).</li>
<li>claude-cli: Claude Code provides command-line tools to manage MCP plugins. Install the claude CLI tool (e.g., through pip install anthropic or other means, see Anthropic documentation for details). After installation, the command line should be able to use the claude command for adding MCP servers and other configurations.</li>
</ul>
<ol start="5">
<li>Start Graphiti MCP Server and register plugin in Claude: The Graphiti repository comes with an MCP Server implementation, used as a bridge between frontends like Claude and the Graphiti backend. There are two startup methods:</li>
</ol>
<ul>
<li>Method A: Start through Claude Code CLI (stdio mode): This method runs Graphiti MCP Server as a subprocess of Claude, communicating through standard input/output. Execute the following command on the command line to add the Graphiti plugin to Claude Code (user scope):</li>
</ul>
<blockquote><code>claude mcp add-json graphiti-memory &#039;{</code><br>
<code>  &quot;type&quot;: &quot;stdio&quot;,</code><br>
<code>  &quot;command&quot;: &quot;/usr/local/bin/uv&quot;,</code><br>
<code>  &quot;args&quot;: [</code><br>
<code>    &quot;run&quot;, &quot;--directory&quot;, &quot;/path/to/graphiti/mcp_server&quot;, </code><br>
<code>    &quot;graphiti_mcp_server.py&quot;, &quot;--transport&quot;, &quot;stdio&quot;</code><br>
<code>  ],</code><br>
<code>  &quot;env&quot;: {</code><br>
<code>    &quot;OPENAI_API_KEY&quot;: &quot;&lt;your OpenAI key&gt;&quot;,</code><br>
<code>    &quot;MODEL_NAME&quot;: &quot;gpt-4.1-mini&quot;,</code><br>
<code>    &quot;NEO4J_URI&quot;: &quot;bolt://localhost:7687&quot;,</code><br>
<code>    &quot;NEO4J_USER&quot;: &quot;neo4j&quot;,</code><br>
<code>    &quot;NEO4J_PASSWORD&quot;: &quot;&lt;your Neo4j password&gt;&quot;</code><br>
<code>  }</code><br>
<code>}&#039;</code></blockquote><p>Replace the paths and parameters in the above command with actual values (e.g., uv executable path, Graphiti repository location, etc.). After execution, Claude Code will register an MCP plugin called &quot;graphiti-memory&quot;, and Claude will automatically start this Server and communicate through stdio when memory is needed during conversations.</p>
<ul>
<li>Method B: Run Graphiti Server independently (SSE mode): In this method, Graphiti runs as an independent service, accessible to Claude through HTTP Server-Sent Events (SSE) interface. You can execute:</li>
</ul>
<blockquote><code>cd graphiti/mcp_server</code><br>
<code>uv run graphiti_mcp_server.py --transport sse --model gpt-4.1-mini</code></blockquote><p>The above command will run Graphiti MCP Server in SSE mode locally (default listening on 0.0.0.0:8000). After successful startup, use Claude CLI to add this service as an MCP plugin:</p>
<p><code>claude mcp add --transport sse --scope user graphiti-memory http://localhost:8000/sse</code></p><p>This way Claude registers a remote MCP service called &quot;graphiti-memory&quot; (connected via HTTP). --scope user means it&#39;s globally available for this user (you can also use --scope project for specific projects). After completion, you can see the graphiti-memory plugin in the &quot;MCP Servers&quot; list in the Claude Code interface.</p>
<p>After completing the above installation and configuration, the Claude Agent now has Graphiti knowledge graph as long-term memory storage. Next, you can try conversing with Claude, recording information, and verifying the memory functionality.</p>
<h2>Usage Verification</h2>
<p>To confirm whether Graphiti memory is working properly, you can directly check from the Neo4j side whether data is written:</p>
<ul>
<li>Knowledge graph node check: Open Neo4j Browser (built into Neo4j Desktop) and connect to the database just created, execute Cypher query: MATCH (n:Episodic) RETURN n LIMIT 25;. Graphiti stores each conversation or information fragment as a node with &quot;Episodic&quot; label, you can view the latest written Episode nodes and their attributes through this query. If you can see the node list, it means Claude has successfully stored conversation content in Neo4j.</li>
</ul>
<p>If you cannot query any Episode nodes or Graphiti functionality is abnormal, it&#39;s recommended to troubleshoot from the following aspects:</p>
<ul>
<li>Bolt connection issues: Confirm that Graphiti MCP Server can connect to Neo4j database. Check whether the NEO4J_URI and port configured in .env are correct, the local default should be bolt://localhost:7687. Make sure the Neo4j database is started and no firewall is blocking local Bolt connections. If Neo4j uses non-default database name or username, Graphiti configuration also needs to be adjusted accordingly.</li>
<li>OpenAI API Key status: When writing conversations, Graphiti will call OpenAI models to extract entities and generate embeddings. If the provided API Key is invalid or has insufficient balance, Graphiti may not be able to complete Episode parsing and writing. You can check the terminal output logs when running Graphiti Server. If there are OpenAI interface errors or insufficient balance messages, you need to replace with a valid API Key (OpenAI can get a certain amount of free quota daily if data sharing is enabled) or ensure the account has sufficient quota.</li>
<li>Claude plugin enablement: Confirm that Graphiti MCP plugin is enabled in Claude frontend. In Claude Code, newly added MCP Servers may need to be enabled in the conversation interface (such as in Claude Desktop, you need to check and enable in the &quot;plugins&quot; list in the upper right corner of the conversation window). If the plugin is not enabled, Claude will not actually call Graphiti. Also note that Claude does not automatically trigger calls to MCP functionality for resources and prompt types by default (see details below), so when testing, you can first ask questions related to already recorded content to see if Claude can use previously stored memories to answer.</li>
</ul>
<h2>Graphiti Memory Functionality Categories</h2>
<p>As an MCP Server, Graphiti provides three types of interface capabilities, corresponding to the three types defined by MCP: Resources, Tools, and Prompts. Understanding these three helps leverage Graphiti memory&#39;s role:</p>
<ol>
<li>Resources: Interfaces for retrieving information. Such as getting content from internal knowledge graphs or external databases. These interfaces only read data without side effects, serving to let LLM access historical information in knowledge bases. For example, Graphiti provides resource interfaces for retrieving nodes and facts, supporting time-aware queries that can get past conversation fragments by time or conditions. Claude can call Resource-type functionality to read relevant content when needing to reference memory.</li>
<li>Tools: Interfaces for executing operations that will change external environments or data. Such as writing data through APIs, performing calculations, etc. Graphiti&#39;s tool interfaces allow LLM to add new knowledge to graphs or call real-time search and graph operations, achieving online memory updates. Whenever users provide new information, Claude Agent can call Graphiti&#39;s tool methods (like add_episode) to store it as new nodes, thus continuously accumulating knowledge.</li>
<li>Prompts: Predefined prompt templates or workflows that facilitate reuse of complex interaction logic between LLM and MCP Server. For example, Graphiti may provide templates for certain queries, encapsulating commonly used multi-step operations. These Prompt templates can be viewed as Agent&#39;s &quot;skill scripts&quot; that are called when specific needs are triggered. Through Prompts, developers can solidify standard query patterns, allowing Claude to generate query requests to Graphiti with one click when needed.</li>
</ol>
<p>Note that in Claude Desktop&#39;s current implementation, Tools-type MCP interfaces (like Graphiti&#39;s write/search functions) can be automatically called based on conversation context, while Resources and Prompts types will not be automatically triggered. That is, even if Graphiti lists available resources and prompt templates, Claude doesn&#39;t know when to use them by default unless users actively attach them. This point is particularly important in actual use, and coping strategies will be discussed in the next section.</p>
<h2>Usage Recommendations and Pitfall Records</h2>
<p>Based on actual experience, here are some noteworthy recommendations and possible pitfalls encountered when using Graphiti long-term memory:</p>
<ul>
<li>Debugging Graphiti writes: When you find that conversation content is not written to Neo4j, you can check the console output logs of Graphiti MCP Server. Graphiti will print information like the model name and Group ID used when starting, and if errors occur during write execution (such as OpenAI returning formats that don&#39;t meet expectations), exception stacks are usually also printed in the logs. When debugging, you can try directly calling Graphiti&#39;s API (such as REST interface) to add test data, or use short and clearly structured inputs to trigger add_episode to isolate problems. Make sure .env is loaded correctly (you can explicitly specify --env-file .env in the startup command just in case). If Graphiti prompts embedding or parsing schema errors, it&#39;s usually caused by model output not conforming to expected JSON format.</li>
<li>Avoiding Schema errors: Graphiti requires that the LLM used supports structured output to ensure correct formatting when extracting entity relationships. It&#39;s recommended to use OpenAI&#39;s GPT-4 or new versions of GPT-3.5 that have function calling or strict JSON output capabilities. If using models that don&#39;t support structured output (especially smaller models), you may encounter situations where Graphiti cannot parse returned content and Episode writing fails (manifested as log errors like schema mismatch). Additionally, running Graphiti for the first time will create required indexes and constraints on Neo4j, and IndexAlreadyExists prompts can be ignored. When adjusting Graphiti&#39;s entity/relationship type definitions, try to maintain consistency with Neo4j schema to avoid write errors due to schema mismatches.</li>
<li>Correctly triggering Memory in Claude: To make Claude fully utilize Graphiti long-term memory, some guidance in conversation strategies is needed. Currently Claude doesn&#39;t automatically use Resource/Prompt, so users or developers need to actively trigger them. There are several practical techniques: First, prompt Claude at the very beginning of conversations that Graphiti memory is available and should query the graph first when needed. For example, you can set system prompts like: &quot;Please search existing knowledge before answering.&quot; Second, skillfully use the <strong>&quot;References&quot;</strong> function provided by Claude interface: In Claude Desktop, you can click the &quot;+&quot; sign to attach stored memory fragments from MCP Server as reference materials. Third, refer to official recommendations to establish conversation conventions - such as &quot;search first, then answer&quot; and &quot;record new information immediately&quot;. These rules can be used as Claude prompts, making the model develop habits of calling add_episode to save when encountering new preferences/facts, and calling search_nodes/search_facts to retrieve relevant nodes and relationships when encountering problems first. Such explicit prompts can greatly improve Graphiti memory utilization. In summary, some human guidance is currently needed, and future versions of Claude may make AI automatically aware of available memory resources and call them.</li>
</ul>
<p>Through stable configuration and adjustment of the above tool chain, the integration of Claude Code with Graphiti + Neo4j can run smoothly, and an AI Agent with long-term memory is built. In real development, we should continuously optimize prompt strategies based on logs and conversation performance to ensure AI both &quot;remembers&quot; knowledge provided by users and can accurately recall and utilize it when needed. This solution can effectively avoid information forgetting in complex projects and greatly improve Agent&#39;s coherence and intelligence level for long-term tasks. In the future, if Claude plugin mechanisms are upgraded to automatically utilize Resource/Prompt, AI long-term memory will become even more handy. Hope the above pitfall experiences can help everyone more easily reproduce this powerful long-term memory Agent solution!</p>

</body>
</html>