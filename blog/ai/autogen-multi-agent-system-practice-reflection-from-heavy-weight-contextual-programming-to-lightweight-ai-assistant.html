<!DOCTYPE html><html lang="zh"> <head><!-- Global Metadata --><meta charset="utf-8"><!--<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">--><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"><link rel="shortcut icon" href="/favicon.png" type="image/png"><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" title="Ge Yuxu • AI &#38; Engineering" href="https://geyuxu.com/rss.xml"><meta name="generator" content="Astro v5.5.6"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><!-- Canonical URL --><link rel="canonical" href="https://geyuxu.com/blog/ai/autogen-multi-agent-system-practice-reflection-from-heavy-weight-contextual-programming-to-lightweight-ai-assistant.html"><!-- Primary Meta Tags --><title>AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant</title><meta name="title" content="AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant"><meta name="description"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://geyuxu.com/blog/ai/autogen-multi-agent-system-practice-reflection-from-heavy-weight-contextual-programming-to-lightweight-ai-assistant.html"><meta property="og:title" content="AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant"><meta property="og:description"><meta property="og:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://geyuxu.com/blog/ai/autogen-multi-agent-system-practice-reflection-from-heavy-weight-contextual-programming-to-lightweight-ai-assistant.html"><meta property="twitter:title" content="AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant"><meta property="twitter:description"><meta property="twitter:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><script src="/js/jquery-3.7.1.min.js"></script><script is:global>
	window.addEventListener('DOMContentLoaded', () => {
		$('.toc ol').css({
		'list-style': 'none',   // 隐藏 1. 2. 3.
		'margin': 0,
		'padding-left': 0,       // 可按需调整
		});
		$('.toc ol > li').css({
		'list-style': 'none',   // 隐藏 1. 2. 3.
		'padding-left': 10
		});
        $('.sidebar').append($('.toc'));
      });
	</script><link rel="stylesheet" href="/_astro/_slug_.BvCO7WHQ.css">
<style>a[data-astro-cid-eimmu3lg]{display:inline-block;text-decoration:none}a[data-astro-cid-eimmu3lg].active{font-weight:bolder;text-decoration:underline}header[data-astro-cid-3ef6ksr2]{margin:0;padding:0 1em;background:#fff;box-shadow:0 2px 8px rgba(var(--black),5%)}h2[data-astro-cid-3ef6ksr2]{margin:0;font-size:1em}h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2],h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none}nav[data-astro-cid-3ef6ksr2]{display:flex;align-items:center;justify-content:space-between}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{padding:1em .5em;color:var(--black);border-bottom:4px solid transparent;text-decoration:none}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none;border-bottom-color:var(--accent)}.social-links[data-astro-cid-3ef6ksr2],.social-links[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{display:flex}@media (max-width: 720px){.social-links[data-astro-cid-3ef6ksr2]{display:none}}footer[data-astro-cid-sz7xmlte]{padding:2em 1em 6em;background:linear-gradient(var(--gray-gradient)) no-repeat;color:rgb(var(--gray));text-align:center}.social-links[data-astro-cid-sz7xmlte]{display:flex;justify-content:center;gap:1em;margin-top:1em}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]{text-decoration:none;color:rgb(var(--gray))}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]:hover{color:rgb(var(--gray-dark))}
.statement[data-astro-cid-uffxixac]{font-size:10px;color:gray}@media (max-width: 640px){.statement[data-astro-cid-uffxixac]{font-size:6px;color:gray}}
</style></head> <body> <header data-astro-cid-3ef6ksr2> <nav data-astro-cid-3ef6ksr2> <!--<h2><a href="/">{SITE_TITLE}</a></h2>--> <h2 data-astro-cid-3ef6ksr2><a style="padding-left:0;color:blue;" href="/" data-astro-cid-3ef6ksr2>Ge Yuxu<br data-astro-cid-3ef6ksr2>AI & Engineering</a></h2> <div class="internal-links" data-astro-cid-3ef6ksr2> <a href="/" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Home </a>  <a href="/blog/1" class="active" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Blog </a>  <a href="/series" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Series </a>  <a href="/projects" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Projects </a>  </div> <div class="social-links" data-astro-cid-3ef6ksr2> <a href="https://github.com/geyuxu" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Go to Ge Yuxu's GitHub repo</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" data-astro-cid-3ef6ksr2><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-3ef6ksr2></path></svg> </a> <a href="https://www.linkedin.com/in/geyuxu/" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Go to Ge Yuxu's LinkedIn profile</span> <svg viewBox="0 0 24 24" width="32" height="32" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" data-astro-cid-3ef6ksr2> <path fill="currentColor" d="M20.447 20.452H17.2v-5.569c0-1.328-.025-3.039-1.852-3.039-1.853 0-2.136 1.447-2.136 2.942v5.666h-3.248V9h3.122v1.561h.045c.435-.823 1.498-1.688 3.083-1.688 3.295 0 3.903 2.17 3.903 4.989v6.59zM5.337 7.433a1.882 1.882 0 110-3.764 1.882 1.882 0 010 3.764zm1.626 13.019H3.708V9h3.255v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.226.792 24 1.771 24h20.451C23.2 24 24 23.226 24 22.271V1.729C24 .774 23.2 0 22.222 0z" data-astro-cid-3ef6ksr2></path> </svg> </a> </div> </nav> <!-- Microsoft Clarity --> <script type="text/javascript">
		(function(c,l,a,r,i,t,y){
			c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
			t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
			y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
		})(window, document, "clarity", "script", "rc2w96osp6");
	</script> </header>  <main class="page"> <!-- 左侧栏 --> <aside class="sidebar"> <div class="meta"> <b>AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant</b> <p><time datetime="2025-07-24T00:00:00.000Z"> 2025/07/24 08:00:00 </time></p>   </div> <hr> <br> </aside> <!-- 右侧正文区域（flex 居中） --> <div class="content-wrapper"> <article class="prose">  <nav class="toc"><ol class="toc-level toc-level-1"><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#introduction-when-the-multi-agent-wave-arrives">Introduction: When the Multi-Agent Wave Arrives</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#1-my-experiment-the-contextual-programming-multi-agent-system">1. My Experiment: The “Contextual Programming” Multi-Agent System</a><ol class="toc-level toc-level-2"><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#11-system-design-a-trinity-of-ai-developers">1.1. System Design: A Trinity of AI Developers</a></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#12-technical-implementation-assembling-the-team-with-autogen">1.2. Technical Implementation: Assembling the Team with AutoGen</a></li></ol></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#2-the-heaviness-in-practice-when-idealism-meets-reality">2. The “Heaviness” in Practice: When Idealism Meets Reality</a><ol class="toc-level toc-level-2"><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#21-interaction-latency-and-the-efficiency-black-hole">2.1. Interaction Latency and the Efficiency Black Hole</a></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#22-uncontrollable-emergent-intelligence">2.2. Uncontrollable “Emergent Intelligence”</a></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#23-complex-state-management-and-context-passing">2.3. Complex State Management and Context Passing</a></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#24-high-configuration-and-debugging-costs">2.4. High Configuration and Debugging Costs</a></li></ol></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#3-reflection-which-scenarios-truly-require-the-heavy-artillery">3. Reflection: Which Scenarios Truly Require the “Heavy Artillery”?</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#4-returning-to-simplicity-a-blueprint-for-lightweight-ai-assistants">4. Returning to Simplicity: A Blueprint for Lightweight AI Assistants</a><ol class="toc-level toc-level-2"><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#41-solution-1-two-stage-agent-pipeline-sequential-pipeline">4.1. Solution 1: Two-Stage Agent Pipeline (Sequential Pipeline)</a></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#42-solution-2-single-agent-with-tools">4.2. Solution 2: Single Agent with Tools</a></li></ol></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#conclusion-finding-the-balance-between-complexity-and-practicality">Conclusion: Finding the Balance Between Complexity and Practicality</a></li></ol></nav><h1 id="autogen-multi-agent-system-practice-reflection-from-heavy-weight-contextual-programming-to-a-lightweight-ai-assistant"><a aria-hidden="true" tabindex="-1" href="#autogen-multi-agent-system-practice-reflection-from-heavy-weight-contextual-programming-to-a-lightweight-ai-assistant"><span class="icon icon-link"></span></a>AutoGen Multi-Agent System Practice Reflection: From Heavy-Weight “Contextual Programming” to a Lightweight AI Assistant</h1>
<h2 id="introduction-when-the-multi-agent-wave-arrives"><a aria-hidden="true" tabindex="-1" href="#introduction-when-the-multi-agent-wave-arrives"><span class="icon icon-link"></span></a>Introduction: When the Multi-Agent Wave Arrives</h2>
<p>Recently, multi-agent frameworks, represented by AutoGen, have undoubtedly become one of the hottest topics in the AI field. They paint an exciting picture: a group of specialized AI agents collaborating like an efficient human team to automate complex tasks. As a developer passionate about exploring practical AI engineering, I was deeply captivated by this idea.</p>
<p>To apply this paradigm to my daily development workflow, I designed and implemented a multi-agent system I called “Contextual Programming.” My vision was to create an AI programming partner that could truly understand the programming context and deliver high-quality code through a team of agents for code generation, quality analysis, and optimization. However, after a day of hands-on practice, I came to a slightly bitter but valuable conclusion: <strong>for many day-to-day development needs, a meticulously designed multi-agent system can be too “heavyweight,” with its overhead costs outweighing its benefits.</strong></p>
<p>This blog post will share my entire journey from conception and practice to reflection. I’ll delve into the pros and cons of AutoGen’s multi-agent systems, discuss their ideal use cases, and propose lighter, more practical alternatives. I hope my real-world experience can serve as a useful reference for others on the path of exploring AI applications.</p>
<h2 id="1-my-experiment-the-contextual-programming-multi-agent-system"><a aria-hidden="true" tabindex="-1" href="#1-my-experiment-the-contextual-programming-multi-agent-system"><span class="icon icon-link"></span></a>1. My Experiment: The “Contextual Programming” Multi-Agent System</h2>
<p>My core objective was to address a key pain point of current AI code assistants: they are often “one-shot” and lack a continuous focus on code quality and subsequent optimization. I wanted my system to simulate a miniature development team.</p>
<h3 id="11-system-design-a-trinity-of-ai-developers"><a aria-hidden="true" tabindex="-1" href="#11-system-design-a-trinity-of-ai-developers"><span class="icon icon-link"></span></a>1.1. System Design: A Trinity of AI Developers</h3>
<p>I designed three highly specialized agents:</p>
<ol>
<li><strong>CoderAgent:</strong> Responsible for generating the initial Python code based on user requirements. Its core duty is to implement functionality quickly.</li>
<li><strong>QualityAnalyzerAgent:</strong> Responsible for reviewing the code generated by <code>CoderAgent</code>. It uses static analysis tools (like <code>pylint</code>) to check for style issues, potential errors, and non-standard practices, then provides specific modification suggestions.</li>
<li><strong>OptimizerAgent:</strong> After the code is functionally correct and meets quality standards, this agent examines it from a higher level, suggesting improvements related to algorithmic efficiency, code structure, and readability.</li>
</ol>
<p>To enable these three agents to collaborate “intelligently,” I chose AutoGen’s powerful <code>GroupChat</code> mode. By setting <code>speaker_selection_method</code> to <code>"auto"</code>, I expected the system to act like a project manager, automatically selecting the most appropriate agent to speak based on the current conversation context.</p>
<h3 id="12-technical-implementation-assembling-the-team-with-autogen"><a aria-hidden="true" tabindex="-1" href="#12-technical-implementation-assembling-the-team-with-autogen"><span class="icon icon-link"></span></a>1.2. Technical Implementation: Assembling the Team with AutoGen</h3>
<p>Here is the core code snippet for the system setup:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">import</span><span style="color:#E1E4E8"> autogen</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># Configure the LLM</span></span>
<span class="line"><span style="color:#E1E4E8">config_list </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.config_list_from_json(</span><span style="color:#79B8FF">...</span><span style="color:#E1E4E8">) </span></span>
<span class="line"><span style="color:#E1E4E8">llm_config </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> {</span><span style="color:#9ECBFF">"config_list"</span><span style="color:#E1E4E8">: config_list}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 1. Define the agents</span></span>
<span class="line"><span style="color:#E1E4E8">coder </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.AssistantAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"CoderAgent"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    system_message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"You are a helpful AI assistant that writes Python code to solve tasks. Return the code in a markdown code block."</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    llm_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_config,</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">quality_analyzer </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.AssistantAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"QualityAnalyzerAgent"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    system_message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"You are a quality assurance expert. You review the given Python code for style, errors, and best practices. Suggest specific improvements."</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    llm_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_config,</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">optimizer </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.AssistantAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"OptimizerAgent"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    system_message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"You are a performance optimization expert. You analyze the Python code for performance bottlenecks and suggest refactoring for better efficiency and readability."</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    llm_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_config,</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">user_proxy </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.UserProxyAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"UserProxy"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    human_input_mode</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"TERMINATE"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    code_execution_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">{</span><span style="color:#9ECBFF">"work_dir"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"coding"</span><span style="color:#E1E4E8">},</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 2. Set up the GroupChat with automatic speaker selection</span></span>
<span class="line"><span style="color:#6A737D"># Using "auto" mode lets the LLM decide the next speaker</span></span>
<span class="line"><span style="color:#E1E4E8">groupchat </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.GroupChat(</span></span>
<span class="line"><span style="color:#FFAB70">    agents</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[user_proxy, coder, quality_analyzer, optimizer],</span></span>
<span class="line"><span style="color:#FFAB70">    messages</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[],</span></span>
<span class="line"><span style="color:#FFAB70">    max_round</span><span style="color:#F97583">=</span><span style="color:#79B8FF">15</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    speaker_selection_method</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"auto"</span><span style="color:#E1E4E8"> </span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">manager </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.GroupChatManager(</span><span style="color:#FFAB70">groupchat</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">groupchat, </span><span style="color:#FFAB70">llm_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_config)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 3. Initiate the task</span></span>
<span class="line"><span style="color:#E1E4E8">user_proxy.initiate_chat(</span></span>
<span class="line"><span style="color:#E1E4E8">    manager,</span></span>
<span class="line"><span style="color:#FFAB70">    message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"Write a Python function to find the nth Fibonacci number, then analyze and optimize it."</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span></code></pre>
<p>With the <code>speaker_selection_method="auto"</code> setting, my ideal workflow was: <code>UserProxy</code> -> <code>CoderAgent</code> -> <code>QualityAnalyzerAgent</code> -> <code>OptimizerAgent</code> -> <code>UserProxy</code>. It looked perfect, didn’t it? However, reality delivered a harsh lesson.</p>
<h2 id="2-the-heaviness-in-practice-when-idealism-meets-reality"><a aria-hidden="true" tabindex="-1" href="#2-the-heaviness-in-practice-when-idealism-meets-reality"><span class="icon icon-link"></span></a>2. The “Heaviness” in Practice: When Idealism Meets Reality</h2>
<p>Once the system was running, I quickly felt a persistent sense of ‘heaviness.’ This feeling wasn’t from a single issue but a combination of several factors.</p>
<h3 id="21-interaction-latency-and-the-efficiency-black-hole"><a aria-hidden="true" tabindex="-1" href="#21-interaction-latency-and-the-efficiency-black-hole"><span class="icon icon-link"></span></a>2.1. Interaction Latency and the Efficiency Black Hole</h3>
<p>For a simple Fibonacci function, the entire process took several minutes. Each handoff between agents is a complete LLM call. The <code>GroupChat</code>’s process for deciding the next speaker also requires an LLM inference of its own. This meant that completing one simple task could involve 5-10, or even more, LLM calls.</p>
<p>In my daily development work, I need code completions and suggestions in seconds, not the result of an AI team “holding a meeting” that I have to wait for after making a cup of coffee. This high latency is fatal for high-frequency, real-time development assistance scenarios.</p>
<h3 id="22-uncontrollable-emergent-intelligence"><a aria-hidden="true" tabindex="-1" href="#22-uncontrollable-emergent-intelligence"><span class="icon icon-link"></span></a>2.2. Uncontrollable “Emergent Intelligence”</h3>
<p><code>speaker_selection_method="auto"</code> is a double-edged sword. It did introduce ‘intelligence,’ but it also brought chaos. I observed several typical problems:</p>
<ul>
<li><strong>Dialogue Loops:</strong> <code>CoderAgent</code> and <code>QualityAnalyzerAgent</code> could get stuck in a back-and-forth ‘tug-of-war,’ with one making changes and the other finding new issues, preventing the process from ever reaching the optimization stage.</li>
<li><strong>Incorrect Scheduling:</strong> Sometimes, right after <code>CoderAgent</code> finished writing the code, <code>OptimizerAgent</code> would ‘jump the gun’ and start talking about optimization, skipping the quality analysis step and disrupting the intended workflow.</li>
<li><strong>Premature Termination:</strong> The system might hand control back to the <code>UserProxy</code> and consider the task complete without sufficient optimization.</li>
</ul>
<p>This unpredictability turned a tool that was supposed to boost efficiency into a ‘black box’ that required careful guidance and observation.</p>
<h3 id="23-complex-state-management-and-context-passing"><a aria-hidden="true" tabindex="-1" href="#23-complex-state-management-and-context-passing"><span class="icon icon-link"></span></a>2.3. Complex State Management and Context Passing</h3>
<p>One of the core challenges of a multi-agent system is state management. In this experiment, the ‘state’ was the piece of code being iterated on. Ideally, <code>QualityAnalyzerAgent</code> should analyze the latest code from <code>CoderAgent</code>.</p>
<p>But the state of a <code>GroupChat</code> is maintained through an ever-growing message history. As the number of conversation rounds increases, the context window expands rapidly. This not only increases token costs but can also cause subsequent agents to ‘lose focus’ due to information overload, ignoring critical code versions or modification suggestions. I had to meticulously craft prompts, repeatedly reminding agents to “please focus on the code in the previous turn’s message,” which was a burden in itself.</p>
<h3 id="24-high-configuration-and-debugging-costs"><a aria-hidden="true" tabindex="-1" href="#24-high-configuration-and-debugging-costs"><span class="icon icon-link"></span></a>2.4. High Configuration and Debugging Costs</h3>
<p>Building this system required me to spend a significant amount of time on ‘meta-work’:</p>
<ul>
<li><strong>Prompt Engineering:</strong> Writing precise <code>system_message</code> for each agent to define its role, capabilities, and communication style.</li>
<li><strong>Flow Design:</strong> Thinking about how to design termination conditions and guide the conversation flow.</li>
<li><strong>Debugging:</strong> When the system didn’t behave as expected, I had to read the entire conversation history to guess whether the problem was with an agent’s prompt or the selector’s decision logic. This debugging difficulty is far greater than with traditional code.</li>
</ul>
<p>These upfront investment and subsequent maintenance costs are clearly disproportionate for solving a problem at the level of ‘writing a Fibonacci function.‘</p>
<h2 id="3-reflection-which-scenarios-truly-require-the-heavy-artillery"><a aria-hidden="true" tabindex="-1" href="#3-reflection-which-scenarios-truly-require-the-heavy-artillery"><span class="icon icon-link"></span></a>3. Reflection: Which Scenarios Truly Require the “Heavy Artillery”?</h2>
<p>This failed attempt was not without value; it gave me a deeper understanding of the nature and application boundaries of multi-agent systems.</p>
<p><strong>The core strengths of multi-agent systems lie in:</strong></p>
<ul>
<li><strong>Specialization and Modularity:</strong> The ability to break down a large, ambiguous task and assign parts to ‘experts’ in different fields, achieving a separation of concerns.</li>
<li><strong>Simulating Complex Workflows:</strong> They are excellent for simulating real-world processes that require multi-role collaboration, such as product development or scientific research.</li>
<li><strong>‘Emergence’ and Creativity:</strong> Free-form discussions between agents can sometimes lead to unexpected and creative solutions.</li>
</ul>
<p><strong>So, what scenarios are suitable for this kind of ‘heavyweight’ system?</strong></p>
<ol>
<li><strong>Exploratory and Research Tasks:</strong> For example, “Investigate the latest advancements in autonomous driving technology and generate an analysis report including a technical summary, key players, and future trends.” Such tasks lack a fixed process, require multiple complex steps like information gathering, integration, and analysis, and have a certain demand for creativity in the final output.</li>
<li><strong>End-to-End Automation Projects:</strong> For example, “Automatically generate a project skeleton, write core code, and configure deployment scripts based on a user requirements document.” These tasks have long cycles, multiple steps, and can be executed asynchronously. A multi-agent system can act like an autonomous project team, working silently in the background.</li>
<li><strong>Complex Decision-Making and Simulation:</strong> For example, simulating a market environment where ‘Consumer Agents,’ ‘Competitor Agents,’ and ‘Marketing Agents’ interact to predict the effectiveness of a marketing strategy.</li>
</ol>
<p><strong>And for the following scenarios, we should decisively opt for a ‘lightweight’ approach:</strong></p>
<ul>
<li><strong>High-frequency, real-time interactive tasks:</strong> Such as code completion, real-time Q&#x26;A, or text polishing.</li>
<li><strong>Deterministic, linear tasks:</strong> If a task can be clearly broken down into A->B->C steps, then forcing it into a free-discussion <code>GroupChat</code> is like using a sledgehammer to crack a nut.</li>
<li><strong>Scenarios that are extremely sensitive to latency and cost.</strong></li>
</ul>
<h2 id="4-returning-to-simplicity-a-blueprint-for-lightweight-ai-assistants"><a aria-hidden="true" tabindex="-1" href="#4-returning-to-simplicity-a-blueprint-for-lightweight-ai-assistants"><span class="icon icon-link"></span></a>4. Returning to Simplicity: A Blueprint for Lightweight AI Assistants</h2>
<p>Since the heavyweight multi-agent system wasn’t suitable for my daily development needs, what is a better alternative? The answer is to return to simplicity, leveraging other patterns provided by AutoGen or shifting our mindset.</p>
<h3 id="41-solution-1-two-stage-agent-pipeline-sequential-pipeline"><a aria-hidden="true" tabindex="-1" href="#41-solution-1-two-stage-agent-pipeline-sequential-pipeline"><span class="icon icon-link"></span></a>4.1. Solution 1: Two-Stage Agent Pipeline (Sequential Pipeline)</h3>
<p>If your process is deterministic, like ‘code first, then review,’ you can organize the agents in a sequential manner. AutoGen’s <code>register_nested_chats</code> feature is perfect for this scenario.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#6A737D"># This is a conceptual example to demonstrate how to build a sequential pipeline.</span></span>
<span class="line"><span style="color:#6A737D"># After the CoderAgent completes its task, its result is automatically passed </span></span>
<span class="line"><span style="color:#6A737D"># as input to the QualityAnalyzerAgent.</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># Assuming CoderAgent and QualityAnalyzerAgent are already defined</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># Nested chat setup</span></span>
<span class="line"><span style="color:#E1E4E8">review_chat </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.GroupChat(</span></span>
<span class="line"><span style="color:#FFAB70">    agents</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[quality_analyzer, user_proxy],</span></span>
<span class="line"><span style="color:#FFAB70">    messages</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[],</span></span>
<span class="line"><span style="color:#FFAB70">    max_round</span><span style="color:#F97583">=</span><span style="color:#79B8FF">2</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    speaker_selection_method</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"manual"</span><span style="color:#6A737D"> # Or another controllable method</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># Register the nested chat to form a pipeline</span></span>
<span class="line"><span style="color:#E1E4E8">coder.register_nested_chats(</span></span>
<span class="line"><span style="color:#E1E4E8">    [{</span><span style="color:#9ECBFF">"recipient"</span><span style="color:#E1E4E8">: quality_analyzer, </span><span style="color:#9ECBFF">"message"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"Please review the following code."</span><span style="color:#E1E4E8">, </span><span style="color:#9ECBFF">"summary_method"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"last_msg"</span><span style="color:#E1E4E8">}],</span></span>
<span class="line"><span style="color:#FFAB70">    trigger</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">user_proxy,</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">user_proxy.initiate_chat(coder, </span><span style="color:#FFAB70">message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"Write a Python function for quick sort."</span><span style="color:#E1E4E8">)</span></span></code></pre>
<p>In this pattern, the control flow is a deterministic <code>User -> Coder -> QualityAnalyzer</code>. It retains the advantage of agent specialization but eliminates the unpredictability and high coordination cost of the auto-selecting <code>GroupChat</code>.</p>
<h3 id="42-solution-2-single-agent-with-tools"><a aria-hidden="true" tabindex="-1" href="#42-solution-2-single-agent-with-tools"><span class="icon icon-link"></span></a>4.2. Solution 2: Single Agent with Tools</h3>
<p>This is a more mainstream and practical paradigm for building AI assistants today, and it’s in the same vein as OpenAI’s Function Calling/Tool Use.</p>
<p><strong>The core idea is:</strong> Instead of creating multiple agents to converse with each other, create one ‘omnipotent’ <code>AssistantAgent</code> and encapsulate capabilities like ‘quality analysis’ and ‘code optimization’ as <strong>tools</strong> it can call.</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">import</span><span style="color:#E1E4E8"> pylint.lint</span></span>
<span class="line"><span style="color:#F97583">import</span><span style="color:#E1E4E8"> io</span></span>
<span class="line"><span style="color:#F97583">from</span><span style="color:#E1E4E8"> pylint.reporters.text </span><span style="color:#F97583">import</span><span style="color:#E1E4E8"> TextReporter</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 1. Define the tool function</span></span>
<span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> lint_code</span><span style="color:#E1E4E8">(code: </span><span style="color:#79B8FF">str</span><span style="color:#E1E4E8">) -> </span><span style="color:#79B8FF">str</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#9ECBFF">    """Runs pylint on the given Python code and returns the report."""</span></span>
<span class="line"><span style="color:#E1E4E8">    pylint_opts </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [</span><span style="color:#9ECBFF">'--disable=all'</span><span style="color:#E1E4E8">, </span><span style="color:#9ECBFF">'--enable=E,W'</span><span style="color:#E1E4E8">]</span></span>
<span class="line"><span style="color:#E1E4E8">    reporter </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> TextReporter(io.StringIO())</span></span>
<span class="line"><span style="color:#E1E4E8">    pylint.lint.Run([io.StringIO(code)], </span><span style="color:#FFAB70">reporter</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">reporter, </span><span style="color:#FFAB70">exit</span><span style="color:#F97583">=</span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">args</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">pylint_opts)</span></span>
<span class="line"><span style="color:#F97583">    return</span><span style="color:#E1E4E8"> reporter.out.getvalue()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 2. Create an agent with tool-calling capabilities</span></span>
<span class="line"><span style="color:#E1E4E8">super_assistant </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.AssistantAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"SuperAssistant"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    system_message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"You are a super-assistant for Python development. You can write code and use tools to check its quality."</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    llm_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_config,</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 3. Create a UserProxyAgent and register the tool</span></span>
<span class="line"><span style="color:#E1E4E8">user_proxy </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.UserProxyAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"UserProxy"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    human_input_mode</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"TERMINATE"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    code_execution_config</span><span style="color:#F97583">=</span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">, </span><span style="color:#6A737D"># We aren't executing code, just calling tools</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">user_proxy.register_function(</span></span>
<span class="line"><span style="color:#FFAB70">    function_map</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">{</span></span>
<span class="line"><span style="color:#9ECBFF">        "lint_code"</span><span style="color:#E1E4E8">: lint_code</span></span>
<span class="line"><span style="color:#E1E4E8">    }</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 4. Let the agent use the tool</span></span>
<span class="line"><span style="color:#6A737D"># In the LLM's prompt, it will be informed that the lint_code tool is available.</span></span>
<span class="line"><span style="color:#6A737D"># The LLM will decide when it's appropriate to generate a request to call this tool.</span></span></code></pre>
<p><strong>The advantages of this pattern are overwhelming:</strong></p>
<ul>
<li><strong>Low Latency:</strong> No communication overhead between multiple agents.</li>
<li><strong>High Controllability:</strong> The flow is driven by the LLM’s decision to call a tool, which is more predictable than a free-form conversation between agents.</li>
<li><strong>Easy to Extend and Maintain:</strong> Adding new capabilities only requires adding a new tool function, not designing a new agent and its complex interaction logic.</li>
</ul>
<h2 id="conclusion-finding-the-balance-between-complexity-and-practicality"><a aria-hidden="true" tabindex="-1" href="#conclusion-finding-the-balance-between-complexity-and-practicality"><span class="icon icon-link"></span></a>Conclusion: Finding the Balance Between Complexity and Practicality</h2>
<p>My journey from ambitious design to pragmatic retreat taught me a profound lesson: <strong>the first principle of technology selection is always ‘fitness for purpose.’</strong> Multi-agent systems are a powerful and fascinating paradigm, but they are not a silver bullet for every problem. To chase a ‘cool-looking’ architecture while ignoring real-world efficiency, cost, and controllability is a classic case of technical self-indulgence.</p>
<p>For those of us building AI applications, our goal shouldn’t be to build the most complex system, but the one that best solves the problem at hand. Within a powerful framework like AutoGen, <code>GroupChat</code> is just one of many tools. Learning to make wise choices between ‘multi-agent collaboration,’ ‘sequential pipelines,’ and ‘single-agent + tools’ based on the nature of the task is the hallmark of a mature AI engineer.</p>
<p>In the future, collaboration between humans and AI, and between AI and AI, will undoubtedly deepen. Our task is to maintain a clear head amidst the constant emergence of new technologies and find that optimal balance point between technology and value.</p> <html lang="en" data-astro-cid-uffxixac> <head><!-- Global Metadata --><meta charset="utf-8"><!--<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">--><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"><link rel="shortcut icon" href="/favicon.png" type="image/png"><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" title="Ge Yuxu • AI &#38; Engineering" href="https://geyuxu.com/rss.xml"><meta name="generator" content="Astro v5.5.6"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><!-- Canonical URL --><link rel="canonical" href="https://geyuxu.com/blog/ai/autogen-multi-agent-system-practice-reflection-from-heavy-weight-contextual-programming-to-lightweight-ai-assistant.html"><!-- Primary Meta Tags --><title>Ge Yuxu • AI &amp; Engineering</title><meta name="title" content="Ge Yuxu • AI &#38; Engineering"><meta name="description" content="Welcome to my blog!"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://geyuxu.com/blog/ai/autogen-multi-agent-system-practice-reflection-from-heavy-weight-contextual-programming-to-lightweight-ai-assistant.html"><meta property="og:title" content="Ge Yuxu • AI &#38; Engineering"><meta property="og:description" content="Welcome to my blog!"><meta property="og:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://geyuxu.com/blog/ai/autogen-multi-agent-system-practice-reflection-from-heavy-weight-contextual-programming-to-lightweight-ai-assistant.html"><meta property="twitter:title" content="Ge Yuxu • AI &#38; Engineering"><meta property="twitter:description" content="Welcome to my blog!"><meta property="twitter:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><script src="/js/jquery-3.7.1.min.js"></script></head> <body data-astro-cid-uffxixac>  <div class="statement" data-astro-cid-uffxixac> <blockquote data-astro-cid-uffxixac> <p data-astro-cid-uffxixac><strong data-astro-cid-uffxixac>脱敏说明</strong>：本文所有出现的表名、字段名、接口地址、变量名、IP地址及示例数据等均非真实，
    仅用于阐述技术思路与实现步骤，示例代码亦非公司真实代码。
    示例方案亦非公司真实完整方案，仅为本人记忆总结，用于技术学习探讨。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;文中所示任何标识符并不对应实际生产环境中的名称或编号。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;示例&nbsp;SQL、脚本、代码及数据等均为演示用途，不含真实业务数据，也不具备直接运行或复现的完整上下文。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;读者若需在实际项目中参考本文方案，请结合自身业务场景及数据安全规范，使用符合内部命名和权限控制的配置。</p> <p data-astro-cid-uffxixac><strong data-astro-cid-uffxixac>版权声明</strong>：本文版权归原作者所有，未经作者事先书面许可，任何单位或个人不得以任何方式复制、转载、摘编或用于商业用途。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;若需非商业性引用或转载本文内容，请务必注明出处并保持内容完整。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;对因商业使用、篡改或不当引用本文内容所产生的法律纠纷，作者保留追究法律责任的权利。<br data-astro-cid-uffxixac><br data-astro-cid-uffxixac> <em data-astro-cid-uffxixac>Copyright&nbsp;©&nbsp;1989–Present&nbsp;Ge&nbsp;Yuxu.&nbsp;All&nbsp;Rights&nbsp;Reserved.</em></p> </blockquote> </div></body></html>  </article> </div> </main> <footer data-astro-cid-sz7xmlte>
&copy; 2025 All rights reserved.
</footer>  </body></html>