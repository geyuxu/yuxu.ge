{
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#0": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统\n\n下面总结基于实践的安装与配置流程：\n1.\t安装 Neo4j Desktop：从 Neo4j 官方网站下载 Neo4j Desktop 并安装。Neo4j Desktop 提供直观的界面来管理本地数据库，非"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#1": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "xample 模板文件。复制一份作为 .env 并根据实际情况填写Neo4j和OpenAI配置：\n\n其中 OPENAI_API_KEY 是 Graphiti 用于调用 OpenAI 接口进行LLM推理和嵌入的密钥，MODEL_NAME 可以指定OpenAI模型（如 gpt-3.5-turbo 或 g"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#2": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "手动创建虚拟环境并使用 pip install -r requirements.txt 安装依赖。\n* uvicorn：如果打算通过 HTTP SSE 方式运行服务，需要安装 ASGI 服务器 uvicorn（通常已在依赖中）。确保命令行下可以调用 uvicorn（例如 pip install uv"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#3": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "r 实现，用于充当 Claude 等前端与 Graphiti 后端之间的桥梁。启动步骤有两种方式：\n* 方法A：通过 Claude Code CLI 启动（stdio 模式）：这种方式将 Graphiti MCP Server 作为 Claude 的子进程，通过标准输入输出通信。在命令行执行以下命令"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#4": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "上述命令将 Graphiti MCP Server 以 SSE 模式跑在本地（默认监听 0.0.0.0:8000）。成功启动后，使用 Claude CLI 将此服务添加为 MCP 插件：\n\n这样Claude就注册了一个名为 “graphiti-memory” 的远程MCP服务（通过HTTP连接）。-"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#5": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "使用验证\n\n要确认 Graphiti 内存是否正常工作，可以从Neo4j侧直接检查数据是否写入：\n* 知识图谱节点检查：打开 Neo4j Browser（Neo4j Desktop 内置）连接到刚才的数据库，执行 Cypher 查询：MATCH (n:Episodic) RETURN n LIMIT"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#6": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "lt 连接问题：确认 Graphiti MCP Server 能连接上 Neo4j 数据库。检查 .env 配置的 NEO4J_URI 和端口是否正确，本地默认应为 bolt://localhost:7687。确保 Neo4j 数据库已启动且未设置防火墙阻止本地 Bolt 连接。如果 Neo4j 使"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#7": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "效的 API Key（OpenAI 如开启数据分享可每日获得一定免费额度）或者确保账户有足够额度。\n* Claude 插件启用：确认 Graphiti MCP 插件已在 Claude 前端启用。在 Claude Code 中，新添加的 MCP Server 可能需要在对话界面中开启（如Claude "
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#8": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "ools 和 Prompts 三种类型 。理解这三者有助于发挥 Graphiti 内存的作用：\n1.\tResources（资源工具）：用于检索信息的接口。如从内部知识图谱或外部数据库获取内容。这类接口只读数据不产生副作用，作用是让 LLM 访问知识库中的历史信息。例如 Graphiti 提供检索节点"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#9": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "Graphiti 的工具类方法（如 add_episode）将其存为新节点，从而持续积累知识。\n3.\tPrompts（提示模板）：指预定义的提示词模板或工作流，方便 LLM 和 MCP Server 之间复用复杂交互逻辑。例如 Graphiti 可能提供某些查询的模板，封装常用的多步操作 。这些 P"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#10": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "它们，除非用户主动附加。这一点在实际使用中尤为重要，下一节会讨论应对策略。\n\n使用建议与踩坑记录\n\n基于实际体验，这里总结一些使用Graphiti长记忆过程中值得注意的建议和可能遇到的坑：\n* 调试 Graphiti 写入：当发现对话内容没有写入Neo4j时，可以检查 Graphiti MCP Se"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#11": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "i 提示embedding或解析schema错误，通常是模型输出不符合预期 JSON 格式导致的。\n* 避免 Schema 错误：Graphiti 要求所使用的 LLM 支持结构化输出，以确保提取实体关系时格式正确 。建议使用 OpenAI 的 GPT-4 或新版 GPT-3.5 等具备函数调用或严"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#12": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "aphiti 的实体/关系类型定义时，尽量保持与Neo4j模式一致，避免因为模式不符导致写入错误。\n* Claude 中正确触发 Memory：为了让 Claude 充分利用 Graphiti 长期记忆，需要在对话策略上进行一些引导。目前Claude对 Resource/Prompt 并非自动使用，"
  },
  "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统#13": {
    "title": "结合 Claude Code、Graphiti 和 Neo4j 构建 Agent 长记忆系统",
    "url": "/content/posts/legacy/结合-claude-code-graphiti-和-neo4j-构建-agent-长记忆系统",
    "date": "2025-07-23",
    "text": "ch_nodes/search_facts 检索相关节点和关系的习惯。这种显式的提示能大大提高 Graphiti 内存的利用率。总之，目前需要一定人为引导，未来版本Claude可能会让AI自动意识到可用的记忆资源并调用。\n\n通过以上工具链的稳定配置和调整，Claude Code 与 Graphiti"
  },
  "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践#0": {
    "title": "深入理解Git子模块更新失败问题与Java环境排查实践",
    "url": "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践",
    "date": "2019-03-05",
    "text": "深入理解Git子模块更新失败问题与Java环境排查实践\n\n可以看出，Git报告子模块中缺少某个提交（以SHA-1标识）。主仓库记录的子模块版本对应的提交在子模块仓库中找不到，因此拉取失败。\n\n排查过程\n\n面对这个错误，我们开始逐步排查可能的原因，主要做了以下几件事：\n* 验证提交存在性：首先怀疑是否"
  },
  "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践#1": {
    "title": "深入理解Git子模块更新失败问题与Java环境排查实践",
    "url": "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践",
    "date": "2019-03-05",
    "text": "失的提交也被成功获取，未出现错误。这说明问题并非源于仓库本身，而是可能出在我们自动化拉取的方式上。\n* 锁定工具差异：由于自动任务并非直接调用 git 命令，而是通过 Java 中的 Git 库执行（类似 JGit 这样的实现），我们怀疑工具本身的行为差异导致了问题。查询相关资料后发现，我们的推测是"
  },
  "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践#2": {
    "title": "深入理解Git子模块更新失败问题与Java环境排查实践",
    "url": "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践",
    "date": "2019-03-05",
    "text": "模块提交缺失，但并非仓库数据真的丢失，而是在拉取过程中没有获取到所需提交对象。具体原因可归纳如下：\n* 子模块引用机制：Git 子模块在主仓库中仅存储了子模块仓库的提交哈希，而不直接包含子模块的内容。因此，在克隆主仓库后，需要额外拉取子模块仓库的内容，并检出对应的提交。如果该提交未被拉取下来，就会出"
  },
  "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践#3": {
    "title": "深入理解Git子模块更新失败问题与Java环境排查实践",
    "url": "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践",
    "date": "2019-03-05",
    "text": "录，所以能拿到所需提交；但 JGit 可能只获取了有限的引用（例如默认分支头），没有涵盖那个提交。\n* 类库 Bug 影响：综上所述，这是工具实现差异引发的异常情况。恰好 JGit 存在该问题的已知 Bug，使得自动化过程中没有拉取子模块的新对象，最终导致 MissingObjectExceptio"
  },
  "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践#4": {
    "title": "深入理解Git子模块更新失败问题与Java环境排查实践",
    "url": "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践",
    "date": "2019-03-05",
    "text": "更新。例如克隆时加上 --recursive 参数，或在 pull/fetch 时开启 fetch.recurseSubmodules=true 配置，确保子模块的提交一并获取。原生 Git 的行为相对可靠，能避免类似不一致的问题。\n* 确保提交存在于远端：开发人员应确保在更新子模块指针后，将对应的"
  },
  "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践#5": {
    "title": "深入理解Git子模块更新失败问题与Java环境排查实践",
    "url": "/content/posts/legacy/深入理解git子模块更新失败问题与java环境排查实践",
    "date": "2019-03-05",
    "text": "否稳定。下节将通过 GitPython 库来演示类似的场景，并给出异常处理和日志记录的实践建议。\n\nJava实践：使用JGit处理子模块拉取与异常捕获\n\n以下是使用JGit的实际代码示例，演示如何正确拉取主仓库及子模块，处理可能出现的缺失对象异常：\n\n总结\n\n这次对子模块更新失败问题的深入分析，不仅"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#0": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice\n\n2. Tuning Methods: Overview and Code Examples\n\nChoosing t"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#1": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "te with runnable code snippets.\n\n2.1 Grid Search\n\n**Core Idea**: A brute-force enumeration of all possible combinations (Cartesian product) of the pro"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#2": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "d the best-performing region.\n\n2.2 Random Search\n\n**Core Idea**: Unlike Grid Search, Random Search samples a fixed number of parameter combinations fr"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#3": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "dealing with a large number of hyperparameters.\n\n**Key Insight**: For hyperparameters sensitive to their order of magnitude, like learning rate and re"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#4": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "dea**: This is a more intelligent search strategy. It uses a probabilistic model (a surrogate) to model the hyperparameter-to-performance function and"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#5": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "significantly saving computational resources.\n\n2.4 Early-Stopping Based Algorithms (Successive Halving / Hyperband)\n\n**Core Idea**: These algorithms a"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#6": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "allocate more resources only to the \"survivors.\"\n\nFor deep learning, `KerasTuner`'s `Hyperband` or `Optuna`'s `SuccessiveHalvingPruner` are more natur"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#7": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "ns a group of models (a \"population\") in parallel. Periodically, it replaces the weights of poor-performing models with those of high-performing model"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#8": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "ine.\n\n3. Common Hyperparameters and Their Impact\n\nUnderstanding how different hyperparameters affect model behavior is key to making informed tuning d"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#9": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "in Groups**: Don't try to tune everything at once. Start with optimization-related parameters (like learning rate, batch size), then move to model arc"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#10": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "-1`) is far more efficient than a linear scale.\n4.  **Visualize and Use Early Stopping**: Monitor training/validation curves with tools like TensorBoa"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#11": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "-tune within the same order of magnitude first.\n6.  **Prioritize Resources**: First, determine the maximum batch size and model size your hardware (es"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#12": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "archCV` with log-uniform sampling is your friend.\n3.  **Training on a GPU with a limited budget?** → `Optuna` (TPE) with pruning or `Hyperband` is the"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-en#13": {
    "title": "A Comprehensive Guide to Hyperparameter Tuning in Machine Learning: From Theory to Practice",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-en",
    "date": "2024-01-01",
    "text": "ptimization, but be prepared for its complexity.\n\nBy combining this theoretical knowledge with hands-on code examples, you will be able to perform hyp"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#0": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "多线程锁实现：原理剖析与工程实践指南\n\n操作系统原语是操作系统提供的一组用于同步和互斥的基本功能，例如信号量（Semaphore）、互斥量（Mutex）和条件变量（Condition Variable）等。这类原语通常由操作系统内核实现。使用基于操作系统原语的锁时，线程可能需要在用户态和内核态之间切"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#1": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "指令，程序员可以在用户态实现锁机制，例如自旋锁（spinlock）就是一种典型基于原子操作的锁。\n\n与操作系统原语实现的锁不同，基于原子指令的锁通常不会主动放弃CPU。线程在尝试获取这类锁时，如果锁目前被其他线程持有，调用原子指令的线程不会被阻塞，而是会反复尝试——这种行为称为忙等待（busy wa"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#2": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "当线程A持有锁时，线程B如果请求相同的锁会被挂起，这样B不会占用CPU，等待A释放锁后再唤醒B。\n\n原子指令实现的锁由于完全在用户态操作，省去了进入内核的成本，因此在低竞争的情况下性能非常高。然而，当许多线程竞争同一把锁时，问题也会出现：由于线程忙等待不会阻塞，它们会持续占用CPU反复尝试获取锁，导"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#3": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "指令的锁会引发处理器资源竞争，进而影响整体性能。\n\n基于上述特性，在不同场景下应选择合适的锁实现：\n* 使用操作系统原语锁的场景：当涉及复杂的同步逻辑（例如需要线程间通知、等待特定条件发生）或者临界区内的操作耗时较长时，采用操作系统提供的锁更为适宜。操作系统原语提供了丰富的功能接口，使用起来也较为简"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#4": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "导致大量CPU时间被浪费，在这种情况下应及时转换为阻塞式的锁机制。\n\nCPU缓存一致性与内存屏障\n\n无论使用哪种方式实现锁，都必须考虑内存可见性和指令有序性的问题。现代CPU为了提高性能，允许对内存操作进行乱序执行（Out-of-Order Execution），并采用多级缓存来加速内存访问。这意味"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#5": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "的写入仍停留在它自己的CPU缓存中尚未对其他核心可见，或者因为指令重排导致写入操作的生效被延后。\n\n为保证多线程程序的正确性，锁的实现中需要引入内存屏障（Memory Barrier）机制。内存屏障可以阻止特定的内存操作重排序，并确保缓存中的数据被及时刷新，使得在屏障之前发生的内存更新对于其他处理器"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#6": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "在解锁操作前后插入 mfence、sfence 等指令以保证内存可见性。而在x86这样内存序较强的架构上，大多数带lock前缀的原子指令（如lock cmpxchg）已经隐含执行了内存屏障的功能。\n\n锁的优化策略\n\n锁的实现和使用可以通过多种策略来优化性能。下面介绍几种常见的优化手段：\n* 自旋与阻"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#7": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "实现采用了自旋与挂起相结合的策略，默认会让线程自旋一段时间，再根据情况决定是否挂起线程以减少竞争。\n* 偏向锁：偏向锁（Biased Locking）是假定锁大部分时间只会被同一个线程占用而进行的优化。在偏向模式下，当一个线程第一次获取锁时，会将锁标记为“偏向”该线程，随后该线程再次获取锁时无需任何"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#8": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "ot JVM 中的一项重要优化（可通过启动参数开启/关闭），其存在是为了提升无锁竞争情况下的性能。\n* 细粒度锁与锁分段：从架构设计层面降低锁竞争也是优化思路之一。如果发现某个大锁（保护大量资源）成为瓶颈，可以考虑将其拆分为多个细粒度锁，让不同线程尽可能地锁定不同的资源，这样能减少同一把锁上的争用（"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#9": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "并发性能。尽管这些策略不属于单个锁实现的底层优化，它们在应用层面上对降低锁竞争、提升性能非常有效。\n* 无锁与锁的替代品：在某些场景下，可以通过无锁编程来减少甚至避免传统锁的使用。例如，使用原子变量或锁自由的数据结构来完成线程间同步。这样的优化能够消除锁的开销，提升并发度。然而，无锁算法通常更为复杂"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#10": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "变量等一系列操作系统原语。下面的代码展示了如何使用 Pthreads 提供的互斥锁来保护临界区：\n\n在这个例子中，两个线程分别对全局变量 counter 进行一百万次递增操作。我们使用 pthread_mutex_lock(&lock) 和 pthread_mutex_unlock(&lock) 将"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#11": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "我们使用 std::atomic_flag 实现了一把简单的自旋锁：每次循环中，线程调用 lock.test_and_set(std::memory_order_acquire) 来尝试获取锁。如果锁已经被占用，则 test_and_set 会一直返回 true，导致 while 循环反复空转等待；"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#12": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "线程执行被保护的代码。下面的示例展示了使用 synchronized 方法实现线程安全的计数器：\n\n在这个例子中，我们将 increment() 方法声明为 synchronized。这样保证了同一时刻只能有一个线程进入该方法，其他线程若调用 increment() 将在入口处阻塞等待。因此，两个线"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#13": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "入内核阻塞等待。下面摘自 HotSpot JVM 的源码片段，可以观察锁竞争时 JVM 的策略：\n\n从上述源码可以看出，JVM 在进入 synchronized 块时会先尝试偏向锁（Biased Locking，如果启用的话），接着尝试轻量级锁（针对“mark word”为 neutral 的情况）"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#14": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "来实现线程安全操作。下面的代码使用 AtomicInteger 实现了一个线程安全的计数器递增：\n\n在这个例子中，两个线程分别对同一个 Counter 对象的 count 变量进行递增操作。通过调用 AtomicInteger 的 incrementAndGet() 方法，我们能够保证对 count"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#15": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "子指令。下面是 AtomicInteger.incrementAndGet() 方法的源码简化：\n\n可以看到，incrementAndGet() 方法采用了一个自旋循环，不断尝试，直到通过 CAS 成功更新 count 值才返回。每次循环中，它先读取当前值，计算新值，然后使用 compareAndS"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#16": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "操作的原子性。\n\n常见问题与注意事项\n\n并发编程中，锁的使用还涉及一些常见的问题和需要注意的地方：\n* 死锁（Deadlock）：如果两个或多个线程互相等待对方释放锁，就会造成死锁。例如，线程 A 持有锁 L1 并等待获取锁 L2，而线程 B 此时持有锁 L2 并等待获取锁 L1，这种循环等待会让线"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#17": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "在锁实现中引入优先级继承机制：当高优先级线程被阻塞时，临时提升持锁的低优先级线程的优先级，使其尽快释放锁。\n* 自旋等待的弊端：使用自旋锁要考虑运行环境和临界区长短。在单核处理器上，自旋锁往往表现不佳——由于只有一个CPU核心，如果持有锁的线程被操作系统调度挂起，其他线程将一直空转等待，而持锁线程得"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#18": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "on）习惯用法来管理锁的生命周期。一把未被释放的锁会导致其他线程永远陷入等待，严重影响系统稳定性。\n* 锁粒度与性能：选择恰当的锁粒度对性能至关重要。锁的粒度过大（例如用一把全局锁保护大量不相关的数据）会降低并发性，让很多原本可以并行的操作被串行化；锁粒度过小（每个很细的对象各自加锁）又会增加编程复"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#19": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "杂同步场景支持有限，而且如果使用不当（比如缺少必要的内存屏障或在不适合的场合忙等）也会带来问题。\n\n在实际开发中，并没有“一招鲜”的锁方案，需要针对具体情况选择最合适的工具。如果只是实现简单的线程计数等，可直接使用原子变量来避免传统锁的开销；如果需要更复杂的互斥/同步控制，操作系统提供的 mutex"
  },
  "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南#20": {
    "title": "多线程锁实现：原理剖析与工程实践指南",
    "url": "/content/posts/legacy/多线程锁实现-原理剖析与工程实践指南",
    "date": "2025-04-28",
    "text": "N. (2008). The Art of Multiprocessor Programming. Morgan Kaufmann.\n* Silberschatz, A., Galvin, P. B. & Gagne, G. (2013). Operating System Concepts. Jo"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#0": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture\n\nUpgraded Tech Stack\n- **Front"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#1": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "ion (for web UI) and JWT tokens (for API clients)\n- **Architecture**: Multi-user server architecture designed to support cross-platform clients\n\nCore "
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#2": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "set to the current timestamp on INSERT operations. For the `updated_at` field to function correctly on UPDATE operations, either the application logic"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#3": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "cation System Implementation\n\nBackend API Design\n\nAuthentication Decorator\n\n4. Frontend Authentication Interface\n\nLogin Page Features\n- **Responsive D"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#4": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "ion, password masking\n\nRegistration Page Features\n- **Input Validation**: Username uniqueness, password confirmation matching\n- **Visual Feedback**: R"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#5": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "rity protection\n- ✅ Automatic rollback on failure\n- ✅ Detailed migration logs\n\nTechnical Challenges and Solutions\n\n1. Database Schema Mismatch Issue\n\n"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#6": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "i/5` instead of `/api/todos/5`\n\n**Solution**: \n\n3. User Data Isolation\n\n**Problem**: Ensuring different users can only access their own data\n\n**Soluti"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#7": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "each query\n- Implement connection pool management\n- Optimize SQL query efficiency\n\n2. Frontend Experience Optimization\n- Implement loading state indic"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#8": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "1. Requirements Analysis and Architecture Design\n- Analyzed technical challenges from single-user to multi-user\n- Designed cross-platform server archi"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#9": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "d JavaScript logic\n- Adapted responsive layout\n\n4. Database Migration Implementation\n- Developed and tested migration scripts\n- Safely migrated produc"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#10": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "Complete registration/login/logout functionality\n- ✅ **Data Isolation**: Each user has independent todo data\n- ✅ **Session Management**: Dual authenti"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#11": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "ion\n- **Compatibility**: Supports modern browsers\n- **Scalability**: Reserved interfaces for multi-platform clients\n\nCross-Platform Development Plan\n\n"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#12": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "ndows client (C# + WPF)\n- Local database caching\n\nPhase 4: Linux + Integration Testing\n- Linux client (Python + PyQt)\n- Cross-platform integration tes"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#13": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "nctional expansion.\n\n2. Caution in Data Migration\nData migration is a high-risk operation that requires adequate backup and rollback preparation. Auto"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#14": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "be ignored.\n\n4. Security-First Design Principles\nSecurity must be considered from the beginning of the project, including password encryption, session"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#15": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "ion web application to a modern multi-user system. This project not only demonstrates web application development best practices but also lays a solid"
  },
  "/content/posts/legacy/todo-list-multi-user-application-development-pract#16": {
    "title": "Todo List Multi-User Application Development Practice: Complete Upgrade from Single-User to Cross-Platform Architecture",
    "url": "/content/posts/legacy/todo-list-multi-user-application-development-pract",
    "date": "2024-01-01",
    "text": "experience and stronger technical capabilities.\n\n**Tech Stack**: Python Flask, SQLite, HTML5, CSS3, JavaScript, JWT, bcrypt  \n**Project Features**: Mu"
  },
  "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development#0": {
    "title": "HTML5 Canvas Classic Tank Battle Game Development: Single-File Game Architecture Practice",
    "url": "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development",
    "date": "2025-07-20",
    "text": "HTML5 Canvas Classic Tank Battle Game Development: Single-File Game Architecture Practice\n\nArchitecture Characteristics\n- **Single-file Design**: All "
  },
  "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development#1": {
    "title": "HTML5 Canvas Classic Tank Battle Game Development: Single-File Game Architecture Practice",
    "url": "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development",
    "date": "2025-07-20",
    "text": "ucture\n\nTank Class Implementation\n\nBullet System\n\nGame Mechanics Implementation\n\nCollision Detection System\n\nLevel System\n\nUI System and Game State\n\nU"
  },
  "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development#2": {
    "title": "HTML5 Canvas Classic Tank Battle Game Development: Single-File Game Architecture Practice",
    "url": "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development",
    "date": "2025-07-20",
    "text": "s**: No external libraries or frameworks required\n- **Easy Sharing**: Convenient for code reading and learning\n- **Fast Loading**: Reduced HTTP reques"
  },
  "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development#3": {
    "title": "HTML5 Canvas Classic Tank Battle Game Development: Single-File Game Architecture Practice",
    "url": "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development",
    "date": "2025-07-20",
    "text": "h hit and explosion effects\n\n3. Extensible Design\n- **Modular Code**: Clear class structure for easy extension\n- **Event System**: Support for custom "
  },
  "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development#4": {
    "title": "HTML5 Canvas Classic Tank Battle Game Development: Single-File Game Architecture Practice",
    "url": "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development",
    "date": "2025-07-20",
    "text": "ion implementation\n\nGame Development Fundamentals\n- Implemented complete game loop architecture\n- Designed efficient collision detection system\n- Buil"
  },
  "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development#5": {
    "title": "HTML5 Canvas Classic Tank Battle Game Development: Single-File Game Architecture Practice",
    "url": "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development",
    "date": "2025-07-20",
    "text": "**Multiplayer Mode**: Local two-player battles\n2. **Level Editor**: Custom map functionality\n3. **Power-up System**: Weapon upgrades and special items"
  },
  "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development#6": {
    "title": "HTML5 Canvas Classic Tank Battle Game Development: Single-File Game Architecture Practice",
    "url": "/content/posts/legacy/html5-canvas-classic-tank-battle-game-development",
    "date": "2025-07-20",
    "text": "ping complete games using native Web technologies. Through carefully designed architecture and efficient implementation strategies, it achieves rich g"
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#0": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "电商商品媒资同步服务迁移至 Apollo 配置中心实践\n\n1 | 现状扫描：Yaml 的痛点\n\n* **环境碎片化**  \n  * *dev*、*test*、*gray*、*prod* 起步，双十一再来一套 *sale‑9.9.，年底清仓还有 *clearance*。  \n  * 每个环境里都有不同"
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#1": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "`；  \n  * 结果把 `oss.secret_key` 也不小心改了，生产直接上传失败。  \n\n**配置中心** 看似只是技术升级，实际上是治理团队协作方式。  \nApollo 成熟、易部署、权限模型完备，于是排除万难，拉它上车。\n\n2 | Apollo 极简科普\n\n两句话概括 Apollo： "
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#2": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "> * `PUT /configs` —— 管理端脚本里做灰度发布  \n\n3 | 设计原则\n\n* *配置即代码，但不混代码仓库* —— Apollo 维护运行时配置，Git 只存默认值。  \n* *一行配置就是一次发布单* —— 通过 Apollo Release 做审计，拒绝跳板机手动改表。  \n"
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#3": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "缩、是否启用 AVIF  \n* `rate_limit` —— 上传并发、磁盘 IOPS 阈值  \n* `promotion` —— 是否展示双十一徽章  \n\n> 划分原则：  \n> * 读写人群不同的，必须拆；  \n> * 生命周期不同的，必须拆；  \n> * 变更频率不同的，最好拆。\n\n4.2 "
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#4": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "每天凌晨定时跑任务，按运营表格切换活动广告标识。\n\n4.5 灰度与回滚\n\n* **灰度**  \n  * 使用 Apollo Portal “灰度发布”功能，选择 5% IP Hash，Pod 级别覆盖。  \n  * Pod 通过 `HOST_IP` 注册到监控，自带标签 `apollo.releas"
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#5": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "o REST `/notifications/v2` 超时要 **>60s**，否则 502。  \n  * Python `requests` 要把 `timeout=(connect, read)` 分开写。  \n* **文本值自动去空格**  \n  * Apollo Portal 会把配置值左右"
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#6": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "* 调 OpenAPI 发布同一个 key 多次会叠加历史版本，回滚 list 会很长。  \n  * 解决：脚本里先 `GET` 判断值是否一致。  \n\n6 | 迁移效果\n\n7 | 最佳实践清单\n\n* **Namespace 粒度**  \n  * 按业务功能拆分，最怕“一个命名空间装天下”。  \n*"
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#7": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "*峰值 QPS 5w+**。  \n配置中心若拉胯，长轮询暴增，ConfigService 吐核。\n\n压测脚本（简化）：\n\n结果：\n\n* **P99 Latency**：45 ms  \n* **吞吐**：9. req / 18 s ≈ 9.0 req/s （单实例）  \n* CPU 占用 < 0.6 "
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#8": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "存 `APOLLO_OPENAPI_TOKEN`，**切勿**打印在日志。  \n\n9.2 批量发布\n\nOpenAPI 没有「一次发布多个 Namespace」的接口，我们写了流水线：\n\n1. 循环调用 `PUT /items` 把所有键写入临时 `draft`  \n2. 最后调用 `POST /re"
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#9": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "OpenAPI 回滚只能按 `releaseId`，所以在发布时**必须**记录该 id。  \n我们在 `commit-msg` 里加脚本，把 `releaseId` 写回 MR Description，方便 SRE 复制粘贴。\n\n务必注意幂等——同一个 release 回滚两次会抛 400，需要代"
  },
  "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践#10": {
    "title": "电商商品媒资同步服务迁移至 Apollo 配置中心实践",
    "url": "/content/posts/legacy/电商商品媒资同步服务迁移至-apollo-配置中心实践",
    "date": "2021-11-12",
    "text": "并不是万灵药。  \n**配置治理** 的核心还是人：  \n\n* 持续审计 —— 删除僵尸字段  \n* 审批流程 —— 谁改了什么，一张表说清  \n* 监控告警 —— 让配置变更像代码回归一样有测试、有指标\n\n**后续规划：**\n\n* **多集群热备** —— 计划把 Apollo 抽象到 Terra"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#0": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "微调：用领域数据提升大模型任务表现\n\n工具链与优化: 在实践中，一整套完善的工具链可以大大简化微调的实现。首先，Hugging Face 的 Transformers 库是微调大模型的基础工具，它提供了预训练模型的加载、训练流程封装以及与PEFT方法的集成。配合 DeepSpeed 和 Coloss"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#1": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "综上，借助Transformers提供的高层接口，结合DeepSpeed、Colossal-AI等优化方案，我们可以在确保预训练模型通用能力不丢失的情况下，低成本地完成大模型在特定任务上的微调训练。这套工程工具链已日趋成熟，为大模型落地各类垂直应用打下了基础。\n\n应用视角：何时微调以及与其他技术的边"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#2": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "该目标进行优化。在这类场景下，微调后的模型通常在一致性和准确性上明显优于零样本或少样本提示的方式。\n* 领域或风格专有： 当任务涉及特定领域知识或行业术语（如医学、法律、金融领域的内容处理），或需要模型采用特定的行文风格（如客服机器人的礼貌用语，公司品牌的措辞风格），微调能够让模型“内化”这些领域特"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#3": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "素——一般来说，上千条以上的数据才能支撑大模型微调出有意义的增益，否则可能欠拟合或效果不明显 。\n\n当然，在决定微调前，还应考虑替代方案或辅助技术，以确保所采用的方法与问题性质匹配。当前，大模型应用中常见的有Prompt工程、RAG、函数调用等技术，它们各有擅长的方面，和微调形成互补关系。下面我们从"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#4": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "mpt中提供大量范例，从而缩短输入、降低调用延迟 。因此，一种实际策略是在项目初期用Prompt工程验证任务可行性；当对输出质量要求很高且有足够数据时，再考虑对模型进行微调以提高上限。\n* 微调 vs RAG（检索增强生成）: RAG通过引入外部知识库，为模型提供实时的检索信息，适合需要最新知识或大"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#5": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "来说，RAG擅长“补充知识”：当模型需要扩展到它未掌握的信息时，通过检索来弥补。微调擅长“专精知识”：当模型已经有一定相关知识，但需要在特定领域上达到专家水平时，通过额外训练来精炼。实际应用中，两者也可以结合——例如先用微调让模型掌握领域内回答问题的风格和流程，再用RAG提供实时事实依据，这样既保证"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#6": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "任务对时效性和专业准确性的要求：静态领域、高专业度优先考虑微调，动态领域、开放问答优先考虑RAG。\n* 微调 vs 函数调用（工具使用）：函数调用指的是LLM在生成响应时触发预定义的API或工具函数，从而获取模型自身之外的额外信息或执行动作 。这一技术让模型的能力边界大大拓展——模型可以查询数据库、"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#7": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "出正确的界面操作序列。这一点在很多应用集成场景下非常关键：UI集成问题更多是工程实现问题，应由应用代码去处理，模型只需配合输出特定格式即可。总之，微调无法取代真正的编程逻辑；当任务需要模型之外的操作时，应该引入工具使用或插件机制，而不是让模型死记硬背这些操作步骤。\n\n综上所述，从应用视角看，微调最适"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#8": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "法\n\n尽管微调强大，仍有一些误区需要避免。以下列出几种错误使用微调的情况，并给出更合理的替代方案：\n* 误区1：用微调更新模型知识库。 有人希望通过定期微调，把最新资料灌输给模型，使其始终知道最新信息。然而正如前文所述，微调后的模型只是记住了训练时的知识快照，面对频繁更新的信息会很快滞后 。频繁微调"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#9": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "辑完成，模型只负责决策哪种操作或提供参数即可。不要试图通过微调让模型“硬编码”所有可能的操作流程。\n* 误区3：为简单问答任务微调大模型。 如果任务只是让模型回答一些常识性问题或简单的知识查询，通常预训练模型已经具备相当能力，可以直接回答或通过轻量的Prompt完成。而有些团队可能匆忙地整理少量Q&"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#10": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "门、通用模型无法胜任时（如专业医疗问诊对话，需要融入病历风格），且有足够此类问答数据时才考虑应用。\n* 误区4：数据不足时盲目微调。 微调是有数据门槛的，数据太少时强行微调大模型可能导致过拟合，反而劣化模型的通用能力。与其如此，不如尝试少样本学习或Prompt范例来提升效果。正确做法：当标注数据很少"
  },
  "/content/posts/legacy/微调-用领域数据提升大模型任务表现#11": {
    "title": "微调：用领域数据提升大模型任务表现",
    "url": "/content/posts/legacy/微调-用领域数据提升大模型任务表现",
    "date": "2024-10-14",
    "text": "些都不是微调该解决的问题。作为开发者，应该把微调用在刀刃上，用在那些能显著收益的场景中。\n\n结语\n\n微调大模型就像打开了一扇通往定制化智能的大门，正确地使用可以令模型在特定任务上表现出色，为业务需求提供有力支撑。工程视角下，借助LoRA等高效微调方法和完善的工具链，我们能够克服大模型微调的资源瓶颈，"
  },
  "/content/posts/legacy/mcp-blog-automation#0": {
    "title": "MCP-Blog：一键搞定 Astro 博客发布，告别繁琐流程",
    "url": "/content/posts/legacy/mcp-blog-automation",
    "date": "2024-01-01",
    "text": "MCP-Blog：一键搞定 Astro 博客发布，告别繁琐流程\n\n1. 在博客项目 `geyuxu.com` 中写完文章\n2. 执行 `git add .`、`git commit -m \"...\"`、`git push` 将源码推送到主分支\n3. 执行 `npm run build` 构建静态文件"
  },
  "/content/posts/legacy/mcp-blog-automation#1": {
    "title": "MCP-Blog：一键搞定 Astro 博客发布，告别繁琐流程",
    "url": "/content/posts/legacy/mcp-blog-automation",
    "date": "2024-01-01",
    "text": "流程自动化**：将多步操作简化为一步，减少人为错误，提升效率\n\n二、技术架构：MCP 的设计哲学\n\n什么是 MCP (Model Context Protocol)？\n\n\"模型上下文协议\"（Model Context Protocol）并非一个公开的网络协议，而是我为本项目设计的一套**命令行交互规"
  },
  "/content/posts/legacy/mcp-blog-automation#2": {
    "title": "MCP-Blog：一键搞定 Astro 博客发布，告别繁琐流程",
    "url": "/content/posts/legacy/mcp-blog-automation",
    "date": "2024-01-01",
    "text": "越\"到 **Astro 博客项目** 的目录中去执行操作。\n\n三、实现细节：一步步构建自动化利器\n\n现在，我们来看最核心的代码实现。整个项目由一个 Shell 脚本驱动。\n\n**项目结构:**\n\n1. 核心脚本 `mcp.sh`\n\n这是我们所有自动化的心脏。它负责接收参数、切换目录、执行命令和处理错"
  },
  "/content/posts/legacy/mcp-blog-automation#3": {
    "title": "MCP-Blog：一键搞定 Astro 博客发布，告别繁琐流程",
    "url": "/content/posts/legacy/mcp-blog-automation",
    "date": "2024-01-01",
    "text": "1`) 传入，增加了灵活性。\n\n- **Astro 集成 (`npm run build`)**:\n  每个 Astro 项目都有一个 `build` 脚本定义在 `package.json` 中。我们的自动化脚本直接调用它，无需关心其内部复杂的构建过程，实现了完美的解耦。\n\n- **GitHub "
  },
  "/content/posts/legacy/mcp-blog-automation#4": {
    "title": "MCP-Blog：一键搞定 Astro 博客发布，告别繁琐流程",
    "url": "/content/posts/legacy/mcp-blog-automation",
    "date": "2024-01-01",
    "text": "一样简单。\n\n1. **赋予脚本执行权限** (只需做一次):\n   \n\n2. **一键发布**:\n   当你在 `geyuxu.com` 中完成写作后，打开终端，执行以下命令：\n   \n\n然后，你就可以泡杯咖啡，看着终端自动完成所有工作：\n\n几分钟后，你的新文章就会出现在线上。\n\n五、总结与展望\n"
  },
  "/content/posts/legacy/mcp-blog-automation#5": {
    "title": "MCP-Blog：一键搞定 Astro 博客发布，告别繁琐流程",
    "url": "/content/posts/legacy/mcp-blog-automation",
    "date": "2024-01-01",
    "text": "脚本升级为更健壮的 Node.js 或 Python CLI 工具，提供更丰富的交互和错误处理\n3. **CI/CD 集成**：虽然本地脚本很方便，但最终极的自动化方案是将其迁移到 GitHub Actions。当 `main` 分支有新的 push 时，自动触发构建和部署流程\n\n希望这个小项目能给"
  },
  "/content/posts/legacy/批量行政区代码更新脚本实战笔记#0": {
    "title": "批量行政区代码更新脚本实战笔记",
    "url": "/content/posts/legacy/批量行政区代码更新脚本实战笔记",
    "date": "2021-10-12",
    "text": "批量行政区代码更新脚本实战笔记\n\n脚本生成思路\n* 源数据整理至 CSV：`STORE_CODE,STORE_TYPE,OLD_AREA,NEW_AREA`。\n* 使用简单 Python 模版批量输出：\n\n* 模板优势：\n* 可读性强，后期维护仅需修改 CSV。\n* 支持追加其他字段（如 city）"
  },
  "/content/posts/legacy/批量行政区代码更新脚本实战笔记#1": {
    "title": "批量行政区代码更新脚本实战笔记",
    "url": "/content/posts/legacy/批量行政区代码更新脚本实战笔记",
    "date": "2021-10-12",
    "text": "批提交：\n  * 每 500 条 COMMIT 一次，减少回滚体积。\n\n校验与回滚\n* 快速校验：\n  * `SELECT COUNT(*) WHERE area = new_area` 验证成功率。\n\n* 聚合对比：`SUM(old_area)` vs `SUM(new_area)`。\n* 回滚方"
  },
  "/content/posts/legacy/批量行政区代码更新脚本实战笔记#2": {
    "title": "批量行政区代码更新脚本实战笔记",
    "url": "/content/posts/legacy/批量行政区代码更新脚本实战笔记",
    "date": "2021-10-12",
    "text": "总结\n* 批量数据脚本需求看似简单，核心在于 **生成可靠脚本** + **完善备份校验**。\n* 小型场景用单条 `UPDATE` 直观易读；大规模可考虑 `MERGE` 或 ETL 工具。\n* 数据治理应在源头加约束，降低后期修补成本。"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#0": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "构建多智能体营销系统：从角色划分到调度协同的实践\n\n首先要明确的是，每个Agent应有明确的职责边界。这一点至关重要：正如OpenAI的Agent开发文档所建议的，“让专门的Agent各司其职，不要指望一个通用Agent能做好所有事情” 。在我们的营销场景中：\n* 创意智能体（Creative Ag"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#1": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "浏览量、转化等），分析效果并生成报告或优化建议。分析Agent专注于数据，不直接创建或发布内容。\n\n通过如此角色划分，每个Agent都有清晰的边界，便于模块化开发和后续优化。这种专注单一职能的设计类似于软件开发中的单一职责原则：一个Agent做好一件事，能够提高系统整体性能和效率 。同时，分离角色还"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#2": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "下文管理等。下面将分别介绍正确的设计实践，以及需要避免的误区。\n\n调度协同与Planner智能体\n\n有了创意、调度、分析三个Agent，还需要一个“大脑”来协调它们的工作顺序和交互。这就是调度者/规划智能体（Planner Agent）。Planner智能体充当监督者，决定何时调用哪个Agent，串"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#3": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "效果不佳，Planner可根据反馈决定下一步，例如重新调用创意Agent调整文案，形成闭环优化。\n\n这样的调度逻辑可以通过代码流程编排实现，也可以交由LLM智能体决策。两种方式各有优劣： 通过代码编排，流程更可控和可预测；通过LLM让Planner智能体自由决策，则系统更灵活，能应对开放式的任务规划"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#4": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "度Agent可以动态调整加大该渠道投放比重——这些决策都可以由训练好的LLM根据提示规则来完成。\n\n无论采用何种方式，使用Planner智能体编排Agent的核心好处在于提高系统的灵活性和智能性：流程不再硬编码，而是可以根据环境和反馈做出调整（这一点对复杂的营销活动特别重要）。同时，集中由Plann"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#5": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "of Least Privilege），为每个Agent赋予其履行职责所需的最小权限 。具体而言：\n* 分开账户与密钥：为创意Agent、调度Agent、分析Agent分别配置不同的API密钥或凭据。创意Agent可能只需要调用语言模型服务的密钥；调度Agent则需要社交平台的API令牌；分析Age"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#6": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "业实践中非常重要，切勿为了省事而让所有Agent共用“万能钥匙”。\n\n上下文管理与Prompt设计\n\n在多Agent系统中如何管理知识和上下文同样是设计要点之一。一个错误的做法是将所有知识一次性堆入主Prompt，试图用一个Agent在一个巨大Prompt中解决所有问题。这么做不仅使Prompt过于"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#7": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "析方法和KPIs解释。每个Prompt里只含与该Agent任务相关的信息，避免无关细节干扰其决策。\n* 共享必要的信息：Agents之间需要协作时，通过Planner或中间结果传递信息，而不是在一开始就把所有信息打包给每个Agent。比如创意Agent生成的文案可以作为输入提供给调度Agent的Pr"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#8": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "说明“只需输出数据洞察，不涉及内容创作或发布动作”。提示清晰可以防止智能体的误解，保证协作有序。\n\n通过精心的上下文管理，我们既减少了每个Agent需要处理的认知负担，又保留了系统的灵活性。正如LangChain的多Agent经验所示，将任务拆解并串联，比起让单个Agent在一长串思路中反复推理，更"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#9": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "独立的模块（或类）。这可以使用LangChain的链（Chain）或Agent接口来封装。例如：\n\n上述伪代码演示了三类Agent的大致实现方式：创意Agent使用LLMChain基于Prompt生成内容，调度Agent封装发布逻辑（此处为简化打印），分析Agent模拟获取并计算指标。实际应用中，调"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#10": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "LM驱动的智能Planner。在此演示一个混合模式——主要流程用代码控制，并结合LLM辅助决策。\n\n在这个简化的Planner实现中，我们线性地调用了创意->调度->分析的流程，并加入了一个基于结果的分支（若第一次分析结果不佳则调整文案再发一次）。在实际系统中，可以更智能地由LLM来判断分析结果并规"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#11": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "任务。这样的Planner相当于动态地“看”到当前状态后再决定下一步，用到了LLM的推理能力 。\n\n无论是硬编码流程还是LLM动态决策，Planner的存在使任务编排变得清晰：它如同流程图的中心节点，控制着各模块的执行顺序和条件。开发者可以在Planner中调整逻辑，添加新的Agent或分支，而不用"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#12": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "hon中，可以利用asyncio等并发机制来实现。例如：\n\n上面的逻辑演示了如何使用asyncio.gather实现多Agent的并行运行——LangChain框架本身也支持类似的并行执行，帮助多智能体系统高效地管理并行任务，优化资源使用和响应时间 。需要注意并行带来的状态管理问题：我们可能需要跟踪"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#13": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "单场景下，我们可以用一个Python字典或数据类作为状态容器，在Planner中逐步填充。例如：\n\n对于更复杂的系统，建议采用事件驱动架构：各Agent通过事件总线发布/订阅消息。例如创意Agent完成后发送“内容已生成”事件，附带内容ID；调度Agent监听到该事件后执行发布并发送“发布完成”事件"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#14": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "地搭建起一个原型系统，然后在真实业务中不断完善各Agent能力和整体协调策略。\n\n常见误区与改进\n\n在开发多智能体营销系统的过程中，我们需要警惕一些常见的设计误区，并采取相应的优化措施：\n1.\t流程写死，缺乏弹性：有的开发者按既定流程顺序硬编码调用Agent，导致流程无法根据实际情况调整。例如，无论"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#15": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "跨Agent的权限联动。这样既保障安全，又方便在某个Agent出现问题时独立调试而不影响全局。\n3.\t忽视安全盲点：除了凭据，共享还有其它安全盲点。例如，未对Agent输出进行审核就直接发布，可能出现不当内容；又如在Prompt中插入未经清洗的用户输入，可能导致提示注入攻击。改进：增加验证与监控机制"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#16": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "工具集合，防止越权操作 。同时，开启日志和审计，对Agent的关键动作留痕，及时发现异常行为。\n4.\tPrompt设计不清，Agent职责混乱：如果Prompt未明确限定Agent角色，可能导致职责混淆，降低协作效率。例如创意Agent的提示不清晰，可能输出包含发布建议；分析Agent提示不清，可能"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#17": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "优，因为多智能体系统的行为可能比较复杂，只有持续观察才能发现潜在的新问题并及时修正。\n\n经验总结\n\n通过构建这个多智能体营销系统，我们验证了将复杂任务拆解给多个AI Agent协同完成的可行性和优势。在实战中有几点体会值得分享：\n* 清晰的Agent分工带来了模块化的好处——各模块可独立演进，整体系"
  },
  "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践#18": {
    "title": "构建多智能体营销系统：从角色划分到调度协同的实践",
    "url": "/content/posts/legacy/构建多智能体营销系统-从角色划分到调度协同的实践",
    "date": "2024-10-03",
    "text": "论是Prompt方案还是调度策略，都需要根据实际效果不断优化，使Agents协作越来越高效可靠。\n\n展望未来，随着大型模型能力的提升和多Agent架构的成熟，此类智能营销系统有望变得更加自主和高效。在实践中，我们将不断积累经验，优化每个Agent的能力边界和协同方式，让AI真正成为数字营销团队中可靠"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#0": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality\n\nThis article will provide a"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#1": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "and reliable. It addresses four key problems:\n\n1.  **Planning First, Clear Thinking (Clarity before Code)**: By generating a detailed \"development blu"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#2": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "tency and direction in subsequent development.\n\n2.  **Controlled Iteration, Agile Development (Controlled Agility)**: We break down grand objectives i"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#3": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "ther than discovering misalignment at the end.\n\n3.  **Built-in Quality, Step by Step (Built-in Quality)**: Developer participation is no longer post-h"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#4": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "roach fundamentally prevents \"black box code.\"\n\n4.  **Complementary Strengths, Synergistic Partnership**: We don't rely on any single model. ChatGPT e"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#5": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "tool's strengths in their respective domains.\n\nII. Workflow Deep Dive: Two Major Phases from Blueprint to Code\n\nThis workflow is clearly divided into "
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#6": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "reate Project Blueprint (The Blueprinting Phase)\n\nThis phase's goal isn't to write any code, but to produce a high-quality, structured project develop"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#7": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "\"Hello, I want to develop a personal blog system. I envision it as a static website based on Node.js and Next.js, supporting Markdown writing with aut"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#8": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "deas, engage in multi-round dialogue with ChatGPT. This process is like brainstorming with a real architect.\n    *   **Technology Stack Questions**: \""
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#9": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "lease help design a Markdown Frontmatter format.\"\n    *   **Project Structure Discussion**: \"Please design a reasonable directory structure for this p"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#10": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "s phase.\n\nBest Practices and Blueprint Template:\n\n*   **Role Assignment**: Having ChatGPT play specific roles (like \"senior architect\" or \"product man"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#11": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "lue of dialogue lies in iteration and correction.\n*   **Focus on \"What\" and \"How\"**: The blueprint should not only explain \"what to do (What)\" but als"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#12": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "─ posts/\n│       └── [slug].js # Post detail page\n├── posts/         # Markdown source files\n├── components/    # React components\n├── lib/           "
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#13": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "e blueprint in hand, we enter the execution phase. The key here is **strictly following the blueprint, doing only one step at a time**, with Claude Co"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#14": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "text.\n    > **Example Prompt (Starting Step 1)**:\n    > \"Hello, we will develop a blog system based on the following project blueprint. Please read th"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#15": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "tter` to parse metadata, sort by date, and return. Please provide complete code and explain how it works.\"\n\n2.  **Execute, Review, Confirm**: Claude C"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#16": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "g conventions standard? Are there potential bugs?\n    *   **Provide Feedback**: If modifications are needed, communicate directly with Claude Code. Fo"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#17": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "> \"Great, Step 1 is complete. The `lib/posts.js` code is as follows:\n    >\n    > \n    >\n    > Now, let's execute **[Step 2]** from the blueprint: Crea"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#18": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "e basic HTML tags, no styling needed for now.\"\n\n4.  **Handling Branches and Changes**: During development, you might have new ideas or discover the bl"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#19": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "h AI (could be Claude or switch back to ChatGPT).\n    *   **Update Blueprint**: Record changes back to your blueprint file and create a new branch ste"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#20": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "n with Traditional and Pure AI Development Modes\n\nAs shown above, the hybrid workflow doesn't simply replace human effort with AI, but elevates develo"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#21": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "firmly grasping project quality and direction.\n\nV. Practical Implementation & Prompting Templates\n\nTo make this workflow truly actionable, here are co"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#22": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "nced approach acknowledges potential challenges:\n\nPitfall 1: Over-Planning Paralysis\nThe blueprint phase can become too detailed.\n**Mitigation:** Keep"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#23": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "rint\" visible while prompting the \"executor\" AI.\n\nPitfall 3: Tool-Chain Fragility\nThe strengths of these models can change over time.\n**Mitigation:** "
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#24": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": ", high-quality software development in the AI era. It moves away from chaotic, unpredictable \"AI magic\" and introduces an engineered, structured colla"
  },
  "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a#25": {
    "title": "ChatGPT + Claude Code Hybrid Development Workflow: A New AI Programming Paradigm Balancing Planning, Agility, and Quality",
    "url": "/content/posts/legacy/chatgpt-claude-code-hybrid-development-workflow-a",
    "date": "2024-01-01",
    "text": "que or trick, but a project management philosophy. It requires developers to transform their role from simple coders to \"project commanders\" capable o"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#0": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "基于地理保护区与多因子排序的系统设计实践\n\n问题建模\n\n在开始设计方案之前，我们需要对问题进行形式化的建模和分析。首先，引入节点保护半径这一概念后，节点排序的问题可以看作是一个多因子决策问题。我们可以将影响排序的主要因素抽象如下：\n\n* 地理距离因子：用户与节点之间的地理距离，通常距离越近服务效率越"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#1": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "可能应享有更高优先级。我们可以为节点类别设定额外的权重或优先级参数，用于在计算综合得分时做出区分。\n* 用户历史偏好因子：如果用户有最近一次使用的节点，而且该节点本次仍在可用候选列表中，那么我们认为该节点对该用户有一定粘性或偏好。这样的节点可以得到一定的额外加分，鼓励为用户提供连续性体验。\n* 人工"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#2": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "eference}(node) + w_4 \\times f_{manual}(node) \n$$\n其中 $f_{distance}$ 可以是基于距离的得分函数，$f_{radius}$ 表示节点保护半径命中与否产生的分值，$f_{preference}$ 代表用户偏好带来的分值，$f_{manua"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#3": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "用户位置未落入任何节点的保护半径。此时排序主要依据距离等常规因子进行，同时考虑用户偏好和人工权重。\n* 场景四：用户偏好节点冲突 – 假设用户上一次使用的节点 A，本次用户位置落在节点 B 的保护范围内，而节点 A 也在可选列表中但未覆盖保护范围。这种情况下，需要平衡用户偏好与保护半径规则。常见的做"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#4": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "辑需要处理的各种情况，以及各因子可能的相对重要性。这为接下来的设计方案制定奠定了基础。\n\n设计方案\n针对上述问题模型，我们设计了分层次的解决方案。整体流程可以概括为“筛选候选节点 -> 计算多因子分值 -> 综合得分排序 -> 输出排序结果”，其中重点在于多因子分值的计算和合并策略。下面分步骤说明："
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#5": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "上次使用节点）、节点的人工干预分值等。这些数据可通过查询配置中心或数据库获得，并在计算前准备就绪。\n* 多因子打分计算： 针对每个候选节点，按照预定的规则计算其综合得分。我们采取可配置权重的线性加和模型，将各因子分值加权相加得到最终 score（如前文公式所示）。距离分可根据距离长短映射为一定区间的"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#6": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "于后续服务（例如展示给用户或调度执行）。整个过程保证了考虑多因素的同时，仍能给出明确的排序结果。\n\n需要强调的是，此设计方案非常注重灵活性和可配置性。各因子的加分值、权重以及具体的评分函数都没有被硬编码死，而是通过配置中心来管理。例如，运营可以调整某类别节点的优先级参数，或调整 radius_bon"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#7": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "之间的距离。为简化示例，我们使用直角坐标近似计算距离（实际生产环境可采用更精准的球面距离公式）：\n\n在这个示例中，我们定义了一个简单的欧几里得距离计算函数 calc_distance，并判断给定的用户和节点之间的距离是否小于节点的保护半径 protection_radius。实际运行时，我们会将所有"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#8": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "节点3：距离2500米，无保护范围命中、无偏好，但带有人工加权10分（可能运营希望稍微提升它）。\n\n按照设定的规则计算后，我们将节点按照score排序并输出每个节点的综合得分。从这个示例可以看到，不同因子的作用体现在最终得分上。例如，节点2虽然距离较远，但因为用户偏好和类别加成，得分反而超过了距离更"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#9": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "据处理上的复杂性，因此性能优化也是设计中的重要考虑点。以下是我们在实现和优化过程中采取的一些措施：\n* 空间索引与候选集削减：正如前文提到的，我们会先根据用户位置筛选出一定范围内的候选节点。这样做可以大幅减少需要详细评分的节点数量。例如，可利用空间索引（如基于经纬度网格或R树）快速查找距离用户坐标一"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#10": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "将距离计算和初步筛选下推到数据库层（利用数据库地理位置查询能力），或者采用本地的C语言扩展来加速。\n* 分阶段计算与剪枝：在多因子打分过程中，我们可以先按照某些主要因素进行预排序或剪枝。例如，如果保护半径是决定性的第一优先级因素，我们可以先将命中保护半径的节点挑选出来重点处理，其余节点暂且放在后面。"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#11": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "或定时刷新缓存的方式，将新数据及时加载。这样既保证了数据的新鲜度，又避免了频繁读取存储带来的延迟。\n* 评估与监控：性能优化离不开监控和评估。我们在上线后对节点排序接口的响应时间进行了监控，通过分析打分耗时来不断优化代码实现。例如，调整距离计算算法、优化数据结构访问等。在确认功能正确的前提下，我们甚"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#12": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "不同业务需求的支持能力，使节点排序结果可以兼顾距离、专属服务范围、用户偏好和运营调控等多个方面。\n\n整个设计遵循了清晰的层次：先筛选候选节点，再计算多因子得分，最后根据得分排序决策。这种流程既保证了结果的准确性，又方便我们在每个阶段进行针对性的优化和调整。同时，利用配置化的参数，我们实现了策略的灵活"
  },
  "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践#13": {
    "title": "基于地理保护区与多因子排序的系统设计实践",
    "url": "/content/posts/legacy/基于地理保护区与多因子排序的系统设计实践",
    "date": "2020-11-27",
    "text": "（如 GeoHash 或 GIS 引擎）来支撑高效查询，并通过水平扩展保证高并发请求下的稳定性。\n\n每一次需求的变化都是对系统弹性和架构能力的考验。这次关于节点保护半径和综合排序的实践，让我们深刻体会到提前设计好扩展点、保持策略可配置的重要性。在满足当前需求的同时，我们也为将来的功能拓展做好了准备。"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#0": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j\n\nBelow is a summary of the installation and configuration process based o"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#1": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "t Neo4j Desktop after installation is complete.\n2. Create a database instance and set password: Create a new local graph database in Neo4j Desktop (ve"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#2": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "l connect to the database through this URI later.\n3. Clone the Graphiti repository and configure the environment: Open terminal, clone the Graphiti so"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#3": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "I configurations according to actual conditions:\n\nWhere OPENAI_API_KEY is the key used by Graphiti to call the OpenAI interface for LLM inference and "
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#4": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "Install required tools (uv, uvicorn, claude-cli):\n* uv: Graphiti recommends using the uv tool developed by Astral to manage Python environments and de"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#5": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "ar to pip but can synchronize dependencies faster. If not using uv, you can also manually create a virtual environment and use pip install -r requirem"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#6": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "provides command-line tools to manage MCP plugins. Install the claude CLI tool (e.g., through pip install anthropic or other means, see Anthropic docu"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#7": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "en frontends like Claude and the Graphiti backend. There are two startup methods:\n* Method A: Start through Claude Code CLI (stdio mode): This method "
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#8": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "cutable path, Graphiti repository location, etc.). After execution, Claude Code will register an MCP plugin called \"graphiti-memory\", and Claude will "
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#9": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "er-Sent Events (SSE) interface. You can execute:\n\nThe above command will run Graphiti MCP Server in SSE mode locally (default listening on 0.0.0.0:800"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#10": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "n also use --scope project for specific projects). After completion, you can see the graphiti-memory plugin in the \"MCP Servers\" list in the Claude Co"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#11": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "ng the memory functionality.\n\nUsage Verification\n\nTo confirm whether Graphiti memory is working properly, you can directly check from the Neo4j side w"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#12": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "pher query: MATCH (n:Episodic) RETURN n LIMIT 25;. Graphiti stores each conversation or information fragment as a node with \"Episodic\" label, you can "
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#13": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "ended to troubleshoot from the following aspects:\n* Bolt connection issues: Confirm that Graphiti MCP Server can connect to Neo4j database. Check whet"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#14": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "figuration also needs to be adjusted accordingly.\n* OpenAI API Key status: When writing conversations, Graphiti will call OpenAI models to extract ent"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#15": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "terminal output logs when running Graphiti Server. If there are OpenAI interface errors or insufficient balance messages, you need to replace with a v"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#16": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "Graphiti MCP plugin is enabled in Claude frontend. In Claude Code, newly added MCP Servers may need to be enabled in the conversation interface (such "
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#17": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "t enabled, Claude will not actually call Graphiti. Also note that Claude does not automatically trigger calls to MCP functionality for resources and p"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#18": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "nswer.\n\nGraphiti Memory Functionality Categories\n\nAs an MCP Server, Graphiti provides three types of interface capabilities, corresponding to the thre"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#19": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "m internal knowledge graphs or external databases. These interfaces only read data without side effects, serving to let LLM access historical informat"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#20": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "evant content when needing to reference memory.\n2. Tools: Interfaces for executing operations that will change external environments or data. Such as "
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#21": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "graph operations, achieving online memory updates. Whenever users provide new information, Claude Agent can call Graphiti's tool methods (like add_epi"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#22": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "encapsulating commonly used multi-step operations. These Prompt templates can be viewed as Agent's \"skill scripts\" that are called when specific needs"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#23": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "requests to Graphiti with one click when needed.\n\nNote that in Claude Desktop's current implementation, Tools-type MCP interfaces (like Graphiti's wri"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#24": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "them by default unless users actively attach them. This point is particularly important in actual use, and coping strategies will be discussed in the "
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#25": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "encountered when using Graphiti long-term memory:\n* Debugging Graphiti writes: When you find that conversation content is not written to Neo4j, you ca"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#26": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "ption stacks are usually also printed in the logs. When debugging, you can try directly calling Graphiti's API (such as REST interface) to add test da"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#27": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "el output not conforming to expected JSON format.\n* Avoiding Schema errors: Graphiti requires that the LLM used supports structured output to ensure c"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#28": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "nction calling or strict JSON output capabilities. If using models that don't support structured output (especially smaller models), you may encounter"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#29": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "4j, and IndexAlreadyExists prompts can be ignored. When adjusting Graphiti's entity/relationship type definitions, try to maintain consistency with Ne"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#30": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "users or developers need to actively trigger them. There are several practical techniques: First, prompt Claude at the very beginning of conversations"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#31": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "Please search existing knowledge before answering.\" Second, skillfully use the **\"References\"** function provided by Claude interface: In Claude Deskt"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#32": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "answer\" and \"record new information immediately\". These rules can be used as Claude prompts, making the model develop habits of calling add_episode to"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#33": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "s can greatly improve Graphiti memory utilization. In summary, some human guidance is currently needed, and future versions of Claude may make AI auto"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#34": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "y, and an AI Agent with long-term memory is built. In real development, we should continuously optimize prompt strategies based on logs and conversati"
  },
  "/content/posts/legacy/building-agent-long-term-memory-system-with-claude#35": {
    "title": "Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j",
    "url": "/content/posts/legacy/building-agent-long-term-memory-system-with-claude",
    "date": "2025-07-23",
    "text": "erence and intelligence level for long-term tasks. In the future, if Claude plugin mechanisms are upgraded to automatically utilize Resource/Prompt, A"
  },
  "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo#0": {
    "title": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide",
    "url": "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo",
    "date": "2024-01-01",
    "text": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide\n\n_*Benchmark examples are averaged from public Q2 2025 tests and m"
  },
  "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo#1": {
    "title": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide",
    "url": "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo",
    "date": "2024-01-01",
    "text": "pro` model reserved for Enterprise and API users.\n*   **Reasoning & Math:** GPT-4o maintains a lead in math-heavy benchmarks like MATH and GSM-8K. How"
  },
  "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo#2": {
    "title": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide",
    "url": "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo",
    "date": "2024-01-01",
    "text": "slightly slower during long-form generation.\n\n2.2. The Efficiency of the o-Series\nA key advantage for OpenAI is the `o3-mini` and `o3-pro` models, des"
  },
  "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo#3": {
    "title": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide",
    "url": "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo",
    "date": "2024-01-01",
    "text": "Eval ≈67%) at less than 10% of the cost of GPT-4o. Anthropic lacks a similarly granular offering, with only its Haiku model serving as a lightweight a"
  },
  "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo#4": {
    "title": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide",
    "url": "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo",
    "date": "2024-01-01",
    "text": "s a clear winner. Claude can only analyze images.\n*   **Writing Style:** Most users across English and Chinese forums report that Claude's prose feels"
  },
  "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo#5": {
    "title": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide",
    "url": "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo",
    "date": "2024-01-01",
    "text": "output.\n\n4. Deep Thinking and Systemic Reasoning\n\nA model's value in strategic planning, scientific research, and decision support is often determined"
  },
  "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo#6": {
    "title": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide",
    "url": "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo",
    "date": "2024-01-01",
    "text": "uction.*\n\n5. Subscription Tiers and Usage Limits\n\n**The Cooldown Pain Point:** Community feedback is filled with complaints that even the Claude Max 2"
  },
  "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo#7": {
    "title": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide",
    "url": "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo",
    "date": "2024-01-01",
    "text": "ommendations\n\n6.1. Choose Claude (Pro / Max) for:\n*   **High-Accuracy Code Review/Refactoring:** Its long context and top HumanEval score are ideal.\n*"
  },
  "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo#8": {
    "title": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide",
    "url": "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo",
    "date": "2024-01-01",
    "text": "ming:** For marketing, design, or research teams.\n*   **Flexible Model Tiers:** To balance speed, cost, and performance from `o3-mini` up to `o1-pro`."
  },
  "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo#9": {
    "title": "2025 Claude Max / Opus 4 vs. ChatGPT Plus / o-Series: The Ultimate Comparison Guide",
    "url": "/content/posts/legacy/claude-max-vs-chatgpt-pro-2025-the-ultimate-showdo",
    "date": "2024-01-01",
    "text": "low hallucination rate, and innovative automation. However, it is hampered by session cooldowns and subscription quotas, making it unfriendly for high"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#0": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs\n\n**v1.0 Limitations**:\n- Traditional task scheduling mech"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#1": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "e memory system: Individual death, eternal wisdom\n- Ecosystem management: Population balance, environmental adaptation, natural selection\n- Knowledge "
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#2": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "d knowledge and experience after Agent \"death\"?\n2. **Knowledge Inheritance**: How to let newborn Agents inherit predecessors' wisdom instead of starti"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#3": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "relevant knowledge in vast historical memories?\n\nThe core of these challenges is: **We need a more intelligent and flexible knowledge storage and retr"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#4": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "lectiveMemory: Enhanced Collective Memory System\n\nThis is the system's core, inheriting from the original CollectiveMemory class but adding powerful g"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#5": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "s and knowledge inheritance chains between Agents\n- **Intelligent Clustering**: Automatically form knowledge clusters based on skill and experience ta"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#6": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "ance Mechanism: Wisdom Flows Through Generations\n\nWhen a new Agent is born, the system intelligently selects the most relevant knowledge from collecti"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#7": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "tem-level best practices and successful patterns\n\nEcosystem-Level Integration\n\nElegant System Upgrade Mechanism\n\nWe designed a backward-compatible upg"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#8": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "implemented a comprehensive fallback mechanism:\n\nThis ensures the system runs stably in any environment while providing optimal enhanced features when"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#9": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "earning → Creation → Inheritance → Perpetuation`\n\nThis is not just a change in technical architecture, but a fundamental rethinking of AI essence. Our"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#10": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "ge**: Track knowledge sources and evolution paths\n- **Wisdom evolves**: Collective memory continuously optimizes over time\n\n2. Breakthrough Applicatio"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#11": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "retrieval\n\n**Graph Applications in Nighthawks**:\n- Dynamic memory network construction\n- Automated knowledge acquisition and updates\n- Intelligent ass"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#12": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "itance efficiency\n- System-wide \"wisdom density\"\n\n🔬 Deep Technical Implementation Analysis\n\nMCP (Model Context Protocol) Integration Strategy\n\nTo com"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#13": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "Network issues don't cause functionality failure\n- **Statistical Monitoring**: Detailed connection status and performance metrics\n\nGraph-based Modelin"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#14": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "nt trends\n\nProgressive API Interface Enhancement\n\nWe designed specialized API endpoints for Graphiti functionality while maintaining compatibility wit"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#15": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "**: Return detailed execution status information\n\n📊 Performance Results and Validation\n\nTest Coverage\n\nWe created a comprehensive test suite to valid"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#16": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "meeting expectations\n\nActual Runtime Performance\n\nThrough functional demonstration scripts, we validated the system's actual performance:\n\n🔮 Future D"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#17": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "apabilities\n\nMedium-term Development (1-2 months)\n- **Visualization Interface**: Develop real-time knowledge graph visualization tools\n- **Advanced An"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#18": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "ndustry standards for AI system memory management\n- **Cognitive Science Integration**: Leverage cognitive science research to optimize memory mechanis"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#19": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "AI system design:\n\nFrom Functionalism to Vitalism\nTraditional AI design follows **functionalism** paradigm: define inputs and outputs, optimize proces"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#20": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "m connected through knowledge graphs is unlimited. We create not smarter individuals, but wiser ecosystems.\n\nFrom Momentary Computation to Eternal Mem"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#21": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "nclusion: Toward True Digital Life\n\nNighthawks v2.0's Graphiti integration is not just the completion of a technical project, but a major breakthrough"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#22": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "ation of knowledge graphs to AI memory management\n- **Architectural Breakthrough**: Designed sustainably evolving AI ecosystems\n- **Philosophical Expl"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#23": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "rstone for building truly \"living\" AI ecosystems\n\nIn today's rapidly developing artificial intelligence landscape, we need not just stronger computing"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#24": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": ", we can create AI systems with true \"vitality.\"\n\n**Individuals die, but life and wisdom continue forever** — This is no longer just a beautiful visio"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#25": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "rces\n\n- **Project Repository**: Nighthawks GitHub\n- **Technical Documentation**: Complete Technical Specifications\n- **Integration Summary**: Graphiti"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en#26": {
    "title": "Beyond Death: How Nighthawks v2.0 Achieves Digital Life Immortality Through Knowledge Graphs",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality-en",
    "date": "2024-01-01",
    "text": "ife system's Graphiti knowledge graph integration. The project embodies deep thinking and innovative practice in AI system design, hoping to contribut"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#0": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "使用 Spring AI 构建 RAG 搜索服务设计\n\n系统整体架构采用分层模块化设计，核心包括以下部分：\n* 文档向量存储（Vector Store）：使用 Qdrant 作为向量数据库存储文档的语义向量表示，用于语义相似度检索。Spring AI 提供了抽象的 VectorStore 接口来封装"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#1": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "于关键词的布尔/全文检索。Elasticsearch 提供倒排索引能够有效匹配用户查询中的关键词。\n* 混合检索器（Hybrid Retriever）：RAG服务的检索层组件，负责将关键词检索与向量语义检索结果结合。查询时同时对ES执行关键词匹配检索，对Qdrant执行向量相似度检索，获取两方面的文"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#2": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "ConcatenationDocumentJoiner 将多数据源的结果集合并为一个文档列表 。\n* RAG服务层：封装整个“检索-生成”流程的核心服务（可称为 RagService）。它负责接收用户查询，调用Hybrid Retriever检索相关文档，将检索到的文档作为上下文提交给LLM，并返回"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#3": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "借助Spring AI的模块化设计，可以方便地更换底层使用的LLM或向量库，而无需大改业务代码 。\n* LLM推理层：大语言模型用于根据用户查询和检索到的文档上下文生成回答。通过Spring AI的ChatModel与ChatClient抽象，我们可以无缝切换不同的模型和提供商。例如，当使用Open"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#4": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "LM-L6-v2）以生成文本嵌入 。此方式保证数据不出本地，响应速度快且无需调用外部API。\n\t2. OpenAI Embedding API：利用OpenAI的embedding接口（如text-embedding-ada-002）获取文本的向量表示，需要网络调用和API密钥。Spring AI "
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#5": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "文档作为提示上下文，交由LLM生成答案并返回给用户。)\n\n核心模块设计\n\n向量存储与混合检索模块\n\nQdrant 向量存储配置：系统使用Qdrant来持久化文档向量及元数据。通过引入依赖 spring-ai-qdrant-store，Spring AI能够自动配置Qdrant相关的Bean  。我们"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#6": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "入模型)  。确保Qdrant实例已启动并可访问，比如通过Docker启动 Qdrant 容器。\n\nElasticsearch 全文检索配置：Elasticsearch用于存储文档文本索引，实现关键词匹配检索。可采用Spring Data Elasticsearch或Rest API进行集成。配置上"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#7": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "如定义DocumentEntity(id, content, metadata)并建立全文索引。\n\n文档索引结构：为了方便混合检索结果的合并，我们为每个文档片段分配唯一ID，并在Qdrant和Elasticsearch中共享该ID作为主键。每份文档在入库时通常会被拆分成若干片段 (chunks)，每"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#8": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "cumentRetriever。其retrieve(Query query)方法内部执行以下步骤：\n* 使用ES执行关键词查询：如构造一个match或bool查询，匹配content字段包含查询文本，取Top K结果。可借助ES的REST客户端或Repository方法实现，得到一组Document"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#9": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "equest 可指定相似度阈值和topK等参数  。例如：\n\n这将返回与查询最相似的5个文档片段。\n* 合并结果：将关键词结果与向量结果合并。可以用文档ID去重，避免同一片段重复。简单策略是直接合并列表；如需更精细的融合，可根据ES相关度分值和向量相似度分值对结果重新排序或加权。由于不同检索的分数不"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#10": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "索可找到语义相似的内容，而关键词检索可保证若有精确匹配的术语不会被遗漏。\n\nLLM 推理与切换模块\nChatClient与ChatModel抽象：Spring AI 提供了 ChatModel 接口表示具体的大语言模型（如OpenAI ChatGPT、Anthropic Claude、本地Llama"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#11": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "用配置中提供OpenAI的API密钥和所选模型名称。例如在application.yml中配置:\n\n这将启用Spring AI对OpenAI Chat API的自动配置。注入的ChatClient将默认使用OpenAI指定的模型。通过ChatClient的fluent API，可以很方便地发送对话消"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#12": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "a实例 。配置上，可在application.yml中指定Ollama服务地址及所用模型，例如:\n\n假设已通过“Ollama pull”命令下载了名称为“llama2”的模型，Ollama将以该模型提供推理。应用启动时，会自动创建连接到Ollama的API客户端 (OllamaApi) 和对应的 C"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#13": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "l的支持是开箱即用的，开发者只需更改配置即可无缝切换LLM提供方，大大减少切换带来的代码改动 。\n\n文本嵌入生成模块\n1. HuggingFace 本地嵌入：为了确保数据安全和降低依赖，本方案支持使用本地Embedding模型。利用Spring AI的Transformer ONNX支持，我们可以在"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#14": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "准备好（可通过Spring AI自动下载缓存）。然后配置EmbeddingModel Bean：\n\n上述 TransformersEmbeddingModel 会加载本地ONNX模型，在调用embed()时对输入文本列表输出对应的向量表示  。作为Spring Bean时，Spring AI会自动调"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#15": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "g模型，如ollama pull hf.co/intfloat/e5-small-v2），然后：\n\n此方式下，所有文本向量将由Ollama本地服务生成，效果等同于直接使用HuggingFace模型。 \n\n2. OpenAI Embedding API：如需借助OpenAI的预训练模型快速获取嵌入，可"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#16": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "成本。\n\n3. 嵌入模式切换：和LLM类似，可通过配置切换嵌入模型来源。比如配置embedding.mode为local或openai。当为local时，启用TransformersEmbeddingModel或OllamaEmbeddingModel；为openai时，则使用OpenAiEmbed"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#17": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "ngModel转为向量并存入Qdrant 。\n\n数据流程说明\n文档索引流程 (ETL离线入库)\n1.\t文档获取与预处理：通过管理后台或批处理任务，获取需要纳入知识库的原始文档。文档格式可以是纯文本、PDF、Markdown等。使用Spring AI的文档读取器将文档转换为文本内容，并按段落或固定长度"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#18": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "嵌入模型将每个块映射为高维向量表示，捕捉语义信息。\n3.\t向量存储入库：调用vectorStore.add(documents)方法，将文档片段批量插入Qdrant向量数据库 。Spring AI 的 VectorStore 接口对底层数据库执行插入操作，并自动处理向量数据和元信息存储。例如对于Qd"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#19": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "的维度和索引参数）  。插入成功后，文档的语义表示就持久化在Qdrant中了，可用于相似检索。\n4.\t全文索引入库：将文档片段索引到Elasticsearch。对于每个Document对象，从中提取必要字段（如id、content、metadata），调用ES的索引API存储。若使用Spring D"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#20": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "及元数据，Elasticsearch持有片段的可检索文本。后续查询即可利用这两种存储提供的能力。\n\n注意： 文档入库流程可以离线批处理，也可以通过提供API让用户动态上传文档。在本设计中，可以实现一个/documents/load接口（或使用Stackademic博文中的/load概念 ），接受文件"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#21": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "务层。\n2.\t混合检索：RAG服务调用 HybridRetriever 来从知识库中检索相关信息：\n  * ES关键词检索：对Elasticsearch执行查询，可使用match或multi_match在content字段搜索用户问题中的关键词。如果有匹配，返回相关度最高的前N个片段，例如N=5。\n"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#22": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "用户问题和检索到的文档片段组装成提示内容传给LLM。通常采用一个预定义的Prompt模板，例如：\n\n其中{{{context}}}占位符由检索到的多个文档片段文本拼接填充，{{{question}}}为用户原始问题。这样生成的完整提示提供了问题所需的参考信息。此步骤可以使用Spring AI的Pro"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#23": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "。\n\n4. LLM生成回答：调用LLM模型生成答案。通过前述配置好的ChatClient来执行：\n\nChatClient会将我们提供的完整提示发送给底层ChatModel（OpenAI或Ollama）。模型接收到含有参考内容的提问后，基于提供的上下文进行作答，从而减小幻觉和出错的概率  。生成的答案"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#24": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "给ChatClient，以实现上下文记忆。但基本的RAG问答场景可不考虑对话历史，每次独立进行。\n\n整个查询流程在用户看来只是提供问题、获得答案，但背后经过了关键词和语义双通道检索，再由大模型综合分析文档给出结果，从而实现“以知识库为基础的问答”。这种RAG技术有效缓解了LLM上下文长度限制、知识截"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#25": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "ter (spring-ai-qdrant-store-spring-boot-starter) \n* Spring AI ONNX Embedding (如使用本地Transformer模型，可选 spring-ai-embeddings-transformer-onnx)\n* Spring Da"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#26": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "ChatModel配置。\n\n关键Bean：汇总本设计涉及的重要Spring Bean及其配置方式：\n* EmbeddingModel Bean：如上所述，可以是OpenAiEmbeddingModel或TransformersEmbeddingModel，负责文本嵌入。  \n* QdrantClie"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#27": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "Builder。在使用多个ChatModel时，也可以注入多个命名的ChatClient。例如：\n\n上述伪代码表明根据配置选择不同的ChatModel创建ChatClient。实际上若使用Spring Boot Starter和配置文件，大部分情况直接@Autowired ChatClient即可（"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#28": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "viceImpl 负责按照在线检索问答流程的步骤完成工作：\n\n上述代码中：\n* retriever.retrieve返回Document列表，每个Document包含content文本等信息。\n* 将片段内容简单拼接为上下文（真实应用可加入分隔符并注明来源）。\n* 用ChatClient.promp"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#29": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "通过上述Controller，前端或用户可以通过HTTP请求与RAG服务交互，实现动态问答。\n\nDocker Compose 环境部署方案\n\n为方便开发和部署，提供Docker Compose配置同时启动所需的外部服务（Qdrant、Elasticsearch、Ollama）和本Spring Boo"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#30": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "TP API（若使用）和6334端口供gRPC客户端。挂载卷qdrant_data持久化向量数据。\n* Ollama：使用Ollama官方Docker镜像。映射11434端口用于与Spring应用通信（Ollama提供REST API），挂载卷ollama_data保存已下载的模型数据，以避免容器重"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#31": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "PI_KEY等。depends_on确保其他服务先行启动。端口8080用于对外提供HTTP接口。\n\n网络配置：Compose默认会将这些服务置于同一网络下，容器名称就是主机名。因此应用在连接Qdrant和ES时，可以使用qdrant:6334、elasticsearch:9200作为地址。Sprin"
  },
  "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计#32": {
    "title": "使用 Spring AI 构建 RAG 搜索服务设计",
    "url": "/content/posts/legacy/1-使用-spring-ai-构建-rag-搜索服务设计",
    "date": "2025-04-29",
    "text": "ocker Compose，一键部署整个RAG系统的依赖，方便在本地或服务器上运行测试。\n\n结论\n\n本设计文档详细描述了一个基于Java Spring生态的RAG搜索服务方案。通过Spring AI框架提供的抽象和集成能力，我们实现了Retriever-VectorStore-RAG Service"
  },
  "/content/posts/legacy/01-pandas-basics#0": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "Pandas Basics: Core Objects & Common Operations\n\n上面代码展示了三种创建 Series 的方式：直接由列表创建（可以指定索引，也可以不指定用默认索引0,1,2,…），以及由字典创建。一般来说，通过列表创建可以灵活指定索引顺序，而通过字典创建会使用字典的"
  },
  "/content/posts/legacy/01-pandas-basics#1": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "引（下标）：按照元素的位置顺序，从0开始计数。例如 s[0] 取第一个元素，s[1:3] 取切片。\n- 标签索引（index）：按照我们定义的索引值来取。例如索引是字符串 ‘zs’，用 s['zs'] 来取对应的值。\n\n下面用具体例子说明 Series 的两种索引方法：\n\n上述代码中，s[3] 通过"
  },
  "/content/posts/legacy/01-pandas-basics#2": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "的下标索引只有正向的，没有反向的。\n\n我们还可以查看 Series 的一些属性来了解数据结构：\n\nindex 属性返回一个 Index 对象，包含 Series 的索引列表；values 则返回一个包含所有值的 NumPy 数组。在这个例子中，值全是整数，所以 dtype 是 int64。如果数据包"
  },
  "/content/posts/legacy/01-pandas-basics#3": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "作由多个共享同一个索引的 Series 组成的字典，每一列是一个 Series，列名是字典的键。\n\n举个例子，一个 DataFrame 可以用来表示多个人的若干属性，例如姓名、年龄、性别，每一列是一种属性，每一行代表一个人。我们可以使用多种方式来构造 DataFrame，常见的方法包括：由字典、由列"
  },
  "/content/posts/legacy/01-pandas-basics#4": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "Gender，并且让不同列来自不同长度的 Series，以演示 Pandas 会如何对齐数据。\n\n在这个 df2 DataFrame 中，我们指定了索引为 'a', 'b', 'c', 'd'。Name 列有这四个索引的值，但 Age 列缺少 'd'的值，Gender 列缺少 'b'的值。Panda"
  },
  "/content/posts/legacy/01-pandas-basics#5": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "aN 被视作浮点类型特殊值。例如 Age 列本来是整数，一旦出现 NaN，就变成了 float。\n\n如果我们不想让某些值缺失，可以在创建 DataFrame 时提供完整的数据，对齐索引。或者创建后再手动填充缺失值。但这些属于后续处理范畴。\n\nDataFrame 的属性和基本操作\n\n类似于 Serie"
  },
  "/content/posts/legacy/01-pandas-basics#6": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "前 n 行数据（默认 n=5）。\n- `df.tail(n)`：查看最后 n 行数据。\n- `df.describe()`：对数值列进行统计汇总（计数、均值、标准差、最小值、四分位数等）。\n- `df.T`：获取转置的 DataFrame（行列互换）。\n\n举例来说，我们可以查看 df2 的一些基本信"
  },
  "/content/posts/legacy/01-pandas-basics#7": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "e 为中心进行讲解。在以下示例中，我们将继续使用刚才创建的 df2 来演示。\n\n列操作 CRUD\n\n通常我们需要对 DataFrame 的列进行各种操作，例如读取某几列数据、添加新列、修改已有列或者删除列。DataFrame 在列操作上非常类似于 Python 的字典：把 DataFrame 当做一"
  },
  "/content/posts/legacy/01-pandas-basics#8": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "会被解释为行切片（这是为了保持语义简单一致，方括号直接索引默认为列，切片符号默认为行切片，这点细节稍微有点反直觉）。\n\n我们来看具体例子：\n\n输出（省略部分）将展示 name_col 是一个 Series，内容就是每个索引对应的 Name；而 subset 是一个 DataFrame，包含两列 Na"
  },
  "/content/posts/legacy/01-pandas-basics#9": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "。\n\n> **注意**： 如果列名中包含空格，比如 \"Total Sales\" 这种，不能用 df.Total Sales（会语法错误或解析错误），此时必须用 df['Total Sales'] 来访问。同样地，列名包含点号、减号等特殊字符，或列名叫max、count等与DataFrame方法重名，"
  },
  "/content/posts/legacy/01-pandas-basics#10": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "一个列表或 ndarray：长度需要跟 DataFrame 的行数相等，数据会按顺序填充这一列。\n- 一个 Pandas 的 Series：如果 Series 的索引能对齐 DataFrame 的索引，那么会根据索引匹配填充，索引没有对应上的位置将出现 NaN。\n\n也可以一次性添加多列。Pandas"
  },
  "/content/posts/legacy/01-pandas-basics#11": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "解释成连续的属性访问而出错），只能用 df['P.E.']。这再次说明了列名命名的规范性重要性。\n\n改（修改列）： 修改列的值实际上和添加列是一样的操作——用新的值赋值给已有的列名。如果该列存在，就会被新值覆盖；如果不存在，就会新建列。因此在语法上没有专门的“改列”方法，直接赋值即可。\n\n例如，我们"
  },
  "/content/posts/legacy/01-pandas-basics#12": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "ies。\n- 使用 `df.drop(columns=[...])` 或 `df.drop([...], axis=1)`，可以一次删除一列或多列。drop 默认返回一个新的 DataFrame，除非指定 inplace=True 原地删除。\n\n下面依次演示用上述方法删除我们不需要的列：\n\n可以看到"
  },
  "/content/posts/legacy/01-pandas-basics#13": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": ") 赋值回去，因为 drop 默认返回删除指定列后的新 DataFrame。\n\n行操作 CRUD\n\n有时候我们需要对表格的行进行操作，例如按行查看数据、添加或删除某些行等。行的操作在 Pandas 中主要通过索引（index）来定位，分为按标签索引（index label）和按整数位置索引两大方式。"
  },
  "/content/posts/legacy/01-pandas-basics#14": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "用它们我们可以非常灵活地按行或按行列组合选取数据。\n\nloc 用法示例：\n\niloc 用法示例：\n\nloc 和 iloc 都可以接受单个索引、切片、列表等形式来选取多行/多列，非常灵活。需要注意几点：\n\n- 用 loc 做标签切片时，区间两端都是闭区间，也就是包含结束标签。例如上例中 `df.loc"
  },
  "/content/posts/legacy/01-pandas-basics#15": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "增（添加行）： DataFrame 添加行相对没有添加列那么直接。以往 Pandas 有 df.append() 方法可以直接添加一行新的数据，但自 Pandas 1.4 起该方法已被废弃，官方建议使用 pd.concat 来完成这一功能。\n\n添加新行的思路是：先构造一个与原 DataFrame 列"
  },
  "/content/posts/legacy/01-pandas-basics#16": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "可能与原有索引冲突导致两个索引相同。这通常不是我们想要的，所以指定一个不会重复的新索引比较安全。\n\n改（修改行）： 修改行通常可以通过 loc 或 iloc 来定位整行然后赋值。例如，我们把刚才添加的 ‘e’ 行数据的 Name 和 Age 修改一下：\n\n我们成功地把索引 e 那行的数据更新为 Na"
  },
  "/content/posts/legacy/01-pandas-basics#17": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "索引标签列表。与删除列类似，drop 默认返回新对象，除非设置 inplace=True。示例：\n\n索引 b 和 d 的行被删除了。可以看到现在 DataFrame 只剩下 a, c, e 三行数据。如果索引是默认的整数且希望按位置删除第几行，也可以直接传索引值（因为默认索引标签就是数字）。例如 d"
  },
  "/content/posts/legacy/01-pandas-basics#18": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "效地读取CSV，以及一些常用参数和技巧。同样，写回CSV也非常简单。\n\n读取 CSV： 使用 pd.read_csv 函数即可读取CSV文件，基本用法是传入文件路径，Pandas 会自动将其解析为 DataFrame。示例：\n\n如果CSV文件包含表头（第一行是列名），pd.read_csv 会自动将"
  },
  "/content/posts/legacy/01-pandas-basics#19": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "置为行索引。例如 index_col='Date' 会将”Date”那列作为索引而不是普通数据列。\n- usecols：可以传入一个列名列表，表示只读取这些列，忽略其他列。对于很大的文件，读取必要的列可以明显加快速度、节省内存。\n- dtype：可以指定列的数据类型，比如将某列强制读成字符串 dty"
  },
  "/content/posts/legacy/01-pandas-basics#20": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "(high)、最低价(low)、收盘价(close)这几列。文件用逗号分隔。读取代码可以这么写：\n\n在这个例子中，我们通过 names 提供了8个列名（文件每行有8个字段，其中第三个字段我们命名为_表示我们不关心），然后用 usecols 选择了我们想要的5列数据（date 和 OHLC 四列），并"
  },
  "/content/posts/legacy/01-pandas-basics#21": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "到上百万行乃至更大，内存和耗时就需要考虑。这种情况下可以使用分块读取：pd.read_csv(..., chunksize=10000) 会返回一个可迭代的 TextFileReader，每次读取10000行，我们可以遍历每个chunk逐步处理。这样可以避免一次性占用太多内存。另一个方法是使用 dt"
  },
  "/content/posts/legacy/01-pandas-basics#22": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "alse 关闭。to_csv 也支持 sep, encoding 等参数，自行根据需要设置即可。\n\n除了 CSV 之外，Pandas 也支持读取/写入多种常见格式：\n\n- Excel：使用 pd.read_excel('file.xlsx') 读取，DataFrame.to_excel('out.x"
  },
  "/content/posts/legacy/01-pandas-basics#23": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/legacy/01-pandas-basics",
    "date": "2023-04-23",
    "text": "DataFrame，to_sql 可以写入数据库表。（这需要SQLAlchemy等支持，这里略过）\n- 以及其它格式例如 Parquet (read_parquet)、HTML表(read_html)、Stata (read_stata) 等等。\n\n简单来说，Pandas 提供了一套统一的高层接口来"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#0": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "项目管理基础知识学习笔记L4\n\nWBS 中包含两种层次的任务：摘要任务和工作包 。摘要任务是高层级的任务项，用来概括项目的主要组成部分。例如，如果我在规划一次大型活动，摘要任务可能包括“场地布置”“餐饮安排”“节目策划”等，每个摘要任务下面还可以进一步细分。摘要任务可以有多级层次，小项目可能两三层就"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#1": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "正如课程所言，“将项目分解为可管理的部分，有助于有效地计划和管理项目工作” 。\n\n如何定义工作包\n\n有了 WBS，我了解到光有任务名称还不够，团队成员还需要清楚每个任务具体该做什么。这就涉及定义工作包的内容。为确保大家理解一致，需要为每个工作包编写工作包文档，详细描述该任务的工作内容 。工作包文档就"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#2": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "此外，如果任务细节在其他文件已有记录（比如技术规范、流程指南），工作包文档里可以引用这些资料 。\n\n工作包文档不仅描述“要做什么”，还应明确“做到什么标准才算完成” 。课程建议在文档中注明任务的可交付成果及验收标准，比如“完成后服务器运行正常，通过所有测试用例”之类 。这样团队才能判断任务是否真正完"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#3": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "规划时，为重要任务都准备这样一份“任务说明书”，避免因为理解不一而走弯路。\n\n如何预估时间与成本\n\n时间和成本的预估一直是项目规划中让我感到棘手的部分。这节课程强调了准确预估对项目成败的重要性。如果估得过低，项目可能因为看似便宜而被错误地批准启动，却无法实现预期结果；而估得过高，本来可行的项目可能被"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#4": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "透彻 。\n\n那么如何进行时间和成本的估算呢？课程中介绍了多种方法，简直像工具箱一样让我大开眼界：\n\n- 类比估算：回顾以往类似项目的数据来估算 。历史经验是宝贵财富，比如之前做过类似产品开发，用那个项目的耗时/费用作为参考基础进行调整。\n- 专家判断：如果项目涉及我们不熟悉的新领域，那就请教有经验的"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#5": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "定性高的任务特别有用，让我们同时考虑“万一一切顺利”或“万一状况百出”的情形，得出相对稳妥的估计。\n- 德尔菲法 (Delphi)：依赖“群众的智慧”来估算 。具体做法是请多位专家各自独立给出估计，然后匿名分享所有人的结果，接着让专家们参考彼此的数据再估一次，如此反复几轮，最后取平均值 。这种群体决"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#6": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "最后把所有任务的数字加总，得到总体估算 。前者快但粗，后者细但慢，我觉得可以视项目情况结合运用。\n\n在估算过程中，课程还提醒了一些实用技巧：一是对大型复杂项目，要记得额外考虑沟通、协调、差旅和管理的时间成本——这些隐形工作有时不少，但容易被忽略 ；二是提防人为“安全余量”的叠加——有人可能为了保险在"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#7": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "力，也包括必要的设备、材料等。这里主要说人力资源的规划。我了解到资源计划的几个关键组成部分：\n\n1. 明确角色与职责：使用责任矩阵（RACI 矩阵）来分清谁负责干什么 。RACI 代表四种角色——R：Responsible（负责人），具体执行任务的人或小组 ；A：Accountable（当责者），对"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#8": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "；要是涉及外包或合作伙伴，也要在矩阵中注明他们的职责边界 。清晰的责任划分能避免以后出现扯皮或没人管的情况。\n\n2. 项目组织结构图：这是一个项目团队的组织架构示意，画出谁向谁汇报 。尤其在大型项目中，团队成员来自不同部门，给他们梳理出清晰的汇报线路很重要——万一我要上报问题或请求支援时，我得知道找"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#9": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "头，要获取准确的人员费用，需要包括工资加福利的全面成本，可以咨询财务或 HR 部门拿数据 。\n\n4. 人员配备计划：有了上面的需求和成本估算，接下来就是制定招人用人计划。包括从哪里获取资源（是内部调配现有人手，还是需要招聘、外包？） ；何时需要到位（例如某些专家只在项目后期才需要，就不用一开始就进场"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#10": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "人员安排表。毕竟“一个巴掌拍不响”，项目成功离不开每个人都各司其职、协同配合。\n\n创建项目进度表\n\n有了任务清单（WBS）、估算和资源计划，我开始着手制定项目进度表。进度表就是把任务在时间维度上排排队、排出先后顺序和持续时间。课程让我明白，WBS 告诉我们需要做什么，但还没告诉我们何时去做、需要多久"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#11": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "外也可能有“开始-开始”“完成-完成”等关系，以及里程碑等，但课上说这些细节后面章节会深入讲。我现在的体会是，明确依赖关系很关键，它决定了项目的关键路径，也就是影响工期的关键环节。\n\n第二步：估算每个任务的持续时间。 这一部分其实前面已经做了——在估算时间时我们得到了每个工作包的大致工期。现在我要把"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#12": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "就是考虑资源工作负荷来调整计划——别让一个人同一时间做三件事，否则甘特图看着很好看，实际却延误。\n\n第四步：考虑其他约束并完善计划。 现实中还有其他因素影响进度，比如硬性截止日期（某任务必须在某日前完成），或者资源可用性（关键人员下个月才入职，那之前相关任务只能延后） 。我把这些限制条件也标注在计划"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#13": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "来微调 。这部分属于进度优化技巧，课后还有更详细的内容。我意识到进度表往往需要多次迭代才能定稿。\n\n最终，项目进度表是项目管理中最重要的输出之一。它告诉我们整个项目从开始到结束会持续多久，每个任务什么时候开始、什么时候完成，以及团队成员何时需要到岗 。当我的进度表定下来并获得批准后，它还将成为进度基"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#14": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "特图”之前就想清楚了逻辑关系和资源分配，相信以后制订出来的进度表会更加切实可行。\n\n制定项目预算\n\n说完进度，再来说说项目预算。老话说得好，“兵马未动，粮草先行”，钱对于大多数项目都是命脉之一。无论项目的目标是赚钱、节省成本，还是不超出有限的经费，“预算”都是必须紧盯的要素 。事实上，范围、进度、成"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#15": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "。\n\n为了估算项目总成本，我需要把与项目工作相关的所有费用都计算进去 。这里面主要包括几个方面：\n\n- 人力成本：也就是项目团队成员的人工费用。正如前面资源计划里提到的，这通常占大头。要注意，员工的成本不光是薪水，还应包括福利、奖金、保险等“全包成本” 。如果是外聘供应商或承包商，他们的合同费用也直"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#16": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "用等 。课程特别提醒我们别忘了这些“隐形成本” ——有时项目预算超支就是因为最初漏算了某些杂费。\n\n在项目早期，其实我们往往只能估算 WBS 顶层几块的费用，得到一个粗略总预算 。随着项目深入，再逐步细化各项成本估算，使预算更精确 。我发现这和时间估算是类似的迭代过程。\n\n现金流也是预算规划中一个容"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#17": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "。我以后在做预算时，会在表格上增加一列“预计发生时间”，以防止因为预算拨付节奏问题影响项目进展。\n\n当我算出项目总成本后，需要和项目的资金上限作比较。很多时候高层已经为项目预拨了一笔款，如果我的预估超出了拨款，就得想办法缩减项目成本，以免老板不批准 。课程给了几招开源节流的思路： 一是削减不重要的支"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#18": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "不多也要150万，于是项目看起来可行 。如果当时算出来要200万，那项目经理就得动脑筋做减法了。\n\n总之，项目预算是我们在执行过程中努力要达成的成本控制目标 。我学到，为了让预算靠谱，需要前期全面细致地估算，并争取留出应急储备金，以从容应对未知开销 。今后做预算，我也会尽量拉上财务人员一起审视，确保"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#19": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "缪。风险管理计划的目的，就是保证当风险真的发生时，我们已经想好怎么应对，能够冷静而聪明地决策 。\n\n第一步：风险识别。 我学到要和团队一起来头脑风暴找出项目可能遇到的风险 。所谓风险，包括对项目有负面影响的威胁，也包括有正面影响的机会（不过课程重点放在威胁）。我们已经知道的风险被称作“已知的未知”，"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#20": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "件的描述、可能影响到哪些项目目标、后果严重性等 。课程提到可以制作“风险登记表”来整理这些信息。\n\n当然，再怎么头脑风暴，也总有“未知的未知”，即我们完全想不到的意外 。对于这类无法提前识别的风险，常见做法是设立应急储备（Contingency Reserve），例如留出一笔机动资金，就像家庭存款里"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#21": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "手足无措。课程点明：识别风险是风险管理的第一步，只有找出了威胁在哪里，才能评估其影响并想对策 。\n\n第二步：风险分析和优先级。 列出一堆风险后，不可能每个都投入大量精力管理，所以要分析每个风险的发生概率和影响程度 。可以采用定性的方法（高/中/低）或定量的方法，先问两个问题：“这个风险发生的可能性有"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#22": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "定采用什么策略来处理 。课程里讲到风险应对策略分类，让我茅塞顿开。我总结了一下常见的风险对策 ：\n\n- 接受：最简单的策略，啥也不做，接受风险后果 。通常针对那些可能性和影响都低的风险，我们可以选择“顺其自然”，万一发生了再处理。这也叫“被动接受”。当然也有“主动接受”，即意识到风险存在，但提前准备"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#23": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "能用时还有时间换方案 。规避策略往往适用于那些高影响的致命风险——能绕开的就绕开，不跟它正面交锋。\n- 减轻（缓解/降低）：采取措施来降低风险发生概率或减少其影响 。这可能是我们用得最多的策略，也叫风险缓解。比如担心新技术不靠谱，我们可以提前做个原型来验证它是否可行，如此一来，即使发现问题还有时间调"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#24": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "延误 。这个例子让我忍俊不禁，也记住了要适度管理风险的原则——花小钱防大灾，而不是花大钱防小灾。\n\n第四步：制定风险管理计划并监控。 一旦决定了应对措施，我们就把这些安排记录在风险登记册（风险日志）中 。风险登记册通常列出每个高优先级风险的详细计划，包括风险描述、诱因（触发风险的事件或条件）、可能的"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#25": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "险真正发生时，就按计划执行应对措施。此外，如果项目推进中识别出新风险，也要及时补充进风险日志中。\n\n通过这节的学习，我切身体会到：风险管理不是乌鸦嘴，而是智者千虑。早一点发现和思考风险，我们就多一分从容，少一分慌乱。课后我打算给自己的项目做一次“风险头脑风暴”，哪怕是小项目，也尝试列出风险清单并想好"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#26": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "必要的变更纳入项目，同时把不合理的变更拒之门外  。\n\n制定变更管理计划，我学到了以下几点：\n\n1. 明确基准和受控范围：首先要决定哪些内容纳入变更控制 。一般来说，项目的核心文档比如范围说明书、需求清单、项目总计划等都会设为“基准”，一经批准就不允许随意改动 。比如，干系人签署通过的需求列表就是需"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#27": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "，小项目可能没这么正式的委员会架构，但至少也该明确谁有权审批变更，别让任何人都能随意改项目。\n\n3. 定义变更流程：不同公司可能流程细节不一样，但大多数变更管理流程都会包括一些基本步骤 ：\n\n- 提交变更请求：任何想改项目的想法，必须先提出变更请求并记录在案 。填写标准化的变更请求表有助于获取完整信"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#28": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "代价和影响。我觉得在这一步，项目经理可以发挥主导，协调技术、测试、业务等相关人员一起把影响讲清楚。\n- 委员会决策：接下来变更审核委员会审议经过评估的请求 。委员会可能有几种决策：拒绝变更（认为没必要或代价太高）；要求更多信息或修改后重提（可能对评估结果存疑，让申请人补充论据）；或者批准变更 。无论"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#29": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "掌握每个变更的进展、负责人、最终影响等 。如果团队规模大，还可以定期通报变更状态，保持信息透明。\n\n课程也提到，并非每个变更都需要严格走完全流程 。可以设置一个“豁免标准”，让项目团队自己消化较小的变更 。比如影响预算在一定金额以下或不影响关键路径的调整，可由项目经理直接决定，事后在例会上告知即可，"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#30": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "的，变更管理计划可以确保必要的变更被纳入项目，同时保护项目不被无谓的变更干扰 。\n\n规划采购流程\n\n在这一部分，我学到了如何制定项目的采购计划。课程一开始用煲鸡汤打比方：就算我们自己下厨煮鸡汤，也不可能什么原料都亲自生产——不会傻到自己养鸡、种菜、磨面，然后花几天熬汤做面条 。我们通常是去市场采购需"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#31": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "这一步其实就是从WBS和资源计划出发，列出自家资源不够用或没有的那些项，形成一个待采购清单。\n\n2. 记录采购流程和职责：接着在计划中明确采购由谁来执行 。有的公司有专门的采购部门，那项目团队需要配合他们走流程；有的情况下项目团队自己就可以负责采购；也可能两者协作（比如技术人员负责选型，采购部门负责"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#32": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "作的开展。我以前参与过一些采购评标，深感提前约定标准的重要性，不然后期容易纠结甚至引发争议。\n\n3. 制定自制或外购决策流程：所谓“Make or Buy”，即决定是内部自制还是外部采购。课程强调，要做出明智的决定，必须充分理解自身需求 。因此流程的第一步是确保需求清晰且优先级明确 。这样才能判断现"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#33": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "第三方组件还是自己写代码，也属于 make or buy 决策，经常要权衡速度、成本、风险。\n\n4. 列出潜在卖方名单：采购计划最后还应该包含潜在供应商列表 。也就是记录我们考察过哪些供应商或承包商，它们提供什么产品/服务，凭什么把它们列为候选（比如价格低、口碑好、以往合作过等标准） 。这样等正式采"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#34": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "频会议系统，可能在计划里就列上三家业内知名厂商，以及各自的优缺点和报价区间。有准备才能有的放矢。\n\n通过学习采购规划，我认识到采购并非临时抱佛脚的事，而是需要事先策略性地考虑。采购计划能确保我们在决定买不买时做出明智选择，也确保采购过程顺利 。对我个人而言，以前做项目总是更关注内部资源协调，现在我会"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#35": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "着你获得了必要的授权和支持 。没有高层和客户的认可，项目后续推进会缺乏后台助力，也容易出现分歧。\n\n一开始我以为，把整套项目计划书写好后，发邮件请相关人签字回复“同意”就行了。可课程不建议用传阅邮件签字的方式来获取批准 。原因是：很多人收到厚厚的计划文件可能不会仔细阅读，草草看两眼就签了。但日后如果"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#36": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "点像签军令状，大家郑重签字，其实也是向项目承诺会支持遵守这个计划。我认为这样的仪式感非常有必要。\n\n现实中，可能无法把所有干系人都凑在一个房间。课程也给出了替代方案：可以召开视频会议或电话会议来走审批流程，如果有人远程参与不了，就让他们会后通过传真、邮件等方式补一个签字 。灵活运用各种手段，最终目标"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#37": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "这个提醒很重要：不要把干系人的签字当成套住他们的把柄，而是过程本身增进了他们对项目的信心和支持。\n\n说回我的体会，以前我也遇到过高层口头上说“行行行”就匆匆走过场，结果执行中不断跳出来提新要求、质疑原计划。如果当初能让他们安下心来详读计划、充分讨论，也许很多后来扯皮的问题就能避免。所以我决定以后坚决"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l4#38": {
    "title": "项目管理基础知识学习笔记L4",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l4",
    "date": "2025-06-12",
    "text": "之，通过这课我认识到，项目启动前的这道审批关绝不是形式，它关系到项目能否在统一步调下顺利开跑 。\n\n学完这一课，我感觉自己对项目规划有了一个全景式的认知。从 WBS、工作包一直到进度、预算、风险、变更、采购，各个模块就像拼图块块终于拼成了一幅完整的规划蓝图。我尤其兴奋的是，这些方法其实完全可以运用到"
  },
  "/content/posts/legacy/电商搜索店铺评分加权实践#0": {
    "title": "电商搜索店铺评分加权实践",
    "url": "/content/posts/legacy/电商搜索店铺评分加权实践",
    "date": "2022-04-01",
    "text": "电商搜索店铺评分加权实践\n\n为实现上述目标，我们在搜索系统中新增了一个店铺评分相关的字段，并建立了一套数据同步和排序加权机制，整体方案如下：\n* 数据来源：店铺评分数据由平台的大数据团队离线计算产生，存储在独立的店铺得分表中（例如每日更新的店铺评分数据库表）。评分取值0~5分，小数点一位精度。为了让"
  },
  "/content/posts/legacy/电商搜索店铺评分加权实践#1": {
    "title": "电商搜索店铺评分加权实践",
    "url": "/content/posts/legacy/电商搜索店铺评分加权实践",
    "date": "2022-04-01",
    "text": "%）；如果评分高于阈值则不受影响（系数为1）。阈值和惩罚系数均做成可配置，以便日后根据效果调优。\n\n下面我们分别介绍数据接入、索引更新和排序加权的具体实现，并给出对应的python代码示例。\n\nKafka消息消费实现\n\n为了实现店铺评分数据的实时同步，我们搭建了Kafka消费者来订阅评分更新主题。例"
  },
  "/content/posts/legacy/电商搜索店铺评分加权实践#2": {
    "title": "电商搜索店铺评分加权实践",
    "url": "/content/posts/legacy/电商搜索店铺评分加权实践",
    "date": "2022-04-01",
    "text": "中，然后异步触发对搜索索引中相关商品的更新（例如调用索引更新接口，更新这些商品的店铺评分字段）。\n\n需要注意的是，实际应用中应考虑消费者的容错和效率：例如确保消费过程是幂等的（重复消息不会造成数据不一致），处理异常情况（Kafka连接中断重试等），以及对更新频率较高的店铺进行批量合并更新等优化。上述"
  },
  "/content/posts/legacy/电商搜索店铺评分加权实践#3": {
    "title": "电商搜索店铺评分加权实践",
    "url": "/content/posts/legacy/电商搜索店铺评分加权实践",
    "date": "2022-04-01",
    "text": "更新模块，将每个店铺对应商品的索引字段更新为最新评分。\n\n下面是批量读取店铺评分数据的代码示例：\n\n上述批处理代码通过pymysql连接到数据库，执行SQL查询批量获取所有店铺的评分数据，并存入mysql。拿到全量数据后，接下来就可以遍历该Map，对搜索索引中的每个店铺相关商品执行更新（下面的索引更"
  },
  "/content/posts/legacy/电商搜索店铺评分加权实践#4": {
    "title": "电商搜索店铺评分加权实践",
    "url": "/content/posts/legacy/电商搜索店铺评分加权实践",
    "date": "2022-04-01",
    "text": "保在批量更新索引时对搜索服务影响最小，可使用低峰期执行并合理控制提交频率。\n\n索引字段扩展与更新\n\n有了店铺评分数据，我们需要将其写入搜索索引，以便在查询排序时使用。首先，我们在索引架构中新增了一个字段，例如store_score，类型可以选择数值类型（如float）以存储评分值。对于已经存在的商品"
  },
  "/content/posts/legacy/电商搜索店铺评分加权实践#5": {
    "title": "电商搜索店铺评分加权实践",
    "url": "/content/posts/legacy/电商搜索店铺评分加权实践",
    "date": "2022-04-01",
    "text": "更新Solr索引：\n\n上述代码通过pysolr连接到Solr服务器，然后构建字典来进行字段更新。\n\n对于使用Elasticsearch等其他搜索引擎的情况，实现方式略有不同，但思路类似：先确保索引有店铺评分字段，然后批量更新文档的该字段值。无论采用何种搜索引擎，目的都是让每个商品文档都携带其店铺评分"
  },
  "/content/posts/legacy/电商搜索店铺评分加权实践#6": {
    "title": "电商搜索店铺评分加权实践",
    "url": "/content/posts/legacy/电商搜索店铺评分加权实践",
    "date": "2022-04-01",
    "text": "终得分将 = 基础分 * 0.95；如果店铺评分为3.5（高于阈值），最终得分 = 基础分 * 1.0（不变）。通过这种方式，低评分店铺的商品得分略微降低，在整体排序中会略微靠后。\n\n下面给出二次排序加权的简化代码示例：\n\n在真实的搜索排序代码中，我们会对每一条候选商品结果应用类似逻辑，计算其最终排"
  },
  "/content/posts/legacy/电商搜索店铺评分加权实践#7": {
    "title": "电商搜索店铺评分加权实践",
    "url": "/content/posts/legacy/电商搜索店铺评分加权实践",
    "date": "2022-04-01",
    "text": "，也可以引入类似机制（如评分高于4.5分的店铺商品提高若干百分比得分），以鼓励优质卖家。\n\n总结\n\n在本次实践中，我们针对电商搜索引擎引入了店铺评分维度的排序优化。通过数据同步+索引更新+排序调整的方案，成功实现了对低评分店铺商品的降权，提升了搜索结果的可靠性和用户体验。实施过程中，我们采用了Kaf"
  },
  "/content/posts/legacy/html5-canvas经典坦克大战游戏开发-单文件游戏架构实践#0": {
    "title": "HTML5 Canvas经典坦克大战游戏开发：单文件游戏架构实践",
    "url": "/content/posts/legacy/html5-canvas经典坦克大战游戏开发-单文件游戏架构实践",
    "date": "2025-07-20",
    "text": "HTML5 Canvas经典坦克大战游戏开发：单文件游戏架构实践\n\n架构特点\n- **单文件设计**: 所有代码集中在一个HTML文件中\n- **面向对象**: 使用ES6类语法组织代码结构\n- **模块化思维**: 清晰的功能分离和职责划分\n- **零依赖**: 无需任何外部库或框架\n\n游戏系统设"
  },
  "/content/posts/legacy/html5-canvas经典坦克大战游戏开发-单文件游戏架构实践#1": {
    "title": "HTML5 Canvas经典坦克大战游戏开发：单文件游戏架构实践",
    "url": "/content/posts/legacy/html5-canvas经典坦克大战游戏开发-单文件游戏架构实践",
    "date": "2025-07-20",
    "text": "馈**: 丰富的击中和爆炸效果\n\n3. 可扩展设计\n- **模块化代码**: 清晰的类结构便于扩展\n- **事件系统**: 支持自定义游戏事件\n- **配置驱动**: 关卡数据与逻辑分离\n\n技术收获\n\nCanvas 2D编程\n- 掌握了Canvas绘图API的高级用法\n- 理解了游戏渲染循环的优化策"
  },
  "/content/posts/legacy/html5-canvas经典坦克大战游戏开发-单文件游戏架构实践#2": {
    "title": "HTML5 Canvas经典坦克大战游戏开发：单文件游戏架构实践",
    "url": "/content/posts/legacy/html5-canvas经典坦克大战游戏开发-单文件游戏架构实践",
    "date": "2025-07-20",
    "text": "完整游戏的可行性。通过精心设计的架构和高效的实现策略，在保持代码简洁的同时实现了丰富的游戏功能。\n\n项目不仅是对经典游戏的致敬，更是现代Web游戏开发技术的实践应用，为轻量级游戏开发提供了完整的解决方案参考。"
  },
  "/content/posts/legacy/00-windows-11-下两种-cuda-开发环境配置-wsl-本地工具链#0": {
    "title": "Windows 11 下两种 CUDA 开发环境配置（wsl & 本地工具链）",
    "url": "/content/posts/legacy/00-windows-11-下两种-cuda-开发环境配置-wsl-本地工具链",
    "date": "2025-05-06",
    "text": "Windows 11 下两种 CUDA 开发环境配置（wsl & 本地工具链）\n\n安装最新驱动后，我们需要设置 WSL2 及 Linux 子系统环境。 在 Windows 11 中，WSL2 的启用和 Ubuntu 发行版的安装非常简便：\n\n1. **启用 WSL功能：** 以管理员身份打开 Pow"
  },
  "/content/posts/legacy/00-windows-11-下两种-cuda-开发环境配置-wsl-本地工具链#1": {
    "title": "Windows 11 下两种 CUDA 开发环境配置（wsl & 本地工具链）",
    "url": "/content/posts/legacy/00-windows-11-下两种-cuda-开发环境配置-wsl-本地工具链",
    "date": "2025-05-06",
    "text": "buntu 发行版：**\n\n安装完成后执行`wsl`命令进入ubuntu，对系统及进行基本配置。\n\n完成以上步骤后，Windows 11 上的 WSL2 + Ubuntu 基础环境就准备就绪。\n\n配置本地工具链与 CUDA 开发环境\n\n在 Windows 环境下，我们可以选择两种方式来配置 CUDA"
  },
  "/content/posts/legacy/00-windows-11-下两种-cuda-开发环境配置-wsl-本地工具链#2": {
    "title": "Windows 11 下两种 CUDA 开发环境配置（wsl & 本地工具链）",
    "url": "/content/posts/legacy/00-windows-11-下两种-cuda-开发环境配置-wsl-本地工具链",
    "date": "2025-05-06",
    "text": "编译器 和 Windows SDK 等组件。该工作负载会自动为你安装所需的 C++ 开发工具。\n\n**注意** ：必须安装c++桌面程序组件，否则没有本地c++工具链\n\n**配置环境变量：** 为了让 CUDA 编译器（nvcc）和 MSVC 编译器能够正常工作，需要将 Visual Studio "
  },
  "/content/posts/legacy/00-windows-11-下两种-cuda-开发环境配置-wsl-本地工具链#3": {
    "title": "Windows 11 下两种 CUDA 开发环境配置（wsl & 本地工具链）",
    "url": "/content/posts/legacy/00-windows-11-下两种-cuda-开发环境配置-wsl-本地工具链",
    "date": "2025-05-06",
    "text": "被添加到环境变量 PATH 中。\n\n**验证安装**：\n\n* 在本地编写hello.cu\n\n  \n\n* powershell中运行`nvcc .\\hello.cu -o hello`进行编译\n\n  \n\n* 执行hello.exe程序\n\n  \n\nWSL工具链配置\n如果你希望在 WSL2 中运行和调试 "
  },
  "/content/posts/legacy/00-windows-11-下两种-cuda-开发环境配置-wsl-本地工具链#4": {
    "title": "Windows 11 下两种 CUDA 开发环境配置（wsl & 本地工具链）",
    "url": "/content/posts/legacy/00-windows-11-下两种-cuda-开发环境配置-wsl-本地工具链",
    "date": "2025-05-06",
    "text": "u文件，执行编译命令`nvcc ./hello.cu -o hello`\n\n   \n\n   \n\n3. **安装 VSCode 和插件：** 在 Windows 上安装 Visual Studio Code 并安装 Remote - WSL 插件，这样可以在 VSCode 中通过 WSL 直接编辑和运"
  },
  "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器#0": {
    "title": "EchoDraft项目计划：音视频内容智能提炼利器",
    "url": "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器",
    "date": "2024-01-01",
    "text": "EchoDraft项目计划：音视频内容智能提炼利器\n\nEchoDraft 项目应运而生，旨在通过自动化和智能化的手段，解决上述痛点。我们的目标是构建一个端到端的 CLI 工具，将音视频内容从下载、处理、转录到最终生成结构化文章的全过程自动化，极大地降低内容处理的门槛和成本，提升信息获取的效率。\n\n技"
  },
  "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器#1": {
    "title": "EchoDraft项目计划：音视频内容智能提炼利器",
    "url": "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器",
    "date": "2024-01-01",
    "text": "块 (`modules/downloader.py`)\n*   **核心技术**：`yt-dlp`\n*   **功能**：作为项目的数据入口，该模块利用强大的 `yt-dlp` 库，支持从 YouTube、Bilibili 等主流音视频平台下载内容。`yt-dlp` 凭借其强大的兼容性和持续更新能力"
  },
  "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器#2": {
    "title": "EchoDraft项目计划：音视频内容智能提炼利器",
    "url": "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器",
    "date": "2024-01-01",
    "text": "**价值**：通过智能的音频加速，我们能够在保证转录质量的同时，实现成本效益的最大化。\n\n3. 语音转文本模块 (`modules/transcriber.py`)\n*   **核心技术**：`faster-whisper`\n*   **功能**：该模块负责将预处理后的音频转换为高质量的文本。我们选"
  },
  "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器#3": {
    "title": "EchoDraft项目计划：音视频内容智能提炼利器",
    "url": "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器",
    "date": "2024-01-01",
    "text": "的智能分析奠定坚实基础。\n\n4. 智能内容分析模块 (`modules/analyzer.py`)\n*   **核心技术**：大型语言模型 (LLM) API\n*   **功能**：这是 EchoDraft 的\"大脑\"，负责从转录文本中提炼知识并生成结构化内容。该模块通过调用 LLM API，实现以"
  },
  "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器#4": {
    "title": "EchoDraft项目计划：音视频内容智能提炼利器",
    "url": "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器",
    "date": "2024-01-01",
    "text": "`)、音视频下载 (`downloader.py`)、音频处理 (`audio_processor.py`) 和语音转文本 (`transcriber.py`) 模块的基础功能集成与端到端流程验证。\n*   **里程碑 2 (进行中)**：智能内容分析模块 (`analyzer.py`) 的 LLM"
  },
  "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器#5": {
    "title": "EchoDraft项目计划：音视频内容智能提炼利器",
    "url": "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器",
    "date": "2024-01-01",
    "text": "lp` 虽然强大，但音视频平台的更新可能导致下载失败；不同音视频的编码、格式差异也增加了处理难度。\n*   **解决方案**：持续关注 `yt-dlp` 的更新，及时升级；在 `audio_processor` 中增加更鲁棒的格式检测和转换逻辑，确保兼容性。\n\n2. 音频加速的质量平衡\n*   **"
  },
  "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器#6": {
    "title": "EchoDraft项目计划：音视频内容智能提炼利器",
    "url": "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器",
    "date": "2024-01-01",
    "text": "tection) 预处理，提升复杂环境下的转录效果。\n\n4. LLM 生成内容的质量控制与成本优化\n*   **挑战**：LLM 可能出现\"幻觉\"、逻辑不连贯或内容冗余；API 调用成本需要控制。\n*   **解决方案**：\n    *   **Prompt Engineering**：投入大量精力"
  },
  "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器#7": {
    "title": "EchoDraft项目计划：音视频内容智能提炼利器",
    "url": "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器",
    "date": "2024-01-01",
    "text": "更丰富的输入源支持**：除了在线平台，增加对本地音视频文件、直播流甚至会议记录工具的直接集成。\n2.  **高级音频处理功能**：引入降噪、人声分离、多说话人识别 (Speaker Diarization) 等功能，进一步提升转录和分析的准确性。\n3.  **LLM 增强功能**：\n    *   "
  },
  "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器#8": {
    "title": "EchoDraft项目计划：音视频内容智能提炼利器",
    "url": "/content/posts/legacy/echodraft项目计划-音视频内容智能提炼利器",
    "date": "2024-01-01",
    "text": "**：探索使用 Docker 等容器技术简化部署；优化并行处理能力，进一步缩短处理时间。\n\n结语\n\nEchoDraft 致力于成为您处理音视频内容的得力助手，将繁琐的体力劳动转化为智能化的洞察力。我们相信，通过持续的迭代和社区的反馈，EchoDraft 将不断成长，为更多用户带来价值。\n\n项目目前处"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#0": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "一次状态同步缺陷引发的技术反思\n\n原因分析\n\n问题原因归结起来其实很简单：批量操作时状态更新和日志记录不一致。究其根本，是代码实现上忽略了和单条操作逻辑的一致性。开发者在新增批量冻结功能时，没有复用单条冻结的完整逻辑，只是直接对主表数据进行了批量更新。由于单条冻结时日志记录是一个单独步骤，批量情况下"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#1": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "自得到不一致的状态视图。在本例中，主库的状态是冻结了，但日志缺失导致依赖日志的组件未感知到冻结。\n\n为何会采用日志表同步而不直接用主表？这是出于系统解耦和性能考虑。一方面，直接让同步任务大范围扫描主表找变化成本高，不如按日志增量同步高效；另一方面，日志表还承担了操作审计的作用，记录谁在何时对哪些资源"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#2": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "进一步造成严重后果。\n\n修复过程\n找准原因之后，解决方案也就相对明确了。修复工作主要包括两个部分：\n* 补录日志： 针对已经被冻结但未记录日志的资源，补写相应的操作日志。这样可以修复那些已经执行过批量冻结但日志缺失的数据，使后续同步任务能正确识别这些资源的冻结状态。具体做法是根据主状态表中标记为冻结"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#3": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "的更新加上了数据库事务，确保主表和日志表的更新要么一起成功，要么一起回滚，杜绝了部分成功的情况。\n\n完成修复后，我们进行了多轮测试。首先单独验证批量冻结/解冻操作，在数据库的主表和日志表都能看到正确更新；接着模拟同步任务运行，确认批量操作后的资源状态能被其他模块正确感知。一切验证通过后，补丁顺利发布"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#4": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "态变更，否则会导致消费方与实际状态不一致。漏记一条日志，在消费方看来就等于漏掉了一次状态更新事件。\n•\t双写原子性： 如果主数据更新和日志记录无法在同一事务中完成，就存在中间状态不一致的风险。必须通过代码控制、重试机制或事务机制（如将日志写入和状态更新放在同一数据库事务，或者使用消息队列事务消息）来"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#5": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "。因此，设计这类系统时需要周全的考虑和大量的测试来验证日志同步的可靠性。\n\n批量操作一致性设计要点\n批量操作在系统设计中也有一些特别需要注意的一致性问题。批量更新往往涉及对多条数据的改动，如果不能保证一致的成功或失败，很容易造成部分成功的尴尬局面。结合本次经验和常见的实践，批量操作要保证一致性应考虑"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#6": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "享同一实现，能保证他们遵循相同的业务规则和数据更新步骤，避免因为两套实现细微差异导致的数据不一致。\n•\t性能与一致性平衡： 批量操作有时为了性能会分批次处理或者异步处理。这种情况下，需要设计好每批次之间的隔离和提交策略，防止批次之间数据依赖问题。例如，批量冻结1000条，可以每100条一个事务，但要"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#7": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "预先考虑一致性问题，减少类似本次事故的发生概率。\n\n示例：Python 实现批量状态更新与日志记录\n为了更直观地展示上述问题和解决方案，我们可以用一个简化的 Python 示例来模拟批量状态更新的过程。假设有两个数据结构：state_table 用于保存资源的当前状态，log_table 用于记录操"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#8": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "了，完全察觉不到B和C的冻结。这将导致B和C在别的模块仍被视为“active”，造成数据不一致。\n\n接下来，我们编写改进的批量冻结函数，确保每个资源的状态更新和日志记录同时进行，并利用Python的异常处理来模拟事务回滚机制：\n\n这段代码中，freeze_batch_with_log 函数会对传入的"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#9": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "来模拟中途出错的情况。\n\n现在重置数据，并尝试使用改进后的函数冻结B和C：\n\n输出结果可能如下：\n\n可以看到，尽管在冻结C时发生了异常，错误被捕获并触发了回滚机制。最终主状态表中B仍保持为\"active\"，C也是\"active\"（批量操作前的状态），日志表也没有留下B或C的残留日志。也就是说，此次批"
  },
  "/content/posts/legacy/一次状态同步缺陷引发的技术反思#10": {
    "title": "一次状态同步缺陷引发的技术反思",
    "url": "/content/posts/legacy/一次状态同步缺陷引发的技术反思",
    "date": "2022-04-25",
    "text": "采用新架构（比如日志驱动同步）时，需要从全局视角去考虑数据流转和状态同步，确保每一步都严谨可靠。\n\n具体而言，一方面要强化开发流程中的审查和测试，对可能影响数据一致性的改动进行重点关注；另一方面，在架构设计上也应尽量避免让系统状态散落在多个来源而缺乏统一校验机制。如果不得不如此（例如为了性能和解耦需"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#0": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting\n\n3. Data Augmentation under Data Scarcity\n\nAmong all strategies for mi"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#1": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "amples that the model has \"never seen\" before.\n\n3.1 Geometric Transformations\n\nThese transformations simulate variations in an object's pose, scale, a"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#2": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "ide even stronger generalization capabilities.\n\n3.2 Pixel-level Perturbations\n\nThese transformations aim to improve the model's robustness to changes "
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#3": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "or MotionBlur.\n\n3.3 Color Space Transformations\n\nTransformations in the color space enhance the model's adaptability to variations in lighting, contra"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#4": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "the model to focus on shape rather than color.\n\n3.4 Synthetic/Mixing Methods\n\nIn recent years, augmentation methods that mix information from multiple"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#5": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "g. Thus, auto-augmentation methods were developed. **RandAugment** is a simple yet effective method that randomly selects N transformations from a pre"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#6": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "ionally expensive.\n\n4. Implementation in PyTorch\n\nHere, we demonstrate how to build a `transform` pipeline in PyTorch that includes various augmentati"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#7": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "ed for the pre-trained model (e.g., ImageNet).\n\n4.2 Plug-and-Play Mixup/CutMix\n\nIn your training loop, you can fetch `inputs` and `targets` from the D"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#8": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "curves for both the training and validation sets. A key practice is **Early Stopping**: when the validation loss stops decreasing and starts to rise f"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#9": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "aximize the effectiveness of data augmentation:\n1.  **Establish Baseline**: First, train the model without any data augmentation and record its accura"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#10": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "nction with Label Smoothing for better results.\n4.  **Phase 3**: If computational resources permit, try using RandAugment or AutoAugment to automatica"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#11": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "stribution.\n\n6. Common Pitfalls & Practical Tips\n\n- **Over-augmentation**: Excessive augmentation can cause a significant distribution shift between t"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#12": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "a small application probability (e.g., `p=0.3`).\n- **Label Synchronization**: In object detection or semantic segmentation tasks, when applying geomet"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#13": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "l's performance on the original data distribution. Typically, only necessary resizing and center cropping are applied, without heavy augmentation.\n- *"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#14": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "rning rate.\n\n7. Conclusion & Further Exploration\n\nWhen faced with the challenge of data scarcity, our core objective is to **expand the diversity** of"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-en#15": {
    "title": "Image Classification: Data Scarcity, Augmentation, and Underfitting/Overfitting",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-en",
    "date": "2024-01-01",
    "text": "a classic starting point for solving this problem. Building on this foundation, you can further explore more advanced directions, such as: using unlab"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-zh#0": {
    "title": "监督学习 vs 非监督学习：概念、算法与实践",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-zh",
    "date": "2024-01-01",
    "text": "监督学习 vs 非监督学习：概念、算法与实践\n\n2. 核心概念与差异\n\n2.1 监督学习（Supervised Learning）\n\n监督学习的核心思想是**从“有标签”的数据中学习**。这里的“标签”（Label）是我们希望模型预测的正确答案。\n\n-   **定义**：给定一组输入数据 `X` 和"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-zh#1": {
    "title": "监督学习 vs 非监督学习：概念、算法与实践",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-zh",
    "date": "2024-01-01",
    "text": "历史数据预测未来一天的气温。\n\n2.2 非监督学习（Unsupervised Learning）\n\n与监督学习相反，非监督学习处理的是**“无标签”的数据**。它不需要人工标注的答案，而是致力于发现数据自身内在的结构和模式。\n\n-   **定义**：仅给定输入数据 `X`，算法的目标是挖掘数据中隐藏"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-zh#2": {
    "title": "监督学习 vs 非监督学习：概念、算法与实践",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-zh",
    "date": "2024-01-01",
    "text": "与原始数据相似的样本。例如，生成逼真的人脸图像。\n\n2.3 差异一览表\n\n3. 工作流程对比\n\n3.1 监督学习流水线\n\n一个典型的监督学习项目遵循一个相对标准化的流程：\n\n1.  **数据标注与划分**：获取或标注高质量的标签数据，并将其划分为训练集、验证集和测试集。\n2.  **特征工程与模型选"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-zh#3": {
    "title": "监督学习 vs 非监督学习：概念、算法与实践",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-zh",
    "date": "2024-01-01",
    "text": "K-means、PCA）对尺度敏感。同时需要选择合适的距离度量方式（如欧氏距离、余弦相似度）。\n2.  **算法与超参数探索**：选择合适的算法（如 K-means、DBSCAN），并探索其关键超参数（如簇的数量 `k`、邻域半径 `ε`）。\n3.  **结果可视化与业务验证**：由于没有“正确答案"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-zh#4": {
    "title": "监督学习 vs 非监督学习：概念、算法与实践",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-zh",
    "date": "2024-01-01",
    "text": "时，通过伪标签（Pseudo-Labeling）、一致性正则化等技术，利用无标签数据提升模型性能。\n-   **弱监督学习（Weakly Supervised Learning）**：标签不完全准确或不完整（例如，只知道一张图里有猫，但不知道猫的具体位置）。\n-   **自监督学习（Self-sup"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-zh#5": {
    "title": "监督学习 vs 非监督学习：概念、算法与实践",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-zh",
    "date": "2024-01-01",
    "text": "：优先考虑非监督学习进行数据探索（聚类、可视化），或使用自监督/半监督方法减少对标签的依赖。\n\n2.  **考虑模型规模与数据复杂度**：\n    -   **大规模感知任务（图像、语音、文本）**：深度学习网络是最佳选择。\n    -   **小样本、高维度数据**：SVM 或树模型（如随机森林）"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-zh#6": {
    "title": "监督学习 vs 非监督学习：概念、算法与实践",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-zh",
    "date": "2024-01-01",
    "text": "些发现作为特征或目标，用于构建**监督学习**模型，并部署到线上提供实时预测服务。\n\n8. 总结\n\n监督学习与非监督学习是解决不同问题的两种强大工具，它们的核心区别在于是否依赖“标准答案”。\n\n-   **监督学习擅长“回答已知问题”**：在明确的目标和高质量的标签驱动下，它能做出精准的预测。\n- "
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-zh#7": {
    "title": "监督学习 vs 非监督学习：概念、算法与实践",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-zh",
    "date": "2024-01-01",
    "text": "9.3 非监督学习示例\n\nK-means 聚类 + 可视化\n\nPCA + t-SNE 可视化\n\n9.4 简易 GAN 骨架 (PyTorch)\n\n这是一个极简的 GAN 结构，用于演示其核心组件，并非一个完整的训练脚本。\n\n10. 参考资料\n\n-   *Pattern Recognition and"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#0": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "Connect Claude Code to Notion MCP with a Single Command\n\nLet's get started.\n\n2. Prerequisites\n\nBefore you begin, please ensure you've completed these "
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#1": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "**) to support this feature.\n\n**For CLI Users:**\n\nOpen your terminal and run the following command to upgrade:\n\n**For Claude Desktop Users:**\n\nOpen th"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#2": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "Notion workspace you want Claude to operate on.\n2.  **Pre-select the authorization scope**: Think about which specific pages or databases you want to "
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#3": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "ge.\n\n3. Add the MCP Server with a Single Command\n\nWith the prerequisites out of the way, open your terminal and execute this single, crucial command:\n"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#4": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "local alias** you are setting for this connection. You can name it whatever you like, such as `my-notion` or `work-notion`. All future commands relate"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#5": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "data exchange between Claude and the Notion API.\n\n> **Advanced Option**: If you prefer using Server-Sent Events (SSE) for a more real-time, bidirectio"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#6": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "now.\n\n4. The First-Time OAuth Authorization Flow\n\nNow, we need to trigger an authorization flow so that Notion knows you are allowing Claude to access"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#7": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "set. The simplest one is to ask for help:\n    \n\n2.  At this point, the Claude CLI or desktop app will detect that the `notion` service is not yet auth"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#8": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "es or databases** you wish to grant access to.\n\n4.  Click the **\"Allow access\"** button.\n\n5.  After successful authorization, the browser will display"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#9": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "ire secure process.\n\n5. Verifying the Connection\n\nHow can you confirm the connection was successful? We can use the `mcp` subcommand to check. Note th"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#10": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "e detailed information for the `notion` service:\n\nYou will see a JSON output, where the most important field is `status`. If everything went well, it "
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#11": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "for troubleshooting.\n\n7. What's Next (A Teaser)\n\nNow that the bridge is built, a wide range of automation possibilities are open for exploration. In u"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#12": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "d Notion content directly from your conversation.\n-   **Build an automation pipeline**: Combine this with local file system tools to create a \"Markdow"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#13": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "iles and writes the content to a Notion database.\n-   **Self-host an MCP service**: For developers with special requirements (like private deployments"
  },
  "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command#14": {
    "title": "Connect Claude Code to Notion MCP with a Single Command",
    "url": "/content/posts/legacy/connect-claude-code-to-notion-mcp-with-a-single-command",
    "date": "2024-01-01",
    "text": "ed a trusted connection between Claude and Notion. This modern integration method does away with the cumbersome and insecure process of manually manag"
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en#0": {
    "title": "The Ultimate Guide to Classification Model Evaluation Metrics",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "The Ultimate Guide to Classification Model Evaluation Metrics\n\n-   **TP (True Positive)**: Correctly predicted positive.\n-   **FN (False Negative)**: "
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en#1": {
    "title": "The Ultimate Guide to Classification Model Evaluation Metrics",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": ". Point-Based Core Metrics (Threshold-Dependent)\n\nThese metrics are calculated based on a specific classification threshold (usually 0.5 by default).\n"
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en#2": {
    "title": "The Ultimate Guide to Classification Model Evaluation Metrics",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "PRC** are often more informative than the ROC-AUC. A high ROC-AUC can be misleadingly optimistic when the number of true negatives (TN) is massive.\n\n4"
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en#3": {
    "title": "The Ultimate Guide to Classification Model Evaluation Metrics",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "verage metric. It weights each **sample** equally. Best for assessing overall performance.\n-   **Macro Average**: Calculates the metric independently "
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en#4": {
    "title": "The Ultimate Guide to Classification Model Evaluation Metrics",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "ation**: Always plot the class distribution first. If it's a long-tail distribution, report both **Macro-F1** and **Micro-F1** to give a complete pict"
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en#5": {
    "title": "The Ultimate Guide to Classification Model Evaluation Metrics",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "abeling negatives as positives (minimizing FP).\n2.  **High Accuracy ≠ Good Model**: On a 99:1 imbalanced dataset, a model that predicts \"negative\" eve"
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en#6": {
    "title": "The Ultimate Guide to Classification Model Evaluation Metrics",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "urves depends on the dataset's class distribution. AUC scores are not directly comparable across different test sets.\n5.  **Separation vs. Calibration"
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en#7": {
    "title": "The Ultimate Guide to Classification Model Evaluation Metrics",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "imbalanced, multi-class classification problem.\n\n**Example Output**:\n\nNotice that the Macro-F1 (0.755) is significantly lower than the Weighted-F1 (0."
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en#8": {
    "title": "The Ultimate Guide to Classification Model Evaluation Metrics",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "cost of a False Positive vs. a False Negative?\n2.  **Select Point-Based Metrics**: If costs are known, tune your threshold and report Precision/Recall"
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en#9": {
    "title": "The Ultimate Guide to Classification Model Evaluation Metrics",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "e calibrated using LogLoss and ECE/Brier Score.\n4.  **Monitor Overall Quality**: During model iteration or A/B testing, use AUPRC (for imbalanced data"
  },
  "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路#0": {
    "title": "Todo List多用户应用开发实践：从单用户到跨平台架构的完整升级之路",
    "url": "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路",
    "date": "2024-01-01",
    "text": "Todo List多用户应用开发实践：从单用户到跨平台架构的完整升级之路\n\n升级后技术栈\n- **前端**: HTML5 + CSS3 + jQuery 3.6.0 + 认证界面\n- **后端**: Flask 2.3.3 + Flask-JWT-Extended + bcrypt\n- **数据库*"
  },
  "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路#1": {
    "title": "Todo List多用户应用开发实践：从单用户到跨平台架构的完整升级之路",
    "url": "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路",
    "date": "2024-01-01",
    "text": ": 防止表单重复提交，密码遮盖\n\n注册页面特性\n- **输入验证**: 用户名唯一性、密码确认匹配\n- **视觉反馈**: 实时的输入状态指示\n- **用户体验**: 注册成功后自动跳转登录\n\n5. 数据库迁移方案\n\n开发了专业的数据库迁移脚本 `migrate_db.py`：\n\n**迁移特性**:"
  },
  "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路#2": {
    "title": "Todo List多用户应用开发实践：从单用户到跨平台架构的完整升级之路",
    "url": "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路",
    "date": "2024-01-01",
    "text": "**: 确保不同用户只能访问自己的数据\n\n**解决方案**: \n- 所有API端点添加用户认证检查\n- 数据库查询必须包含 `user_id` 过滤条件\n- 实施严格的会话管理\n\n性能优化实践\n\n1. 数据库连接优化\n- 避免每次查询都新建连接\n- 实施连接池管理\n- 优化SQL查询效率\n\n2. 前"
  },
  "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路#3": {
    "title": "Todo List多用户应用开发实践：从单用户到跨平台架构的完整升级之路",
    "url": "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路",
    "date": "2024-01-01",
    "text": "发与测试\n- 生产数据安全迁移\n- 数据一致性验证\n\n5. 集成测试与优化\n- API接口功能测试\n- 用户注册登录流程验证\n- 数据隔离安全测试\n\n项目成果\n\n功能特性\n- ✅ **用户管理**: 完整的注册/登录/登出功能\n- ✅ **数据隔离**: 每个用户拥有独立的待办事项数据\n- ✅ **"
  },
  "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路#4": {
    "title": "Todo List多用户应用开发实践：从单用户到跨平台架构的完整升级之路",
    "url": "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路",
    "date": "2024-01-01",
    "text": "lyst）\n- Core Data离线缓存\n\nPhase 3: Android + Windows\n- Android客户端（Kotlin + Compose）\n- Windows客户端（C# + WPF）\n- 本地数据库缓存\n\nPhase 4: Linux + 集成测试\n- Linux客户端（Py"
  },
  "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路#5": {
    "title": "Todo List多用户应用开发实践：从单用户到跨平台架构的完整升级之路",
    "url": "/content/posts/legacy/todo-list多用户应用开发实践-从单用户到跨平台架构的完整升级之路",
    "date": "2024-01-01",
    "text": "目开始就要考虑安全性，包括密码加密、会话管理、数据隔离等。后期补救的成本远高于前期设计。\n\n总结\n\n今天的Todo List应用升级是一次完整的技术实践，从单一功能的Web应用成功演进为具备现代化特征的多用户系统。这个项目不仅展示了Web应用开发的最佳实践，也为后续的跨平台开发奠定了坚实的基础。\n\n"
  },
  "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp#0": {
    "title": "使用一条命令把 Claude Code 接入 Notion MCP",
    "url": "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp",
    "date": "2024-01-01",
    "text": "使用一条命令把 Claude Code 接入 Notion MCP\n\n让我们开始吧。\n\n2. 基础准备\n\n在开始连接之前，请确保完成以下两个简单的准备步骤。\n\n2.1 更新 Claude CLI / Desktop\n\nMCP (Message-based Communication Protocol"
  },
  "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp#1": {
    "title": "使用一条命令把 Claude Code 接入 Notion MCP",
    "url": "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp",
    "date": "2024-01-01",
    "text": "对希望 Claude 操作的 Notion 工作区（Workspace）拥有管理员或成员权限。\n2.  **预先选好授权范围**：想好你希望授权给 Claude 的具体页面或数据库。一个最佳实践是专门创建一个数据库（例如，命名为 \"AI Drafts\"）或一个顶级页面（例如 \"Claude Inbo"
  },
  "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp#2": {
    "title": "使用一条命令把 Claude Code 接入 Notion MCP",
    "url": "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp",
    "date": "2024-01-01",
    "text": "。后续所有与 Notion 相关的指令都将使用这个别名作为前缀，例如 `notion.help`。\n- `https://mcp.notion.com/mcp`: 这是 Claude 官方提供的、用于连接 Notion 的公共 MCP 端点。它是一个托管在云端的安全代理，负责处理 Claude 与 "
  },
  "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp#3": {
    "title": "使用一条命令把 Claude Code 接入 Notion MCP",
    "url": "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp",
    "date": "2024-01-01",
    "text": "或终端中，尝试调用任何一个以你刚才设置的别名开头的工具指令。最简单的就是请求帮助：\n    \n\n2.  此时，Claude CLI 或桌面应用会检测到 `notion` 服务尚未授权，并**自动打开你的默认浏览器**，跳转到 Notion 的登录和授权页面。\n\n3.  在浏览器中，登录你的 Noti"
  },
  "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp#4": {
    "title": "使用一条命令把 Claude Code 接入 Notion MCP",
    "url": "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp",
    "date": "2024-01-01",
    "text": "对你的 Notion 内容进行任何写入或修改操作**。\n\n首先，列出所有已配置的 MCP 服务：\n\n你应该能看到刚才添加的 `notion` 服务，以及它的通信方式：\n\n接下来，获取 `notion` 服务的详细信息：\n\n你会看到一段 JSON 输出，其中最重要的字段是 `status`。如果一切顺"
  },
  "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp#5": {
    "title": "使用一条命令把 Claude Code 接入 Notion MCP",
    "url": "/content/posts/legacy/使用一条命令把claude-code接入notion-mcp",
    "date": "2024-01-01",
    "text": "` 和 `notion.search` 等工具，直接在对话中创建、更新和查找 Notion 内容。\n-   **构建自动化流水线**：结合本地文件系统工具，实现一个 \"Markdown → Notion\" 的摘要流水线，自动将本地的 `*.md` 文件内容总结并写入到 Notion 数据库。\n-  "
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#0": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案\n\n举个例子，假设某文档当前的 _version 为 5，如果另一进程试图基于版本 4 的过期数据进行更新，Elasticsearch 会返回如下错误（HTTP 409 状态）：\n\n这段报错信息清楚地表明：当前文档版"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#1": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "败。\n\n版本冲突的常见原因\n\n了解版本冲突的原理后，我们来看下实际开发中哪些场景容易触发这种问题：\n* 高并发写入：最典型的情况是多个线程或服务同时对同一个文档进行更新。例如，两个用户几乎同时修改同一商品的库存信息，或者微服务 A 和 B 不约而同地更新同一用户的数据。当并发写入交叉发生时，后提交的"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#2": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "地，如果上一个事务操作失败或回滚，后续操作没有意识到实际数据已经改变，也可能出现版本不一致的问题。\n* 分布式同步延迟：Elasticsearch 集群的多副本架构以及客户端的读写模式也可能引发意外的冲突。如果应用从某个 副本分片 读取了稍旧的数据，然后紧接着对原始文档发起更新，此时主要分片上也许已"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#3": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "覆盖较新的版本，也会被 ES 拒绝。这些都属于因使用方式导致的冲突错误。\n\n版本冲突错误信息解析\n\n当发生版本冲突时，Elasticsearch 会返回 HTTP 409 Conflict 状态的错误响应，核心内容就是我们前面看到的 version_conflict_engine_exception"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#4": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "，这在REST语义中专指请求与服务器的当前状态冲突。在ES里，这个状态码几乎就和版本冲突划等号。\n\n通过错误信息，我们可以快速确定是哪一个文档发生了冲突，以及冲突发生时文档的版本情况。这为后续的排查提供了直接线索。\n\n值得一提的是，在 Elasticsearch 7+ 版本中，引入了 _seq_no"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#5": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "_version（或 _seq_no）等信息。确认现在文档处于哪个版本，这为分析提供了基础数据。\n* 回溯操作顺序：梳理应用程序中对该文档的更新流程。思考在冲突发生前后，是否有两个或多个并行操作在更新这份文档。查看相关的代码或日志，确认是否存在同时更新的情况，或是否有操作使用了过期的数据。例如，是否"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#6": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "fresh=true）后再读。排查时，可以检查应用是否有类似的读->改->写模式且未考虑刷新延迟。\n* 特殊操作导致：确认是否使用了 version 或 if_seq_no 等参数、op_type=create、version_type=external 等特殊用法。如果有，仔细核对这些参数的取值和"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#7": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "在使用 Update API 时指定遇到冲突后自动重试的次数，省去我们手动捕获异常再重试的麻烦。\n\n此外，将更新逻辑放在 Elasticsearch 服务端执行（比如使用 Painless 脚本进行局部更新），也能降低冲突风险。因为相比先从ES取出数据在客户端修改再写回的模式，直接在服务端基于最新数"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#8": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "次。每次重试时，它会重新获取最新的文档内容来执行我们提供的脚本，从而最大程度确保更新能成功应用。\n\n需要注意，retry_on_conflict 虽然有效减少了冲突失败的概率，但并不是万能的——如果短时间内持续有并发写入，重试多次后仍可能失败。因此我们还可以配合下一步的措施，对失败的操作进行应用层面"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#9": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "实践中，这种应用层的重试通常和日志监控配合使用：若最后仍有失败，及时记录报警，以便人工介入调查。\n\n当然，需要控制重试的次数和频率，以免在冲突严重时陷入无限重试或对集群造成过大压力。通常 3~5 次重试已足够，大量冲突重试可能意味着需要从架构上重新考虑并发写设计了。\n\n3. 合理设计文档更新流程\n\n"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#10": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "比如定时任务每次都写入相同的数据就没有意义，应在应用层加以判断。写入次数的减少直接降低了冲突几率。\n* 及时刷新读取：如果业务流程必须在写入后立刻读取再写入，那么应该在写入后使用 refresh=wait_for 或及时刷新索引，保证读到最新数据。或者干脆使用实时 GET 获取文档以获取最新版本。总"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#11": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "ion 和 version_type=external。ES会比较提供的版本号与当前文档的版本号：\n* 如果提供的版本号 大于 当前ES中文档的版本，则认为这是一个更新，ES会接受该操作并将文档版本设置为这个新的外部版本号；\n* 如果提供的版本号 小于或等于 当前版本，则会被判定为过期更新，因而返回"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#12": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "于的情况，但一般用不到）。哪怕是相同的数据重复写入，也应该带更高的版本号，否则ES会将其视为冲突。\n* 性能影响：使用外部版本意味着每次写入都绕过了ES内部的自动版本递增逻辑，而用你提供的数字替代。这本身不会带来明显性能损耗，但如果你的版本分配不当（比如非常大或者经常出现冲突），依然会引发大量异常处"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#13": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "仅增加系统负担，还可能掩盖真正的设计问题。一般设置几次重试足矣，若超出仍失败，应从流程上寻找原因。\n* 冲突频发需审视数据模型：如果某类文档经常发生冲突，高概率是数据模型或业务流程存在热点更新。例如，多人频繁修改同一记录。这时应考虑是否可以优化，例如前面提到的拆分文档或引入队列串行化，以从源头上降低"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#14": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "也会报冲突异常。切勿仍使用旧版的 ?version 参数进行控制，因为现在ES会直接拒绝这种用法。\n* 使用实时读写接口：尽量使用实时的 _doc GET 接口读取需要更新的文档，而不是通过搜索查询再更新。因为搜索结果可能不是实时最新的，尤其在索引尚未刷新时。这一点在需要连续读写的流程中很重要，可以"
  },
  "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案#15": {
    "title": "结合原理与实践，全面解析Elasticsearch中常见版本冲突问题及工程化解决方案",
    "url": "/content/posts/legacy/结合原理与实践-全面解析elasticsearch中常见版本冲突问题及工程化解决方案",
    "date": "2024-05-28",
    "text": "护机制。对于开发者来说，版本冲突错误既是一种挑战，也是线索：它提醒我们系统中存在并发写入的竞争。\n\n通过深入理解 Elasticsearch 的版本机制，我们可以在设计阶段就减少冲突的可能；在实现阶段善用 retry_on_conflict 等工具自动解决小概率冲突；在冲突仍发生时，通过日志排查和合"
  },
  "/content/posts/legacy/todo-list全栈应用开发实践-前后端分离架构设计#0": {
    "title": "Todo List全栈应用开发实践：前后端分离架构设计",
    "url": "/content/posts/legacy/todo-list全栈应用开发实践-前后端分离架构设计",
    "date": "2025-07-21",
    "text": "Todo List全栈应用开发实践：前后端分离架构设计\n\n后端技术栈\n- **Python Flask**: 轻量级Web框架\n- **SQLite**: 嵌入式数据库\n- **RESTful API**: 标准化接口设计\n- **JSON**: 数据交换格式\n\n功能设计\n\n核心功能\n1. **任务"
  },
  "/content/posts/legacy/todo-list全栈应用开发实践-前后端分离架构设计#1": {
    "title": "Todo List全栈应用开发实践：前后端分离架构设计",
    "url": "/content/posts/legacy/todo-list全栈应用开发实践-前后端分离架构设计",
    "date": "2025-07-21",
    "text": "- 清晰的职责划分\n- RESTful API 设计\n- 前端专注用户交互，后端专注数据处理\n\n2. 技术选型合理\n- 原生 JavaScript 保证性能\n- jQuery 简化 DOM 操作\n- Flask 轻量级易于开发\n- SQLite 零配置数据库\n\n3. 代码组织良好\n- 模块化的 Ja"
  },
  "/content/posts/legacy/todo-list全栈应用开发实践-前后端分离架构设计#2": {
    "title": "Todo List全栈应用开发实践：前后端分离架构设计",
    "url": "/content/posts/legacy/todo-list全栈应用开发实践-前后端分离架构设计",
    "date": "2025-07-21",
    "text": "发进度\n\n代码质量\n- **模块化设计**提高了代码复用性\n- **异常处理**保证了应用的稳定性\n- **数据验证**确保了数据的完整性\n\n未来优化方向\n\n1. **功能扩展**: 任务分类、优先级、截止日期\n2. **性能优化**: 分页加载、缓存机制\n3. **用户系统**: 登录注册、多用户"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#0": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践\n\n在开始搭建之前，需要准备好基础运行环境和硬件资源。本方案假设使用 Linux 服务器（例如 CentOS 或 Ubuntu），并已安装合适版本的 Java JDK（因为 Cas"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#1": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "台 Solr 节点，组成搜索索引集群，每台部署 SolrCloud 实例（假定 IP 分别为 10.201.X.X 三台）。\n* \tPython 微服务：至少包含两个服务示例：\n* \t数据同步服务：消费 Kafka 消息，将新产品数据写入 Cassandra，并更新 Solr 索引。\n* \t搜索 A"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#2": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "二进制发行版（本文以 Cassandra 3.11.12 为例）。将安装包上传到目标服务器 10.201.X.X 并解压，例如：\n\nCassandra 解压后即可使用，无需额外编译。进入 Cassandra 目录，可以直接通过 bin/cassandra 命令启动节点。第一次启动前，我们需要修改配置"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#3": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "设置为本机 IP，如：rpc_address: 10.201.X.X （在 Cassandra 3.x 中 rpc_address 控制 CQL 服务绑定）。\n* seed_provider：种子节点列表。如果是单节点测试，可将其设为本机 IP；如是多节点集群，填入初始引导的种子节点 IP 列表。例"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#4": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "生产集群应根据机房分布采用 NetworkTopologyStrategy 并设定合适的副本数。\n\n设计 Cassandra 表： 针对搜索系统的需求，我们设计 Cassandra 数据模型来存储商品及相关属性信息。原则上 Cassandra 适合存储宽表结构的数据，每个表以查询需求为导向设计主键。"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#5": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "ry 等)：根据业务需要建立，例如按类目、品牌、促销等维度组织的数据表，用于支持特定查询或统计。\n\n每个商品在 Cassandra 中会有一系列关联记录。例如商品基本信息在主表一行，属性信息在属性表中一行，等等。这种设计便于通过商品ID快速获取完整信息。由于搜索查询主要由 Solr 执行，Cassa"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#6": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "0.201.X.X。\n\n配置 Zookeeper\n\n在每台节点的 conf 目录下复制一份模板：\n\n编辑 zoo.cfg，主要关注以下配置：\n* \tdataDir=/path/to/zookeeper/data：指定数据存储目录，比如 /opt/app/zookeeper/data，确保该目录存在并"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#7": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "。如果需要验证 ZK 集群可用性，使用 zkCli 连接任意节点:\n\n可以尝试创建节点测试，如：\n\n成功创建则说明 ZK 正常工作。我们稍后会在 ZK 上使用路径 /solr_demo 来存储 SolrCloud 的配置数据（即设置一个chroot路径）。\n\n安装与配置 Kafka\n\n安装 Kafk"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#8": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "XT://:9092 监听所有网卡。如果有多网卡或 Docker 环境需设置 advertised.listeners 为实际可访问地址，比如 PLAINTEXT://10.201.X.X:9092。\n* zookeeper.connect：设置连接的 Zookeeper 集群地址列表。例如：\n\n如"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#9": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "eeper 客户端查看 /brokers/ids 节点下是否有对应的 broker ID 出现。\n\n创建主题 (Topic)\n\n 根据业务需要创建 Kafka 主题，用于传递产品数据更新。例如创建一个名为 product_update 的主题，副本因子为2，分区数为3：\n\n（--bootstrap-"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#10": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "zip 或 tgz），然后在每台 Solr 节点上解压。例如：\n\n准备 SolrCloud 配置\n\n在首次启动 SolrCloud 之前，需要将 Solr 核心配置 上传到 Zookeeper，或者在启动时指定让 Solr自动上传。本项目的 Solr 模块包含一个名为 “product” 的 col"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#11": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "i 创建过 /solr_demo 节点）。\n\n* 集群其他配置： 如果需要，可以在 solr.in.sh 中调整 JVM 内存大小（SOLR_HEAP）以及 GC 策略等。默认情况下 Solr 7 会给出合理的 JVM 参数，我们根据节点内存大小调整，例如设置 SOLR_HEAP=\"1g\"。\n* D"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#12": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "义的 DIH Handler 插件，例如本项目提供的 solr-support-7.7.0-1.0.jar，也复制到该目录）\n\n这些操作可以在一台机器上完成 Solr 配置准备，然后打包整个 solr 目录供所有节点使用。例如，将配置好的 /opt/app/solr 压缩成 solr.zip，然后传"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#13": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "nfig 下载，如 ./bin/solr zk downconfig -n product -d ./downloaded_conf -z ...）。\n\n启动 Solr 节点\n\n在每台 Solr 服务器上，以 SolrCloud 模式启动 Solr，并让其加入集群：\n\n参数说明：-c 表示以Clou"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#14": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "使用我们上传的名为 product 的配置集，设置2个分片，每片2个副本。如果已在 solr.in.sh 设置 ZK_HOST，脚本会在集群上创建collection，并在各节点间分配 cores。成功后，SolrCloud 开始对外提供搜索服务。可以在浏览器访问任何一台 Solr 的管理界面（例如"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#15": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "等功能。我们以 Python 重写这些模块，并提供示例说明如何启动和管理。\n\n微服务功能划分\n\n1.\t数据同步服务（Kafka 消费者）：持续消费 Kafka product_update 主题消息。每当有商品数据更新消息时，使用 Cassandra 驱动将新数据写入 Cassandra 对应表；然"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#16": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "Cassandra，使用 requests 或 pysolr 调用 Solr 的 API。\n\n2.\t搜索 API 服务：对外提供搜索接口（REST API）。客户端的搜索请求由此服务接收，并转发查询给 SolrCloud，整理结果后返回。可以基于 Flask 或 FastAPI 框架实现。服务内部使"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#17": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "hon 调用其 HTTP 接口或按照协议实现执行器。这里不展开细节。\n\n微服务代码与启动脚本示例\n\n我们以 FastAPI 构建搜索 API 服务为例，并示范如何编写 Python 启动脚本来管理服务的启动和停止。假设搜索服务代码为 app.py，内容如下（简化示例）：\n\n在实际项目中，可能会有更复"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#18": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "，并将其置于独立进程组以脱离父进程（相当于 nohup）。日志输出定向到 service.log。\n* \tstop() 使用系统命令 pgrep 查找匹配 uvicorn 和端口号的进程，然后发送 SIGTERM 信号关闭（也可直接用 process.pid 文件记录的方法，或使用更便捷的 psut"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#19": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "Supervisor、systemd 或容器编排等），此处的脚本仅作为示范。\n\n集群部署注意事项\n\n在将上述所有组件部署完成后，还需关注一些集群搭建的细节和最佳实践：\n* 配置管理与同步： 集群环境配置繁多，建议使用配置管理工具（如 Ansible、Chef）或至少使用脚本确保每台机器配置一致。例如"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#20": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "序/聚合功能，也要考虑增加堆内存。Solr 索引放置在本地磁盘时，注意磁盘空间充足且IO性能良好。\n  * Kafka 对文件系统顺序写较友好，但要确保日志目录有足够空间，同时为 JVM 堆和操作系统页面缓存预留内存。通常 Kafka 本身堆不宜过大（几GB即可），更多依赖操作系统缓存加速磁盘IO。"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#21": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "olrCloud 在防火墙隔离环境，需要开放 Solr 对外查询端口和 Zookeeper 端口。\n* 数据导入与一致性： 首次部署时，需要将已有的商品数据导入 Cassandra 和 Solr。可以通过编写批处理脚本读取原始数据源（如CSV/数据库）写入 Cassandra，然后利用 Solr D"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#22": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "参数。\n  * Solr 可监控查询QPS、索引大小、缓存命中率等，通过接口或 JMX 获取指标。\n  * Kafka 需监控消息堆积情况（Lag）、消费者组状态、磁盘使用等。\n  * Python 微服务应记录关键操作日志（如消费了多少消息、查询耗时多少），并配置守护进程确保异常退出时自动重启。可"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#23": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "broker 挂掉后消息是否仍可正常发送和消费。一旦验证通过，再正式上线运行。\n\n总结与经验教训\n\n通过上述实践，我们成功搭建了一个基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的分布式搜索系统。相比传统单体搜索应用，这种架构具有良好的扩展性和"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#24": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "数据变化频率不高，也可以考虑直接由应用触发 Solr 更新，但引入消息队列使系统更松耦合、可伸缩。\n* 充分的测试验证：集群环境的配置细节繁杂，部署完成后需要反复测试。如曾遇到 Solr 节点无法加入集群，后发现是 ZK 路径配置错误；Kafka 消费延迟过高，追查是因消费者线程处理过慢。通过逐一定"
  },
  "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服#25": {
    "title": "基于 Cassandra、SolrCloud、Zookeeper、Kafka 和 Python 微服务的搜索系统搭建实践",
    "url": "/content/posts/legacy/基于-cassandra-solrcloud-zookeeper-kafka-和-python-微服",
    "date": "2022-02-14",
    "text": "等方式优化）。在我们的实践中，Python 完全能够胜任数据消费和查询API的工作，并且易于维护。\n* 配置与维护：集中管理配置是运维成功的关键。建议将配置文件纳入版本控制，并使用配置管理工具批量部署。对于敏感信息（如密码、密钥），使用加密或配置中心管理。整个系统上线后，要有定期的维护计划，包括 C"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#0": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "多语言智能客服术语翻译解决方案\n\n双管齐下的正确方案概述\n\n要破解多语言客服术语翻译的难题，我们需要将提示词优化和 **检索增强生成（RAG）** 相结合，形成“双管齐下”的解决思路。其中：\n* 提示词优化（Prompt Engineering）：在模型提示词中嵌入整理好的术语翻译表，引导模型参照指"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#1": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "依地给出解释。这种知识增强方法能够显著提高回答的准确性，并避免模型因知识盲区而产生的猜测或幻觉。\n\n通过结合上述两种方法，我们既能在提示阶段校准模型的翻译倾向，又能在生成阶段为模型提供最新最全的术语资料，最大程度上确保内部专业术语被准确翻译和解释。接下来，我们将分别深入探讨这两种方法的原理及实践，并"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#2": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "ew-shot 示例时，将这份术语对照信息嵌入进去。例如，我们可以在系统提示中加入这样一段内容：\n\n通过这样的提示，模型在接收到用户问题后，会参考已经提供的术语对照来生成回答，从而确保这些词汇的翻译和解释与预期保持一致。\n\n这种方法在术语数量较少的情况下非常有效。因为术语不多时，我们完全可以将关键术"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#3": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "导致某些信息无效。此外，企业术语表是动态更新的，新术语不断出现，靠手工更新提示内容也不便于维护。\n\n因此，在实践中，我们通常将提示词优化作为基础手段：保证少量核心术语始终在模型的认知范围内。而对于规模庞大的术语集或者频繁更新的专业名词库，则需要配合更智能的机制，即我们下面讨论的 RAG 检索增强方案"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#4": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "到客服系统中，在用户提问时实时查询相关术语的翻译和解释，并提供给LLM参考。\n\nRAG 原理速览\n\nRAG的流程一般分为两个阶段：检索和生成。首先，系统会根据用户的输入内容进行检索，从知识库中找到最相关的文档片段（在本场景下就是与输入中的专业术语相关的翻译解释条目）。接着，将检索到的结果与原始用户问"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#5": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "术语检索流程\n\n当用户发起一条问句后，引入RAG的智能客服系统会执行下列流程（产品架构角度）：\n1.\t识别查询中的术语：系统首先分析用户的提问内容，检测其中是否包含内部专业术语。可以通过简单的字符串匹配、正则表达，或更先进的分词+词典匹配方法来完成。例如，将用户提问进行分词，只保留那些命中术语库中关"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#6": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "匹配的术语（比如不同语言的同义描述），可以考虑在术语库中维护别名，或使用向量匹配来提高召回率。\n3.\t获取术语翻译和解释：检索到的记录会包含该术语在目标语言下的标准翻译，以及对术语的解释说明。有的系统可能直接存储多语言对照表 ；也有的方案将术语解释文档向量化存储，检索返回整段解释文本供模型参考。这一"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#7": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "为模型增加了“短期记忆”：即便这些术语不在模型训练集中，模型现在也能在回答时引用这些外部知识。\n5.\t生成答案：增强提示准备好后，交由底层的大语言模型（例如 GPT-4、Claude 等）生成最终答复。因为提示中提供了术语翻译和解释，模型会据此进行语言组织，回答中包含正确的译名并适当解释术语涵义。值"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#8": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "在术语库中存储多语言版本的解释，直接根据会话语言选择相应版本，避免模型二次翻译可能引入的偏差。\n6.\t返回结果并优化：最终的答案返回给用户，其中内部术语已被正确翻译。例如，当用户用西班牙语询问一个包含中文内部代号的问题时，系统可识别出该代号对应的官方英文名称及西班牙语解释，将其融入回答。用户将收到一"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#9": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "有数；另一方面，又避免了把大量无关术语一次性注入上下文造成的干扰和成本 。\n\n技术选型与实现细节\n\n在工程实现层面，我们需要搭建起支撑上述流程的各个组件：\n* 术语数据库/知识库：可根据规模和性能要求选择适当的存储方案。如果术语量不大（几千条以内）且主要通过精确匹配检索，一个传统的关系型数据库或No"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#10": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "空间，从而实现跨语言的相似度匹配。无论哪种方案，都需保证查询延迟低、吞吐高，以支撑实时客服的要求。\n* 检索服务：这是连接LLM和知识库的中间层。可以利用LangChain等开源框架来简化实现。LangChain 提供了统一的Retriever接口，支持多种后端（向量库、SQL、NoSQL）的检索操"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#11": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "ptTemplate，我们还能自定义拼接提示的格式，确保术语资料以模型容易理解利用的方式呈现给它。\n* 模型调用与编排：结合提示词优化和RAG后，整个系统的调用流程可以通过一个多步骤Chain或Agent来编排。比如，LangChain 支持定义多步骤的链：第一个步骤执行术语检索（如上所述），第二个"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#12": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "地对接外部工具，更加灵活。不过相对也复杂一些，在术语场景下常规的固定检索->回答链已能够满足需求。\n* 多语言支持：由于面向多语言用户，我们需要处理好源语言和目标语言。通常智能客服会检测用户提问的语言，以便选择适当的回复语言和内容。在术语检索上，也要考虑语言因素。如果术语库记录的是某一主语言的术语映"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#13": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "附带其他语言翻译，查询时无论输入语种如何，都先定位主术语条目，再提取对应语言的翻译和解释供输出。\n\n通过上述组件的协同，我们构建出一个具备术语查询能力的多语言客服引擎。当用户提出的问题涉及内部知识时，系统会“想一想”数据库，查到权威资料后再回答，极大提升了回答的可靠性和专业性。这套机制的引入，从根本"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#14": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "号解释”，以规范模型回答格式。这确保了无论检索结果如何，模型都有遵循既定规则来处理术语的倾向性。\n\n随后，RAG机制又为模型提供了实时的知识支援。即便提示中没覆盖到的术语，检索步骤也会把相关翻译和解释补充上来，让模型在回答时不至于“无词可用”。特别对于那些未曾在对话开头声明的新术语或最新定义，RAG"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#15": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "键术语。就算LLM对某个术语一知半解，检索到的资料也会纠正其倾向，使最终答案中的术语翻译万无一失。\n* 解释完整性增强：由于客服回答需要不仅翻译术语还要解释其含义，模型在有了检索资料后，能够给出更翔实的解释说明。例如，提示词让模型知道术语X译成“产品Alpha”，而检索的结果提供了“产品Alpha是"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#16": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "杜撰大大减少。同时也避免了遗漏术语不答的情况发生——因为模型知道任何不懂的词系统都会提供资料给它。\n* 易于维护和扩展：整个方案中，大部分专业知识维护在术语库中。当有新术语加入、旧术语更新或翻译调整时，只需修改术语库即可，提示模板可能只需很小变动甚至不变。模型本身无需重新训练，维护成本低。而提示词工"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#17": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "与实践案例\n\n从产品架构的角度来看，引入术语机制后的多语言智能客服系统通常呈现出模块化的分层设计：\n1.\t多语言支持层：负责语言检测与转换。例如识别用户消息的语言种类，将用户输入和输出在不同语言间转换。这一层确保了系统可以无缝面向全球用户，但在术语方案中需要与术语库配合处理多语言映射关系。\n2.\t提"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#18": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "gChain，可以将这一层实现为一个独立的Retriever对象，其背后连接着术语库的数据源。\n4.\tLLM对话层：也就是大语言模型调用层。这里通过一个Chain或Agent来 orchestrate 对话：它接收用户输入，调用检索工具层获取扩展信息，然后将完整的提示送入LLM得到结果。LangCh"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#19": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "如果有罕见术语未翻译或用户追问进一步细节，该层也负责将这些信息反馈回步骤2-4，进行下一轮交互。\n\n为了更直观地理解，可以参考某实际案例的架构流程 ：在离线阶段，企业先将自己的多语言术语映射表通过数据管道导入到一个高速数据库中（如 DynamoDB）供实时查询使用；在在线阶段，每当有用户提问进入系统"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#20": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "术语相当于在提示阶段锁定关注点，而数据库检索映射则是典型的RAG操作，两者共同服务于LLM回答。\n\n在工程实践中，一些企业已经成功应用了上述方法。以亚马逊AWS团队分享的方案为例，他们使用 Amazon DynamoDB 存储了海量术语翻译映射，AWS Glue 定期离线处理更新术语数据，在线则通过"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#21": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "题无论包含多少内部代号，都能被准确理解和回应，而客服机器人的回答既有专业水准又通俗易懂。\n\n结语\n\n多语言智能客服要提供卓越的用户体验，离不开对术语翻译和解释机制的重视。内部专业术语承载着企业独有的知识和信息壁垒，如果翻译不当，将成为沟通中的绊脚石。本文提出的“提示词优化 + RAG方案双管齐下”正"
  },
  "/content/posts/legacy/多语言智能客服术语翻译解决方案#22": {
    "title": "多语言智能客服术语翻译解决方案",
    "url": "/content/posts/legacy/多语言智能客服术语翻译解决方案",
    "date": "2024-10-11",
    "text": "据支撑。 这种结合让AI客服系统既有规则指导，又有即时查询能力，达到了静动结合、相辅相成的效果。\n\n对于产品经理和工程师来说，这一方案在实现上具有很高的性价比。我们无须训练定制模型，仅通过构建术语知识库和巧妙的提示设计，就能大幅提升通用LLM在垂直领域、多语言场景下的表现。更重要的是，随着业务的发展"
  },
  "/content/posts/legacy/statistics-foundations-zh#0": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "统计推断基础：从数据到决策\n\n典型的统计分析遵循以下步骤：\n1. **定义问题：** 我们想要揭示的具体真相是什么？（例如，\"新药的真实有效率是多少？\"）\n2. **规划数据收集：** 我们将如何收集相关数据？（例如，设计临床试验或调查。）\n3. **分析数据：** 使用统计模型分析数据并做出推断。"
  },
  "/content/posts/legacy/statistics-foundations-zh#1": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "这突出了一个基本规则：数据必须与问题相关。再复杂的分析也无法从不相关的数据中提取有意义的答案。\n\n统计结论的可靠性也在很大程度上取决于样本量。考虑一个声称新的 250 美元跑鞋显著提高性能的说法。如果《纽约时报》的数据集包含 50 万次跑步时间，涵盖 50 种不同的鞋子，并且始终将这款鞋排名第一，证"
  },
  "/content/posts/legacy/statistics-foundations-zh#2": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "P(\\mathrm{结果}=1) = p$ 和 $P(\\mathrm{结果}=0) = 1-p$。\n当我们说随机变量 $X$ 服从参数为 $p$ 的伯努利分布时，我们写作 $X \\sim \\mathrm{Bernoulli}(p)$。\n\n伯努利模型是统计学的基石。许多复杂模型都基于它构建。例如，如果"
  },
  "/content/posts/legacy/statistics-foundations-zh#3": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "我们样本中成功的比例。这个样本比例是我们对真实概率 $p$ 的自然估计。\n\n**例子：接吻研究**\n一项有趣的研究观察接吻情侣是否倾向于将头偏向右侧或左侧。研究人员收集了 $n=124$ 对情侣的数据，向右偏记录为\"1\"，向左偏记录为\"0\"。在这个数据集中，80 对情侣向右偏。\n\n我们对向右偏情侣比"
  },
  "/content/posts/legacy/statistics-foundations-zh#4": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "结果不会影响另一次试验的结果。\n- **好例子：** 连续投掷公平骰子，或随机拨号电话调查的回应。\n- **坏例子：** 每日股价（今天的价格与昨天的相关）、社交媒体上的\"点赞\"（朋友的行为会相互影响）或同一家庭成员的血压读数（共同的遗传和生活方式）。\n\n当独立性被违反时，大数定律和中心极限定理等标"
  },
  "/content/posts/legacy/statistics-foundations-zh#5": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "特征的不同子群体，我们应该使用更复杂的技术，如分层建模，而不是假设单一、均匀的分布。\n\ni.i.d. 假设是一个强大的简化。良好的实验设计——使用随机化、盲法和仔细抽样——往往旨在创造数据可以合理地被视为 i.i.d. 的条件。\n\n样本均值的性质\n\n样本均值（或样本平均）是最基本的统计量。对于 i."
  },
  "/content/posts/legacy/statistics-foundations-zh#6": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "at p$ 成为 $p$ 的**无偏估计器**。平均而言，我们的估计会命中真实值。\n\n方差（精度）\n当然，任何单次实验都不会完全匹配期望。样本均值的方差告诉我们它预期在真实值周围波动多少。对于方差为 $Var(R_i) = p(1-p)$ 的独立 $R_i$，$\\hat p$ 的方差是：\n$$\\op"
  },
  "/content/posts/legacy/statistics-foundations-zh#7": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "们产生更稳定和精确的估计。\n\n大数定律和中心极限定理\n这些性质导致了统计学中两个最重要的定理：\n1. **大数定律 (Law of Large Numbers, LLN)：** 当样本量 $n$ 无限增大时，样本均值 $\\hat p$ 收敛于真实总体均值 $p$。这保证了有足够的数据，我们的估计将任"
  },
  "/content/posts/legacy/statistics-foundations-zh#8": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "物分子 3D 结构的革命性技术。科学家冷冻并拍摄数十万个单独的蛋白质颗粒，但每个图像都非常嘈杂。\n\n为了重构结构，图像被对齐然后平均。因为每个图像中的噪声是随机和独立的，它在平均过程中相互抵消。然而，蛋白质的微弱潜在信号是一致的，并在平均中得到强化。\n\n这是我们讨论的原理的直接应用：\n- **独立性"
  },
  "/content/posts/legacy/statistics-foundations-zh#9": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "$\\hat p$ 中的不确定性？我们有两个主要工具：理论公式和计算模拟。\n\n1. 解析方法（理论）\n使用概率论，我们可以推导误差度量的精确公式。如我们所见，$\\hat p$ 的标准差，称为**标准误差**，是 $\\sigma_{\\hat p} = \\sqrt{p(1-p)/n}$。这给我们一个估计误"
  },
  "/content/posts/legacy/statistics-foundations-zh#10": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "次实验，每次有 124 对\"情侣\"。在每次实验中，我们生成 124 个随机 0/1 值（$p=0.5$）并计算模拟的 $\\hat p$。通过绘制这 100,000 个模拟 $\\hat p$ 值的直方图，我们得到一个经验分布，显示如果真实比例为 50%，我们可以期望的结果范围。\n\n如果我们实际观察的值"
  },
  "/content/posts/legacy/statistics-foundations-zh#11": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "。\n   - **备择假设 ($H_1$)：** 这是我们想要证明的。这里，$H_1: p > 0.5$（偏向右的偏好）。\n\n2. **计算检验统计量和 p 值：**\n   我们的检验统计量是\"成功\"（向右偏）的数量，即 $X=80$。**p 值**量化这个结果有多极端。它定义为*假设零假设为真，观"
  },
  "/content/posts/legacy/statistics-foundations-zh#12": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "t p\\ge 0.645)\\;=\\;0.00084\\;\\;(\\text{约 }0.084\\%)$\n\n这个模拟 p 值极小。它告诉我们，如果真的没有偏好，我们看到这种偏向右侧的结果的概率不到千分之一。因此，我们有强有力的统计证据拒绝零假设，并得出结论：接吻时向右偏确实存在真实偏好。\n\n假设检验的替代方"
  },
  "/content/posts/legacy/statistics-foundations-zh#13": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "剂），我们可以隔离治疗效果并最小化混杂偏差。随机化是确保 i.i.d. 假设成立的强大工具。\n\n2. **代表性抽样：** 对于观察性研究，目标是获得一个作为总体微型复制品的样本。简单随机抽样是理想的，但分层抽样等策略可能更有效。关键是避免选择偏差。仅通过在线论坛进行的调查可能过度代表特定人群，无法"
  },
  "/content/posts/legacy/statistics-foundations-zh#14": {
    "title": "统计推断基础：从数据到决策",
    "url": "/content/posts/legacy/statistics-foundations-zh",
    "date": "2025-01-24",
    "text": "能太昂贵。在这些情况下，我们必须在约束内找到最佳设计，并在报告结果时对数据限制保持透明。\n\n结论\n\n统计学不仅仅是公式的集合；它是一种关于不确定性和从世界中学习的原则性思维方式。从框定问题和设计实验到建立模型和量化不确定性，每一步都至关重要。通过理解核心假设（如 i.i.d.）和估计器的基本性质，我"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#0": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "从传统图像处理到深度学习：车牌识别系统演进实践\n\n**2. 初版方案：传统图像处理路线**\n\n我们最早的一版系统，其实没有用任何深度学习，就是靠图像处理+逻辑判断“硬撸”出来的。虽然精度不高，但原型很快就能跑起来。\n\n**2.1 滑窗 + OpenCV 做车牌区域检测**\n\n我们用 OpenCV 把"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#1": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "出来了。比如字体粗细变了、字歪了、背景有点反光，全都容易识错。\n\n**2.3 实际遇到的问题**\n\n我们内部测试的时候觉得还凑合，但真上线了就开始掉链子——\n\n• 下雨天车牌有水渍，识别率暴跌；\n\n• 晚上光线暗，边缘提不出来；\n\n• 有些车歪着进场，角度一偏字符就分不准了；\n\n• 模板匹配对字形太"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#2": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "st Text Proposal Network）**。\n\n**3.1 为什么选 CTPN？**\n\n那时候还没有像现在这么多轻量级的 OCR 模型。CTPN 虽然不是最新的，但它是专门做**自然场景中的文本检测**的，特别适合处理那些角度稍歪、背景有干扰的文字区域。而且它的原理比较有意思：不是把整行"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#3": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "牌轻微倾斜，也能正确框出整行字符；\n\n• 遇到遮挡或者局部模糊的车牌，也能保证字符区域尽量完整；\n\n• 最关键的是，字符行出来了之后就**不用再手动分割字符**了！\n\n这对我们后面的字符识别环节简直是质的飞跃。\n\n**3.3 性能表现**\n\nCTPN 本身不算轻量，尤其是在当年的设备环境下（主要是边"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#4": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "NN），但发现效果也不稳定：字符框切得不准就识别错误，而且这种方式对字符的前后顺序毫无理解能力。\n\n所以最终我们上了比较经典的一套组合：**CRNN + CTC**。\n\n**4.1 CRNN 是啥？**\n\n简单说，CRNN（Convolutional Recurrent Neural Network"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#5": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "*不要求字符和位置一一对齐**。也就是说，我们训练的时候只需要提供整张图片对应的文字标签，比如：\n\n<img src=\"/blog/images/legacy/image-2025040201.png\" title=\"\" alt=\"\" width=\"296\">\n\n标签：鲁N Y97L0\n\nCTC 会"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#6": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "符集设计不完善，漏掉了新能源车的“D”“F”前缀；\n\n• 数据分布不均，造成某些字符识别率偏低；\n\n不过整体来说，模型在验证集上的准确率很快就拉到了 95% 左右，最关键的是——在一些传统方法完全识别不出来的场景，它居然能读出来！像那种模糊不清但人眼还能猜的图，它也能成功识别，算是给我们打了一针强心"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#7": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "强的图直接扔掉；\n\n• **人工标注**：用一个简单的图像标注工具，人肉输入每张图的真实车牌号；\n\n• **字符集整理**：收集所有可能的字符，建立一套车牌字符字典（包括新能源前缀、军牌、省份简称等等）；\n\n标注过程真的挺磨人的，不过好在只要首批数据标得够准，后面可以用模型做预标注，再人工纠正，就轻"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#8": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "如遮挡、反光那些，我们后来干脆拉了一批「问题图」单独训练，变成模型的专项强化练习（笑）。\n\n**5.3 数据分布也很重要**\n\n一开始我们犯了个低级错误：数据集中上海车牌（沪A、沪B）占了大头，导致模型总是喜欢猜“沪”。后来我们调整了数据分布比例，让不同省份、不同类型的车牌在训练集里更均匀，这才缓过"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#9": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "；\n\n• /ping：健康检查；\n\n• /reload（内部用）：重新加载模型，方便后面热更新。\n\n每次请求进来就走一套流程：图像预处理 → CTPN → CRNN+CTC → 后处理输出字符串。\n\n虽然有点原始，但胜在简单可靠，后来部署到线下场景也挺稳定的。\n\n**6.2 模型加载和推理效率优化*"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#10": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "hape；\n\n• **预处理和后处理放主线程处理**，只把纯模型推理部分用锁保护，提升并发能力；\n\n这些小改动，虽然不难，但每一条都能救你一口性能。\n\n**6.3 系统联动：识别 + 计费 + 放行**\n\n模型不是孤岛，它得和停车场管理系统打配合。我们这边做了几个联动：\n\n• **入场识别**：摄像"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#11": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "er 服务部署在局域网网关设备上，响应时间更稳，维护也方便。\n\n**7. 实战成效与经验总结**\n\n系统上线那天其实我们还是挺紧张的，尤其是第一家门店，设备一接好，路口刚好就排着三四辆车等着进出，全靠我们模型不给我们“添堵”。\n\n**7.1 系统上线表现**\n\n我们系统最终在实际场景中跑得比预期还要"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#12": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "门卫经常抓狂写错车牌、算错钱，现在每天轻松很多（笑）。\n\n**7.2 遇到的坑（踩过才知道）**\n\n虽然结果不错，但中间也踩了不少坑，这里随便列几个，大家可以避避：\n\n• **模型没做字符合法性校验**，一开始竟然识别出“1A2B3C4”这种根本不存在的车牌号，后来加了正则规则和置信度筛选才缓解；\n"
  },
  "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践#13": {
    "title": "从传统图像处理到深度学习：车牌识别系统演进实践",
    "url": "/content/posts/legacy/从传统图像处理到深度学习车牌识别系统演进实践",
    "date": "2025-04-01",
    "text": "会是：\n\n> OCR 项目从来不是纯模型问题，而是\n> \n> **数据、业务、部署、系统联动**\n\n从传统方法到深度学习，看上去像是“技术升级”，但其实更像是一次「认知升级」：你开始关注更多系统层面的事情，比如服务性能、接口设计、用户体验、甚至运维和日志。\n\n当然，我们这套也不完美，还有很多可以优化"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#0": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant\n\nMy core objective was to address "
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#1": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "s\n\nI designed three highly specialized agents:\n\n1.  **CoderAgent:** Responsible for generating the initial Python code based on user requirements. Its"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#2": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "hen provides specific modification suggestions.\n3.  **OptimizerAgent:** After the code is functionally correct and meets quality standards, this agent"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#3": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "tly,\" I chose AutoGen's powerful `GroupChat` mode. By setting `speaker_selection_method` to `\"auto\"`, I expected the system to act like a project mana"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#4": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "e is the core code snippet for the system setup:\n\nWith the `speaker_selection_method=\"auto\"` setting, my ideal workflow was: `UserProxy` -> `CoderAgen"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#5": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": ", I quickly felt a persistent sense of 'heaviness.' This feeling wasn't from a single issue but a combination of several factors.\n\n2.1. Interaction La"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#6": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "task could involve 5-10, or even more, LLM calls.\n\nIn my daily development work, I need code completions and suggestions in seconds, not the result of"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#7": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "troduce 'intelligence,' but it also brought chaos. I observed several typical problems:\n\n*   **Dialogue Loops:** `CoderAgent` and `QualityAnalyzerAgen"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#8": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "rocess from ever reaching the optimization stage.\n*   **Incorrect Scheduling:** Sometimes, right after `CoderAgent` finished writing the code, `Optimi"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#9": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "e task complete without sufficient optimization.\n\nThis unpredictability turned a tool that was supposed to boost efficiency into a 'black box' that re"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#10": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "hould analyze the latest code from `CoderAgent`.\n\nBut the state of a `GroupChat` is maintained through an ever-growing message history. As the number "
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#11": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "ritical code versions or modification suggestions. I had to meticulously craft prompts, repeatedly reminding agents to \"please focus on the code in th"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#12": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "its role, capabilities, and communication style.\n*   **Flow Design:** Thinking about how to design termination conditions and guide the conversation f"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#13": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "culty is far greater than with traditional code.\n\nThese upfront investment and subsequent maintenance costs are clearly disproportionate for solving a"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#14": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "core strengths of multi-agent systems lie in:**\n\n*   **Specialization and Modularity:** The ability to break down a large, ambiguous task and assign p"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#15": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "ch as product development or scientific research.\n*   **'Emergence' and Creativity:** Free-form discussions between agents can sometimes lead to unexp"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#16": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "technical summary, key players, and future trends.\" Such tasks lack a fixed process, require multiple complex steps like information gathering, integr"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#17": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "ent scripts based on a user requirements document.\" These tasks have long cycles, multiple steps, and can be executed asynchronously. A multi-agent sy"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#18": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "edict the effectiveness of a marketing strategy.\n\n**And for the following scenarios, we should decisively opt for a 'lightweight' approach:**\n\n*   **H"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#19": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "hat` is like using a sledgehammer to crack a nut.\n*   **Scenarios that are extremely sensitive to latency and cost.**\n\n4. Returning to Simplicity: A B"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#20": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": ": Two-Stage Agent Pipeline (Sequential Pipeline)\n\nIf your process is deterministic, like 'code first, then review,' you can organize the agents in a s"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#21": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "tion cost of the auto-selecting `GroupChat`.\n\n4.2. Solution 2: Single Agent with Tools\n\nThis is a more mainstream and practical paradigm for building "
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#22": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "nd 'code optimization' as **tools** it can call.\n\n**The advantages of this pattern are overwhelming:**\n\n*   **Low Latency:** No communication overhead"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#23": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "g a new agent and its complex interaction logic.\n\nConclusion: Finding the Balance Between Complexity and Practicality\n\nMy journey from ambitious desig"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#24": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "ut they are not a silver bullet for every problem. To chase a 'cool-looking' architecture while ignoring real-world efficiency, cost, and controllabil"
  },
  "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro#25": {
    "title": "AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant",
    "url": "/content/posts/legacy/autogen-multi-agent-system-practice-reflection-fro",
    "date": "2025-07-24",
    "text": "ke AutoGen, `GroupChat` is just one of many tools. Learning to make wise choices between 'multi-agent collaboration,' 'sequential pipelines,' and 'sin"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-zh#0": {
    "title": "机器学习超参数调优：从理论到实践的全面指南",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-zh",
    "date": "2024-01-01",
    "text": "机器学习超参数调优：从理论到实践的全面指南\n\n2. 调优手段综述与代码实践\n\n选择合适的调优策略是平衡探索（覆盖更广的搜索空间）和利用（在有希望的区域进行更精细的搜索）的艺术。下面我们逐一深挖各种主流方法，并提供可直接运行的代码骨架。\n\n2.1 网格搜索 (Grid Search)\n\n**核心思路*"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-zh#1": {
    "title": "机器学习超参数调优：从理论到实践的全面指南",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-zh",
    "date": "2024-01-01",
    "text": "样会比线性均匀分布更有效。\n\n2.3 贝叶斯优化 (Bayesian Optimization)\n\n**核心思路**：这是一种更智能的搜索策略。它使用一个概率模型（代理模型）来建模“超参数-性能”函数，并利用历史评估结果来选择下一个最有希望的评估点。这使得它能用更少的迭代次数逼近最优解。`Optun"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-zh#2": {
    "title": "机器学习超参数调优：从理论到实践的全面指南",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-zh",
    "date": "2024-01-01",
    "text": "veHalvingPruner` 是更自然的选择，它们可以将 `epoch` 作为资源维度。\n\n2.5 进化策略 (Population-Based Training, PBT)\n\n**核心思路**：这是一种更高级的混合策略，常见于大规模分布式训练。它并行训练一组模型（一个“种群”），并周期性地用表"
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-zh#3": {
    "title": "机器学习超参数调优：从理论到实践的全面指南",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-zh",
    "date": "2024-01-01",
    "text": "则化强度等超参数，在对数尺度上（如 `1e-5` 到 `1e-1`）进行搜索远比线性尺度高效。\n4.  **可视化与早停**：使用 TensorBoard 或 WandB 等工具监控训练/验证曲线。一旦发现验证损失停止下降或开始上升，就应考虑提前终止训练或增强正则化。\n5.  **借鉴已有成果**："
  },
  "/content/posts/legacy/hyperparameter-tuning-guide-zh#4": {
    "title": "机器学习超参数调优：从理论到实践的全面指南",
    "url": "/content/posts/legacy/hyperparameter-tuning-guide-zh",
    "date": "2024-01-01",
    "text": "a` (TPE) 结合剪枝 (`Pruner`) 或 `Hyperband` 是最高效的选择。\n4.  **拥有大规模分布式集群？** → `Ray Tune` 的 PBT 能发挥最大威力。\n5.  **进行学术研究或需要极致精调？** → 可以探索梯度式超参优化，但要准备好应对其复杂性。\n\n通过将"
  },
  "/content/posts/legacy/法律咨询场景中的大模型微调前评估#0": {
    "title": "法律咨询场景中的大模型微调前评估",
    "url": "/content/posts/legacy/法律咨询场景中的大模型微调前评估",
    "date": "2024-10-05",
    "text": "法律咨询场景中的大模型微调前评估\n\n在决定微调之前，应该尝试通过专业提示词来测试模型在法律问答上的性能。具体步骤包括：\n* 收集代表性咨询问题： 与法律产品团队合作，收集一组具有代表性的法律咨询问题及期望回答。这些问题应涵盖常见法律领域（如合同、劳动、婚姻等）的咨询场景。\n* 设计多样化提示策略： "
  },
  "/content/posts/legacy/法律咨询场景中的大模型微调前评估#1": {
    "title": "法律咨询场景中的大模型微调前评估",
    "url": "/content/posts/legacy/法律咨询场景中的大模型微调前评估",
    "date": "2024-10-05",
    "text": "最佳提示 。如果通过优化提示已能满足大部分咨询场景的需求，那么模型或许无需大幅微调即可投入试用。\n\n在法律场景中，提示设计可以非常具体。例如要求模型回答时列出相关法条依据，或者在回答末尾提醒用户咨询专业律师。这些细节都可以在提示中明确说明。实践中，建议团队准备一个“提示词手册”，总结哪些提示措辞对改"
  },
  "/content/posts/legacy/法律咨询场景中的大模型微调前评估#2": {
    "title": "法律咨询场景中的大模型微调前评估",
    "url": "/content/posts/legacy/法律咨询场景中的大模型微调前评估",
    "date": "2024-10-05",
    "text": "利用提示词工程这一低成本手段，先榨取预训练模型的潜力，再决定是否需要进一步微调。\n\n知识增强架构\n\n技术逻辑： 知识增强架构通常是指基于检索增强的生成（Retrieval-Augmented Generation, RAG）系统。在法律咨询应用中，RAG通过将外部法律知识库与LLM结合，使模型能够检"
  },
  "/content/posts/legacy/法律咨询场景中的大模型微调前评估#3": {
    "title": "法律咨询场景中的大模型微调前评估",
    "url": "/content/posts/legacy/法律咨询场景中的大模型微调前评估",
    "date": "2024-10-05",
    "text": "溯的依据。\n\n评估方法： 在微调前，评估是否通过引入知识增强架构即可满足需求，可以从以下方面入手：\n* 准备法律知识库： 整理一套权威的法律文本资料，例如现行法律法规条文、典型判例摘要、司法解释等，将其加载进检索系统（如向量数据库）。注意数据需要结构化处理，如按条款或判决要点分段存储，方便精准检索。"
  },
  "/content/posts/legacy/法律咨询场景中的大模型微调前评估#4": {
    "title": "法律咨询场景中的大模型微调前评估",
    "url": "/content/posts/legacy/法律咨询场景中的大模型微调前评估",
    "date": "2024-10-05",
    "text": "关法规后回答往往更切题。 指出在法律服务中，RAG可以调取相关案例法或法规以辅助模型回答法律查询。\n* 评估系统复杂度和收益： 同时考虑实现成本：引入RAG需要维护更新法律数据库和检索服务，增加了一定系统复杂性。但如果评估发现其对回答准确性的提升显著（例如错误率降低、引用法条准确率提高)，那么这一步"
  },
  "/content/posts/legacy/法律咨询场景中的大模型微调前评估#5": {
    "title": "法律咨询场景中的大模型微调前评估",
    "url": "/content/posts/legacy/法律咨询场景中的大模型微调前评估",
    "date": "2024-10-05",
    "text": "落。总之，知识增强架构在法律AI产品中往往是性价比很高的选择，在正式微调模型前应认真验证其效果。\n\nRetrieval Augmented Generation (RAG) 架构示意图：流程1（左）表示将法律知识文档预处理并向量化存入知识库；流程2（下）表示用户提问后系统检索相关向量并将结果与查询一"
  },
  "/content/posts/legacy/法律咨询场景中的大模型微调前评估#6": {
    "title": "法律咨询场景中的大模型微调前评估",
    "url": "/content/posts/legacy/法律咨询场景中的大模型微调前评估",
    "date": "2024-10-05",
    "text": "关性指数据的内容确实属于法律咨询范畴；代表性则意味着数据涵盖主要的法律领域和问题类型，避免偏科。\n\n评估方法： 针对数据准备情况，采取以下评估步骤：\n* 统计数据量与分布： 首先盘点用于微调的法律问答数据有多少条，以及来源构成。例如，包含多少对问答、涵盖哪些法律主题，每个主题的数据量占比如何。这一步"
  },
  "/content/posts/legacy/法律咨询场景中的大模型微调前评估#7": {
    "title": "法律咨询场景中的大模型微调前评估",
    "url": "/content/posts/legacy/法律咨询场景中的大模型微调前评估",
    "date": "2024-10-05",
    "text": "甚至下降，表明现有数据已接近饱和或存在质量问题，与其一味增加数据量，不如优化数据质量或内容多样性。\n* 检查数据质量与覆盖： 抽样审查一些训练数据的问答对，确保答案内容专业正确，无违背法律常识的错误。同时评估数据覆盖的场景：例如是否既有简明的法律咨询（如咨询离婚手续），也有复杂案例分析（如特定案情的"
  },
  "/content/posts/legacy/法律咨询场景中的大模型微调前评估#8": {
    "title": "法律咨询场景中的大模型微调前评估",
    "url": "/content/posts/legacy/法律咨询场景中的大模型微调前评估",
    "date": "2024-10-05",
    "text": "微调前，数据评估是一道不可跳过的关卡——只有当数据储备充足且合适，微调才能发挥预期效益。\n\n结语\n\n在法律咨询场景下开发大语言模型，贸然进行大规模微调并非总是最优策略。通过在前期仔细评估提示词工程、知识增强架构和数据规模这三大要素，团队可以更明智地制定方案：能用提示优化解决的，就不必动用微调；能通过"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#0": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System\n\nDuring the initial architecture design, I followed several cor"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#1": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "epeated task execution produces no side effects\n4. **Scalability**: Easy to add new news sources or processing steps\n\nTechnical Architecture\n\nBased on"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#2": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "rates Chinese summaries → `summary_{date}.json`\n4. **Markdown Generation** → Organized by category → `news_{date}.md`\n5. **Git Publishing** → Push to "
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#3": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "ent\n- URLs may differ due to tracking parameters\n\nThe solution is **semantic-based vector deduplication**:\n\nThis method effectively identifies article"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#4": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "ch LLM to choose, but how to design **Prompts**:\n\nThrough clear roles, detailed instructions, and output format requirements, we achieve stable, high-"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#5": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "e is a Git commit, providing clear change records\n- **Decoupling and Security**: The bot only needs Git repository write permissions, no need to expos"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#6": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "are needed:\n\n1. Define News Content Collection\n\n2. Create LatestNews Component\n\n3. Fix Dynamic Route Rendering\n\nDue to structural changes in entry obj"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#7": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "during page rendering\n\nDiverse Execution Methods\n\nTo adapt to different deployment environments, I designed multiple execution methods:\n\n1. Direct Exe"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#8": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "y\n- OpenAI cost: ~$0.01-0.05/day\n\nLog Management\n\nProject Value and Results\n\nTest Validation Results\n\nLatest test (2025-07-26):\n- ✅ **Fetcher**: Retri"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#9": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "d to blog repository\n\nNews Classification System\n\nThe system automatically categorizes news into 9 tech domains:\n- 🤖 Artificial Intelligence\n- 📱 Mob"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#10": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "ver and recommend new high-quality news sources\n2. **Trend Analysis & Topic Aggregation**: Identify hot topics within specific time periods and aggreg"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#11": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "se technology to solve your own problems\" project. It organically combines AI, automation scripts, modern web development frameworks (Astro), and DevO"
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#12": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "atabases, GitOps, and other emerging technologies. If you want to build a similar system, I hope this article provides some inspiration and reference."
  },
  "/content/posts/legacy/astro-news-bot-technical-practice#13": {
    "title": "Astro-News-Bot: Building an AI-Driven Automated News Aggregation and Publishing System",
    "url": "/content/posts/legacy/astro-news-bot-technical-practice",
    "date": "2024-01-01",
    "text": "ts + Cron Jobs\n- **Data**: JSON + Markdown + Git\n\nThe entire system embodies modern AI application development best practices: modular design, vectori"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#0": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践\n\n值得一提的是，OpenAI的研究者将幻觉分为两类： \n* 上下文内幻觉：模型应该严格依据给定的上下文内容回答，如果输出与提供的资料不一致，就是出现了幻觉。\n* 外在幻觉：模型输出应该基于它的世界知识（预训练知识）。当模型给出超出其知识范围且"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#1": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "建议。如果模型因为幻觉编造了不存在的症状或误判检查结果，医生若未察觉就可能基于错误信息做出误诊。\n\n幻觉案例：在医疗文本处理中已经观察到模型幻觉的真实例子。例如，有研究让GPT-4模型对50份详细病历生成摘要，结果发现GPT-4生成的摘要中有42%（21份）包含错误的医学信息 。另一个案例是一款医疗"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#2": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "antibiotics”（超活性抗生素） ！这类幻觉显然可能误导医护人员，对患者造成潜在危险。\n\n后果分析： 医疗AI一旦出现幻觉且未被及时发现，后果是严重的。误写一项关键化验指标，可能让医生漏诊重要疾病；编造不存在的药物，可能导致用药错误。患者安全与生命健康受到直接威胁。此外，从业人员对AI工具的"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#3": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "之别。如果AI在起草合同时产生幻觉，可能会虚构法律条款、扭曲原意或模棱两可，给用户带来法律风险。\n\n幻觉案例：一个典型例子发生在2023年，美国纽约有律师尝试用ChatGPT撰写法律诉状，结果ChatGPT在文件中引述了六个完全不存在的虚假判例作为参考 。这些案例名字听起来有模有样，但经对方律师和法"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#4": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "众角度，一旦因AI错误导致权益受损，谁来担责也会成为棘手问题——这在后文的治理部分我们还将讨论。\n\n场景三：教育领域历史知识问答系统\n\n场景特点： 在教育场景中，AI常被用作智能问答助手，回答学生的提问或辅助教师备课。对于历史这类知识型问答，准确性和可靠性同样至关重要。AI如果输出错误信息，可能直接"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#5": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "早在它发射前16年就已拍摄 。这个张冠李戴的错误当时引发了轩然大波，甚至导致谷歌股价在第二天重挫7.7%（市值蒸发近1000亿美元） 。可见即使是大厂的顶尖模型，在知识问答上也会犯常识性错误。另外，在课堂上也出现过AI幻觉的离谱事件：美国一位大学教师用ChatGPT检查学生论文是否为AI创作时，Ch"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#6": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "保内容真实可靠，否则“AI助教”就可能变成传播谬误的扩音器，适得其反。\n\n减少幻觉风险的技术实践\n\n面对AI幻觉风险，开发者和产品设计者可以从技术上采取多种措施加以防范。以下是几项关键的实践方法：\n* 提示设计优化：精心设计Prompt（提示）可以在一定程度上缓解幻觉。首先，应提供尽可能明确和详细的"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#7": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "示例：\n\n可以看到，改进后的提示明确了身份和任务，并强调了不允许胡乱编造，从而降低幻觉的可能性。\n\n* 模型微调与知识注入：通过微调（Fine-tuning）模型或注入权威知识，可以让模型的输出更加可信。在高风险领域，开发者可以收集领域数据（如医学病例、法律法规文本、权威百科资料）对预训练模型进行微"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#8": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "模型。尽管微调和知识注入不能百分百消除幻觉，但在关键领域下经过专门调教的模型确实更不容易张口就来。\n* 检索增强生成（RAG）：目前公认行之有效的办法是采用Retrieval-Augmented Generation（检索增强生成）架构 。其核心思想是：不让模型闭门造车，而是先查资料。实现上，系统会"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#9": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "hain等）构建RAG管道。在RAG模式下，模型更像一个“阅读理解”系统：先查再答，而非凭空生成。\n* 结果置信度评估与人类审校：对于高风险场景，绝不能让AI给出结果就直接用于决策，增加结果的评估与审核环节是必要的。开发者可以尝试让模型对自己的回答给出一个置信度评分或列出支撑其回答的依据。如果模型对"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#10": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "核AI起草的合同并承担责任。这样的机制能将幻觉风险降到最低。\n\nAI治理与伦理：责任划分与透明度\n\n在技术之外，治理和伦理框架同样是高风险AI应用中不可或缺的一环。首先是责任划分问题：当AI提供错误信息导致损害时，谁来承担责任？一般认为，最终责任应由使用决策的人类专家承担，因为AI目前被定位为辅助工"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#11": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "企业也应明确告知用户模型的局限性，包括可能出现幻觉，并在服务协议中说明不当使用的风险和各方责任。\n\n其次是透明度的建立。在医疗、法律、教育场景中，引入AI系统应该是一个透明的决策。相关利益方（患者、客户、学生）有权知情：他们面对的是AI生成的内容。实践中，可以通过标识和解释来增强透明度。比如医疗报告"
  },
  "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践#12": {
    "title": "防范 AI 幻觉：在医疗、法律与教育场景中的应用安全实践",
    "url": "/content/posts/legacy/防范-ai-幻觉-在医疗-法律与教育场景中的应用安全实践",
    "date": "2024-10-01",
    "text": "质量等。这些治理举措的目的都是为了降低AI幻觉引发的危害，在鼓励创新的同时守住安全底线。\n\n总结\n\nAI幻觉是当前大语言模型的一大挑战，尤其在医疗、法律、教育这类容错率极低的场景下，我们必须慎之又慎。本文剖析了幻觉产生的技术原因，并通过真实案例展示了幻觉在不同领域可能造成的严重后果。好消息是，我们并"
  },
  "/content/posts/legacy/building-intelligent-content-management-pipeline-f#0": {
    "title": "Building an Intelligent Content Management Pipeline from Obsidian to Notion: A Three-Layer Architecture for Knowledge Automation",
    "url": "/content/posts/legacy/building-intelligent-content-management-pipeline-f",
    "date": "2024-01-01",
    "text": "Building an Intelligent Content Management Pipeline from Obsidian to Notion: A Three-Layer Architecture for Knowledge Automation\n\nLayer Responsibility"
  },
  "/content/posts/legacy/building-intelligent-content-management-pipeline-f#1": {
    "title": "Building an Intelligent Content Management Pipeline from Obsidian to Notion: A Three-Layer Architecture for Knowledge Automation",
    "url": "/content/posts/legacy/building-intelligent-content-management-pipeline-f",
    "date": "2024-01-01",
    "text": "ssing Layer: Claude Code / Gemini CLI Integration\n\nClaude Code Integration\n\n**MCP Tool Configuration**\n\n**Usage Example**\n\nGemini CLI Integration\n\n**I"
  },
  "/content/posts/legacy/building-intelligent-content-management-pipeline-f#2": {
    "title": "Building an Intelligent Content Management Pipeline from Obsidian to Notion: A Three-Layer Architecture for Knowledge Automation",
    "url": "/content/posts/legacy/building-intelligent-content-management-pipeline-f",
    "date": "2024-01-01",
    "text": "omplete Automation Script\n\nAutomation Deployment\n\n**cron Scheduled Tasks**\n\n**systemd Service**\n\nKey Limitations & Best Practices\n\nPlatform Limitation"
  },
  "/content/posts/legacy/building-intelligent-content-management-pipeline-f#3": {
    "title": "Building an Intelligent Content Management Pipeline from Obsidian to Notion: A Three-Layer Architecture for Knowledge Automation",
    "url": "/content/posts/legacy/building-intelligent-content-management-pipeline-f",
    "date": "2024-01-01",
    "text": "plement retry mechanisms for network fluctuations\n   - Log detailed information for troubleshooting\n   - Set timeout controls to avoid long-term block"
  },
  "/content/posts/legacy/building-intelligent-content-management-pipeline-f#4": {
    "title": "Building an Intelligent Content Management Pipeline from Obsidian to Notion: A Three-Layer Architecture for Knowledge Automation",
    "url": "/content/posts/legacy/building-intelligent-content-management-pipeline-f",
    "date": "2024-01-01",
    "text": "API Key Management**\n   \n\n2. **Network Security**\n   - Bind Obsidian REST API to local address only\n   - Use HTTPS and strong passwords to protect end"
  },
  "/content/posts/legacy/building-intelligent-content-management-pipeline-f#5": {
    "title": "Building an Intelligent Content Management Pipeline from Obsidian to Notion: A Three-Layer Architecture for Knowledge Automation",
    "url": "/content/posts/legacy/building-intelligent-content-management-pipeline-f",
    "date": "2024-01-01",
    "text": "xtended Application Scenarios\n\nBidirectional Sync\nIf you need to sync Notion updates back to Obsidian later, you can implement a reverse pipeline:\n\nMu"
  },
  "/content/posts/legacy/building-intelligent-content-management-pipeline-f#6": {
    "title": "Building an Intelligent Content Management Pipeline from Obsidian to Notion: A Three-Layer Architecture for Knowledge Automation",
    "url": "/content/posts/legacy/building-intelligent-content-management-pipeline-f",
    "date": "2024-01-01",
    "text": "uth, unified management of all markdown content\n2. **Intelligent Processing**: AI tools automatically generate summaries and analysis, enhancing conte"
  },
  "/content/posts/legacy/building-intelligent-content-management-pipeline-f#7": {
    "title": "Building an Intelligent Content Management Pipeline from Obsidian to Notion: A Three-Layer Architecture for Knowledge Automation",
    "url": "/content/posts/legacy/building-intelligent-content-management-pipeline-f",
    "date": "2024-01-01",
    "text": "l intervention, ensuring content synchronization\n\nThrough this system, knowledge workers can focus on content creation while delegating repetitive org"
  },
  "/content/posts/legacy/building-intelligent-content-management-pipeline-f#8": {
    "title": "Building an Intelligent Content Management Pipeline from Obsidian to Notion: A Three-Layer Architecture for Knowledge Automation",
    "url": "/content/posts/legacy/building-intelligent-content-management-pipeline-f",
    "date": "2024-01-01",
    "text": "ficiency.\n\nIs it worth the investment? Absolutely. This pipeline not only solves the pain point of multi-platform content synchronization but more imp"
  },
  "/content/posts/legacy/构建obsidian到notion的智能内容管理流水线#0": {
    "title": "构建Obsidian到Notion的智能内容管理流水线：三层架构实现知识自动化处理",
    "url": "/content/posts/legacy/构建obsidian到notion的智能内容管理流水线",
    "date": "2024-01-01",
    "text": "构建Obsidian到Notion的智能内容管理流水线：三层架构实现知识自动化处理\n\n层次职责分析\n\n详细技术实现方案\n\n1. 内容源层：Obsidian 配置\n\n安装必要插件\n\n**Local REST API 插件**\n\n**Advanced URI 插件**\n\nAPI 端点配置\n\n安装 Loc"
  },
  "/content/posts/legacy/构建obsidian到notion的智能内容管理流水线#1": {
    "title": "构建Obsidian到Notion的智能内容管理流水线：三层架构实现知识自动化处理",
    "url": "/content/posts/legacy/构建obsidian到notion的智能内容管理流水线",
    "date": "2024-01-01",
    "text": "stemd 服务**\n\n关键限制与最佳实践\n\n平台限制\n\n性能优化建议\n\n1. **批处理策略**\n   - 按主题归并相关笔记后再处理\n   - 使用增量同步，只处理变更内容\n   - 实现智能去重，避免重复处理\n\n2. **错误处理**\n   - 实现重试机制，处理网络波动\n   - 记录详细日"
  },
  "/content/posts/legacy/构建obsidian到notion的智能内容管理流水线#2": {
    "title": "构建Obsidian到Notion的智能内容管理流水线：三层架构实现知识自动化处理",
    "url": "/content/posts/legacy/构建obsidian到notion的智能内容管理流水线",
    "date": "2024-01-01",
    "text": "工具配置**\n\n**第四步：运行测试**\n\n**第五步：自动化部署**\n\n扩展应用场景\n\n双向同步\n如果后续需要把 Notion 的更新同步回 Obsidian，可以实现反向流水线：\n\n多源集成\n支持从多个数据源收集内容：\n\n总结\n\n这个三层架构的内容管理流水线实现了：\n\n1. **集中管理**：O"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#0": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?\n\n¹ **Dynamic Message Limits**: Pro and Max message limits are not fixed values but "
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#1": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "e the applicable scenarios for different models.\n\n**Impact on Claude Code**:\n- **Subscription**: Perfect for **interactive coding scenarios** like cod"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#2": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "*: Using Sonnet or Opus to analyze Pull Requests.\n  - **Codebase intelligent Q&A systems**: Combining RAG (Retrieval-Augmented Generation) with Haiku/"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#3": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "pical moderate-complexity coding interaction (e.g., pasting a 200-line file, asking a question, receiving code and explanation) consumes approximately"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#4": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "s API) ≈ $0.60**\n\n**Break-even Point Analysis**:\n\n- **Claude Pro ($20/month)**:\n  - $20 / $0.60 ≈ **33 interactions/month**.\n  - If your monthly high-"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#5": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "0.60 ≈ **333 interactions/month** (premium price)\n  - If your monthly interactions are between 33-167, Pro remains the best choice. If far exceeding 1"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#6": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "users**: Pro/Max subscriptions are clear winners. You don't need to worry about per-question costs and can explore and iterate more freely.\n- **Enterp"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#7": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "0.12**, while Haiku costs less than **$0.01**.\n\n4. Special Scenario Analysis: Claude Selection Strategy for Heavy ChatGPT Users\n\nFor many users who ar"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#8": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "choose the $20/month Pro subscription, or directly use its API?\n\nThis \"Hybrid AI Usage\" model—using ChatGPT as the general-purpose workhorse and Claud"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#9": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "tion.\" A typical programming task might include:\n\n- **Input**: Pasting a piece of code (e.g., 200 lines of Python code), an error log, feature require"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#10": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "tely 150-200 lines of code + problem description)\n- **Average Output Tokens**: 1,000 tokens (approximately 40-50 lines of code + explanation)\n\n**API P"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#11": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "$0.135 / session**\n\n**Monthly cost calculation:**\nThis user's usage frequency is \"moderate to heavy,\" we take the middle value, assuming **3 sessions "
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#12": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "ssion ≈ 148 sessions`\n- This equals `148 / 30 ≈ 4.9` sessions/day.\n\nThis means, **only when you consistently conduct about 5 or more heavy-duty coding"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#13": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "the API model's cost advantage is very obvious.\n\n*Note: If using the more economical Claude 3 Sonnet model (API price about 1/5 of Opus), the API cost"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#14": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "xperience.\n\n4.3 Recommendations for Hybrid Users\n\nCombining cost and experience, we provide the following specific recommendations for \"hybrid users\":"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#15": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "far exceeds switching between browser and editor. Managing API Keys and using related tools has a low barrier for developers.\n   - **Action Path**: Re"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#16": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "rience.\n\n2. **Specific Scenarios for Claude Pro**\n   Despite API's clear advantages, Pro subscription might be more suitable in these situations:\n   -"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#17": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "on't want to write additional processing scripts.\n   - **Absolute technical avoidance**: You don't want to manage any API Keys or configurations, just"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#18": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "s a programming-specific tool is adopting its API. This approach achieves dual optimization of cost-effectiveness and workflow efficiency, allowing yo"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#19": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "ccasional Use**: Start with **API pay-as-you-go**. Set a low budget (like $10/month), experience different model capabilities.\n2. **Daily Dependence P"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#20": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "ption status, immediately start using **API**.\n\n6.2 Upgrade Path Recommendations\n\nA typical developer growth path might be:\n\n`API (exploration) -> Cla"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#21": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "call management (enterprise-level)`\n\nConclusion\n\nChoosing Claude Pro/Max subscription versus API is not an either-or decision, but a strategic choice "
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#22": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "-frequency, exploratory conversational workflows.\n- **API** provides you with an **\"infinitely scalable intelligent engine\"**, the foundation for buil"
  },
  "/content/posts/legacy/claude-code-pricing-comparison-en#23": {
    "title": "Claude Code Pricing Analysis: Subscription vs API - How to Choose?",
    "url": "/content/posts/legacy/claude-code-pricing-comparison-en",
    "date": "2025-07-24",
    "text": "egration, transitioning to API becomes inevitable. For users already heavily dependent on Claude for daily work, **Claude Max** provides greater freed"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#0": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏\n\n将RPG Maker与OpenAI API相结合，可以开发出前所未有的动态游戏体验。通过引入AI来生成内容，游戏世界不再局限于设计者的预设，而能根据玩家的操作和输入即时改变。下面我们来看看这种集成能够带来哪些具体优势：\n"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#1": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "以与NPC展开多轮对话——NPC会“记住”之前交谈的内容，使对话连贯且富有逻辑，提高玩家的沉浸感。\n* 游戏教程和帮助：在游戏过程中，玩家难免会遇到困惑或瓶颈。通过引入ChatGPT这样的AI，我们可以为游戏添加一个智能帮助系统。当玩家向游戏内的“指南精灵”或帮助菜单提出问题时，AI可以根据游戏当前"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#2": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "nAI API，开发者可以让NPC实时分析游戏状态并生成合理的反应逻辑，使NPC形象更加立体鲜活。\n* 自适应剧情和难度：每个玩家的游戏风格不同，AI可以根据玩家的选择动态调整游戏的剧情分支和难度曲线。例如，当AI检测到玩家总是喜欢探索支线剧情时，可以生成更多有趣的支线任务；如果玩家在战斗中节节取胜"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#3": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "将AI融入RPG游戏的魅力，我们可以尝试先做一个小型的原型Demo。以下是一个基本的实现流程：\n1. 准备工作：首先，确保你已安装最新版本的RPG Maker（如RPG Maker MV或MZ），因为这些版本使用JavaScript作为脚本语言，方便与Web API交互。此外，前往OpenAI官方网"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#4": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "作为我们测试AI对话的舞台。简单的环境即可，无需耗费太多时间美化地图——我们的重点是功能验证。\n3. 编写脚本以集成 OpenAI API：接下来，我们需要编写代码让游戏能够和OpenAI的服务器通信。在RPG Maker MV/MZ中，你可以通过编写**插件（Plugin）**的方式加入自定义Ja"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#5": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "请求。\n下面是一段使用fetch调用OpenAI Chat Completion接口的示例代码：\n\n上面这段代码向OpenAI的服务器发送了一条对话：我们设定system角色提示AI扮演村长NPC，并提供了user角色的一句话（模拟玩家的提问），然后模型会生成NPC（assistant角色）的回答。"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#6": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "AI接口。利用OpenAI提供的Python库，几行代码就能完成与上述JS代码等价的操作，例如：\n\n无论使用哪种语言，实现的关键都是：构造请求 -> 发送请求 -> 接收并处理回复。确保你的请求数据格式符合OpenAI API要求，例如Chat Completion需要一个messages列表。拿到"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#7": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "令将回答呈现出来。举个简单的方法：可以预先在数据库中预留一个变量，比如变量编号1，用于存储AI回复。在脚本拿到reply后，执行$gameVariables.setValue(1, reply)将内容存入变量1。接着在事件里插入一个“显示文字”的指令，内容填入\\V[1]，RPG Maker会将其替换"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#8": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "由NPC先问玩家一个问题，然后根据玩家选择的选项去构造不同的提示给AI，从而得到相应回答。\n* 5. 测试和调试：现在运行游戏，和NPC对话，看看效果如何。第一次集成可能不会一蹴而就，所以需要反复测试和调试。如果NPC没有回应，或者游戏卡住了，可以打开调试控制台（在游戏窗口按下F12，在Consol"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#9": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "PC的动态对话作为切入点。下面通过一个简单示例，再次梳理如何让NPC基于OpenAI生成对话回应：\n* 步骤1：创建NPC交互事件：在地图场景中，选中我们的NPC村长，打开事件编辑器。将事件的触发设置为“与玩家交谈”（即玩家按下确定键触发）。在事件内容中，我们可以先加入一段NPC开场白，比如：“村长"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#10": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": ")，将玩家的问题字符串传递进去。脚本会将问题打包成请求发送给OpenAI，并等待返回NPC的回答。\n* 步骤3：显示AI生成的NPC回答：脚本拿到OpenAI的回复后，会通过我们预先设定的方式将回答注入游戏。例如，脚本内将回答存入变量1。现在在事件编辑器中，我们添加一个“显示文字”命令，用于呈现NP"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#11": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "里总在夜里出现奇怪的蓝光，据说那是精灵在嬉戏，但也有人说可能藏着宝藏。\n玩家：有关于魔王的传闻吗？\n村长（AI生成）：魔王的传闻倒是久远的很。据我祖父说，百年前这里的人们曾联手击败过一位魔王的爪牙。不过最近倒是风平浪静，年轻人不用过于担心。\n从上面的对话可以看到，借助AI，NPC能够根据玩家提出的不"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#12": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "RPG Maker和OpenAI API还可以创造出更多新奇有趣的玩法。以下是几个值得尝试的思路：\n* 动态剧情和支线任务生成：让AI承担部分“编剧”职责，根据游戏进程动态生成新的剧情段落或支线任务。例如，当玩家抵达某个阶段时，调用AI根据当前世界状态生成一个全新的任务描述：“镇长请求你去调查最近袭"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#13": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "，营造出持续互动的真实感。实际上，这相当于为NPC赋予了状态，通过AI的上下文机制来维持这种状态。\n* 基于玩家行为的剧情分支：利用AI分析玩家在游戏中的所作所为，实时调整剧情走向。比如，玩家如果一直扮演一个行侠仗义的角色，AI可以在后续剧情中引入更多需要英雄主义的桥段，甚至生成一个专属的正义结局。"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#14": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "AI的发挥既天马行空又不至于偏离游戏的基本规则，但一旦实现，将使游戏的自由度达到一个全新的高度。\n\n以上创意并非易事，但它们展示了AI在游戏开发领域的巨大潜力。开发者可以从小处着手，逐步将这些想法融入自己的项目中。随着对OpenAI API使用的日趋熟练，你完全可以尝试让AI承担更多游戏内容创作的重"
  },
  "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏#15": {
    "title": "结合RPG Maker与OpenAI API，打造创意十足的动态角色扮演游戏",
    "url": "/content/posts/legacy/结合rpg-maker与openai-api-打造创意十足的动态角色扮演游戏",
    "date": "2025-02-28",
    "text": "建了一个动态对话的原型示例，可以看到哪怕只是加入一个简单的AI对话，游戏的趣味性也有了显著提升。\n\n对于开发者来说，这样的尝试具有非常高的回报：投入一些时间学习并集成API，就可能让你的作品脱颖而出，给予玩家前所未有的新鲜体验。当然，过程中也会遇到一些挑战，例如API调用的延迟和费用、AI回复的不可"
  },
  "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查#0": {
    "title": "从 404 到 200：记一次 Astro + GitHub Pages 样式丢失问题的深度排查",
    "url": "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查",
    "date": "2024-01-01",
    "text": "从 404 到 200：记一次 Astro + GitHub Pages 样式丢失问题的深度排查\n\n这些 CSS 文件的路径看起来像这样：\n\n问题很明确：服务器无法找到 Astro 构建出来的 CSS 文件。但为什么呢？\n\n二、漫漫排查路：错误的假设\n\n我的排查过程遵循了典型的从易到难、从普遍到特殊"
  },
  "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查#1": {
    "title": "从 404 到 200：记一次 Astro + GitHub Pages 样式丢失问题的深度排查",
    "url": "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查",
    "date": "2024-01-01",
    "text": "结果**：清理缓存，重新部署，问题依旧。`_astro` 目录下的 CSS 文件仍然是 404。\n\n这个结果让我很困惑。`.nojekyll` 应该已经禁用了 Jekyll，为什么以下划线开头的资源还是无法访问？\n\n假设 2：目录访问问题？\n\n我开始怀疑是不是 `_astro` 目录本身因为某些服务"
  },
  "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查#2": {
    "title": "从 404 到 200：记一次 Astro + GitHub Pages 样式丢失问题的深度排查",
    "url": "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查",
    "date": "2024-01-01",
    "text": "盖 GitHub Pages 服务器的所有规则。\n\n经过一番搜索和验证，我终于发现了问题的关键：\n\n> **GitHub Pages (或其底层的 Web 服务器) 有一条更深层的规则：它会阻止所有对以下划线 (`_`) 开头的文件的直接访问，这似乎是一个安全或约定策略，独立于 Jekyll 的行为"
  },
  "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查#3": {
    "title": "从 404 到 200：记一次 Astro + GitHub Pages 样式丢失问题的深度排查",
    "url": "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查",
    "date": "2024-01-01",
    "text": "来定制构建行为。\n\n配置方案\n\n具体的配置项是 `vite.build.rollupOptions.output.assetFileNames`。它可以让我们完全控制资源文件（如 CSS、图片等）的输出路径和名称。\n\n打开项目根目录下的 `astro.config.mjs` 文件，添加 `vite`"
  },
  "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查#4": {
    "title": "从 404 到 200：记一次 Astro + GitHub Pages 样式丢失问题的深度排查",
    "url": "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查",
    "date": "2024-01-01",
    "text": "行 `npm run build`，然后将 `dist` 目录部署到 GitHub Pages：\n\n**结果**：成功！CSS 文件现在以 `assets-slug_.BvCO7WHQ.css` 这样的路径加载，HTTP 状态码从 404 变成了 200。网站样式完美呈现。\n\n我们可以通过以下命令验"
  },
  "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查#5": {
    "title": "从 404 到 200：记一次 Astro + GitHub Pages 样式丢失问题的深度排查",
    "url": "/content/posts/legacy/从404到200记一次astrogithubpages样式丢失问题的深度排查",
    "date": "2024-01-01",
    "text": "Vite）通常都提供了强大的配置选项。深入阅读文档、了解这些配置项，是解决复杂问题的金钥匙。\n\n4. **下划线是特殊字符**：在 Web 开发中，以下划线开头的文件/目录通常有特殊含义（如 Jekyll, Node.js 的私有模块等）。在命名和部署时要特别留意，避免与平台规则冲突。\n\nDebug"
  },
  "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式#0": {
    "title": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式",
    "url": "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式",
    "date": "2025-07-24",
    "text": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式\n\n经过多次实践与迭代，我摸索出了一套行之有效的 **\"ChatGPT + Claude Code 混合开发工作流\"**。这套工作流的核心思想是 **\"规划与执行分离，人类主导决策\"**，它将Chat"
  },
  "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式#1": {
    "title": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式",
    "url": "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式",
    "date": "2025-07-24",
    "text": "构、技术选型和实现路径。这份蓝图是整个项目的\"唯一真相来源\"，确保了后续开发的方向性和一致性。\n2.  **迭代可控，敏捷开发 (Controlled Agility)**：我们将宏大的目标拆解成蓝图中一个个具体、可执行的步骤。每一步都在开发者的监督下完成，这天然地形成了一个\"编码-审查-确认\"的微"
  },
  "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式#2": {
    "title": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式",
    "url": "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式",
    "date": "2025-07-24",
    "text": "稳健的代码生成能力，在具体实现上表现更优。混合工作流正是要让它们在各自最擅长的领域发挥最大价值。\n\n二、 工作流详解：从蓝图到代码的两大阶段\n\n这套工作流被清晰地划分为两个主要阶段：**蓝图规划阶段** 和 **分步实现阶段**。\n\n阶段一：与ChatGPT对话，共创项目蓝图 (The Bluepr"
  },
  "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式#3": {
    "title": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式",
    "url": "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式",
    "date": "2025-07-24",
    "text": "演一位资深技术架构师，和我一起规划这个项目。首先，让我们来明确一下它的核心功能和技术选型。\"\n\n2.  **多轮迭代，深化细节 (Iterative Refinement)**：通过追问、提供反馈和注入新想法，与ChatGPT进行多轮对话。这个过程就像与一位真正的架构师进行头脑风暴。\n    *  "
  },
  "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式#4": {
    "title": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式",
    "url": "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式",
    "date": "2025-07-24",
    "text": "将所有讨论结果整理成一份结构化的\"开发蓝图\"。这是本阶段最重要的产出物。\n\n最佳实践与蓝图模板：\n\n*   **赋予角色**：让ChatGPT扮演特定角色（如\"资深架构师\"、\"产品经理\"）能显著提升回答的专业性。\n*   **保持对话**：不要试图用一个完美的\"超级提示词\"一步到位。对话的价值在于迭"
  },
  "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式#5": {
    "title": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式",
    "url": "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式",
    "date": "2025-07-24",
    "text": "ents/    # React 组件\n├── lib/           # 辅助函数/库代码\n└── public/        # 静态资源\n\n阶段二：携手Claude Code，分步编码实现 (The Implementation Phase)\n\n拿到蓝图后，我们就进入了执行阶段。这里的"
  },
  "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式#6": {
    "title": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式",
    "url": "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式",
    "date": "2025-07-24",
    "text": "**[步骤 1]**: 实现文章数据读取逻辑。\n    > 具体任务是：在 `lib/posts.js` 中创建一个函数 `getSortedPostsData`，它需要能读取 `/posts` 目录下所有 `.md` 文件，使用 `gray-matter` 解析元数据，并按日期排序后返回。请提供完"
  },
  "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式#7": {
    "title": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式",
    "url": "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式",
    "date": "2025-07-24",
    "text": "ve Advancement)**：当一个步骤完美完成后，带着已完成的代码和原始蓝图，进入下一步。\n    > **提示词示例 (开始步骤2)**：\n    > \"很好，步骤1已经完成。`lib/posts.js` 的代码如下：\n    >\n    > \n    >\n    > 现在，我们来执行蓝图"
  },
  "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式#8": {
    "title": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式",
    "url": "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式",
    "date": "2025-07-24",
    "text": "**讨论变更**：像在阶段一一样，与AI（可以是Claude或切回ChatGPT）讨论新想法。\n    *   **更新蓝图**：将变更记录回你的蓝图文件，并创建一个新的分支步骤，如 **[步骤 3.1]**。\n    *   **继续执行**：基于更新后的蓝图继续前进。\n\n三、 工具协同分析：Ch"
  },
  "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式#9": {
    "title": "ChatGPT + Claude Code 混合开发工作流：一种兼顾规划、敏捷与质量的AI编程新范式",
    "url": "/content/posts/legacy/chatgpt-claude-code-混合开发工作流-一种兼顾规划-敏捷与质量的ai编程新范式",
    "date": "2025-07-24",
    "text": "量软件开发的清晰路径。它告别了混乱的、不可预测的\"AI魔法\"，引入了工程化的、结构化的协作范式。\n\n通过 **\"蓝图驱动\"**，我们确保了方向的正确性；通过 **\"分步执行\"**，我们保证了过程的可控性；通过 **\"人类确认\"**，我们守护了最终的质量。\n\n这不仅仅是一种技术或技巧，更是一种项目管理"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#0": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "面向内容检索平台的预发布环境搭建\n\nSolrCloud 是 Solr 的分布式部署模式，用于处理大规模搜索索引。SolrCloud 将索引拆分成多个 分片 (Shard)，每个分片包含整个索引的一部分文档集合 。集合 (Collection) 是用户逻辑上的一个完整索引，它可能由一个或多个分片组成。"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#1": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "r 支持 分布式查询，即一个查询会由查询节点转发到所有分片执行，汇总各分片结果后再返回给客户端。\n\n每个分片为了高可用起见可以有多个 副本 (Replica)。所有副本的数据完全相同，其中有且只有一个被选举为 Leader，负责该分片的索引更新协调 。其余副本称为 Follower（以前也叫从属），"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#2": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "通过 Solr 的 Collections API 通知 ZooKeeper 再由集群协同执行。\n\n这样的设计带来了高可用和容错能力：同一分片有多份副本提供服务，即使某个副本宕机，查询请求会自动由剩余副本处理，不影响整体服务 。如果某分片的 Leader 宕机，ZooKeeper 会在剩余副本中自动"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#3": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "模，并保证在预发布环境中也能模拟查询的分布式过程和容错行为。\n\nZooKeeper 选主算法解析\n\nZooKeeper 在上述架构中充当“集群大脑”，为分布式系统提供配置存储、命名服务和同步原语等功能。其中最重要的一点是它需要保证自己的数据一致性——这通过 选主算法 来实现。一个 ZooKeeper"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#4": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "r 节点参与复制和投票。如果 Leader 宕机，剩余节点会通过选举算法选出新的 Leader。\n\nZooKeeper 的选主算法本质上是一个 多数投票协议。每个 ZooKeeper 节点有一个唯一的 服务器ID (myid)，以及记录自身数据状态的 事务ID (ZXID) 和轮次编号 Epoch。"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#5": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "er 。选举完成后，集群状态更新：胜出节点切换为 LEADING 状态成为 Leader，其他节点切换为 FOLLOWING 状态成为追随者，开始从新Leader同步数据。 \n\n通过上述过程，ZooKeeper 保证了在任意时刻只有一个 Leader，并且至少有半数节点保存了最新的数据日志副本。当客"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#6": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "索平台各组件的协调机制在发布前得到充分验证。\n\nPython 批量写入 Cassandra 示例\n\n预发布环境通常需要构造测试数据。下面通过 Python 和 Cassandra 驱动实现向 Cassandra 批量写入数据的示例。我们假设 Cassandra 已有名为 test_keyspace "
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#7": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "sh COPY、DSBulk 工具来导入大规模数据 。\n\nPython 批量更新 Solr 示例\n\n有了数据存储，下一步通常需要将数据索引到 SolrCloud 以供检索。下面提供一个 Python 脚本示例，通过 Solr 的 HTTP 接口实现 批量更新索引（添加文档）。这里使用 Python "
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#8": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "ent 等字段。如果集合尚未创建，可以通过 Solr 提供的命令快速创建一个，例如在容器中执行：\n\n上述命令将在 ZooKeeper 协调下创建一个名为 “my_collection”的新集合，使用内置的 data_driven_schema_configs 默认配置。创建完成后，运行 Python"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#9": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "查脚本，它依次检测 Cassandra、Solr 和 ZooKeeper 三个服务是否正常响应：\n\n这个脚本通过尝试建立 TCP 连接来判断服务端口是否开放。其中对 ZooKeeper，我们发送了特殊的四字命令 “ruok”（意为“Are you ok”）并期望收到 “imok” 响应，表明 Zoo"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#10": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "功能，例如对 Cassandra 执行一个简单的 SELECT，对 Solr 发一个查询请求等。\n\n运行上述健康检查脚本，可快速定位预发布环境中哪个组件出现故障。例如输出 Solr check failed: [Errno 111] Connection refused 则说明 Solr 没有启动或"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#11": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "a 集群，以模拟生产环境的分布式架构。下面是完整的 docker-compose.yml 示例：\n\n上述 Compose 文件定义了三个 ZooKeeper 容器（zoo1、zoo2、zoo3）、三个 Solr 容器（组成一个 SolrCloud 集群），以及三个 Cassandra 容器（组成一个"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#12": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "注意这并不保证启动顺序完全按预期或 ZooKeeper 已经准备就绪，必要时可加入健康检查机制）。\n* SolrCloud：每个 Solr 实例启动时通过 ZK_HOST 指定 ZooKeeper 集群地址列表，使其加入 SolrCloud。我们开放了 solr1 的 8983 端口以访问 Web "
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#13": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "//localhost:8983/solr/ 打开 Solr 管理界面，查看集群状态、创建集合等。\n* Cassandra：采用官方 Cassandra 镜像来启动三个节点。通过 CASSANDRA_SEEDS 我们指定种子节点地址为 cassandra1（第一个节点自己作为种子），这样其他节点能够"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#14": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "集群状态，每个节点应显示为 UN (Up/Normal) 且握有均匀的 Token Range。\n\n完成 Compose 文件后，运行 docker-compose up -d 即可在后台启动整个预发布集群。请耐心等待所有容器完成启动：可以通过 docker-compose logs -f 动态跟踪"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#15": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "看到报错 Could not connect to ZooKeeper ... within ... ms，说明 Solr 在指定时间内无法连上 ZooKeeper  。这可能是 ZooKeeper 尚未启动完成或 ZK_HOST 配置不正确。排查：首先执行 docker-compose logs "
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#16": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "ds_on 的 condition: service_healthy 设置）。正常情况下，Solr Admin UI 打开后，在 “Cloud -> Graph” 能看到 ZooKeeper 状态及集群拓扑。\n* Solr 集群没有 Leader：创建 collection 时提示 “no acti"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#17": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "Solr 副本。通常在预发布环境，重启 SolrCloud 或等待数秒都能重新选出 leader。\n* Cassandra 节点未成功加入集群：运行 nodetool status 发现每台 Cassandra 只显示自身，没发现其他节点，或者日志出现集群名称不匹配的错误。排查：首先确保所有 Cas"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#18": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "th any seeds 等消息。如果有，重启出现问题的节点容器。最后，使用 docker exec -it cassandra1 cqlsh 连接Cassandra，执行 SELECT peer, rpc_address FROM system.peers; 查看种子节点眼中已发现的集群同伴列表，"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#19": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "。使用 ZooKeeper 自带命令行：docker exec -it zoo1 zkServer.sh status 分别查看各节点状态：正常情况下应有一台显示 leader，其余显示 follower。如果都显示 standalone 或 looking，则说明没选出 Leader。此时核对 Z"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#20": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "选举。待其中一台日志出现 LEADING 并打印 ZooKeeper启动完成的信息，即告选主成功。\n* 数据无法持久化（非报错但需要注意）：默认情况下，上述 Docker Compose 未对 Cassandra 和 Solr 的数据目录做持久化挂载，这意味着容器删除或重建后数据会丢失（ZooKee"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#21": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "和内置管理工具，逐一检查各组件的配置和状态，再结合对原理的理解，即可定位并解决问题。\n\n经验总结\n\n最后，根据实践经验，我们对面向内容检索平台的预发布环境搭建给出以下最佳实践和注意事项：\n* 配置尽量贴近生产：预发布环境应使用与生产相同的软件版本和配置参数（ZooKeeper 节点数、Solr分片副"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#22": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "到的同时节约资源。切忌为了省事用单节点假集群，那样很多分布式问题（选主、网络分区等）就测不出来了。\n* 自动化与基础设施即代码：使用 Docker Compose、Kubernetes 或 Terraform 等工具来定义和部署预发布环境。一键部署减少人为失误，也方便环境的反复销毁重建。Compos"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#23": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "t太多、读修复频繁）等。如果预发环境日志中已有异常或警告，在生产环境往往会被放大，需在发布前修复。\n* 定期演练故障：在预发环境可以主动演练一些故障，以验证系统的自动恢复能力。例如杀掉一个 Cassandra 节点观察读写是否正常（根据一致性设置可能有短暂失败，但应该在节点重启后自动恢复并进行 Hi"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#24": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "（理想情况下预发只读生产快照）。此外，为防止误操作，预发布和生产的访问入口、管理账号应有明显区分。\n* 资源监控：不要因为是预发布就忽视监控。建议部署基本的监控和告警，如节点CPU/内存、Cassandra 的 compaction 延迟、Solr JVM 内存使用、ZooKeeper 延时等。在预"
  },
  "/content/posts/legacy/面向内容检索平台的预发布环境搭建#25": {
    "title": "面向内容检索平台的预发布环境搭建",
    "url": "/content/posts/legacy/面向内容检索平台的预发布环境搭建",
    "date": "2022-02-14",
    "text": "能帮助你顺利搭建自己的预发布环境，在实战中不断完善，打造出稳健可依赖的内容检索平台！\n\n参考资料：\n* Cassandra 官方文档 - Architecture - Dynamo-style Replication  \n* Apigee Docs - About Cassandra Replica"
  },
  "/content/posts/legacy/01-行列式和七个性质#0": {
    "title": "线性代数学习笔记1：行列式和七个性质",
    "url": "/content/posts/legacy/01-行列式和七个性质",
    "date": "2020-10-01",
    "text": "线性代数学习笔记1：行列式和七个性质\n\n•\t其他应用：比如在积分变换中的雅可比行列式（Jacobian determinant）用于坐标变换的体积元素缩放；在机器学习中判断矩阵条件数（行列式接近0表示矩阵病态）；图像处理中的畸变校正等，都可能遇到行列式的身影。\n\n下面我们通过行列式的性质，理解行列式"
  },
  "/content/posts/legacy/01-行列式和七个性质#1": {
    "title": "线性代数学习笔记1：行列式和七个性质",
    "url": "/content/posts/legacy/01-行列式和七个性质",
    "date": "2020-10-01",
    "text": "& b \\\\ c & d\\end{vmatrix} = ad - bc\n$$\n交换两行后变为\n$$\n\\begin{vmatrix}c & d \\\\ a & b\\end{vmatrix} = cb - da = -(ad - bc) \n= -\\begin{vmatrix}a & b \\\\ c & d\\"
  },
  "/content/posts/legacy/01-行列式和七个性质#2": {
    "title": "线性代数学习笔记1：行列式和七个性质",
    "url": "/content/posts/legacy/01-行列式和七个性质",
    "date": "2020-10-01",
    "text": "\\end{vmatrix} = 0\n$$\n\n性质3：某一行（或列）乘以常数 k，行列式也乘以 k\n\n矩阵某一行伸长或缩短倍数，行列式作为体积也会相应放大或缩小同样的倍数 ￼。生活中不妨想象一个可伸缩的盒子：如果你把盒子的长边拉长两倍，那盒子体积也就跟着变两倍；如果把高缩短成原来一半，体积就变成一半。"
  },
  "/content/posts/legacy/01-行列式和七个性质#3": {
    "title": "线性代数学习笔记1：行列式和七个性质",
    "url": "/content/posts/legacy/01-行列式和七个性质",
    "date": "2020-10-01",
    "text": "计算再相加。这有点类似于分摊工作：一行的贡献可以分成两份，各算各的行列式，最后把结果加起来。\n$$\nA = \\begin{pmatrix}\na_1+a_2 & b_1+b_2\\\\ \nc & d\n\\end{pmatrix}\n$$\n\n$$\nA = \\begin{pmatrix}a_1 & b_1\\\\ c"
  },
  "/content/posts/legacy/01-行列式和七个性质#4": {
    "title": "线性代数学习笔记1：行列式和七个性质",
    "url": "/content/posts/legacy/01-行列式和七个性质",
    "date": "2020-10-01",
    "text": "& 6\n\\end{vmatrix} = 0\n$$\n\n性质6：两行（或两列）成比例，行列式为 0\n\n这一条和性质5类似，也是说如果矩阵的两行在方向上完全相同（即其中一行是另一行的数倍），那行列式照样为0。因为成比例其实意味着这两行是平行或共线的向量，没有新增的维度信息。本质上还是线性相关导致“体积”坍"
  },
  "/content/posts/legacy/01-行列式和七个性质#5": {
    "title": "线性代数学习笔记1：行列式和七个性质",
    "url": "/content/posts/legacy/01-行列式和七个性质",
    "date": "2020-10-01",
    "text": "x} + \\begin{vmatrix}\na & b & c\\\\ \n3a & 3b & 3f\\\\ \ng & h & i\n\\end{vmatrix}\n=\n\\begin{vmatrix}\na & b & c\\\\ \nd & e & f\\\\ \ng & h & i\n\\end{vmatrix} + 0\n$$\n\n"
  },
  "/content/posts/legacy/01-行列式和七个性质#6": {
    "title": "线性代数学习笔记1：行列式和七个性质",
    "url": "/content/posts/legacy/01-行列式和七个性质",
    "date": "2020-10-01",
    "text": "列）成比例时，行列式也为零。\n\t•\t性质7：将一行（列）的若干倍加到另一行（列），行列式值不变。\n\n通过以上性质的说明和实例展示，进一步明确了行列式的计算特性和几何含义，有助于在实际编程和工程实践中高效利用这些性质，简化矩阵和向量计算的复杂度，提高数值计算的效率和准确性。"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned-zh#0": {
    "title": "我的AI编程伙伴差点让项目翻车：一个惨痛的教训",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned-zh",
    "date": "2025-07-27",
    "text": "我的AI编程伙伴差点让项目翻车：一个惨痛的教训\n\n1. **核心调度引擎**：一个健壮的、基于`asyncio`的调度器。\n2. **智能任务执行**：一个能够分析任务结果并动态调整未来运行参数的系统。\n3. **自我改进任务生成**：AI可以根据性能指标或失败重写任务底层脚本的功能。\n4. **人"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned-zh#1": {
    "title": "我的AI编程伙伴差点让项目翻车：一个惨痛的教训",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned-zh",
    "date": "2025-07-27",
    "text": "本原因并不新颖或奇特；它们是经典的软件工程失败，被AI放大和加速了。\n\n1. 过度工程的诱惑之歌\n\nAI没有业务上下文或架构前瞻性来说\"这一次太多了\"。它是一个极其强大的实现引擎。通过一次性要求所有功能，我无意中指导它为一个还不存在的未来构建解决方案，忽略了对稳定基础的直接需求。\"智能\"功能被强行附"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned-zh#2": {
    "title": "我的AI编程伙伴差点让项目翻车：一个惨痛的教训",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned-zh",
    "date": "2025-07-27",
    "text": "下文，使用了方便的`asyncio.run()`，不知道它是更大的、已经运行的事件循环的一部分。\n\n此外，选择`apscheduler`的`CronTrigger`引入了另一层复杂性。它的阻塞性质和独立的线程模型与我设想的完全异步设计不能很好地融合，导致时序错误和难以调试的竞态条件。\n\n3. 机器中"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned-zh#3": {
    "title": "我的AI编程伙伴差点让项目翻车：一个惨痛的教训",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned-zh",
    "date": "2025-07-27",
    "text": "nScheduler`知道\"智能任务执行\"模块工作方式的内部细节。\n\n**概念问题：紧密耦合**\n\n调试是一场噩梦。一个组件的失败会在整个系统中级联，使得无法隔离根本原因。系统不是一个协作模块的集合；它是一台单一的、脆弱的机器。\n\n恢复：人机合作的经验教训\n\n从这个边缘爬回来是一次谦逊的练习，也是回"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned-zh#4": {
    "title": "我的AI编程伙伴差点让项目翻车：一个惨痛的教训",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned-zh",
    "date": "2025-07-27",
    "text": "经理\"改为\"首席架构师和高级开发者\"。AI是我聪明但缺乏经验的初级伙伴。我的新工作流程如下：\n\n1. **定义一个小的、隔离的任务**（例如，\"创建一个插件类，将任务失败记录到JSON文件\"）\n2. **AI生成代码**\n3. **我批判性地审查每一行**。我检查反模式、架构不匹配和错误假设。\n4."
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned-zh#5": {
    "title": "我的AI编程伙伴差点让项目翻车：一个惨痛的教训",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned-zh",
    "date": "2025-07-27",
    "text": "开发者执行。AI为本地目标优化，可能不会选择最简单的全局路径。\n\n最后的思考：飞行员，而不是乘客\n\nAI开发工具不是你项目的自主驾驶员；它们是极其强大的副驾驶。它们可以处理复杂的机动、处理大量信息，并以超人的速度执行指令。但人类开发者必须保持机长的身份，负责飞行计划（架构）、起飞前检查（代码审查）和"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned-zh#6": {
    "title": "我的AI编程伙伴差点让项目翻车：一个惨痛的教训",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned-zh",
    "date": "2025-07-27",
    "text": "次添加一个功能并彻底测试\n5. **架构很重要**：人类必须保持架构师的身份，而不仅仅是项目经理\n\n软件开发的未来不在于用AI替代人类判断，而在于创建一个伙伴关系，其中每个人都贡献他们独特的优势，更快、更可靠地构建更好的软件。"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#0": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统\n\n总的来说，RAG 解决“知识获取”，微调/数据增强提升“语言与领域适应”，而Agent赋予“操作执行”能力。这几种技术往往可以组合使用：“在实际应用中，一个智能客服系统可能同时用到 RAG 获取最新产品信息，微调提升对客户问题的理解，"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#1": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "状态”，并提取关键信息（如订单号或下单时间段）。如果用户未提供订单号，Agent可以追问获取。\n2.\t函数调用：Agent 决定调用后端提供的订单查询接口，例如 getOrderStatus(order_id) 函数。它会生成对应的函数调用请求，将订单号作为参数传递。OpenAI 的函数调用机制允许"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#2": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "的订单到哪了’），请调用check_order_status接口查询。”\n\n场景2：修改个人信息\n\n假设用户说：“我要把账号绑定的手机号码改成新的号码，可以帮我修改吗？”\n1.\t意图解析：Agent 明确用户希望更改账户手机号。这属于需要鉴权的敏感操作。\n2.\t身份验证：在调用真正的修改接口前，系统"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#3": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "：后台接口验证权限后，修改数据库中用户的手机号，返回操作是否成功的结果（或新的联系方式记录）。\n5.\t反馈用户：Agent 根据接口返回，生成回答：“好的，您的手机号已更新为XXX。如非本人操作请及时联系客服。”。若接口返回错误（比如格式不符或权限不足），Agent 则礼貌地告知用户失败原因，并提供"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#4": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "号和退款原因（从用户描述中提取，若未提供可追问）。这个调用会在后台创建退款工单或触发退款流程。\n4.\t结果处理：退款接口返回受理结果，例如退款申请单号或处理状态。Agent 将此信息转述给用户：“您的订单退款申请已提交，单号为XXXX，我们将在3个工作日内处理，退款将原路返回至您的支付账户。”\n5."
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#5": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "Agent 的实现方法：LangChain 与 OpenAI Function Calling\n\n要让模型具备上述 Agent 能力，开发者可以利用现有框架和API来实现“模型调用函数”的机制。当前比较流行的两种途径是使用 LangChain 框架的 Agent 或 OpenAI 的函数调用(Fun"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#6": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "态的工具：\n\n类似地，可以定义修改手机号、提交退款的工具，并适当在描述中注明何时使用该工具。\n\n2.\t初始化 Agent：选择一个 LLM（如 GPT-4）作为决策大脑，指定 Agent 类型（ZeroShotReactDescription 等）和工具列表。LangChain会在幕后构造提示，让模"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#7": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "输出决定调用哪个工具和传入何种参数。\n\n3.\t运行对话：将用户问题传给 Agent，例如agent.run(\"查询订单12345的配送状态\")。模型收到带有工具说明的上下文，会产生类似：“Thought: 我需要查询订单状态\\nAction: get_order_status\\nAction Inp"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#8": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "in的Agent属于第三方库实现，其提示工程和决策流程可调整的空间较大，需根据模型表现反复调优。\n\n基于 OpenAI 函数调用的实现\n\nOpenAI 提供了内置的函数调用机制，使得模型能够按规范返回一个函数调用请求，开发者再执行该函数并将结果反馈给模型 。实现步骤如下：\n1.\t定义函数及描述：在后"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#9": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "型收到函数列表和对话内容后，如果判断需要查询订单，就会在回答中返回一个特殊的函数调用响应，例如：\n\n这表示模型选择调用get_order_status，并填充了参数。\n\n3.\t执行函数并反馈结果：我们的应用收到上述响应后，解析出需要调用的函数名称和参数，然后实际调用get_order_status("
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#10": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "况 。开发者也可以通过检查 function_call 的内容，在执行前做最后的验证和安全检查。\n\n对比：LangChain Agent 更偏向高层封装和跨工具的灵活决策，适合快速集成各种类型的工具（包括搜索、计算等）; OpenAI 函数调用则提供了一种更底层和精细控制的方法，将函数调度纳入模型推"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#11": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "先限定权限的服务账户。这样就算Agent被恶意指令利用，也只能在既定权限范围内行动，避免越权操作。\n* 最小权限原则：为 Agent 提供的接口应尽量细粒度、受限。每个函数只执行特定业务逻辑，并对可接受的参数和调用频率做限制。比如 requestRefund 接口内部可以限定只有特定状态的订单才能退"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#12": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "行函数时也需要try-catch异常，将错误转化为对用户友好的回复，而不暴露系统敏感信息或调用栈。\n* 内容过滤与隐私保护：Agent回复中应避免泄露超出用户权限范围的敏感信息。 例如，严格防止一个用户通过Agent查询到他人订单的信息。这要求在函数实现层就做好数据隔离，以及在结果返回模型前做检查。"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#13": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "对于关键操作（如大额退款），可以加入人工复核环节：Agent给出操作建议后需要人工确认再真正执行。\n* 防范提示注入：Prompt Injection是已知的攻击向量，恶意用户可能试图诱导模型忽略规则、调用不应调用的功能。为缓解此风险，可以在系统消息中明确不可违反的指令，例如：“不得在未验证身份情况"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#14": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "在将Agent集成方案付诸实际部署时，还会遇到一些实战挑战。下面列举几个常见问题及相应的优化策略：\n* 接口命名与语义一致性：模型需要依据用户意图匹配到正确的函数调用，这要求我们设计的函数/工具名字和描述要直观明了、语义独特。例如，不要有两个函数都含糊称“查询信息”，而应明确区分getOrderSt"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#15": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "，增强模型对接口意图的联想。例如提示：“用户说‘查订单物流’应使用getOrderStatus”。\n* 工具使用能力（解释/理解工具）：有时模型并未充分明白某个工具的作用或使用场景，可能出现不调用该用的时候反复试错。为提升工具调用正确率，可以在Prompt中提供明确的指导和约束。正如前文提到的，直接"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#16": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "如数据库返回的结构数据），可让工具函数先将结果整理成易读摘要，再给模型，减少模型对数据的解释负担。\n* 上下文保持与多轮对话：智能客服往往是多轮会话，Agent需要记住用户先前提供的信息（例如之前询问过的订单号、用户身份等）。为此可以引入对话记忆机制。LangChain自带记忆模块，可在每轮对话时将"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#17": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "已完成。必要时可通过中间结果总结来减小Prompt长度，同时保留关键信息，防止超出模型上下文窗口。\n* 错误恢复与容错：在部署初期，难免出现模型调用错误函数或参数不合规的情况。我们需要制定策略让Agent从错误中恢复，而不是卡死在错误上。优化手段包括：当检测到模型函数调用无效时，反馈一个特定的系统消"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#18": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "误场景的处理方式。异常处理的健壮性也是提升用户体验的一部分，避免由于一次调用失败就让对话陷入僵局。\n* 性能与一致性：在真实系统中，响应速度和结果一致性也很重要。引入Agent多了函数执行步骤，会稍微增加响应延迟，要注意优化。例如函数调用尽量并行（如需多个查询可异步处理），模型响应和函数执行可以流水"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#19": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "下，单Agent加清晰工具集已经能够满足需求，除非业务规模庞大且模块清晰才考虑多Agent架构。\n\n通过针对上述挑战采取相应的优化策略，我们可以大幅提高智能客服Agent的可靠性和用户体验。例如，精心设计的工具描述和提示可以让模型正确率显著提高 ；完善的记忆和错误处理让对话更加流畅连贯。最终，部署成"
  },
  "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统#20": {
    "title": "打造具备行动力的智能客服：用 Agent 让大模型接入真实系统",
    "url": "/content/posts/legacy/打造具备行动力的智能客服-用-agent-让大模型接入真实系统",
    "date": "2024-03-11",
    "text": "论了安全权限控制措施，确保Agent在赋能的同时不失控，并分享了实际部署中遇到的挑战和优化经验。\n\n借助 Agent，一个原本只能“回答问题”的客服AI升级为可以“解决问题”的强大助手：它连接了用户与后端系统，让对话不再停留于表面回答，而是能够直接执行操作达成用户目标。这种范式正是下一代智能客服系统"
  },
  "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践#0": {
    "title": "腾讯、高德和百度地图坐标系转换详解与工程实践",
    "url": "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践",
    "date": "2023-04-28",
    "text": "腾讯、高德和百度地图坐标系转换详解与工程实践\n\n对于开发者而言，这意味着如果直接将 GPS 获取的 WGS-84 坐标用于中国大陆的地图，会产生位置偏差。例如，一个真实位置的 WGS-84 坐标点在未转换直接显示到 GCJ-02 地图上时，可能会有100～700米的误差 。正因如此，在中国从事地图开"
  },
  "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践#1": {
    "title": "腾讯、高德和百度地图坐标系转换详解与工程实践",
    "url": "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践",
    "date": "2023-04-28",
    "text": "陆以外地区，这些地图服务通常使用 WGS-84 坐标系 或当地的标准坐标系，而不会再进行偏移加密。\n* 百度地图：百度地图使用 BD-09 坐标系，这是在 GCJ-02 基础上二次加密得到的坐标系 。由于 BD-09 相对 GCJ-02 有小幅偏移，因此如果要将腾讯/高德地图的坐标用于百度地图（或反"
  },
  "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践#2": {
    "title": "腾讯、高德和百度地图坐标系转换详解与工程实践",
    "url": "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践",
    "date": "2023-04-28",
    "text": "> 火星坐标 (GCJ-02)，火星坐标 (GCJ-02) -> 百度坐标 (BD-09) 等。\n\n首先，WGS-84 与 GCJ-02 的转换可以通过偏移算法实现。由于 GCJ-02 偏移算法受法规限制，官方并未公开提供从 GCJ-02 还原为 WGS-84 的接口 。不过幸运的是，业界已有多种语"
  },
  "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践#3": {
    "title": "腾讯、高德和百度地图坐标系转换详解与工程实践",
    "url": "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践",
    "date": "2023-04-28",
    "text": "，反算精确坐标需要迭代逼近才能达到很高精度 ，但在一般应用场景下，一次反推的近似结果已足够使用。\n\n接下来重点介绍 GCJ-02 与 BD-09 之间的转换。百度官方提供了坐标转换接口，可将 GCJ-02（或WGS-84）坐标转换为 BD-09，但我们也可以直接使用公开的公式自行实现  。其核心算法"
  },
  "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践#4": {
    "title": "腾讯、高德和百度地图坐标系转换详解与工程实践",
    "url": "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践",
    "date": "2023-04-28",
    "text": "用需求。\n\n常见问题与工程实践建议\n\n在实际工程中，关于坐标转换还有一些常见的坑和需要注意的地方：\n* 坐标系混用：务必明确每个数据源使用的坐标系。例如，GPS 模块通常提供 WGS-84 坐标，高德/腾讯地图 API 返回 GCJ-02 坐标，百度地图 API 返回 BD-09 坐标 。如果搞错了"
  },
  "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践#5": {
    "title": "腾讯、高德和百度地图坐标系转换详解与工程实践",
    "url": "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践",
    "date": "2023-04-28",
    "text": "实践中，应当存储和使用原始坐标，在最终展示或输出时再进行一次必要的转换，避免多次来回转换同一坐标。\n* 精度与算法选择：上述转换算法的精度在工程上已足够，一般可保证与官方转换结果在小数点后4位以内吻合 。由于浮点运算本身的限制，转换难免存在极其细微的精度损失。如果对精度要求极高（例如将 GCJ-02"
  },
  "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践#6": {
    "title": "腾讯、高德和百度地图坐标系转换详解与工程实践",
    "url": "/content/posts/legacy/腾讯-高德和百度地图坐标系转换详解与工程实践",
    "date": "2023-04-28",
    "text": "要使用非官方算法 ；不过在离线批量转换等场景下，采用公开算法自行转换也能达到与官方接口相当的精度。\n* 底图数据差异：即使完成了正确的坐标系转换，不同地图服务商的底图数据差异也可能导致位置对不齐的现象。比如某些道路或建筑物在不同地图上的绘制存在细微差别，因此将一个平台的坐标转换后显示在另一平台的地图"
  },
  "/content/posts/legacy/01-数据预处理#0": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "机器学习中的数据预处理\n\n数据预处理的目的就是应对这些问题，具体包括：去除无效或错误的数据、填补缺失值，以及对数据的范围、单位、格式进行规范化处理，把原始数据处理成模型喜欢的样子。良好的预处理能大大提升模型训练的效率和效果。这部分内容往往比模型调参更费时，但也是机器学习工程中最重要的基础之一。\n\n下"
  },
  "/content/posts/legacy/01-数据预处理#1": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "缺，或者使用固定值（如0或“未知”）标记缺失。填充值应尽量反映数据的总体趋势，避免引入明显偏差。\n\n举个例子，假如某一特征是产品价格，缺失了一些值，我们可以用该特征的平均价格来填补缺失项。这样模型仍能利用大部分样本的信息，且不会因为空值而无法计算。再比如用户填写表单时有时会漏掉“年龄”这一栏，我们可"
  },
  "/content/posts/legacy/01-数据预处理#2": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "律。因此，我们需要根据业务理解选择合适的处理策略，尽量还原数据的真实分布或提供模型可理解的信号。\n\n在实际项目中，常常需要针对不同特征选择不同的缺失值填充策略。例如，用户年龄缺失可以填充为平均年龄，商品评论缺失可以填充为空字符串或特殊标记。同时要注意记录哪些值是填充得来的，必要时模型可以区别对待这些"
  },
  "/content/posts/legacy/01-数据预处理#3": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "它的数值较大。为避免这种“量纲偏差”，我们需要对特征做缩放变换，使得不同特征处于相近的数值范围。\n\n常用的数值特征缩放方法包括标准化和归一化两大类，下面分别介绍。\n\n标准化（Standardization，均值归零）\n\n标准化旨在将特征数据调整为均值为0、标准差为1的分布。转换公式是对每个特征列执行"
  },
  "/content/posts/legacy/01-数据预处理#4": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "d_samples 每列均值接近0，标准差接近1（由于浮点误差可能不是完全0和1，但非常接近）。\n\n通过标准化，数据的尺度被拉到相同水平。这在训练诸如线性回归、逻辑回归和神经网络时尤为重要：特征标准化后，梯度下降求解更稳定，收敛更快；模型对不同特征的权重调整也更公平，不会因为未标准化数据某一维数值特"
  },
  "/content/posts/legacy/01-数据预处理#5": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "X’ = \\frac{X - X_{\\min}}{X_{\\max} - X_{\\min}}\n$$\n\n其中 $X_{\\min}$ 和 $X_{\\max}$ 分别是该特征列的最小值和最大值。经过这样的映射处理，每个特征的最小值变为0，最大值变为1，其他值按原相对位置映射到0~1之间。\n\n归一化的作用也是"
  },
  "/content/posts/legacy/01-数据预处理#6": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "间，因此归一化后为0.5；同样地，原始第二列5在2到8区间中也大约居中，对应归一化结果约0.5。\n\nMin-Max归一化的注意点在于：它会压缩原有的差值分布，对最大最小值（可能是异常值）非常敏感。如果数据中存在极端异常值，Min-Max归一化会把大部分正常数据挤在接近0的位置，失去分辨率。因此，在使"
  },
  "/content/posts/legacy/01-数据预处理#7": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "样本自身的所有特征值之和为1（或平方和为1）。这种操作通常用于关注各特征占比而非绝对大小的场景。\n\n例如，一份统计中有两年的编程语言使用人数：2017年 Python 10万人，Java 20万人，PHP 5万人；2018年 Python 8万人，Java 10万人，PHP 1万人。两年总人数都不相"
  },
  "/content/posts/legacy/01-数据预处理#8": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "会等于1。例如，第一行 [10, 20, 5] 归一化后变为 [0.2857, 0.5714, 0.1429]（各元素即为原值占总和的比例，检查可得 $0.2857+0.5714+0.1429=1$）。这种预处理在需要比较组成成分而非绝对值大小的任务中（如文本单词频率向量归一化）非常有用。\n\n二值化"
  },
  "/content/posts/legacy/01-数据预处理#9": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "于60的全部变为0，高于60的变为1。需要注意，二值化会丢失数值的细粒度信息（例如把65.5和89.0都变成1，区别消失了），而且这个转换不可逆（无法从结果0/1还原原始值）。因此，除非模型确实只需要关注超过阈值与否这种信息，否则应谨慎使用。如果想保留可逆的数值转换来表示类别信息，可以考虑下文的独热"
  },
  "/content/posts/legacy/01-数据预处理#10": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "用于不同的场景，下面分别介绍。\n\n独热编码（One-Hot Encoding）\n\noutput:\n\n在这个例子中，我们有3列分类特征。OneHotEncoder 会自动识别每列中的不同取值种类，并为每一列分别创建对应的独热编码。最终输出 oh_samples 是一个4行×9列的矩阵：前三列对应原第一"
  },
  "/content/posts/legacy/01-数据预处理#11": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "nverse_transform 我们还可以验证编码正确性，它能将独热矩阵再转回原始的类别取值。\n\n独热编码不会丢失信息，并且是可逆的（如上所示我们能还原回去）。但缺点是会使数据维度变高，特别是当类别种类很多时，会生成大量稀疏的0/1特征。这会增加模型的计算和存储负担，不过对于大多数线性模型和树模型"
  },
  "/content/posts/legacy/01-数据预处理#12": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "有序信号。如果类别本身没有大小关系（如颜色、城市），一般更倾向使用独热编码而非直接使用标签编码。\n\n标签编码通常用于已有大小意义的序数特征（例如教育程度高中=0、大专=1、本科=2、硕士=3）或者用于对模型输出标签进行编码（如二分类标签正/负映射为1/0）。在预处理阶段，也经常先用标签编码把文字类别"
  },
  "/content/posts/legacy/01-数据预处理#13": {
    "title": "机器学习中的数据预处理",
    "url": "/content/posts/legacy/01-数据预处理",
    "date": "2023-04-27",
    "text": "关系；独热编码更安全通用，但会增加维度。视具体情况选择合适的编码方式是特征工程的一部分。\n\n总结\n\n数据预处理是机器学习过程中不可或缺的一步。通过清洗无效数据、合理填补缺失、规范特征尺度以及正确编码类别信息，我们为模型提供了一个健康干净的数据集。正如盖房子要打好地基一样，充分的数据预处理能让后续的模"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#0": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video\n\nThe EchoDraft project was thus conceived to address these pain points thr"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#1": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "cribing to finally generating structured articles. This significantly lowers the barrier and cost of content processing and enhances information retri"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#2": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "y, and extensibility of its functional components. The entire processing workflow is meticulously divided into several core stages, unifiedly orchestr"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#3": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "e stability and efficiency of the entire system.\n\nCore Functional Modules Introduction\n\n1. Audio/Video Download Module (`modules/downloader.py`)\n*   *"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#4": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "m audio/video platforms like YouTube and Bilibili. `yt-dlp`, with its robust compatibility and continuous updates, can handle various complex download"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#5": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "re-process downloaded audio, primarily involving:\n    *   **Audio Acceleration**: Speeding up the audio without significantly compromising sound quali"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#6": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "requirements of subsequent transcription modules.\n*   **Value**: Through intelligent audio acceleration, we can maximize cost-effectiveness while main"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#7": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "erting pre-processed audio into high-quality text. We chose `faster-whisper`, an optimized version of the OpenAI Whisper model, which offers the follo"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#8": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "acy risks and reducing reliance on external APIs.\n    *   **High Accuracy**: Inherits the Whisper model's excellent transcription capabilities across "
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#9": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "Core Technology**: Large Language Model (LLM) API\n*   **Functionality**: This is the \"brain\" of EchoDraft, responsible for extracting knowledge from t"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#10": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "s in the text to generate clear chapter outlines.\n    *   **Article Generation**: Based on the outline and original text content, generates coherent a"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#11": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "entity recognition, sentiment analysis, and more.\n*   **Value**: Transforms large volumes of unstructured audio data into easily readable and understa"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#12": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "nt (`main.py`), audio/video download (`downloader.py`), audio processing (`audio_processor.py`), and speech-to-text (`transcriber.py`) modules' basic "
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#13": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "tline generation and article draft functionality.\n*   **Milestone 3 (Upcoming)**: Optimizing LLM output quality, introducing more refined Prompt Engin"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#14": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "ive testing.\n\nTechnical Challenges and Solutions\n\nDuring the development of EchoDraft, we have encountered and are working to resolve the following te"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#15": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "ideo content also increase processing difficulty.\n*   **Solution**: Continuously monitor `yt-dlp` updates and upgrade promptly; add more robust format"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#16": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "audio quality or reduced transcription accuracy.\n*   **Solution**: Determine optimal acceleration multipliers through experimentation, balancing cost "
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#17": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "`faster-whisper` Performance and Accuracy Tuning\n*   **Challenge**: Selecting appropriate model sizes (Tiny, Base, Small, Medium, Large) to balance lo"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#18": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "plex scenarios like accents and background noise.\n*   **Solution**: Provide flexible model selection configuration; test and tune for specific scenari"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#19": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "nt content; API call costs need to be controlled.\n*   **Solutions**:\n    *   **Prompt Engineering**: Invest significant effort in designing and optimi"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#20": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "to LLM for processing, then integrate and refine.\n    *   **Cost Control**: Optimize input token quantity, such as preliminary summarization of transc"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#21": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "te and expand around the following directions:\n\n1.  **Richer Input Source Support**: Beyond online platforms, add direct integration with local audio/"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#22": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "ysis accuracy.\n3.  **LLM Enhancement Functions**:\n    *   **Multi-dimensional Content Analysis**: Such as sentiment analysis, keyword clouds, entity r"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#23": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "generation.\n4.  **User Experience Optimization**:\n    *   Develop more user-friendly graphical user interfaces (GUI) or web interfaces to lower the en"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#24": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "new downloader, processor, or analyzer modules.\n6.  **Performance and Deployment Optimization**: Explore using Docker and other container technologies"
  },
  "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref#25": {
    "title": "EchoDraft Project Plan: The Intelligent Content Refiner for Audio and Video",
    "url": "/content/posts/legacy/echodraft-project-plan-the-intelligent-content-ref",
    "date": "2025-07-25",
    "text": "ng tedious manual labor into intelligent insights. We believe that through continuous iteration and community feedback, EchoDraft will continue to gro"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#0": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践\n\n上述模块串联形成会议内容处理的闭环流水线：会议音频通过语音识别得到转录文本，随后经由大语言模型压缩提炼成摘要，最后通过语音合成将摘要朗读出来供人收听。接下来，我们将分别介绍每个模块的功能定位、技术选型和实现要点。\n\n模块一：语音转写（ASR"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#1": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "，以及标注不同发言人（说话人分离）。\n\n技术选型： 当今有多种自动语音识别（ASR）方案可供选择：\n* 离线开源模型: OpenAI 的 Whisper 是业界知名的开源大模型，训练了68万小时多语种语音，在口音、噪音和技术语言环境下具有接近人类的鲁棒性。Whisper 支持多语言转写，并可直接将多"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#2": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "模型的速度和准确率权衡，大模型在普通CPU上转写一小时音频可能耗时数小时，小模型虽快但准确率略低。\n* 云服务API: 商业云提供经过大规模训练优化的ASR服务，具有高精度和实时性优势。例如，阿里云语音识别提供实时和录音文件转写，针对普通话、英语等进行了优化，在复杂环境下字符错误率低于15% 。科大"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#3": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "的转写结果格式，包括时间戳和说话人标签，方便后续摘要提取使用。\n\n模块二：文本摘要生成（NLP）\n\n功能目标： 文本摘要模块负责从冗长的会议转录中「浓缩精华」。它需要自动提炼出会议纪要，包括主要议题讨论结果、达成的决策以及后续行动项（TODO 列表），并可按需添加标注或元数据（如任务负责人、截止日期"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#4": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "长，可将转录拆分片段分别摘要后再综合。开源模型的优势在于可控性和数据隐私，本地运行不依赖外部服务。\n* 闭源API大模型：如Anthropic公司的 Claude v2/v3，OpenAI的GPT-4等。这类模型提供强大的能力，例如 Claude 支持长达100k tokens的上下文（约7.5万字"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#5": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "直接产出JSON结构，以确保结果包含所需字段并便于程序解析。例如，可让模型输出如下JSON示例：\n\n像上述格式就清晰地结构化了摘要内容，包括概要、决策和行动项等。在实践中，有开源脚本利用LLM从会议转录生成JSON和Markdown双输出。当然，模型生成JSON可能会有不严格符合格式的情况，我们可以"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#6": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "LM已经能产出相当有用的会议摘要，大大节省人工整理笔记的时间。\n\n模块三：语音摘要播报（TTS）\n\n功能目标： 有了文本形式的会议摘要，有时我们希望进一步将其“复活”为语音。一方面，语音播报可以让无法方便阅读文字的人（开车途中等）也能获取信息；另一方面，经过优化的合成语音比生硬的机器朗读更加自然，听"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#7": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "1 模型作为TTS方案。\n\nCosyVoice-v1 是新一代生成式语音合成大模型，具备多项优势：\n* 拟人化效果：CosyVoice并非逐字拼接音频，而是通过理解全文语境来预测情绪、语调和韵律。因此它朗读摘要时能根据内容调整语气，比如对决议采用肯定的语调、对待办事项使用提示的语气，让合成声音更贴近"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#8": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "发者可以根据需求选择合适的声音，例如用稳重的男声播报决策，用亲切的女声播报问候，从而增强听觉体验。\n* 流式输出与效率：CosyVoice支持流式合成，即可以一边输入文本一边即时输出语音。对于会议纪要这样的中短文本，合成延迟本就不高，但流式能力意味着系统完全可以在收到摘要文本后数秒内开始播放音频，而"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#9": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "文本断句清晰、有必要的标点，这样合成引擎才能正确把握语调停顿。此外如果对某些专有名词发音有特殊要求，也可以通过添加标注或发音字典的方式微调。但总的来说，CosyVoice 默认模型已经能胜任大部分中文会议摘要的播报需求，其生成的语音清晰自然，足以让用户通过听觉就获取会议的关键信息。\n\n多模态数据流程"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#10": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "型决定是否需要翻译。标准化的转写结构不仅方便机器处理，也使开发者在调试时能清晰对照音频位置。\n\n2. 摘要生成接口：给摘要模型的输入可以直接是纯文本（例如拼接所有发言形成的大段文字），但更好的做法是结合提示在输入中保留一定结构，例如：\n\n通过在转写文本中显式划分议题和发言人，模型更容易按议题生成摘要"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#11": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "本。若上一步得到的是JSON，需要将其中的内容拼接成适合朗读的文本串。例如可以生成如下可读稿件：\n\n这里我们在文本中适当加入了口语化的连接词，使朗读更自然；对重要决策加粗（如果TTS支持一定程度的标注可以强调语气）；用清单形式罗列行动项。由于CosyVoice目前不支持直接解析Markdown或SS"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#12": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "容分多段合成，以在不同段落之间插入停顿音效等。不过一般来说，一段连贯的播报足以涵盖摘要要点。\n\n4. 模块通信方式：在实现上，可根据部署情况选择合适的中间通信机制。如果所有模块部署在同一后端服务中，直接使用函数调用并传递内存数据结构（如Python字典/列表）即可，无需序列化为字符串。如果ASR或T"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#13": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "JSON结构，然后在最终播报前整理为易读的段落文本。清晰的格式和约定使多模态模块的协作更加顺畅。\n\n轻量级闭环系统的部署实践\n\n在完成各模块的选型和开发后，我们需要将它们集成部署成一个可以实际提供服务的系统。考虑到很多团队可能希望先构建一个原型验证价值，这里介绍一种轻量级部署方案，在单台服务器上即可"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#14": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "线程，可借助任务队列（如Celery + Redis）或简单的线程池。任务执行流程按照流水线顺序：\n  * 调用语音识别模块，将音频文件发送给ASR服务或本地模型，获取转写文本结果。\n  * 将转写结果送入摘要生成模块，得到结构化的摘要内容（例如JSON格式）。\n  * 从摘要JSON提取主要内容并"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#15": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "器控件播放语音摘要。这样用户既能快速浏览文字，又可选择听取语音回顾会议内容。\n\n**关键细节**：\n* 部署时确保服务器具备足够的算力。如使用Whisper大模型和本地LLM，建议配备GPU以加速推理；CosyVoice合成也可利用GPU提升速度。如果没有GPU，可尽量采用云端API以减轻本地负载。"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#16": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "服务）而不影响其余部分。同时模块间交互只通过明确的数据契约（如前述JSON格式）完成，减少耦合。\n\n通过上述方式，我们能够在一台服务器上快速搭建起一个原型系统，实现从音频输入到语音摘要输出的一条龙服务。用户体验是相当友好的：只需上传会议录音文件，几分钟内即可获得图文并茂的会议纪要和语音播报。整个过程"
  },
  "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践#17": {
    "title": "构建闭环智能会议助手：从语音转写到语音摘要播报的技术实践",
    "url": "/content/posts/legacy/构建闭环智能会议助手-从语音转写到语音摘要播报的技术实践",
    "date": "2024-07-21",
    "text": "手将能提供更深入的会议分析和实时辅助功能，比如实时翻译多语言交流 、自动提醒未完成的行动项等等。\n\n对于AI工程师和架构师而言，目前正是将这些先进模型组合应用的好时机。从 Whisper 到 Qwen，再到 CosyVoice，我们手中的工具日益强大且易用。一个轻量级的闭环系统足以证明概念并创造价值"
  },
  "/content/posts/legacy/sql视图优化api查询性能实战#0": {
    "title": "SQL视图优化API查询性能实战",
    "url": "/content/posts/legacy/sql视图优化api查询性能实战",
    "date": "2022-03-24",
    "text": "SQL视图优化API查询性能实战\n\n- 单次请求响应时间超过1秒，影响用户体验；\n- 并发访问时接口处理能力不足，容易超时失败；\n- 查询逻辑存在大量循环数据库访问（典型N+1问题）；\n- 返回数据冗余，增加网络负载和处理开销。\n\n优化思路概览\n\n针对上述瓶颈，我们采取了如下优化策略：\n\n1. **"
  },
  "/content/posts/legacy/sql视图优化api查询性能实战#1": {
    "title": "SQL视图优化API查询性能实战",
    "url": "/content/posts/legacy/sql视图优化api查询性能实战",
    "date": "2022-03-24",
    "text": "需要一次SQL就能获取所有需要的信息，极大减少了数据库负载和网络开销。\n\n2. 视图整合查询逻辑\n\n为了进一步简化SQL并减少后端拼装工作，我们设计了一个聚合视图（View），预先关联了原本分散在多个表中的字段：\n\n视图的好处是：\n- 统一了数据结构，接口层代码无需关心多表关联逻辑；\n- 查询性能提"
  },
  "/content/posts/legacy/sql视图优化api查询性能实战#2": {
    "title": "SQL视图优化API查询性能实战",
    "url": "/content/posts/legacy/sql视图优化api查询性能实战",
    "date": "2022-03-24",
    "text": "X/coordinateY`；\n- 无实际用途的冗余字段；\n- 某些字段内容体积过大，且不常用。\n\n于是我们对返回字段进行筛选，只保留最小必要集：\n- 核心ID、名称、地理位置、配送信息等必要字段；\n- 取消重复字段，仅保留标准名称如longitude/latitude；\n- 删除后台内部处理字段，"
  },
  "/content/posts/legacy/sql视图优化api查询性能实战#3": {
    "title": "SQL视图优化API查询性能实战",
    "url": "/content/posts/legacy/sql视图优化api查询性能实战",
    "date": "2022-03-24",
    "text": "护成本下降。\n3. **输出顺序要控制在应用层**：批量查询后要显式恢复顺序，保证业务一致性。\n4. **字段控制与瘦身不可忽视**：合理筛选返回字段，可以在不改动业务逻辑的情况下提升整体性能。\n5. **性能优化需量化验证**：每一次优化后必须用监控工具对比前后效果，做到有数据支撑、有反馈闭环。\n"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#0": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages\n\nThe paths for these CSS files looked like this:\n\nThe issue was clear"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#1": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "default, GitHub Pages uses Jekyll to build sites. A well-known convention of Jekyll is that it ignores all files and directories that begin with an un"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#2": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "pty `.nojekyll` file to the root of my repository. The purpose of this file is to tell GitHub Pages, \"Don't use Jekyll to process my site; treat it as"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#3": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "starting with an underscore still inaccessible?\n\nHypothesis 2: A Directory Access Issue?\n\nI started to wonder if the `_astro` directory itself was ina"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#4": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "files, not trying to list a directory's contents.\n\n3. The Breakthrough: Pinpointing the Real Cause\n\nAfter ruling out the common Jekyll issue, I took a"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#5": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "ng and research, I finally found the root cause:\n\n> **GitHub Pages (or its underlying web server) has a deeper, more fundamental rule: it blocks direc"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#6": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "he real reason the `.nojekyll` file wasn't enough. We weren't just dealing with the `_astro` directory, but the filenames themselves.\n\n4. The Ultimate"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#7": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "e hood and exposes Vite's configuration API to us. We can customize the build behavior by modifying the `astro.config.mjs` file.\n\nConfiguration Soluti"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#8": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "e `vite` configuration object:\n\nCode Explanation\n\n- `assetFileNames` can be a function that is called for each asset\n- `assetInfo.name` contains the o"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#9": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "vCO7WHQ.css`\n\nAlternative Simpler Implementation\n\nIf your only goal is to solve the underscore problem without major restructuring, a simpler function"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#10": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "ployed the new `dist` directory to GitHub Pages:\n\n**Result**: Success! The CSS files were now being loaded from paths like `assets-slug_.BvCO7WHQ.css`"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#11": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "raints Deeply**: Don't assume a common fix like `.nojekyll` is a silver bullet. It's crucial to understand the hosting platform's (GitHub Pages) own u"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#12": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "s is a cleaner and more maintainable solution.\n\n3. **Leverage Your Tool's Configuration**: Modern frontend frameworks (like Astro) and build tools (li"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#13": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "l meaning (e.g., Jekyll, private Node.js modules). Be mindful of this convention when naming files and deploying to avoid conflicts with platform rule"
  },
  "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css#14": {
    "title": "From 404 to 200: A Deep Dive into Solving Missing CSS on Astro with GitHub Pages",
    "url": "/content/posts/legacy/from-404-to-200-deep-dive-into-solving-missing-css",
    "date": "2024-01-01",
    "text": "TP status codes often contain crucial information\n- **Consult Documentation**: When common solutions fail, dive deep into tool configuration options\n\n"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#0": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy\n\nTo understand the advantag"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#1": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "fall AI project\" usually follows this pattern:\n\n1.  **Lengthy Requirements Communication:** Project managers and users attempt to define all functions"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#2": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "em integration with minimal user communication.\n3.  **\"Shock-style\" Delivery:** Finally, a seemingly complete system is delivered to users. At this po"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#3": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "cycle, market or user needs have already changed.\n    *   **Hidden Surprises:** AI's performance in certain edge cases is completely unexpected, both "
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#4": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "t, where any rework means enormous resource waste. For AI projects, their inherent \"black box\" characteristics and exploratory nature make \"getting it"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#5": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "ers interact closely at every critical juncture.\n\nImplementation Framework: Three-Step Micro-Loop Method\n\n1.  **Step One: Task Decomposition and Singl"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#6": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "rator\" project can be broken down into:\n        1.  Step 1: Implement data source connection and reading functionality.\n        2.  Step 2: Implement "
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#7": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "preliminary chart visualizations.\n        5.  ...\n    *   Developers use AI-assisted tools (like the GPT+Claude workflow we discussed previously) to e"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#8": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "lts) to users in the most intuitive way possible.\n    *   **Key Point:** Deliverables must be **perceivable and verifiable**. Avoid technical jargon a"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#9": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "eir heads,\" but have three clear decision options. This embodies the **dual purpose** of user participation:\n        *   **A. Quality Assurance & Conf"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#10": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "ctness of the current direction.\n\n        *   **B. Correction & Iteration:**\n            *   **User Feedback:** \"This KPI calculation method is wrong."
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#11": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "tion.\n\n        *   **C. Exploration & Pivoting:**\n            *   **User Feedback:** \"After seeing this preliminary chart, I realize we might not need"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#12": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "sults, users generate new, more valuable insights. The project can **legitimately and cost-effectively** enter a new, potentially more promising imple"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#13": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "ose a \"pivot\" request, developers need to assess:\n*   **Technical Feasibility:** How complex is this new idea to implement?\n*   **Resource Impact:** H"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#14": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "to \"pivot\" or \"document for future consideration.\" This mechanism ensures project agility while avoiding endless scope creep, keeping developers as th"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#15": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "oject management.\n\n1.  **Ultimate Risk Control:**\n    *   **Front-loaded Risk Exposure:** In traditional models, an understanding gap might only be di"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#16": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "st a few hours), with near-zero correction costs.\n    *   **Eliminating \"Black Box\" Fear:** Users no longer feel anxious about AI development processe"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#17": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "ng a quality checkpoint at the product's terminus. The PD-UP model includes user validation in every micro-loop, with quality continuously and progres"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#18": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "acceptance cycles.\n\n3.  **True Agile Response:**\n    *   **Embracing Change Rather Than Resisting It:** Traditional project management views \"requirem"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#19": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "aluable insights emerge during project execution.\n    *   **Opportunity-Driven Development:** Project paths are no longer locked by rigid documents bu"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#20": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "1.  **Establish Clear Communication Protocols:**\n    *   **Define \"Checkpoint\" Format:** Should it be sharing screenshots via instant messaging or con"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#21": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "y.\n\n2.  **Master the Art of Task Decomposition:**\n    *   One of developers' core skills is breaking down large goals into **logically independent, va"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#22": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "tests developers' project management capabilities. One must clearly distinguish between insight-based \"strategic pivoting\" and goal-deviating \"scope c"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#23": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "a version control system (like Git) are essential. All steps, outputs, feedback, and decisions should be clearly recorded, forming project memory.\n\n5."
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#24": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "eir sense of participation and responsibility.\n\nV. Comparison with Traditional and Pure AI Development Models\n\nAs shown above, the PD-UP model doesn't"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#25": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "riting workers\" to \"generals commanding AI armies.\" You're responsible for strategy (implementation plans) and supervising each battle (step-by-step i"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#26": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "ar more than a faster coding technique or process. **It's a management philosophy that transforms developers and users from traditional \"client-vendor"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#27": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "could be an opportunity to discover greater value. Developers, leveraging their professional capabilities and rhythm control, guide the project ship t"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#28": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "eaching or even exceeding expected destinations.\n\nFor all teams and developers in the AI era, committed to solving complex and ambiguous problems, mas"
  },
  "/content/posts/legacy/a-project-management-paradigm-revolution-progressi#29": {
    "title": "A Project Management Paradigm Revolution Progressive Development and User-Participatory AI Project Implementation Strategy",
    "url": "/content/posts/legacy/a-project-management-paradigm-revolution-progressi",
    "date": "2025-07-24",
    "text": "ft from waterfall to agile was just the beginning. The PD-UP model represents the next evolution—a framework specifically designed for the unique chal"
  },
  "/content/posts/legacy/应用服务接口性能优化实践#0": {
    "title": "应用服务接口性能优化实践",
    "url": "/content/posts/legacy/应用服务接口性能优化实践",
    "date": "2022-03-24",
    "text": "应用服务接口性能优化实践\n\n优化方案\n针对上述问题，我们制定了以下优化方案：\n* \t批量获取数据，减少查询次数：针对N+1查询问题，我们决定将循环内的多次数据库查询改为一次批量查询。也就是，将原来按ID逐个查询改为利用数据库的IN子句一次性请求所有所需资源的数据。为了实现这一点，我们引入了数据库视图"
  },
  "/content/posts/legacy/应用服务接口性能优化实践#1": {
    "title": "应用服务接口性能优化实践",
    "url": "/content/posts/legacy/应用服务接口性能优化实践",
    "date": "2022-03-24",
    "text": "排列结果列表，确保与未优化前的业务排序需求一致。这样做既避免了缓存调用，又保证了结果顺序的正确性。\n* \t数据预加载和缓存（可选）：在分析过程中我们还提出了预加载数据的思路。例如针对地理范围查询，可以提前加载特定范围内所有资源的数据到内存，或者利用现有的搜索索引直接获取完整数据，从而减少实时查询数据"
  },
  "/content/posts/legacy/应用服务接口性能优化实践#2": {
    "title": "应用服务接口性能优化实践",
    "url": "/content/posts/legacy/应用服务接口性能优化实践",
    "date": "2022-03-24",
    "text": "data`。\n* 按照原始 `id_list` 顺序重新组装结果，保持业务一致性。\n\n排序逻辑简化\n* 去除排序阶段对缓存的依赖，改为直接使用视图中的 `score` 字段。\n* 若仍需复杂排序，可在 SQL 中完成：`ORDER BY score DESC, distance ASC`.\n\n新实现"
  },
  "/content/posts/legacy/应用服务接口性能优化实践#3": {
    "title": "应用服务接口性能优化实践",
    "url": "/content/posts/legacy/应用服务接口性能优化实践",
    "date": "2022-03-24",
    "text": "优化前每次请求耗时大约在数百毫秒到上千毫秒不等，而优化后普遍能够稳定在几十毫秒左右，性能提升明显。\n* \t在线上环境的监控中，之前该接口的99th百分位响应时间曾经达到数秒，优化发布后，99th响应时间降到了亚秒级（显著低于1000ms）。大部分请求的耗时从原来的500ms降低到100ms以内，性能"
  },
  "/content/posts/legacy/webgl-3d坦克大战游戏开发实践-现代webgl技术应用#0": {
    "title": "WebGL 3D坦克大战游戏开发实践：现代WebGL技术应用",
    "url": "/content/posts/legacy/webgl-3d坦克大战游戏开发实践-现代webgl技术应用",
    "date": "2025-07-21",
    "text": "WebGL 3D坦克大战游戏开发实践：现代WebGL技术应用\n\n核心技术栈\n- **WebGL 2.0**: 3D图形渲染\n- **GLSL**: 着色器编程语言\n- **JavaScript ES6+**: 游戏逻辑实现\n- **Web Audio API**: 音效系统\n- **Canvas 2"
  },
  "/content/posts/legacy/webgl-3d坦克大战游戏开发实践-现代webgl技术应用#1": {
    "title": "WebGL 3D坦克大战游戏开发实践：现代WebGL技术应用",
    "url": "/content/posts/legacy/webgl-3d坦克大战游戏开发实践-现代webgl技术应用",
    "date": "2025-07-21",
    "text": "碰撞体**: 使用简单形状代替复杂模型\n\n3. AI优化\n- **行为缓存**: 缓存AI决策结果\n- **分帧更新**: AI在不同帧更新，分散计算负载\n- **层次化决策**: 粗略决策 + 精细调整\n\n项目特色与创新\n\n1. 现代WebGL技术应用\n- 使用WebGL 2.0的高级特性\n- 自"
  },
  "/content/posts/legacy/webgl-3d坦克大战游戏开发实践-现代webgl技术应用#2": {
    "title": "WebGL 3D坦克大战游戏开发实践：现代WebGL技术应用",
    "url": "/content/posts/legacy/webgl-3d坦克大战游戏开发实践-现代webgl技术应用",
    "date": "2025-07-21",
    "text": "学会了多种性能分析方法\n- 实施了有效的优化策略\n- 平衡了功能复杂度与性能表现\n\n未来发展方向\n\n1. **多人在线**: WebSocket实现实时对战\n2. **地形编辑器**: 可视化关卡编辑工具\n3. **粒子系统**: 更丰富的视觉效果\n4. **VR支持**: WebXR实现虚拟现实体"
  },
  "/content/posts/legacy/极空间-nas-部署-tailscale-指南#0": {
    "title": "极空间 NAS 部署 Tailscale 指南",
    "url": "/content/posts/legacy/极空间-nas-部署-tailscale-指南",
    "date": "2024-01-01",
    "text": "极空间 NAS 部署 Tailscale 指南\n\n1. 准备工作\n* 登录 Tailscale 网页控制台。\n* 生成 **Auth Key**：\n    * 勾选 **Reusable** (可复用)\n    * 勾选 **Ephemeral** (非临时/长期有效)\n    * 勾选 **Pre"
  },
  "/content/posts/legacy/极空间-nas-部署-tailscale-指南#1": {
    "title": "极空间 NAS 部署 Tailscale 指南",
    "url": "/content/posts/legacy/极空间-nas-部署-tailscale-指南",
    "date": "2024-01-01",
    "text": "* 装载路径：手动填写 `/var/lib/tailscale`\n2.  **网络**：\n    * 修改为 **Host** 模式 (必须，否则无法做网关)。\n3.  **环境**：\n    * 添加变量名：`TS_AUTHKEY`\n    * 添加变量值：粘贴你复制的 Key。\n4.  **能力"
  },
  "/content/posts/legacy/积分商城用户数据加密改造实战笔记#0": {
    "title": "积分商城用户数据加密改造实战技术博客",
    "url": "/content/posts/legacy/积分商城用户数据加密改造实战笔记",
    "date": "2021-11-19",
    "text": "积分商城用户数据加密改造实战技术博客\n\n- **实现策略：** 使用 **AES** 加密算法，将敏感字段加密后存储，同时保留原始数据处理方式以实现同时兼容。\n- **解决方案：** 通过 **MyBatis TypeHandler** 解耦存取过程，自动将某些指定字段进行加密和解密操作，无需修改上"
  },
  "/content/posts/legacy/积分商城用户数据加密改造实战笔记#1": {
    "title": "积分商城用户数据加密改造实战技术博客",
    "url": "/content/posts/legacy/积分商城用户数据加密改造实战笔记",
    "date": "2021-11-19",
    "text": "找出所有旧数据\n- 调用AesUtil进行加密\n- 更新回原数据表\n\n示例：\n\n4. 实践结果\n\n完成数据加密改造后，系统正常运行，上线用户体验无明显变化，同时提升了数据安全性，成功满足后续安全管控需求。\n\n整体过程中，最关键的是定制好规范，遵循加密协议，确保各组件互相兼容。实际工程中，还可考虑增加"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#0": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘\n\n1.\t输入文本 – 模型接收到原始的文本字符串。\n2.\t分词 (Tokenization) – 将文本拆解成一个个 Token（词元） 序列。\n3.\t映射 ID – 每个 Token 对应到模型词表中的一个 整数 ID 。\n4.\t向量化 (Em"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#1": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "答案。\n\n下面我们将沿着这条“思维”流程，逐步揭秘大语言模型如何从分词到推理再到最终的文本生成。\n\n文本分词：从字符串到 Token 序列\n\n为什么要分词？ 大语言模型无法直接处理原始文本字符——模型只能理解数字。因此，输入的句子首先必须转换为数字才能送入模型 。这个转换过程的第一步就是分词（Tok"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#2": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "符或符号，具体取决于所使用的分词算法和词汇表。分词的结果，是把文本转化为一个 Token 序列。\n\n如何分词？ 为了高效地表示不同语言内容，现代 LLM 常使用子词分词算法，例如 Byte-Pair Encoding (BPE，字节对编码) 或 WordPiece 等。以 BPE 为例，它通过反复合"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#3": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "为新的 token，不断迭代。这意味着模型的词汇表中既包含完整单词，也包含这些高频子词或字片段。\n\nToken 与 ID： 无论采用哪种分词算法，最后都会得到一系列 Token。每个 Token 再通过查表被映射为一个唯一的整数 ID，方便模型处理 。可以把模型的词汇表想象成一个巨大“字典”，里面收"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#4": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "整单词，还是“ap”这样的子词，亦或是标点符号等）都对应于 0 到 50256 之间的某个ID。\n\n**一个直观示例：**假如我们有一句英文输入 “I have a dream”，使用 GPT-2 的 BPE 分词器会将其拆成 Token：[\"I\", \" have\", \" a\", \" dream\"]"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#5": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "为计算方便的向量形式，这就是 Token 向量化。\n\nToken 向量化：让计算机“理解”自然语言\n\n得到 Token 的 ID 序列后，模型并不会直接拿这些 ID 数字进行计算。原因很简单：直接使用 ID（例如 14324 这样的数字）并没有任何语义上的意义——ID 之间的大小关系并不反映词语含义"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#6": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "映射为一个稠密的向量。这个过程我们称为 Token 向量化（Token Embedding）。\n\n什么是嵌入向量？ 简而言之，嵌入向量是用来表示词元的高维向量（通常数百维）。与简单的“单热（one-hot）”编码不同，Embedding 向量的每个维度都是连续值。这些向量是模型训练过程中学出来的，使"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#7": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "王-男人+女人”≈“王后”这样的关系可以通过向量运算近似体现出来，这正是嵌入向量捕捉语义的威力。\n\n向量化的过程： 可以将嵌入层看作一个查表操作：它维护了一个形状为 ($是词汇表大小，$d$是嵌入维度（如 512, 768 或更高）。当一个 Token 的ID为 $i$ 时，嵌入层输出的就是矩阵 $"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#8": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "...] 这样的形式，高维空间中每个向量可能无法直接直观理解，但模型可以利用它们进行后续计算。\n\n经过嵌入层的处理，原本的文本已经变成了一个个可以被模型“消化”的向量。  正如 Hugging Face 的博文所述：这些嵌入向量序列才是神经网络真正的输入。有了它们，模型接下来就能在连续向量空间中对文"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#9": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "长程依赖。虽然本篇焦点不在 Transformer 细节，但了解其作用有助于理解模型如何“思考”：\n* 自注意力机制让模型可以在每一层动态关注序列中不同 Token 之间的关系。比如，当模型处理一句话时，注意力机制可以让词语“看到”句子中相关的其他词，从而结合上下文调整自身表示。\n* 多层堆叠与非线"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#10": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "“I have a dream” 之后的内容，模型最后一层可能计算出像 \"of\"、\",\"、\"...\" 等数万个 Token 各自的分数。假设其中 Token \"of\" 的得分很高。此时模型实际上已经完成了“下一词预测”的主要工作，但这些 logits 还需要转换成概率形式才能用于最终输出决策。**注"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#11": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "化，得到一个概率分布，使所有可能 Token 的概率之和为 1 。Softmax公式一般表示为：\n\n$$ P(w_i) = \\frac{\\exp(\\text{logit}i)}{\\sum{j}\\exp(\\text{logit}_j)} $$\n\n其中 $P(w_i)$ 就是模型认为 Token $w_"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#12": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "ream”}) = 0.17$ 。概率越高的 Token，自然是模型认为越符合上下文的续接词汇。\n\n贪心还是随机？ 有了下一词的概率分布，直觉上，我们可以选择其中概率最高的 Token 作为输出（这被称为贪心搜索或 Greedy Decoding）。贪心策略每一步都选择最可能的词，优点是简单直接，且"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#13": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "陷入重复循环 。因此，在生成长文本时，我们通常希望引入适当的随机性，以获得更加多样和自然的结果。\n\n引入随机性的采样策略： 为了让模型的输出更灵活多样，业界发展出多种采样（sampling）策略，在保证文本连贯的同时引入随机选择。主要策略包括 Temperature 温度系数、Top-k 采样和To"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#14": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "表现为将 logits 除以 $T$ 再送入 Softmax。 当 $T$ 较高时（例如 $T=1.0$ 是默认值），概率分布比较平滑，模型有较大机会选择到那些原本概率不高但非零的词；反之，当 $T$ 很低时（趋近于0），Softmax 会使最高概率的那个词几乎垄断概率质量，输出基本等同于贪心选择 "
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#15": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "相同的答案 。这是因为 $T=0$ 实际上等效于总是选择概率最高的 Token（完全取消随机性）。\n* Top-k 采样： Top-k 的思路是只考虑概率最高的 K 个候选 Token。模型原本给出了整个词表的概率分布，但很多词概率极低基本不可能，我们没必要管它们。通过设定一个 $K$ 值，比如 $"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#16": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "小则输出更稳定，但可能过于保守。极端地，$K=1$ 就退化为贪心解码（每次只选最可能的一个） 。\n* Top-p 采样（又称核采样，Nucleus Sampling）： Top-p 采样不是固定选取前多少个词，而是选取一个概率累积阈值 $p$。它从最高概率开始累加，直到累积概率超过设定的 $p$，取"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#17": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "样性  。\n\n需要注意的是，以上策略可以结合使用。例如我们经常会同时设置一个较高的 $p$（如 0.9）和一个适中的 $k$（如 50），模型会先选出Top-k，再在其中应用Top-p限制，从而“双重过滤”。调节这些参数可以在文本质量和多样性之间取得平衡——过低的温度或 p 值会让输出非常确定但可能"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#18": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "话不至于每次一模一样。这种随机性来源于模型推理阶段的采样策略，而并非模型在“记不住”之前的回答。\n\n小示例：假设模型当前的上下文是 “今天的天气”，它预测下一个词可能是：“很好”（概率40%）、“不好”（概率30%）、“一般”（概率25%）、其他词（合计5%）。如果采取贪心策略，模型将选择概率最高的"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#19": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "rmers）来处理 Token 化和文本生成。这些库已经封装好了大部分细节，让我们可以方便地调用：\n* 使用分词器(Tokenzier)： 每个预训练的模型都会配套提供一个分词器。开发者需要先加载分词器，用它的 encode 或 __call__ 方法将输入文本转换为 Token ID 列表。例如，"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#20": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "度0.8和 Top-p 0.9 来生成文本。如果将 temperature=0 和 top_p=1.0（或 do_sample=False）则会采用贪心方式生成确定性输出。\n\n* 结果解码： 模型生成的是一系列 Token ID，我们需要用分词器的 decode 方法将它们转换回可阅读的文本 。例如"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#21": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "网络中基于训练所得的知识计算出下一词的概率分布，然后按照一定策略抽取输出，从而逐步生成文本答复。\n\n这种生成机制使得模型能够产出连贯且富有语义的语言，但也决定了它本质上是一个概率模型。我们驳斥了“相同输入必定得到相同输出”的误解，理解了随机采样在生成中的作用。同时，我们也强调了嵌入向量对于模型“理解"
  },
  "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘#22": {
    "title": "大语言模型是如何“思考”的：从分词到推理的全过程揭秘",
    "url": "/content/posts/legacy/大语言模型是如何-思考-的-从分词到推理的全过程揭秘",
    "date": "2024-10-07",
    "text": "着确定的逻辑流程和数学基础，我们可以既仰赖它强大的预训练知识，又通过工程手段精细地掌控它的输出。\n\n大语言模型的发展仍在继续，从改进分词方法到更先进的采样策略，都有大量研究涌现。希望这篇文章为您提供了一个清晰的全景视角，帮助技术从业者更深入地理解 LLM 的工作原理，也为实际应用和调优提供一些指导。"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#0": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job\n\n2. Other Common Metrics\n\nBeyond the core metrics,"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#1": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "w Do Outliers Affect Metrics? A Small Experiment\n\nTo intuitively understand the sensitivity of different metrics to outliers, let's conduct a simple e"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#2": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "inst outliers.\n- **R²** drops to a negative value. This means that after adding the outlier, the model's performance is worse than the baseline model "
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#3": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "anomalies, MAE/MedAE is a more robust choice.\n\n5. How to Choose the Right Metric for Your Project: A Scenario-Based Guide\n\nChoosing the right metric b"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#4": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "f by 1° on average\" or \"off by 5° occasionally\"?\n\nThis question gets to the heart of your model's error tolerance, especially its sensitivity to large"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#5": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "more to the total error than a 1° error ($1^2=1$). This makes MSE/RMSE extremely sensitive to large errors and outliers, acting like an alarm system t"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#6": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "elds, a single extreme error can be very costly.\n\n-   **If you're more concerned with being \"off by 1° on average\" (Stability Priority):**\n    -   **P"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#7": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "nce, without being skewed by a few extreme values. Median Absolute Error (MedAE) is even more robust, as it is completely insensitive to outliers.\n   "
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#8": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "out \"relative percentages\" or \"absolute values\"?\n\nThis question is about the metric's audience and its ease of communication.\n\n-   **If your audience "
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#9": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "., \"Our sales forecast is accurate to within 5%\"). It's also excellent for comparing performance across different scales, such as forecasting sales fo"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#10": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "alues\":**\n    -   **Primary Metrics: RMSE / MAE**\n    -   **Reasoning**: The units of these metrics are the same as your target variable (e.g., the RM"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#11": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "$1,000, which is within our acceptable range\").\n\nScenario 3: What are the characteristics of my data distribution?\n\nThe nature of your data is a criti"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#12": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "are more about relative errors than absolute ones. For example, predicting a \\$1M house as \\$1.1M (a \\$100k error) is different from predicting a \\$10"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#13": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "your data contains many important zero values:**\n    -   **Primary Metrics: MAE / RMSE**\n    -   **Reasoning**: As mentioned, MAPE fails when the actu"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#14": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "reporting habits, addressing Scenarios 1 and 2.\n2.  **Quantitative Analysis (Data Exploration)**: Plot a histogram of your data to check for long tail"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#15": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "hensive understanding of your model's behavior.\n4.  **Final Selection (Deployment)**: Based on the analysis, choose 1-2 of the most critical metrics t"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en#16": {
    "title": "A Deep Dive into Regression Evaluation Metrics: From MAE to R², Choosing the Right Tool for the Job",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive-en",
    "date": "2024-01-01",
    "text": "idge that connects your model to real-world value. We hope this guide helps you choose and interpret evaluation metrics with more confidence in your f"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#0": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale\n\n1.  **Core Scheduling Engine:** A robust, `asyncio`-based scheduler.\n2.  "
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#1": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "cript based on performance metrics or failures.\n4.  **Human Ticketing System:** When a task failed irrecoverably, the system would generate a \"ticket,"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#2": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "On the surface, it looked like a massive success. The problem was that I was acting as a project manager, not an architect. I was specifying *what* to"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#3": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "tried to run the integrated system, it collapsed. The root causes were not novel or exotic; they were classic software engineering failures, amplified"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#4": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "t is an incredibly powerful implementation engine. By asking for everything at once, I had inadvertently directed it to build a solution for a future "
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#5": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "he theoretical problems became painfully concrete. The AI, in its effort to satisfy all requests, made expedient choices that created fundamental conf"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#6": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "ematic Code Snippet 1: Conflicting Event Loops**\n\nWhen `handle_failed_task` was called by the running scheduler, it would crash with a `RuntimeError: "
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#7": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "onTrigger` introduced another layer of complexity. Its blocking nature and separate threading model didn't mesh cleanly with the fully asynchronous de"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#8": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "list of features and expecting a coherent result. I had abdicated my role as the architect and reviewer.\n\nA human developer, if asked to build all thi"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#9": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "holistic understanding that comes from experience. Without regular, manual code reviews and integration testing at each step, I was blind to the accum"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#10": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "the \"Intelligent Task Execution\" module worked.\n\n**Conceptual Problem: Tight Coupling**\n\nDebugging was a nightmare. A failure in one component would c"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#11": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "cise in humility and a return to first principles. The recovery process gave me a clear framework for working with AI, one that leverages its power wi"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#12": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "nce,\" no \"self-improvement.\" Just a stable core.\n\nOnly after this core was built, tested, and proven did I begin to add the AI features back, one by o"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#13": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "esson 2: The Human-in-the-Loop is Non-Negotiable\n\nI changed my role from \"project manager\" to \"lead architect and senior developer.\" The AI is my bril"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#14": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "tectural mismatches, and incorrect assumptions.\n4.  **I refactor and integrate the code myself.** I am the one who connects it to the main application"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#15": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "Lesson 3: Simple is (Still) Better Than Complex\n\nThe `asyncio` problem was solved by enforcing a single, simple rule: there is only one event loop, an"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#16": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "implicity—must be enforced by the human developer. An AI, optimizing for a local goal, may not choose the simplest global path.\n\nFinal Thoughts: The P"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#17": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "n, and execute instructions with superhuman speed. But the human developer must remain the pilot-in-command, responsible for the flight plan (architec"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#18": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "resist the temptation to let it run unsupervised. Instead, we must guide it, question it, and integrate its output with the wisdom and foresight that "
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#19": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "d foundation before adding intelligent features\n2. **Human Review is Critical**: Every AI-generated code needs human architectural review\n3. **Modular"
  },
  "/content/posts/legacy/ai-assisted-development-lessons-learned#20": {
    "title": "My AI Coding Partner Almost Drove My Project Off a Cliff: A Cautionary Tale",
    "url": "/content/posts/legacy/ai-assisted-development-lessons-learned",
    "date": "2025-07-27",
    "text": "main the architect, not just the project manager\n\nThe future of software development lies not in replacing human judgment with AI, but in creating a p"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#0": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "从离线部署到K8s流水线发布：一线工程师的实战总结\n\n在没有联网的环境中部署应用，我们采取了一套离线部署 Jar 包的方案。主要步骤包括：\n* 准备可执行 Jar：通过 CI 在内网构建出可执行的 uber JAR（将依赖打包），或将所有依赖手动下载好。确保版本正确且依赖完整，避免部署后因无法联网下"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#1": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "。\n\n* 验证部署结果：检查应用日志和端口监听确保启动成功。例如，通过 tail -f nohup.out 实时查看日志确认没有报错，以及使用 netstat -tunlp | grep 8080 确认服务端口已被监听。\n\n以上流程保证了在无外网环境下顺利部署应用。但该手工方式也存在明显缺点：每次更"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#2": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "面对数亿行数据时，COPY TO 运行非常缓慢，中途容易因为网络波动或超时失败，恢复起来也麻烦。\n\n* 优化方案：分片批量导出：我们决定采用分批导出策略，将大表拆分为小块依次导出。具体做法是利用主键或时间范围分段：编写脚本按范围查询数据，每次导出几十万行追加到文件。这种分段处理避免单次传输过多数据导"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#3": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "ulk 将一张约5千万行的表导出为 CSV，耗时从最初的数小时缩短到不到1小时，大大提升了效率。\n\n* 结果与验证：导出完成后，务必验证数据完整性。我们通过对比导出行数和 Cassandra 中记录数来校验是否有遗漏，并随机抽样对比内容。导出的 CSV 则压缩归档保存，以便日后可能的恢复或分析使用。"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#4": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "两套服务时，应用在初始化 Atomikos 事务管理器时抛出了异常，导致启动失败。日志片段如下：\n\n从错误可以看出，Atomikos 尝试创建事务日志文件时发生冲突（Log already in use）。原因是同一环境中同时运行了多个使用 Atomikos 的应用，且它们默认使用相同路径的事务日志"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#5": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "时运行的只有一个 Atomikos 实例。如果必须分开部署，也可以通过容器化等方式隔离运行环境。\n\n采用了修改日志路径的方法后，我们重新启动应用，Atomikos 初始化成功，冲突不再发生。这个案例提醒我们：中间件的默认配置不一定适用于特殊场景，需根据部署情况做适当调整。例如，对于需要在同一主机部署"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#6": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "ZooKeeper 本身不可用。我们登陆到 ZooKeeper 所在服务器，运行 zkServer.sh status 发现服务确实没有启动。在这个测试环境中，ZooKeeper 被意外关闭而我们没有注意。\n* 防火墙或网络问题：在确认启动 ZooKeeper 服务后，依然出现连接失败。这让我们检查"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#7": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "DNS 无法解析。在本次事件中虽未出现这种错误，但我们在自查过程中也验证了配置项以排除这类因素。\n\n解决方案：针对上述原因采取了相应措施——启动 ZooKeeper 服务进程，并调整防火墙策略允许访问 ZooKeeper 的端口（例如2181）。随后重启微服务，Curator 成功建立连接，应用顺利"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#8": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "理解其工作机制和配置项，有助于快速找到问题根源并加以解决。\n\nKubernetes 标准发布流程\n\n在解决了初步的部署和运行问题后，我们着手引入 Kubernetes (K8s) 来重构发布流程。目标是实现从构建、部署到发布的流水线自动化，将过去繁琐的手工步骤标准化。下面介绍我们落地 K8s 标准发"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#9": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "文件，包括 Deployment、Service 等资源。示例 Deployment 清单片段：\n\n上述清单定义了两个副本的部署，并配置了应用容器使用我们构建的镜像。同时设置了 就绪探针 (Readiness Probe) 和 存活探针 (Liveness Probe)，定期访问应用的健康检查接口 "
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#10": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "t 存储，启动时通过环境变量注入。这样在不同环境下（测试、生产）可以使用不同的配置而不需更改镜像。\n* CI/CD 流水线：我们将构建和部署步骤集成到 CI/CD 工具（如 Jenkins 或 GitLab CI）的流水线中。当代码合并到主干分支时，流水线自动执行：编译测试 -> 构建Docker镜"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#11": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "* 灰度发布策略：对于重大版本采用分批发布，先在一小部分实例上部署观察运行状况，再逐步扩至全量。\n\n通过 Kubernetes 的标准化部署，我们的应用发布从此进入流水线作业，实现了一键部署和回滚，减少了人为失误。每次部署都有记录和监控，使得问题追溯和快速恢复更加方便。\n\n日志监控体系搭建\n\n随着系"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#12": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "误，我们可以在 Kibana 一处查看该服务所有实例的日志，按照时间线追踪问题，大大提升排查效率。\n* 性能指标监控：我们搭建了基于 Prometheus + Grafana 的监控系统。Prometheus 定时抓取各服务的指标数据（包括基础资源如CPU、内存，及应用自定义指标如请求次数、错误率）"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#13": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "过阈值（如 CPU 长时间过高、错误率突增），系统会自动通过短信或钉钉机器人通知相关人员及时响应。\n* 链路追踪和分析：除了日志和指标，我们还评估了链路追踪工具（如 SkyWalking、Jaeger）用于分布式调用跟踪。在复杂的微服务环境中，这类工具可以帮助我们追踪一次用户请求经过的多个服务，定位"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#14": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "）\n通过上述一系列改进，我们对比了优化前后的效果：\n\n（表：系统在部署和运维方面优化前后的对比）\n\n从上表可以看出，系统经过改造后在发布效率、可靠性和可维护性方面都有了显著提升。例如发布效率方面，由原来的每次发布耗时半小时、需多人配合，优化为流水线后通常几分钟即可完成，且基本零人工干预。再如故障排查"
  },
  "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结#15": {
    "title": "从离线部署到K8s流水线发布：一线工程师的实战总结",
    "url": "/content/posts/legacy/从离线部署到k8s流水线发布-一线工程师的实战总结",
    "date": "2022-03-10",
    "text": "择专业工具大幅提高效率；在监控方面，不盲目追新，而是根据团队能力循序渐进地引入适合的组件。\n  3. 故障演练和预案：在实现了自动化和监控后，更应定期演练故障场景（如单点故障、发布失败回滚等），确保团队对新体系下的异常处理熟练有素。\n* 未来改进：我们计划进一步完善持续交付，实现一键部署到多环境和蓝"
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive#0": {
    "title": "分类模型评估指标权威指南：从混淆矩阵到AUC与F1分数",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "分类模型评估指标权威指南：从混淆矩阵到AUC与F1分数\n\n-   **TP (真正例)**: 真实为正，预测也为正。\n-   **FN (假负例)**: 真实为正，但预测为负（第 I 类错误）。\n-   **FP (假正例)**: 真实为负，但预测为正（第 II 类错误）。\n-   **TN (真负"
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive#1": {
    "title": "分类模型评估指标权威指南：从混淆矩阵到AUC与F1分数",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "好的错觉。\n\n4. 概率质量指标\n\n这类指标直接评估模型输出概率的质量，而非最终的分类标签。\n\n5. 多分类与不均衡的加权方式\n\n在多分类任务中，我们需要将每个类别的指标汇集成一个总分。\n\n-   **Micro 平均 (Micro Average)**：将所有类别的 TP, FP, FN, TN "
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive#2": {
    "title": "分类模型评估指标权威指南：从混淆矩阵到AUC与F1分数",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "**Micro-F1**，以全面了解模型在多数类和少数类上的表现。\n\n6. 常见误区与排雷\n\n1.  **高 Accuracy ≠ 好模型**：在 99:1 的数据上，一个把所有样本都预测为负类的“傻瓜模型”也能达到 99% 的准确率。\n2.  **混淆 Precision 和 Recall**：请"
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive#3": {
    "title": "分类模型评估指标权威指南：从混淆矩阵到AUC与F1分数",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "准。在生产环境中，需要同时关注 LogLoss 或 ECE。\n\n7. Python 快速实战模板\n\n下面是一个使用 `scikit-learn` 在一个（不均衡的）多分类数据集上计算多种指标的模板。\n\n**输出示例**:\n\n观察到 Macro-F1 (0.755) 明显低于 Weighted-F1 "
  },
  "/content/posts/legacy/classification-evaluation-metrics-deep-dive#4": {
    "title": "分类模型评估指标权威指南：从混淆矩阵到AUC与F1分数",
    "url": "/content/posts/legacy/classification-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "校准。使用 LogLoss 作为训练损失，并用 ECE 或 Brier Score 进行验证。\n4.  **监控整体性能**：在模型迭代或 A/B 测试中，使用 AUPRC (不均衡数据) 或 ROC-AUC (均衡数据) 来评估模型的整体排序能力。\n5.  **处理不均衡问题**：如果 Macro"
  },
  "/content/posts/legacy/理解和使用字符实体-从基础到实践#0": {
    "title": "理解和使用字符实体：从基础到实践",
    "url": "/content/posts/legacy/理解和使用字符实体-从基础到实践",
    "date": "2025-03-27",
    "text": "理解和使用字符实体：从基础到实践\n\n字符实体广泛应用于HTML、XML等标记语言，用于表示特殊符号、空格、换行等内容。使用字符实体可以确保这些特殊字符不会被解析器误认为是代码的一部分，从而能够正确显示。常见的字符实体包括：\n\n上面列表中的实体都是命名字符实体，使用特定的名字如lt、amp等来引用字符"
  },
  "/content/posts/legacy/理解和使用字符实体-从基础到实践#1": {
    "title": "理解和使用字符实体：从基础到实践",
    "url": "/content/posts/legacy/理解和使用字符实体-从基础到实践",
    "date": "2025-03-27",
    "text": "体名称（或者记不住名字），使用数字字符实体也是一种通用的做法。\n\n在 Python 开发中的实践\n\n随着 Python 3 的普及，字符串默认使用 Unicode 编码，这意味着我们在源码和字符串字面量中可以直接使用绝大多数字符而不出现乱码问题。然而，当我们在 Python 中处理 HTML 或 X"
  },
  "/content/posts/legacy/理解和使用字符实体-从基础到实践#2": {
    "title": "理解和使用字符实体：从基础到实践",
    "url": "/content/posts/legacy/理解和使用字符实体-从基础到实践",
    "date": "2025-03-27",
    "text": "(text, quote=True)，这会把 \" 和 ' 一并转换为&quot;和&apos;。\n\n对于反转义（将实体还原为符号），可以使用 html.unescape() 函数：\n\nhtml.unescape() 会识别字符串中的所有命名和数字字符引用，并替换为相应的 Unicode 字符 ￼。上"
  },
  "/content/posts/legacy/理解和使用字符实体-从基础到实践#3": {
    "title": "理解和使用字符实体：从基础到实践",
    "url": "/content/posts/legacy/理解和使用字符实体-从基础到实践",
    "date": "2025-03-27",
    "text": "ython 开发中，应优先使用html.escape和html.unescape来处理字符实体。\n\n除了手动调用这些函数，现代的 Web 开发框架也普遍提供了自动转义机制。例如，在 Django 和 Flask 的模板引擎中，模板变量会默认进行HTML转义，这意味着开发者不必自己调用转义函数就能防止"
  },
  "/content/posts/legacy/理解和使用字符实体-从基础到实践#4": {
    "title": "理解和使用字符实体：从基础到实践",
    "url": "/content/posts/legacy/理解和使用字符实体-从基础到实践",
    "date": "2025-03-27",
    "text": "在某些必须使用ASCII的场景下（比如早期的纯ASCII邮件或者特殊系统），字符实体仍然是必要的。\n* 字符集与存储： 在数据库或文件中保存文本时，确保使用合适的字符编码。如果使用 UTF-8 等通用编码，可以直接存储 Unicode 字符而不是实体编码形式。例如，与其在数据库中存储&middot;"
  },
  "/content/posts/legacy/理解和使用字符实体-从基础到实践#5": {
    "title": "理解和使用字符实体：从基础到实践",
    "url": "/content/posts/legacy/理解和使用字符实体-从基础到实践",
    "date": "2025-03-27",
    "text": "实体或自行声明实体。开发中如果不确定目标环境支持某个命名实体，最好使用通用的数字实体以确保兼容性。\n* 避免重复转义： 对同一段文本不要反复进行转义操作。例如，如果字符串已经包含&amp;，再次对其执行转义会变成&amp;amp;，导致数据显示异常。一般来说，在输入和输出的不同阶段各处理一次转义/反"
  },
  "/content/posts/legacy/理解和使用字符实体-从基础到实践#6": {
    "title": "理解和使用字符实体：从基础到实践",
    "url": "/content/posts/legacy/理解和使用字符实体-从基础到实践",
    "date": "2025-03-27",
    "text": "码为%20，在HTML中可以用&nbsp;，而在Python字符串里则直接就是空格字符。\n\n总结\n\n字符实体是一种在文本中表示特殊字符的机制，从基础的HTML转义符（如&lt;表示<）到各种符号、语言字符的实体引用，都极大地方便了在不同环境下的字符显示。在现代开发中，我们应根据具体场景选择最佳实践："
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide#0": {
    "title": "解构约克大学双轨制：学术参与与签证合规深度指南",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide",
    "date": "2025-07-24",
    "text": "解构约克大学双轨制：学术参与与签证合规深度指南\n\n2. 核心支柱一：学术参与与健康福祉政策 (AEW) 精解\n\nAEW 是保障学生学术体验与个人福祉的基础框架，其监测要点构成了整个系统的\"数据源\"。\n\n课堂参与监测 (Attendance Monitoring)\n\n学生必须使用大学的 Check-I"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide#1": {
    "title": "解构约克大学双轨制：学术参与与签证合规深度指南",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide",
    "date": "2025-07-24",
    "text": "互动 (Academic Supervision)\n\n定期的导师互动是学术引导和支持的关键环节。\n\n-   **授课型硕士 (PGT):** 要求每学期至少进行 2 次学术督导，其中至少 1 次为线下一对一会面。在暑期毕业设计/论文阶段，则要求至少有 3 个\"参与点\"(engagement poin"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide#2": {
    "title": "解构约克大学双轨制：学术参与与签证合规深度指南",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide",
    "date": "2025-07-24",
    "text": "Student Hub) 等多种支持路径。\n\n3. 核心支柱二：学生签证条款 (SVTC) 详解\n\nSVTC 是国际学生必须严格遵守的法律义务清单，直接关系到签证的有效性。\n\nCAS 与签证的专属性 (CAS & Visa Usage)\n\n学生的 CAS (Confirmation of Accep"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide#3": {
    "title": "解构约克大学双轨制：学术参与与签证合规深度指南",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide",
    "date": "2025-07-24",
    "text": "参与的移民合规 (Attendance & Engagement for Compliance)\n\nSVTC 明确要求国际学生必须完全遵守 AEW 的所有监测流程。任何由 AEW 系统标记的缺勤或学术脱节，都会自动触发移民合规团队的审查。若学生对校方的联系持续不作回应，大学有法律义务向 UKVI 报"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide#4": {
    "title": "解构约克大学双轨制：学术参与与签证合规深度指南",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide",
    "date": "2025-07-24",
    "text": "现，大学有权撤销其学生签证担保 (Sponsorship)。\n\n4. 双轨协同：政策如何联动运行\n\nAEW 和 SVTC 通过数据共享和流程衔接，形成一个从预警到干预再到合规上报的闭环。\n\n数据联动：从学术监测到合规审查\n\nAEW 系统产生的出勤打卡、作业提交和导师会面记录，是 SVTC 判断学生是"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide#5": {
    "title": "解构约克大学双轨制：学术参与与签证合规深度指南",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide",
    "date": "2025-07-24",
    "text": "ce Team) 将正式介入，并根据法律义务决定是否向 UKVI 报告。\n\n灵活的豁免与记录机制\n\n该体系并非僵化不变。如学生因健康问题需要缺勤，可以通过自我证明或官方的请假流程 (Leave of Absence) 来暂停 AEW 的\"缺勤计数\"。然而，所有此类申请和批准都必须在 eVision "
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide#6": {
    "title": "解构约克大学双轨制：学术参与与签证合规深度指南",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide",
    "date": "2025-07-24",
    "text": "vice):** 为学生提供专业的移民法律建议，尤其适用于拒签、行政复议或复杂的 ATAS 问题。\n-   **学生福利与学术支持中心 (Student Hub):** 提供一站式支持，包括申请评估延期、心理健康辅导、残障服务等。\n-   **院系办公室 / 学术导师:** 处理日常学术问题的首要联"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide#7": {
    "title": "解构约克大学双轨制：学术参与与签证合规深度指南",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide",
    "date": "2025-07-24",
    "text": "通。绝大多数问题在早期沟通后都能得到妥善解决，远胜于事后被动解释。\n\n关注政策动态：保持信息同步\n\nUKVI 的移民法规和大学的执行细则都可能发生变化。定期查收学校邮件，并留意官网 AEW 和 SVTC 页面的更新，是每位学生的责任。\n\n结论\n\n约克大学的 AEW 与 SVTC 政策共同构成了一个旨"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#0": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化\n\n失败原因分析\n\n导致训练过程中损失发散的原因可能来自两个方面：一是优化过程中的参数设置或算法问题，二是数据方面的问题。下面从这两方面分别分析常见原因。\n\n优化相关原因\n* 学习率过高：过大的学习率是训练发散最常见的原因之一。当学"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#1": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "NaN，之后损失就彻底飞散了 。因此，如果训练从某个迭代开始损失骤增，很可能是学习率过大引起的。\n* 梯度爆炸：梯度爆炸是指在深层网络中反向传播时梯度值指数级增大，使得参数更新过大，模型无法正常学习。即使学习率适中，如果模型结构或初始化不当，也可能出现梯度爆炸现象，造成损失陡增 。例如网络过深且未采"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#2": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "炸往往和学习率过高有关联（高学习率放大了本就偏大的梯度 ），但也可能由模型本身的数值不稳定性引起。\n* BatchNorm 不稳定：批量归一化（Batch Normalization）一般用于稳定和加速训练，但在某些情况下反而会引入不稳定性。如果BatchNorm层使用不当（例如批大小过小、数据分布"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#3": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "稳定 ）。总的来说，BatchNorm 若未正确配置，有可能成为训练不稳定的诱因。\n\n数据相关原因\n* 数据格式错误：数据输入的格式若不符合模型预期，会导致模型学习到错误的东西，严重时使损失异常波动或发散。例如输入数据包含了非法值（NaN/Inf），或者特征的维度、归一化方式不正确，都会影响损失计算"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#4": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "N 。因此，任何数据管道中的格式或数值错误（包括特征处理和标签处理）都可能导致训练损失的异常上升。\n* 标签错位或错误：如果数据集的标签与输入没有正确对齐，模型实际上学不到正确的对应关系，损失自然无法正常降低。标签错位可能发生在数据预处理或加载阶段，例如在序列建模任务中，输入和目标序列出现偏移，或者"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#5": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "签是否正确匹配到对应的输入。数据标签错误或错位往往会导致训练无法收敛，甚至比随机标签的情况更糟糕。\n* 样本不均衡：训练数据中不同类别或不同类型的样本分布严重不均衡，也可能引发训练困难。模型在训练时会倾向于优化总体损失，占多数的样本类别主导了梯度方向，当某一轮碰巧遇到少数类样本时，损失可能会飙升，因"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#6": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "对策略\n\n针对上述训练失败的可能原因，我们可以从优化参数和数据处理两方面采取相应的工程措施来改进：\n* 调低学习率：首先考虑将学习率降低一个量级或更多。经验上，如果在训练初期（比如前100个迭代）就观察到loss出现NaN或暴涨，往往是学习率过高所致，应及时将学习率调小 。降低学习率可以减缓每次参数"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#7": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "测到梯度出现异常增大趋势时，裁剪操作可以将其拉回合理区间，从而避免损失函数梯度爆炸导致的训练发散。\n* 采用学习率 Warmup：Warmup（预热）策略指在训练开始阶段使用较小的学习率，然后再逐步提高到预设值。这样做可以让模型先以安全的步长开始学习，避免一开始由于学习率过大而发散 。具体而言，我们"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#8": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "，对于像Qwen2.5-1.5B这样的大模型微调，引入适当的学习率warmup有助于稳定训练开局。\n* 检查数据管道：彻底排查数据读取和预处理流程，确保输入数据和标签的格式与模型要求一致。需要验证数据集中是否存在异常值或错误标注，例如：图像数据是否正确归一化，文本数据的token是否正确对齐标签，分"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#9": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "的样本。此外，建议在训练代码中加入断言或日志监控，一旦读入的数据出现不合理值，能够及时发现并纠正。\n* 验证标签配对：针对标签错位或不正确的问题，建议取少量样本手动检查模型输入与标签是否一一对应。可以打印一些训练样本及其标签，人工确保它们匹配无误。如果是序列生成或序列标注任务，要确认对齐方式符合预期"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#10": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "据，并观察其loss能否下降——如果连单一batch都无法收敛，十有八九是数据和标签存在对应问题。\n* 平衡样本分布：对于样本类别不均衡引起的训练不稳定，可采用一些策略来缓解其影响。例如，在采样时对少数类样本过采样、对多数类欠采样，或在损失函数中引入类别权重，使模型在计算loss时更加关注少数类。另"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#11": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "过度偏向某一部分数据 。通过这些措施，减轻数据不均衡对模型优化轨迹的干扰，使训练损失曲线更加平稳。\n* 监控异常值并及时停止：在训练过程中加入对loss和梯度的监控也是重要的工程手段。可以定期检查梯度范数和loss值，一旦发现loss出现异常巨大的增幅或者变为NaN/Inf，应当触发早停机制或中断训"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#12": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "上述措施（降学习率等）。总之，及时发现并停止能防止模型在错误的方向上越走越远，减少无效的计算开销。\n* 调整模型及其他超参：如果经过以上排查仍无法稳定训练，可能需要审视模型本身的设计和其他超参数。比如检查网络层的设置（过深的网络是否加了残差结构来缓解梯度问题），选择合适的激活函数和初始化方法来保证数"
  },
  "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化#13": {
    "title": "一次微调训练失败案例解析：从 Qwen2.5 的损失曲线看问题与优化",
    "url": "/content/posts/legacy/一次微调训练失败案例解析-从-qwen2-5-的损失曲线看问题与优化",
    "date": "2024-10-09",
    "text": "步逼近稳定收敛的配置。\n\n总结\n\n通过对上述案例的损失曲线进行分析，我们确定该 Qwen2.5-1.5B 模型微调过程中出现了训练失败（损失发散）现象。判断依据是训练损失在若干轮后不仅没有下降，反而以指数趋势上升，这是训练过程严重异常的标志。造成这种问题的原因可能包括学习率设置不当、梯度爆炸未被抑制"
  },
  "/content/posts/legacy/java静态博客转换器开发实践与技术总结#0": {
    "title": "Java静态博客转换器开发实践与技术总结",
    "url": "/content/posts/legacy/java静态博客转换器开发实践与技术总结",
    "date": "2025-07-22",
    "text": "Java静态博客转换器开发实践与技术总结\n\n- **语言**: Java 8\n- **构建工具**: Maven 3.x\n- **核心库**: FlexMark-Java（Markdown处理）、Jackson（JSON/YAML处理）\n- **测试框架**: JUnit Jupiter\n- **编"
  },
  "/content/posts/legacy/java静态博客转换器开发实践与技术总结#1": {
    "title": "Java静态博客转换器开发实践与技术总结",
    "url": "/content/posts/legacy/java静态博客转换器开发实践与技术总结",
    "date": "2025-07-22",
    "text": "- **输入验证**: 严格的文件路径和内容验证  \n- **异常处理**: 完整的异常处理机制\n- **路径安全**: 防止目录遍历攻击\n\nMaven构建配置\n\n依赖管理\n\nShade插件配置\n\n使用 Maven Shade 插件生成可执行的 Fat JAR：\n\n使用方式\n\n命令行接口\n\n输出结构"
  },
  "/content/posts/legacy/java静态博客转换器开发实践与技术总结#2": {
    "title": "Java静态博客转换器开发实践与技术总结",
    "url": "/content/posts/legacy/java静态博客转换器开发实践与技术总结",
    "date": "2025-07-22",
    "text": "eepSeek API Key集成\n- 灵活的配置文件管理\n\n4. 测试覆盖\n\n- 完整的单元测试\n- 集成测试\n- 多场景测试用例\n- 自动化测试流程\n\n版本迭代与优化\n\n项目经历了多个版本的迭代：\n\n1. **初始版本**: 基础Markdown转HTML功能\n2. **功能增强**: 添加模板"
  },
  "/content/posts/legacy/java静态博客转换器开发实践与技术总结#3": {
    "title": "Java静态博客转换器开发实践与技术总结",
    "url": "/content/posts/legacy/java静态博客转换器开发实践与技术总结",
    "date": "2025-07-22",
    "text": "**Stream API**: 提升集合处理效率\n- **Lambda表达式**: 简化代码逻辑\n- **Optional类**: 优雅的null值处理\n\n应用场景\n\n这个静态博客转换器适用于：\n\n1. **个人博客**: 快速搭建个人技术博客\n2. **文档站点**: 将Markdown文档转换为"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#0": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance\n\n2. Core Pillar One: A Detaile"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#1": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "e\" for the entire system.\n\nAttendance Monitoring\n\nStudents must use the University's Check-In system to electronically register their attendance for a"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#2": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "vention process.\n\nAssessment Submission Tracking\n\nThe submission status of all summative assessments (e.g., assignments, essays) is recorded by the sy"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#3": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "efore the issue escalates.\n\nAcademic Supervision\n\nRegular interaction with a supervisor is a key component of academic guidance and support.\n\n-   **Ta"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#4": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "inimum of three \"engagement points\" are required.\n-   **Postgraduate Researchers (PGR):** Students are required to maintain more frequent contact with"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#5": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "isor or student within two weeks of the meeting.\n\nEarly Support Mechanisms\n\nThe policy emphasizes fairness and inclusivity. When a student's academic "
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#6": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "at the Student Visa Terms and Conditions (SVTC)\n\nThe SVTC is a list of mandatory legal obligations that international students must strictly follow, d"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#7": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "course typically requires a new visa application. Non-compliant use will result in the University reporting the student to UKVI, which may lead to the"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#8": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "to the eVision system before their course begins. Upon arrival in the UK, they must attend an in-person Student Visa Registration event on campus with"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#9": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "hdrawal.\n\nAttendance & Engagement for Compliance\n\nThe SVTC explicitly requires international students to fully comply with all monitoring processes un"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#10": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "ggers a review by the immigration compliance team. If a student is persistently unresponsive to the University's attempts at contact, the University h"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#11": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "ity via the eVision system within 10 working days. This includes, but is not limited to: significant changes to their course or research topic, change"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#12": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "s and work type restrictions stated on their visa. Engaging in employment beyond the permitted scope is a serious violation. If discovered, the Univer"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#13": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "ention and, ultimately, to compliance reporting.\n\nData Integration: From Academic Monitoring to Compliance Review\n\nThe attendance, submission, and sup"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#14": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "nely and continuously engaging with their studies.\" When academic support teams identify a student at risk of disengaging, they will simultaneously in"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#15": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "an automated email reminder from the department.\n-   **Tier 2 (Intervention):** Persistent absence or unresponsiveness escalates the case to student s"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#16": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "VI.\n\nFlexible Exemption and Recording Mechanisms\n\nThe system is not inflexible. If a student needs to be absent due to health issues, they can use sel"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#17": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "Practical Checklist: Key Actions at Key Times\n\n6. Seeking Support: Key Contacts and Resources\n\n-   **Visa Compliance Team:** Handles all matters relat"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#18": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": ", administrative reviews, or complex ATAS issues.\n-   **Student Hub:** Offers one-stop support, including applications for assessment extensions, ment"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#19": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "The Check-In: An Indispensable Chain of Evidence\n\nYour Check-In record is the most direct evidence that you are actively participating in your studies"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#20": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "must upload it to the eVision system immediately. Outdated information can lead to discrepancies in your official record.\n\n3. Proactive Communication:"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#21": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "mic supervisor or the relevant support department. The vast majority of issues can be resolved effectively through early communication, which is far b"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#22": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "l AEW and SVTC webpages for updates.\n\nConclusion\n\nThe University of York's AEW and SVTC policies together form a robust system designed to safeguard s"
  },
  "/content/posts/legacy/york-university-aew-svtc-policy-guide-en#23": {
    "title": "Deconstructing the University of York's Dual-Track System: An In-depth Guide to Academic Engagement and Visa Compliance",
    "url": "/content/posts/legacy/york-university-aew-svtc-policy-guide-en",
    "date": "2025-07-24",
    "text": "in understanding and integrating into this system. By adhering to four simple principles in your daily studies—**\"Check-in on time, submit on time, re"
  },
  "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test#0": {
    "title": "AI同传眼镜 vs. 专业翻译App：真实场景下的效果对决",
    "url": "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test",
    "date": "2024-01-01",
    "text": "AI同传眼镜 vs. 专业翻译App：真实场景下的效果对决\n\n**测试视频源**: https://www.bilibili.com/video/BV1cM4y1A7ne/\n\n对决第一方：Rokid Glasses 同传\n\n*   **产品形态**：AR眼镜，硬件价格2499元。\n*   **服务费"
  },
  "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test#1": {
    "title": "AI同传眼镜 vs. 专业翻译App：真实场景下的效果对决",
    "url": "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test",
    "date": "2024-01-01",
    "text": "容。这并非简单的识别错误，而是底层AI模型产生了严重的“幻觉”，在内部生成了完全不存在的语言。\n2.  **显示层的“信息黑洞”**：一个有趣的观察是，这些错误的日语并未直接显示在眼镜镜片上。相反，在这些时间点，镜片上常常是空白，不显示任何内容。这很可能是一种上层过滤机制：系统可能检测到底层输出的置"
  },
  "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test#2": {
    "title": "AI同传眼镜 vs. 专业翻译App：真实场景下的效果对决",
    "url": "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test",
    "date": "2024-01-01",
    "text": "**服务费用**：高精同传/AI同传服务，价格为0.35元/分钟。\n*   **测试结果**：\n\n**分析与点评**\n\nitourtranslator的表现与Rokid形成了鲜明对比，结果质量高下立判。\n\n1.  **稳定可靠的识别**：与Rokid形成鲜明对比，该App准确地识别了核心的英语对话，"
  },
  "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test#3": {
    "title": "AI同传眼镜 vs. 专业翻译App：真实场景下的效果对决",
    "url": "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test",
    "date": "2024-01-01",
    "text": "\"好的\" 或 \"没错\"。对 \"the code from the UK\" 的理解也出现了偏差。\n\n**初步结论**：itourtranslator作为一款专业的付费翻译应用，其后端的AI模型显然更加强大和鲁棒。它能够有效应对复杂的音频环境，提供基本可靠的翻译结果，完全达到了“可用”的级别，体现了“一"
  },
  "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test#4": {
    "title": "AI同传眼镜 vs. 专业翻译App：真实场景下的效果对决",
    "url": "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test",
    "date": "2024-01-01",
    "text": "段，硬件的形态创新无法弥补AI核心能力的不足。当翻译质量本身不达标时，再便捷的交互也失去了意义。\n\n给Rokid的建议：从“封闭产品”到“开放平台”\n\n通过本次深度测试，我们能清晰地看到Rokid AR眼镜在硬件形态和交互体验上的巨大潜力。抬头即见的翻译字幕，是比任何手持设备都更自然、更高效的交互方"
  },
  "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test#5": {
    "title": "AI同传眼镜 vs. 专业翻译App：真实场景下的效果对决",
    "url": "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test",
    "date": "2024-01-01",
    "text": "**，以及国内的 **讯飞**、**腾讯翻译君**，国际的 **DeepL** 等）进行合作。\n3.  **提供付费增值**：在眼镜的App中，允许用户根据自己的需求，选择并登录这些专业的翻译服务。服务费由第三方平台收取，Rokid可以探索收入分成的商业模式。\n\n这将带来三方共赢的局面：\n\n*   "
  },
  "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test#6": {
    "title": "AI同传眼镜 vs. 专业翻译App：真实场景下的效果对决",
    "url": "/content/posts/legacy/rokid-vs-itourtranslator-simultaneous-interpretation-test",
    "date": "2024-01-01",
    "text": "*：无需投入巨额成本去追赶顶级的AI翻译模型，可以将精力更集中在打磨AR硬件、光学和交互系统上。\n\n*   **对于翻译服务商**：\n    *   **获得创新入口**：获得了一个极具未来感的硬件入口，将其服务从手机App延伸到更自然的AR交互层。\n    *   **拓展用户群体**：触达了广大"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#0": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "项目管理基础知识学习笔记L1\n\n- **项目目标和范围：** 明确项目要达到的目标以及要完成的工作范围，避免出现范围蔓延等问题。目标应当清晰且可衡量，范围需要经过需求收集和确认来明确。\n- **进度与时间：** 制定合理的项目进度计划，明确各里程碑和截止日期，并通过过程中的监控与调整确保项目按时完成"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#1": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "的其他资源（设备、材料等），保证在需要时有恰当的资源投入项目。这包括团队成员的分工、培训及激励等。\n- **沟通协调：** 建立良好的沟通机制，确保项目相关的各方（团队内部、客户、供应商等）信息畅通。沟通计划需要涵盖沟通频率、渠道、内容和责任人等。\n- **采购与外部合作：** 如项目需要采购产品或"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#2": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "于在既定的质量要求下，平衡好范围、进度和成本三者关系，同时兼顾其他方面的需求，最终实现项目目标。\n\n**项目的定义与特征**\n\n根据项目管理协会 PMI 的定义：“**项目**是为创造独特的产品、服务或成果而进行的临时性工作”。简单来说，项目具有明确的目的，并在一定约束条件下开展的一次性任务。项目区"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#3": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "此每个项目都有其独特之处。这种独特性意味着项目团队常常面临新情况和挑战，需要针对具体环境定制方案。\n- **目标导向：** 项目以实现特定目标为导向开展。项目必须有清晰的目标或可交付成果，并且所有活动都围绕这一目标展开。目标导向也要求项目团队在资源和时间有限的条件下尽可能高效地完成工作。\n- **渐"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#4": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "组织的各个部门，大家为了共同的项目目标临时组成团队。项目经理需要在团队中建立清晰的分工与协作机制。\n- **不确定性与风险：** 相较日常业务，项目面临更高的不确定性。项目是一次性的尝试，过程中可能遇到各种变化和风险（例如需求变更、技术挑战、外部环境变化等）。因此，良好的项目管理必须包含主动的风险识"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#5": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "项目管理的思想和工具，而运营则更多应用流程管理、持续改进等思想。\n\n**项目经理应具备的素质**\n\n项目经理是项目成功的关键角色，承担着策划和执行项目的全面责任。要胜任这一角色，项目经理需要具备多方面的素质和技能。概括来说，一名优秀的项目经理应当具备以下几点：\n\n- **专业的项目管理技能：** 项"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#6": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "意义。业务知识还包括基本的商业意识，如成本效益考虑、市场动态等，这有助于项目经理做出更明智的判断。\n- **解决问题和应变能力：** **“项目永远不会完全按计划进行”**——项目经理的很大一部分工作就是在各种问题出现时想办法解决，确保项目仍能达成目标。这要求项目经理具备出色的分析和应变能力，能够冷"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#7": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "保各方在同一频道上协同工作。通过协调各方，项目经理可以减少误解与冲突，让团队朝着共同目标顺利前进。\n- **领导力与影响力：** 项目经理并不只是“管理员”，更是团队的领导者。需要有号召力去激励团队成员投入工作，树立共同愿景。优秀的领导力体现在：为团队指明方向，建立信任和合作的团队文化；授权团队成员"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#8": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "的时间，以及团队整体的时间投入。通过缜密的计划和组织，项目经理可以使繁杂的项目工作有条不紊地进行。\n- **工具使用能力：** 现代项目管理离不开各种工具软件的支持。项目经理应熟练掌握常用的项目管理工具，如甘特图制作工具（进度计划）、看板工具（任务跟踪）、思维导图（头脑风暴和结构化思考）、Offic"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#9": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "。抗压能力还意味着在高强度的项目环境下，依然能够冷静决策、不迷失方向，保持对团队的稳定军心作用。\n\n综上，项目经理是一位**“全能型选手”**：既要懂专业、会管理，又要善沟通、强领导。培养这些素质没有捷径，唯有通过持续的学习和实践不断提高。当项目经理具备了以上素质，在项目运作中就能如鱼得水，带领团队"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#10": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "动过程的产出通常是项目章程的批准和项目经理被正式任命。一旦项目立项获得批准，项目就进入下一个阶段。\n2. **规划过程组（Planning）：** 在规划阶段，项目经理和团队要回答“我们**要做什么**、**如何去做**、**怎样才算完成**”这三个基本问题。具体来说，需要详细制定**项目管理计划*"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#11": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "成后通常需要相关方评审和批准，确保计划可行且获得承诺。只有规划得到认可，项目才会正式进入执行。\n3. **执行过程组（Executing）：** 一旦项目计划获批，项目团队就开始按照计划投入工作，进入执行阶段。这一过程组的重点是**落实计划**、完成项目交付物。项目经理需要组织并获取所需的资源，让团"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#12": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "持，确保大家能高效地完成任务。此外，执行阶段也包括过程中的质量管理、沟通管理、采购实施等活动。\n4. **监控过程组（Monitoring & Controlling）：** 监控过程与执行过程通常是并行进行的。项目经理在执行阶段的日常职责之一就是**监控项目进展**，对比实际绩效与计划的偏差，并采"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#13": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "往体现在每次迭代的回顾与调整上；在传统项目中，则通过里程碑评审、状态报告等形式体现监控与控制。\n5. **收尾过程组（Closing）：** 收尾阶段标志着项目的正式结束，但同样不可马虎。项目经理需要确认所有项目工作已经完成，**获得客户或项目发起人的正式验收**。收尾过程还包括整理并移交项目的最终"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#14": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "团队可以有条不紊地推进工作，不遗漏关键步骤。\n\n**传统 vs 敏捷项目管理的比较及适用场景**\n\n在项目管理领域，**传统（瀑布式）方法**和**敏捷（迭代式）方法**是两种主要的范式。它们在理念、流程和实践上存在显著差异，也各有适用的场景。下面我们对传统与敏捷项目管理进行对比，并讨论各自适用的典"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#15": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "晰界定，需完成当前阶段并经批准后才能进入下一阶段。这种模式类似瀑布从上而下，阶段之间基本没有回溯。\n- **详细的前期计划：** 在项目启动时花大量时间详细规划整个项目，包括进度表、资源分配、成本预算等。计划一旦制定，即作为项目执行的主要依据，中途只有经过正式变更控制程序才能修改。\n- **文档驱动"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#16": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "法，强调**灵活性**和**快速反馈**，特别适合需求经常变化或不确定性高的项目。其主要特点有：\n\n*敏捷项目管理示意图：项目划分为多个短周期的迭代，每次迭代都包括规划、执行、交付和反馈等活动，并产生可用的增量成果。团队不断根据反馈调整方向，循环往复直至项目完成。*\n\n- **迭代式开发：** 将整"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#17": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "下一个迭代中据此调整方向。这种持续的反馈回路提高了产品对用户需求的契合度，也更早地发现并修正问题。\n- **自组织团队协作：** 敏捷强调团队的自主协作。团队通常是跨职能的小组，成员共同负责项目的成果。团队内部沟通频繁，通过每日站会、迭代评审和回顾等方式不断协同改进。**自组织**意味着团队有较大自"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#18": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "终符合客户期望，大幅提高客户满意度和最终交付的价值。\n\n**两种方法的核心区别可以总结如下：**\n\n- **计划方式：** 传统方法强调**详尽的预先规划**，项目伊始即制定完整计划；敏捷方法采用**逐步规划**，边做边计划，在每次迭代前详细规划近期工作，并允许计划持续调整。\n- **需求管理：**"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#19": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "制**态度，以降低风险；敏捷方法**拥抱变化**，通过迭代不断调整来适应变化，将变更视为改进机会。\n- **客户参与：** 传统项目通常仅在开头需求和结尾验收时让客户深度介入；敏捷项目**鼓励客户持续参与**每个迭代，全程紧密合作。\n\n**各自的优势和适用场景：** 传统和敏捷方法各有优劣，并非一方"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#20": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "更倾向传统方法。优点是各阶段责任明确、过程可控，缺点是一旦前期规划有误或环境变化，项目调整成本大。\n- **敏捷项目管理**适合**需求不确定、可能频繁变化**的项目，尤其常见于软件开发、互联网产品、新产品研发等领域。当业务环境快速变化、竞争激烈，需要不断根据用户反馈改进产品时，敏捷方法的灵活性价值"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#21": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "定性、团队能力和企业文化选择**最适合**的方式。下表列出了一些选择项目管理方法时可考虑的因素：\n\n- 如果项目**规模庞大、涉及人员众多**，且团队分布分散，那么传统方法提供的结构化框架可能更有利。而敏捷更适合**小而集中的团队**快速协作。\n- 如果客户或用户能够**高频参与**项目过程（提供持"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#22": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "和严格控制有助于风险管理；若项目对时程预算有一定弹性而更追求最大价值产出，则敏捷的弹性更有优势。\n\n总的来说，没有“一招鲜吃遍天”的方法。**传统**与**敏捷**各擅胜场，在不同情境下发挥作用。项目经理应理解两种方法的原理和差异，根据具体项目的需求选择或调整管理方式，提高项目成功的机会。无论采取何"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#23": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "组织和矩阵型组织**（矩阵又细分为弱矩阵、平衡矩阵、强矩阵）。下面我们分别介绍它们对项目的影响。\n\n- **职能型组织：** 这是传统的以职能部门划分的层级结构，如研发部、市场部、人事部各司其职。在这种结构下，项目工作通常通过部门内的层层管理完成。**对项目的影响**是：项目经理的角色可能并不正式，"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#24": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "要投入大量时间跨部门沟通协调。项目成功很大程度上取决于高层对项目的重视程度以及各部门的配合意愿。\n\n- **项目型组织：** 在另一极端，组织按照项目来组织资源，成立临时的项目团队，项目经理拥有对团队和资源的**完全控制权**。团队成员从各部门抽调出来，全职隶属于项目经理领导，在项目期间通常集中办公"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#25": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "。此外，小型创业公司在创始期也几乎是项目型的，因为大家围绕一个产品/项目工作，没有固定部门之分。\n\n- **矩阵型组织：** 矩阵结构是职能型和项目型的混合体，团队成员保持在原有部门编制，但为项目临时组建跨部门团队，实行“双重汇报”：既向项目经理汇报项目工作，又向自己的部门经理汇报日常工作。矩阵根据"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#26": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "投入大量精力说服和协调。如果组织没有形成良好的项目协作机制，弱矩阵下的项目很容易因部门壁垒而迟滞。\n  - **平衡矩阵**是介于强弱之间，项目经理有一定权力但不完全，比如会**正式任命一位全职项目经理**领导项目，但对人员调配和资金仍不能完全做主，需要与职能经理共享控制。相对于弱矩阵，平衡矩阵明确"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#27": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "，让项目经理有足够的权威推进跨部门项目，同时人员在不参加项目时仍在部门内工作，保持稳定。\n\n  \n\n可以看出，组织结构直接影响**项目经理的权限**和**资源获取方式**。在职能型/弱矩阵中，项目经理需要更多地**依赖高层支持**和**跨部门协调**才能完成项目；而在项目型/强矩阵中，项目经理可以相"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#28": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "置的代价；当组织越趋向职能型，项目运作越需要高层推动和协调，项目经理个人的软实力就显得格外重要。\n\n对项目经理而言，理解自己组织的结构类型，可以帮助预判项目推进中可能遇到的挑战，并采取相应策略。例如，在弱矩阵环境下，项目经理应该更加注重**纵向汇报**，取得职能经理和高层的支持，以及通过影响力而非直"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#29": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "如何工作、如何决策，以及项目在组织中能获得多少支持。以下从多个方面说明企业文化如何影响项目管理：\n\n- **使命愿景与战略契合：** 企业的使命和愿景塑造了整体文化，也影响项目的重要性。如果一个项目能够明显支撑公司使命或战略目标，那么在文化上组织会更加重视这个项目，往往给予更多资源和关注。这种项目推"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#30": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "自问：“这样的选择是否符合我们的使命和价值观？”。在文化认同上获得高层支持的项目，更有成功的底气。\n- **领导风格与授权方式：** 企业文化的一部分体现在管理层的领导方式上：是集权还是分权，信任员工还是严密控制？如果文化鼓励**赋权于员工**、领导定方向员工自主执行，那么项目经理通常会得到比较大的"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#31": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "擅自行动引发冲突。总之，授权文化强的企业，项目经理更像领袖；授权文化弱的企业，项目经理更像协调员。\n- **工作氛围与团队动力：** 企业的工作环境是积极进取还是消极敷衍，也深刻影响项目团队士气。在**积极的文化环境**中，员工有干劲、乐于合作和分享。项目经理在这样的氛围里推动项目会相对轻松：团队成"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#32": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "项目经理在负面文化中要充当“消防员”和“心理辅导”，而在正面文化中则更多扮演“教练”和“领跑者”。\n- **规则意识与创新精神：** 不同企业文化对于规则和创新的态度差异很大。有些文化**高度注重规范和流程**，要求做事严格遵守标准，不鼓励逾矩；而有些文化**推崇创新**，允许打破常规、提倡试错。这"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#33": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "项目经理的管理侧重：如果文化强调过程合规，即使最终结果欠佳也要确保过程正确；如果文化重视结果达成，那么只要目标完成，过程灵活些无妨。项目经理需要判断自己企业属于哪种，以相应的方式治理项目。\n- **风险偏好与变更管理：** 文化还体现在组织对风险和变更的态度上。如果公司文化**害怕风险、追求稳定**"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#34": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "变更”导致项目方向摇摆。一个实用的方法是在项目中定义清晰的变更机制，让团队既有自由度又有一定约束。\n- **多元文化团队：** 在大型企业或跨国项目中，团队成员可能来自不同地域、不同子文化。组织文化本身也许包容多样性，但**跨文化沟通**依然是项目经理必须直面的挑战。不同文化背景的人在交流风格、决策"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#35": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "励大家认识文化差异并相互适应。只有这样，全球化团队才能高效协同，否则文化误解将严重阻碍项目沟通。\n\n总而言之，**企业文化在潜移默化中影响着项目如何开展以及能否成功**。项目经理作为连接战略和执行的桥梁，一方面要尊重并适应公司文化的特质，在文化允许的边界内运作项目；另一方面也可以发挥带动作用，将一些"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#36": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "杂度、团队规模和企业偏好来决定使用哪些工具。以下将介绍主要的项目管理工具类型及选型时的考虑因素：\n\n**常用项目管理工具类型：**\n\n- **进度计划与任务调度工具：** 这类软件用于编制项目进度计划、分配任务和跟踪进展。简易情况下，一些人可能仅用电子表格手工列出任务清单和日期来管理小项目。但对于大"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#37": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "时了解项目进度状况。如果项目涉及许多任务和依赖关系，使用此类软件能够避免遗漏和冲突，使计划更科学。\n- **文档编辑与模板：** **文档工具**（如 Microsoft Word 或国产wps文字等）几乎是项目管理中不可或缺的一部分。项目从立项到收尾都会产生各种文档——计划书、需求说明、设计方案、"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#38": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "优先关注的风险因素。电子表格灵活强大，几乎每个项目经理都会用它来制作自定义的跟踪表格或小型数据库。\n- **演示和汇报工具：** **演示文稿软件**（如 Microsoft PowerPoint 等）常用于对项目情况进行汇报或总结。项目经理需要定期向高层、客户或团队说明项目状态，PowerPoin"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#39": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "段，则用于展示成果和经验。一个好的项目汇报PPT能够提升沟通效果，让相关方快速理解项目进展和需求。\n- **协作与信息共享平台：** 对于团队成员较多或远程协作的项目来说，**协作工具**非常重要。这类工具包括像 Basecamp、Microsoft SharePoint、Confluence、Te"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#40": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "好的协作工具可以极大降低沟通成本，特别是在团队成员不在同一地点或者需要与外部合作伙伴协同的情况下。\n- **企业级项目管理系统：** 当你所处的是执行**多个大型项目**的组织，或者一个项目本身**规模庞大**（许多子项目、数百成员）时，可能需要考虑更全面的**企业项目管理（EPM）软件**。这类系"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#41": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "**选择项目管理软件时的考虑因素：** 工具没有好坏之分，关键在于**适配性**。选择前应评估：\n\n- **团队和企业的工作习惯：** 公司的文化和日常工作方式会影响工具的接受度。例如，有的公司习惯用钉钉或企业微信沟通协作，那么选择与之兼容的项目插件或小程序可能比上一个全新的系统更实际。再如，如果团"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#42": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "虑进度规划软件、资源管理系统等更强大的解决方案。总之，**工具的能力应能覆盖项目管理的复杂性**。\n- **成本预算：** 许多高级项目管理软件价格不菲，引入还可能需要培训和维护成本。必须考虑软件的**性价比**。有些开源或免费工具（如一些开源的看板系统、思维导图工具等）也能满足需求，预算有限时可以"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#43": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "提高，可能希望工具可以扩展，或数据易于导出整合。因此要考察软件的扩展能力、与其他系统的集成接口等。\n- **团队人数和分布：** **小团队**倾向于轻量工具，因为沟通直接，流程简单。而**大团队/跨地域团队**需要更严谨的系统来同步信息、权限管理等。比如几个人的项目直接用协作平台里的任务列表就能分"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#44": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "。合适的软件会成为项目经理的好帮手，让繁杂的信息变得井井有条、协作变得高效顺畅。\n\n**结语**\n\n通过本课的学习，我们搭建了项目管理的基础知识框架：了解了项目管理需要关注的关键问题领域，从项目的概念和特征入手，认识到项目与日常运营的区别；明确项目经理应具备的多维度素质，为今后自身能力提升指明了方向"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l1#45": {
    "title": "项目管理基础知识学习笔记L1",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l1",
    "date": "2025-06-09",
    "text": "需要因地制宜地调整管理策略；最后，我们也关注了项目管理工具的选择，为提高工作效率提供了实践指南。\n\n项目管理是一门既讲究**科学**也依赖**艺术**的学问：一方面有流程、方法、工具等硬性知识，需要我们系统掌握并灵活运用；另一方面，每个项目所处的环境和涉及的人各不相同，又需要项目经理发挥软技能和经验"
  },
  "/content/posts/legacy/cassandra-数据清理实战#0": {
    "title": "Cassandra 数据清理实战",
    "url": "/content/posts/legacy/cassandra-数据清理实战",
    "date": "2022-02-24",
    "text": "Cassandra 数据清理实战\n\n针对上述问题，我们设计了一套数据清理方案，主要步骤如下：\n1.\t导出全部商品ID：从Cassandra中导出商品数据表的所有商品ID，形成全量ID列表文件。\n2.\t获取有效商品ID列表：从业务系统获取当前仍有效（在售/有效）商品的ID列表，作为比对的权威数据源。\n"
  },
  "/content/posts/legacy/cassandra-数据清理实战#1": {
    "title": "Cassandra 数据清理实战",
    "url": "/content/posts/legacy/cassandra-数据清理实战",
    "date": "2022-02-24",
    "text": "存储的所有商品ID列表。假设商品数据表名为 products，我们只需导出该表的主键ID列即可。\n\n我们可以使用Cassandra自带的cqlsh提供的COPY命令导出数据。为了应对数千万行的数据量，导出前可以适当提高超时时间。例如，在命令行执行：\n\n上述命令将 products 表的id列全部导出"
  },
  "/content/posts/legacy/cassandra-数据清理实战#2": {
    "title": "Cassandra 数据清理实战",
    "url": "/content/posts/legacy/cassandra-数据清理实战",
    "date": "2022-02-24",
    "text": "的JSON结果可能需要进行简单处理，例如提取出其中的商品ID字段并保存为文本文件valid_ids.txt，每行一个ID。经过以上处理，我们得到valid_ids.txt，内含当前所有有效商品的ID。\n\n筛选无效商品ID\n\n有了Cassandra导出的全量ID列表和业务侧提供的有效ID列表，我们就可"
  },
  "/content/posts/legacy/cassandra-数据清理实战#3": {
    "title": "Cassandra 数据清理实战",
    "url": "/content/posts/legacy/cassandra-数据清理实战",
    "date": "2022-02-24",
    "text": "，务必采用逐行读取方式以避免内存不足；本例假定有效ID数量相对较小可以放入内存。\n\n删除无效数据\n\n现在我们已经拿到了需要删除的无效ID列表，下一步就是在Cassandra中批量删除这些数据。我们可以使用Python的Cassandra驱动库来连接数据库并执行删除语句。\n\n下面提供一个删除脚本的示例"
  },
  "/content/posts/legacy/cassandra-数据清理实战#4": {
    "title": "Cassandra 数据清理实战",
    "url": "/content/posts/legacy/cassandra-数据清理实战",
    "date": "2022-02-24",
    "text": "和维护。\n\n验证清理结果\n\n当删除脚本执行完毕后，我们需要验证清理是否成功。可以采用以下两种方式：\n* 重新导出ID列表比对：重复执行最开始的数据导出步骤，导出清理后的products表ID列表，与清理前的列表比较行数是否减少，减去的数量应当与garbage_ids.txt中记录的无效ID数量一致。"
  },
  "/content/posts/legacy/cassandra-数据清理实战#5": {
    "title": "Cassandra 数据清理实战",
    "url": "/content/posts/legacy/cassandra-数据清理实战",
    "date": "2022-02-24",
    "text": "准确可靠，避免误删正常数据。大规模操作前做好数据备份或留存关键日志（例如保留待删除ID列表文件）。\n* 使用批处理和脚本：针对海量数据，手工操作无法完成，借助脚本可以提高效率并降低出错风险。利用Cassandra的COPY导出功能和Python脚本相结合，是处理此类数据清理的有效方式。\n* 注意性能"
  },
  "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略#0": {
    "title": "项目管理的范式革命：渐进式开发与用户参与的AI项目实施策略",
    "url": "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略",
    "date": "2025-07-24",
    "text": "项目管理的范式革命：渐进式开发与用户参与的AI项目实施策略\n\n要理解新范式的优势，我们必须先看清旧模式的痛点。一个典型的\"瀑布式AI项目\"通常如下：\n\n1.  **漫长的需求沟通：** 项目经理和用户试图在项目开始前，定义所有功能、细节和预期结果，并将其固化为一份\"完美\"的需求文档。\n2.  **封"
  },
  "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略#1": {
    "title": "项目管理的范式革命：渐进式开发与用户参与的AI项目实施策略",
    "url": "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略",
    "date": "2025-07-24",
    "text": "资源浪费。对于AI项目而言，其内在的\"黑箱\"特性和探索性，使得\"一次性做对\"几乎是不可能的任务。\n\n二、 PD-UP模型的核心原则：检查点与决策节点\n\nPD-UP模型的核心，是将宏大的项目目标，解构成一个由**\"执行-检查-决策\"**组成的微循环链条。在这个链条中，开发者和用户在每个关键节点上紧密互"
  },
  "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略#2": {
    "title": "项目管理的范式革命：渐进式开发与用户参与的AI项目实施策略",
    "url": "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略",
    "date": "2025-07-24",
    "text": "辅助工具（如我们之前讨论的GPT+Claude工作流）高效完成**当前且仅当前一个**步骤。\n\n2.  **第二步：设立检查点（Checkpoint）**\n    *   **开发者职责：** 在完成每一步后，立即将产出物（一段代码、一个可运行的脚本、一张图表、一个API的初步结果）以最直观的方式呈"
  },
  "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略#3": {
    "title": "项目管理的范式革命：渐进式开发与用户参与的AI项目实施策略",
    "url": "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略",
    "date": "2025-07-24",
    "text": "*   **用户反馈：** \"是的，这正是我想要的，数据清洗得很干净。请继续下一步。\"\n            *   **项目影响：** 流程按计划推进。开发者获得了明确的\"通行证\"，确保当前方向的正确性。\n\n        *   **B. 修正与迭代（Correction & Iteratio"
  },
  "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略#4": {
    "title": "项目管理的范式革命：渐进式开发与用户参与的AI项目实施策略",
    "url": "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略",
    "date": "2025-07-24",
    "text": "图表后，我意识到我们可能不需要饼图。能不能换成趋势线，并增加一个同类对比的功能？这似乎更有价值。\"\n            *   **项目影响：** 这是PD-UP模型最强大的地方。用户基于已实现的、可见的中间结果，产生了新的、更具价值的洞见。项目在这里可以**合法地、低成本地**进入一个新的、可"
  },
  "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略#5": {
    "title": "项目管理的范式革命：渐进式开发与用户参与的AI项目实施策略",
    "url": "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略",
    "date": "2025-07-24",
    "text": "的需求蔓延，让开发者始终是项目的\"舵手\"，而非被动执行者。\n\n三、 PD-UP模型的项目管理优势\n\n与传统方法相比，PD-UP模型在项目管理上展现出无与伦比的优势。\n\n1.  **极致的风险控制：**\n    *   **风险暴露前置：** 传统模式下，一个理解偏差可能在开发两个月后才发现，造成巨大"
  },
  "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略#6": {
    "title": "项目管理的范式革命：渐进式开发与用户参与的AI项目实施策略",
    "url": "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略",
    "date": "2025-07-24",
    "text": "在\"意外\"。交付过程平滑过渡为最终的确认，大大缩短了验收周期。\n\n3.  **真正的敏捷响应：**\n    *   **拥抱变化，而非抵制变化：** 传统项目管理视\"需求变更\"为洪水猛兽。PD-UP模型从机制上欢迎并鼓励有价值的\"转向\"。它认识到，在探索性项目中，最初的需求往往是不完美的，最有价值的"
  },
  "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略#7": {
    "title": "项目管理的范式革命：渐进式开发与用户参与的AI项目实施策略",
    "url": "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略",
    "date": "2025-07-24",
    "text": "\"修正\"、\"转向\"这样的结构化语言进行反馈，提高决策效率。\n\n2.  **精通任务分解的艺术：**\n    *   开发者的核心技能之一，就是将大目标分解为**逻辑独立、价值递增、可快速验证**的小步骤。每个步骤的产出都应让用户能明确感知到\"我们又向前迈进了一步\"。\n\n3.  **管理\"转向\"而非\""
  },
  "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略#8": {
    "title": "项目管理的范式革命：渐进式开发与用户参与的AI项目实施策略",
    "url": "/content/posts/legacy/项目管理的范式革命-渐进式开发与用户参与的ai项目实施策略",
    "date": "2025-07-24",
    "text": "他们明白自己的角色不仅是需求方，更是项目成功的关键合作伙伴。这能极大地提升他们的参与感和责任感。\n\n结论：从执行者到价值共创者\n\n渐进式开发与用户参与（PD-UP）模型，远不止是一个更快的编码技巧或流程。**它是一种将开发者和用户从传统的\"甲乙方\"关系，转变为\"价值共创伙伴\"关系的管理哲学。**\n\n"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#0": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南\n\n市面上有很多静态网站生成器（SSG），例如 Hexo、Hugo、11ty 等等。而 Astro 是近年来备受关注的一款，原因包括：\n\n- 极快的加载速度：Astro 默认采用静态渲染，生成纯静态的页面，没有多余的前端负担。"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#1": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "找到资源和解答。而且部署非常方便，官方文档提供了多种部署方案。对于我们来说，省心是很重要的因素。\n\n相比一些老牌的静态站点工具，Astro 更现代化、更易上手，也更符合当前前端的发展趋势 。如果你想尝试新的技术栈，Astro 值得一试。\n\n2. 创建 Astro 博客项目\n\n在开始之前，请确保你已经"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#2": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "客的预览效果 。如果一切顺利，你现在应该可以看到一个默认的 Astro 博客站点在本地跑起来了。\n\n> 小提示：如果 4321 端口被占用了，Astro 会尝试使用下一个可用端口。终端会打印实际使用的地址，请以终端输出为准。\n\n现在，我们已经成功创建了 Astro 项目并在本地运行起来，接下来就可以"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#3": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "src/content/blog/ 目录下撰写或添加 Markdown/MDX 文件来发布文章。\n\n一般来说，博客模板会附带几篇示例博文。你可以参考它们的格式，然后撰写自己的文章：文件放在 src/content/blog/ 下，使用 markdown 前置 YAML () 来写标题、日期等元信息，"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#4": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "，描述你的背景等。注意 heroImage 引用了 /blog-placeholder-about.jpg，这是放在 public/ 目录下的一张图片（Astro 会自动映射 /public 为网站根路径，关于图片的处理我们稍后详谈）。\n\n3.2 生成 /about.html而不是/about/in"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#5": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "L 文件而非目录。这纯粹是路径风格的选择问题：两种方式都能正常访问页面，使用哪种取决于你的喜好。\n\n完成内容定制后，你的博客在本地看起来应该更有个人特色了。不过，光有本地页面还不够，我们还需要考虑图片资源和部署等问题。下一节先来看看在 Astro 中如何正确地处理 Markdown 文档中的图片资源"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#6": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "文件中这样插入：\n\n- 路径以斜杠开头 /，表示从网站根目录查找，对应到 public 文件夹。\n\n按照上述方式放置和引用图片，好处是在本地写作时编辑器预览能找到图片，在 Astro 构建时也会将 public 下的图片原封不动地打包进最终的 dist 目录 。因此，无论开发环境还是部署后，图片都能"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#7": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "希望在网站上引用的静态资源（图片、视频等）都放进 public/ 里。这样可以避免很多路径问题。\n\n> 📌 小经验：我在实践中就踩过一次图片路径的坑——部署后发现文章里的图片无法加载。最后才意识到是自己偷懒把图片放错了地方。按官方建议调整到 public 后，问题迎刃而解。\n\n现在，博客内容和资源"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#8": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "该包提供了命令行工具，方便我们将静态文件发布到指定分支。\n\n2. 配置 astro.config.mjs：打开项目根目录下的 astro.config.mjs，设置站点的 base 路径。\n\n如果你的 GitHub 仓库名是比如 virtual-velocity，那么需要添加如下配置：\n\n上述配置中"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#9": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "elocity，GitHub Pages 部署后访问路径会是 https://用户名.github.io/virtual-velocity/，所以这里 base 要设为 /virtual-velocity/。切记，这个路径一定要与你的仓库名称一致，否则部署后页面的静态资源（CSS、JS、图片）路径会"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#10": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "目的 package.json 文件中加入一条方便的部署脚本。在 \"scripts\" 部分添加：\n\n这行脚本包含两个命令：先运行 astro build 构建出静态文件到 dist 文件夹，然后调用 gh-pages -d dist --branch gh-pages 将 dist 目录部署到远程仓"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#11": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "）。如果一切顺利，命令执行完毕后，GitHub 仓库应该已经更新了 gh-pages 分支。\n\n5. 验证 GitHub Pages 部署：部署完成后，登录 GitHub 打开你的仓库，进入 Settings → Pages 查看 GitHub Pages 的配置。通常，当仓库存在一个 gh-pag"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#12": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "ame.github.io/virtual-velocity/ 就应该能看到部署后的博客主页了。\n\n> 注意：如果 gh-pages 部署过程中提示错误 “分支已存在” 或 push 被拒绝，可以在脚本命令里添加 --force 参数强制覆盖远程分支。例如：gh-pages -d dist --br"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#13": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "部署博客的过程中，曾遇到过一些小问题。下面整理了几项常见的问题和对应的解决方法，方便你对照排查：\n\n- sharp 模块缺失：首次运行项目如果出现类似 *“Error: Cannot find module ‘sharp’”* 的错误，这是因为 Astro 的图像优化功能默认使用了 sharp 库，"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#14": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "是 /about.html：这是 Astro 的默认行为。如果你希望直接生成根目录下的 about.html 文件，可以将页面文件命名为 about.html.astro（参考前文 3.2 节），这样构建结果就是单个 HTML 文件而非子目录。\n- 使用 gh-pages 部署时报错“remote "
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#15": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "的远程地址：运行 git remote set-url origin https://github.com/yourname/yourrepo.git 将远程地址切换为 HTTPS。HTTPS 通常走443端口，普遍不会被封锁。\n- GitHub 不接受账户密码推送：如今 GitHub 已经禁用了通"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#16": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "们来详细说明一下 GitHub 的鉴权设置。\n\n7. GitHub Token 鉴权配置（重要）\n\n自 2021 年末起，GitHub 已禁用使用帐户密码进行 Git 推送。也就是说，当你执行 git push 或通过类似 gh-pages 工具推送内容到 GitHub 时，不能再用用户名+密码的方"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#17": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "设置的 Developer Settings 中生成一个 PAT（选择 classic 类型，勾选.repo 权限） 。生成后复制保存这串 Token。在推送代码时，当终端要求输入密码时，就粘贴这个 Token。注意，Token 只会显示一次，务必妥善保存；而且出于安全考虑，不要把 Token 明文"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#18": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "帐号，那么可以使用 SSH 来免密推送代码。方法是将本地仓库的远程地址改为 SSH 格式。例如：\n\n把上面的 yourname/yourrepo 替换为你的 GitHub 用户名和仓库名。执行该命令后，本地仓库的 origin 地址就从 https:// 改为了 git@github.com（SSH"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#19": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "程走下来，建议至少提前准备好上述两种方案之一，否则在部署时可能会因为没有权限推送而卡住。\n\n总结\n\n通过 Astro + GitHub Pages 的组合，我们可以相当迅速地搭建起一个现代化、极简且易维护的个人博客。从创建项目、个性化内容，到配置部署脚本、解决常见问题，每一步都相对清晰。一旦把这些配"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#20": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "的 GitHub 用户名和仓库名）\n\n🔧 配置自定义域名（如 blog.geyuxu.com）\n\n以上步骤完成后，你的博客已经可以通过 GitHub 提供的默认域名访问（例如 https://yourname.github.io/yourrepo/）。但是很多人希望使用一个自己的域名，让博客看起来"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#21": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "跳转到安全的 https 上。\n\n2. 在项目的 public/ 目录中添加 CNAME 文件：\n\n   在本地项目的 public/ 文件夹下，新建一个名为 CNAME 的文件（没有扩展名的纯文本文件）。文件内容仅需一行，写上你的自定义域名，例如：\n\n   \n\n   保存该文件并确保提交到仓库（也"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#22": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "，例如使用 blog.geyuxu.com 就填 blog（如果想直接绑定顶级域名如 geyuxu.com，主机记录留空或填 @，但顶级域名绑定还需添加 A 记录，稍后提及）\n- 指向（值）：填写 yourname.github.io，将其替换为你的 GitHub 用户名 后加 .github.io"
  },
  "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南#23": {
    "title": "使用 Astro 构建并部署个人博客到 GitHub Pages全流程指南",
    "url": "/content/posts/legacy/使用-astro-构建并部署个人博客到-github-pages-全流程指南",
    "date": "2025-04-02",
    "text": "时应该能够看到你的博客页面正常显示了。如果没有生效，耐心等待并检查上述步骤是否正确。\n\n小贴士：\n\n- 每次使用 npm run deploy 部署时，gh-pages 工具都会自动包含并上传 public/CNAME 文件，所以在第一次设置好后，后续无需每次手动去 GitHub 设置页面修改域名。"
  },
  "/content/posts/legacy/full-stack-todo-list-application-development-pract#0": {
    "title": "Full-Stack Todo List Application Development Practice: Front-End and Back-End Separation Architecture",
    "url": "/content/posts/legacy/full-stack-todo-list-application-development-pract",
    "date": "2025-07-21",
    "text": "Full-Stack Todo List Application Development Practice: Front-End and Back-End Separation Architecture\n\nBackend Technology Stack\n- **Python Flask**: Li"
  },
  "/content/posts/legacy/full-stack-todo-list-application-development-pract#1": {
    "title": "Full-Stack Todo List Application Development Practice: Front-End and Back-End Separation Architecture",
    "url": "/content/posts/legacy/full-stack-todo-list-application-development-pract",
    "date": "2025-07-21",
    "text": "*Task Editing**: Modify task content and status\n4. **Task Deletion**: Remove completed or unwanted tasks\n5. **Status Toggle**: Mark tasks as completed"
  },
  "/content/posts/legacy/full-stack-todo-list-application-development-pract#2": {
    "title": "Full-Stack Todo List Application Development Practice: Front-End and Back-End Separation Architecture",
    "url": "/content/posts/legacy/full-stack-todo-list-application-development-pract",
    "date": "2025-07-21",
    "text": "teraction**: Intuitive user operation experience\n\nFrontend Implementation\n\nJavaScript Core Logic\n\nCSS Style Design\n\nBackend Implementation\n\nFlask API "
  },
  "/content/posts/legacy/full-stack-todo-list-application-development-pract#3": {
    "title": "Full-Stack Todo List Application Development Practice: Front-End and Back-End Separation Architecture",
    "url": "/content/posts/legacy/full-stack-todo-list-application-development-pract",
    "date": "2025-07-21",
    "text": "es performance\n- jQuery simplifies DOM operations\n- Flask is lightweight and easy to develop\n- SQLite is a zero-configuration database\n\n3. Well-Organi"
  },
  "/content/posts/legacy/full-stack-todo-list-application-development-pract#4": {
    "title": "Full-Stack Todo List Application Development Practice: Front-End and Back-End Separation Architecture",
    "url": "/content/posts/legacy/full-stack-todo-list-application-development-pract",
    "date": "2025-07-21",
    "text": "cal Development Environment\n\nDirectory Structure\n\nTechnical Insights and Reflections\n\nArchitecture Design\n- **Front-end and back-end separation** impr"
  },
  "/content/posts/legacy/full-stack-todo-list-application-development-pract#5": {
    "title": "Full-Stack Todo List Application Development Practice: Front-End and Back-End Separation Architecture",
    "url": "/content/posts/legacy/full-stack-todo-list-application-development-pract",
    "date": "2025-07-21",
    "text": "eatly simplified DOM operations and AJAX requests\n- **Flask's** simplicity accelerated development progress\n\nCode Quality\n- **Modular design** improve"
  },
  "/content/posts/legacy/full-stack-todo-list-application-development-pract#6": {
    "title": "Full-Stack Todo List Application Development Practice: Front-End and Back-End Separation Architecture",
    "url": "/content/posts/legacy/full-stack-todo-list-application-development-pract",
    "date": "2025-07-21",
    "text": "ystem**: Login registration, multi-user support\n4. **Interface Enhancement**: Drag-and-drop sorting, batch operations\n5. **Mobile Adaptation**: PWA su"
  },
  "/content/posts/legacy/full-stack-todo-list-application-development-pract#7": {
    "title": "Full-Stack Todo List Application Development Practice: Front-End and Back-End Separation Architecture",
    "url": "/content/posts/legacy/full-stack-todo-list-application-development-pract",
    "date": "2025-07-21",
    "text": "anagement application with good user experience.\n\nThe project demonstrates how to use classic Web technology stack to build modern applications, layin"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#0": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "通过AI助手、笔记工具与番茄工作法进行高效学习\n\n**每周规划**：每周初在 Notion 中制定学习计划，列出各科待办（章节阅读、习题、项目等）并分配到每日。采用主题日或交替学习的方法避免枯燥：例如每周安排1–2次较长的英语输入（观看英文电影/讲座），1次AI项目实战或竞赛题训练，穿插于日常计划中"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#1": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "达和学习清单；Obsidian 则可用于整理长期的语法知识点和高频词汇笔记，形成个人英语知识库。\n\n*   **每日学习任务**：利用2个番茄时间专注英语输入和输出。第一段25分钟可进行输入练习：阅读英语新闻/杂志或听英文播客。在阅读过程中，如遇生词短语，可随时在 ChatGPT Pro 询问词义或"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#2": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "以粗体标出修改处，让你直观了解提升之处。这样的模拟对话和纠错练习，有助于口语表达和地道用法的提升。\n*   **每周学习任务**：每周选择1-2个主题深入练习。例如，本周主题为“旅游”，则阅读相关英文文章，整理常用词句；周末观看一部英文电影或纪录片。之后利用 ChatGPT Pro 对本周主题进行总"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#3": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "记忆工具对高频词汇进行间隔重复记忆，不断巩固语言基础。\n\nAI技术与算法学习：工具组合与任务规划\n\n**主要工具组合**：AI技术和算法学习建议充分利用AI 编程助手和大模型的优势。这里推荐将 Claude Code 和 Gemini CLI 作为代码编写与调试的智能助手，同时用 ChatGPT P"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#4": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "ion 用于规划学习路径、记录学习笔记和代码笔记；Obsidian 用于构建个人知识图谱，将算法思想、代码实现心得链接成网，方便融会贯通。\n\n*   **每日学习任务**：安排3个番茄时间专注AI理论和算法实践。\n    *   **理论学习（约1番茄）**：通过在线课程、教程或论文学习一个AI相关"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#5": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "的联网功能也能帮忙检索最新资料，当遇到晦涩难懂的技术细节时，可以让它搜索相关文档并提供简明解释。\n    *   **算法编码实践（约2番茄）**：选择一道算法题（如LeetCode挑战）或进行小型项目练习。在编写代码时，Claude Code 或 Gemini CLI 充当即时辅导：比如当卡在 b"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#6": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "GPT Pro 提问算法思路（例如：“如何优化快速排序的最坏情况？”）或让其解释你写的代码复杂度。\n    *   **记录与反思**：将当天学习的新算法思想、Bug教训记录到 Notion 的学习日志中，简单列出问题和解决方法。晚间利用 Obsidian 撰写更深入的笔记，例如针对当天学到的算法写"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#7": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "命令来跑通项目，并在失败时调整，近似实现半自动编码（需注意及时介入指导，以免AI在错误思路上浪费时间）。周日进行知识整理和复盘：在 Obsidian 中梳理一周所学AI知识点，更新“AI术语词条”笔记并通过双链链接相关概念（例如把“梯度下降”笔记链接到“神经网络训练”笔记）。可以让 ChatGPT "
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#8": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "始的实践和回顾，在AI技术领域循序渐进地夯实基础并拓展技能。\n\n专业课程学习：工具组合与任务规划\n\n**主要工具组合**：专业课程（如大学专业课）学习需要结合课程教材、课堂笔记和作业要求，以理解记忆和应试应用为导向。ChatGPT Pro 可以成为课业学习的强力助教，用于解惑答疑、要点总结和提供练习"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#9": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "**每日学习任务**：根据课程表，在上课以外留出至少4-5个番茄时间用于当日课程的预复习和作业。\n    *   **课前预习**：在正式课堂前，花半个小时快速浏览将讲授的章节。在 Notion 中打开课程笔记页面，列出本章的学习目标和关键概念。如果遇到不解之处，可询问 ChatGPT Pro：“用"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#10": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "GPT，请它指出漏洞或给予提示（切忌直接拷贝作业题完整求解，以免影响独立思考能力和违反学术诚信）。\n    *   **完成作业**：在编程类或数据分析类作业中，充分利用 AI 工具调试和优化。比如，编写程序遇到报错时，将错误信息和相关代码段提交给 Claude Code，请它定位错误原因并提供修改"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#11": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "安排到每天。对于临近的测验或大型作业，预留充分的准备时间（例如提前2周开始复习或分阶段完成项目）。\n    *   **整合学习**：如果专业课程之间存在关联（例如高等数学为物理课提供数学工具），周中或周末抽时间在 Obsidian 中写“连接笔记”，总结不同课程知识的联系，加深对知识的整体理解。\n"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#12": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "公式添加进去，并链接到应用这些公式的例题笔记上。坚持每周这样归纳整理，在期末复习时就能依赖自己构建的知识网络快速回顾。通过有条不紊的周计划管理，确保不遗漏任何一门课程的学习任务，在平时就扎实掌握知识点，减少考前压力。\n\n阅读文献与内容总结的高效方法\n\n**工具最佳用途**：在阅读学术文献、专业资料或"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#13": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "炼后的要点。Gemini CLI 则可在需要时联网搜索文中提及的概念或术语的最新解释，确保你的理解与前沿同步。\n*   **提取关键词和建立索引**：阅读完一篇资料后，使用 ChatGPT 提取其中的关键词和关键句。例如：“列出本文出现的5个核心术语并解释其含义”。将这些术语和解释记录在 Notio"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#14": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "比如每天阅读完英文文章后，让 ChatGPT 扮演老师询问细节，你用英语作答。这种问答能逼你回忆文章细节，同时锻炼英语表达，一举两得。\n\n代码调试与编程实践的高效方法\n\n**工具最佳用途**：在编程练习和项目开发中，AI 工具可充当智能调试助手和虚拟对话伙伴，协助你高效解决问题并积累经验。\n\n*  "
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#15": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "可能的错误模块并提出解决步骤。这种自动化处理让你仿佛拥有一位不知疲倦的资深搭档，时刻提供调试思路。\n*   **代码生成与优化**：在遇到难以实现的功能时，可以先用 ChatGPT Pro 讨论实现思路，甚至直接让它生成示例代码片段供参考。Claude Code 和 Gemini CLI 则能够直接"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#16": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "关，必要时手动调整。通过与 AI 反复协作，你能逐步优化代码质量，从中学习到更简洁高效的实现方式。\n*   **算法思路辅导**：在算法题训练或编程竞赛准备中，AI 可以扮演思路引导者。当你苦思某个问题解法时，不妨将你已有的想法告诉 ChatGPT，请它提示下一步。例如：“我打算用动态规划解决这个问"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#17": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "情况下的表现是否正确。借助这些工具，你可以更快地验证想法、纠正错误，从而专注于算法思想本身的学习。\n*   **实践项目协作**：在较大型的实践项目（课程设计或科研项目）中，合理使用 AI 能提升开发效率。尝试把项目任务拆解，在 Notion 上列出待完成功能。对于每个子功能，先自行构思方案，再用 "
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#18": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "和定期复盘巩固。Notion 和 Obsidian 的结合能够满足任务管理和知识沉淀两方面需求：\n\n*   **Notion**：充当学习中控和信息整理平台。使用 Notion 创建一个学习仪表板，包括每日待办、周计划、课程笔记数据库、阅读清单等模块。Notion 非常适合记录原始笔记和素材：例如课"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#19": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "明日调整。其强大的数据库和视图功能让你对学习任务做到心中有数，随时调整计划以保证各目标的均衡进展。\n*   **Obsidian**：充当个人知识库，将 Notion 中的“原始笔记”进一步提炼、关联，形成长久记忆的“永恒笔记”。Obsidian 的Markdown笔记和双向链接功能非常适合整理知识"
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#20": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "，将笔记内容转化为问答卡片，定期自测。\n*   **定期复盘机制**：坚持日清周结的笔记复盘习惯。\n    *   **每日复盘**：利用睡前15分钟浏览当日笔记，尤其关注当天标记的难点或未解决问题。如果仍有困惑，标注下来第二天请教老师或让 ChatGPT 解答。\n    *   **每周复盘**："
  },
  "/content/posts/legacy/full-time-student-efficient-learning-guide#21": {
    "title": "通过AI助手、笔记工具与番茄工作法进行高效学习",
    "url": "/content/posts/legacy/full-time-student-efficient-learning-guide",
    "date": "2024-01-01",
    "text": "勾，对未完成事项分析原因并调整下周计划。这种闭环复盘能让你的学习流程不断优化，做到高效且心中有数。\n*   **协同使用示例**：比如你本周用 Notion 记录了“卷积神经网络”一课的笔记和一些不解之处。周末整理时，在 Obsidian 新建“卷积神经网络”永久笔记，写下你对其原理的理解，并链接到"
  },
  "/content/posts/legacy/claude-automation-platform-en#0": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase\n\n- `POST https://api.notion.com/v1/pages` - Create new pag"
  },
  "/content/posts/legacy/claude-automation-platform-en#1": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "ages/databases with content insertion permissions. Otherwise, write requests will return HTTP 403 errors.\n\nMarkdown Content Writing Solutions\n\nThe Not"
  },
  "/content/posts/legacy/claude-automation-platform-en#2": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "a database page and add text paragraph content:\n\nWhere `parent` specifies the target database ID, `properties` sets page attributes (title, tags, date"
  },
  "/content/posts/legacy/claude-automation-platform-en#3": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "m of SDKs and integration tools:\n\nAuto-GPT Plugin\nAn open-source Auto-GPT Notion plugin exists that allows autonomous agents to read, create, and upda"
  },
  "/content/posts/legacy/claude-automation-platform-en#4": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "onment configuration, and whitelisting the plugin. Once enabled, AI agents can automatically save searched information or generated notes to specified"
  },
  "/content/posts/legacy/claude-automation-platform-en#5": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "iding Notion API tokens\n2. Running MCP services\n3. Registering as tools in Claude Code or Claude Desktop\n\nOnce configured, Claude can execute instruct"
  },
  "/content/posts/legacy/claude-automation-platform-en#6": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "orm with the highest degree of automation support. Through official APIs, Markdown notes can be created in batches, provided content is converted to N"
  },
  "/content/posts/legacy/claude-automation-platform-en#7": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "omation\n\nOfficial Support Status and Limitations\n\nObsidian is a local-first note-taking application that **does not provide officially open cloud APIs"
  },
  "/content/posts/legacy/claude-automation-platform-en#8": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "res workaround solutions using local automation.\n\nViable Automatic Writing Solutions\n\n1. Direct File System Operations\nObsidian notes are stored as Ma"
  },
  "/content/posts/legacy/claude-automation-platform-en#9": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "ed .md files are detected and loaded in real-time. This method doesn't require Obsidian to provide interfaces but requires automation programs to have"
  },
  "/content/posts/legacy/claude-automation-platform-en#10": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "Obsidian operations through specific URL calls:\n\nAdvanced URI converts URL parameters into file read/write actions within Obsidian, making it ideal fo"
  },
  "/content/posts/legacy/claude-automation-platform-en#11": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "developed the **Obsidian Local REST API plugin**. When installed and enabled, it starts a local HTTPS server (default ports 27123/27124) providing RES"
  },
  "/content/posts/legacy/claude-automation-platform-en#12": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "ols and AI Applications\n\nAuto-GPT Obsidian Plugin\nSimilar to Notion, third parties have developed Auto-GPT plugins for Obsidian. This plugin allows Au"
  },
  "/content/posts/legacy/claude-automation-platform-en#13": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "- Generating memory cards based on note content\n\nAuto-GPT achieves these functions by calling files in Obsidian Vaults (using interfaces encapsulated "
  },
  "/content/posts/legacy/claude-automation-platform-en#14": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "full note text\n- Browsing Vault file structures\n\nWhile current MCP integrations focus on reading analysis (like having AI search for answers across al"
  },
  "/content/posts/legacy/claude-automation-platform-en#15": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "e implementation through local plugins or scripts. The community-provided local REST API plugin is a more general solution that, combined with AutoGPT"
  },
  "/content/posts/legacy/claude-automation-platform-en#16": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "Platform: Limited Options in a Closed Ecosystem\n\nOfficial Support and Limitations\n\nHeptabase **currently does not provide public APIs**. According to "
  },
  "/content/posts/legacy/claude-automation-platform-en#17": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "ased on user needs before supporting general APIs. However, Heptabase is currently a relatively closed system overall, with no official interfaces for"
  },
  "/content/posts/legacy/claude-automation-platform-en#18": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "note-taking tools:\n\nMarkdown Import Functionality\nHeptabase includes built-in functionality for importing notes from Markdown files. Users can:\n\n1. Im"
  },
  "/content/posts/legacy/claude-automation-platform-en#19": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "function in the bottom left to select \"Obsidian\"\n- Can also directly select individual .md files for import within the application\n\nHeptabase preserve"
  },
  "/content/posts/legacy/claude-automation-platform-en#20": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "tes as Markdown or PDF to ensure data portability. However, these are manually triggered import/export operations for data migration and backup, not p"
  },
  "/content/posts/legacy/claude-automation-platform-en#21": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "AutoGPT or LangChain specifically for Heptabase.\n\nRegarding AI functionality, Heptabase itself has launched a built-in \"AI Chat\" feature that can inte"
  },
  "/content/posts/legacy/claude-automation-platform-en#22": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "to write content.\n\nViable Alternative Solutions\n\nBefore official APIs are released, if automatic updating of Heptabase content is absolutely necessary"
  },
  "/content/posts/legacy/claude-automation-platform-en#23": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "to quickly append logs to Heptabase's today page. These scripts use AppleScript to call Heptabase application windows, insert specific strings at the "
  },
  "/content/posts/legacy/claude-automation-platform-en#24": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "g one-click addition of timestamped log entries.\n\nThis approach essentially \"plays human\" when no API exists, partially satisfying personal workflow a"
  },
  "/content/posts/legacy/claude-automation-platform-en#25": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "nterface changes.\n\nIndirect Collaborative Updates\nIf users simultaneously use Heptabase and another API-supporting note tool (like Obsidian or Notion)"
  },
  "/content/posts/legacy/claude-automation-platform-en#26": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "updates and is more of a batch import approach.\n\n**Summary:** Currently, there's no way to programmatically update Heptabase notes directly through Cl"
  },
  "/content/posts/legacy/claude-automation-platform-en#27": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "ummary\n\nTechnical Implementation Recommendations\n\nFor Notion Integration\n1. **Recommended Solution**: Official SDK + Claude MCP integration\n2. **Imple"
  },
  "/content/posts/legacy/claude-automation-platform-en#28": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "irect writing backup\n2. **Implementation Steps**:\n   - Install and configure Local REST API plugin\n   - Set API keys and ports\n   - Develop or configu"
  },
  "/content/posts/legacy/claude-automation-platform-en#29": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "otion\n   - Periodically export to Markdown format\n   - Process in batches through Heptabase import functionality\n   - Use AppleScript and other tools "
  },
  "/content/posts/legacy/claude-automation-platform-en#30": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "achieve automatic content creation and updates.\n\n**Obsidian provides flexible local automation solutions through community plugins**. While requiring "
  },
  "/content/posts/legacy/claude-automation-platform-en#31": {
    "title": "Technical Research on Using Claude for Automated Updates to Notion, Obsidian, and Heptabase",
    "url": "/content/posts/legacy/claude-automation-platform-en",
    "date": "2025-01-24",
    "text": "t workflows to achieve partial automation needs.\n\nFor knowledge management workflows pursuing high degrees of automation, we recommend prioritizing No"
  },
  "/content/posts/legacy/图像增强在ocr中的实战作用#0": {
    "title": "图像增强在 OCR 中的实战作用",
    "url": "/content/posts/legacy/图像增强在ocr中的实战作用",
    "date": "2025-04-01",
    "text": "图像增强在 OCR 中的实战作用\n\n这篇文章就来分享一下我们实际做过的图像增强方式、效果对比、还有一些实验记录。\n\n**2. 为啥 OCR 更依赖图像增强？**\n\n图像增强这件事，其实很多做分类模型的朋友可能觉得“锦上添花”，不增强也能训。但 OCR 是另一个物种。\n\n**OCR 有几个天然硬伤：*"
  },
  "/content/posts/legacy/图像增强在ocr中的实战作用#1": {
    "title": "图像增强在 OCR 中的实战作用",
    "url": "/content/posts/legacy/图像增强在ocr中的实战作用",
    "date": "2025-04-01",
    "text": "不一定是网络不够，而是数据太“单纯”。**\n\n**3. 我们用过的图像增强方法（按类型分类）**\n\n为了让模型识别能力更贴近真实环境，我们当时尝试了几种图像增强方式，基本可以分为以下几类：\n\n**🌀 3.1 几何变换类**\n\n> 模拟各种角度拍摄、图像倾斜、歪斜摆放等场景。\n\n• **轻微旋转（±"
  },
  "/content/posts/legacy/图像增强在ocr中的实战作用#2": {
    "title": "图像增强在 OCR 中的实战作用",
    "url": "/content/posts/legacy/图像增强在ocr中的实战作用",
    "date": "2025-04-01",
    "text": ".3 模糊/噪声类**\n\n> 很多图模糊并不是摄像头坏，而是运动中拍的。\n\n• **高斯模糊**\n\n模拟镜头没对好焦或车牌快速移动时的拖影。\n\n• **椒盐噪声**\n\n模拟图像传输压缩时的噪点，车牌压缩图经常出问题。\n\n• **运动模糊（Motion Blur）**\n\n模拟车辆进出过快导致的拉丝感。"
  },
  "/content/posts/legacy/图像增强在ocr中的实战作用#3": {
    "title": "图像增强在 OCR 中的实战作用",
    "url": "/content/posts/legacy/图像增强在ocr中的实战作用",
    "date": "2025-04-01",
    "text": "OCR 结构，在 5k 训练样本上训练，验证集 1k 张）：\n\n最明显的提升来自两个方向：\n\n1. **旋转 + 遮挡**：因为现实中这两种情况最常见；\n\n2. **增强组合使用，而不是单独用一两种**。\n\n而且我们还发现一个现象：**增强带来的提升，在训练数据量较小时特别明显**。小数据集 + 强"
  },
  "/content/posts/legacy/图像增强在ocr中的实战作用#4": {
    "title": "图像增强在 OCR 中的实战作用",
    "url": "/content/posts/legacy/图像增强在ocr中的实战作用",
    "date": "2025-04-01",
    "text": "前面训练过一轮、或者模型已经“稳住”之后再加入。\n\n**⚙ 增强策略建议（我们自己的经验）：**\n\n• **前 10 轮训练不要加太重的增强**\n\n模型刚开始还没学会基本形状，加太多干扰会迷糊；\n\n• **中期可以分批加增强**\n\n我们是每 5~10 个 epoch 动态开启一种新增强，逐步加压；\n"
  },
  "/content/posts/legacy/图像增强在ocr中的实战作用#5": {
    "title": "图像增强在 OCR 中的实战作用",
    "url": "/content/posts/legacy/图像增强在ocr中的实战作用",
    "date": "2025-04-01",
    "text": "loss 跌得慢了一点，但实际稳定得多——尤其在夜间、雨天、边缘图像这些“真实世界的黑暗面”。\n\n所以，如果你也正在做 OCR 项目，或者是小样本图像分类，不妨认真想一想：\n\n与其花三天调网络结构，可能还不如花一天，好好做做数据增强。"
  },
  "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod#0": {
    "title": "WebGL 3D Tank Battle Game Development Practice: Modern WebGL Technology Application",
    "url": "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod",
    "date": "2025-07-21",
    "text": "WebGL 3D Tank Battle Game Development Practice: Modern WebGL Technology Application\n\nCore Technology Stack\n- **WebGL 2.0**: 3D graphics rendering\n- **"
  },
  "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod#1": {
    "title": "WebGL 3D Tank Battle Game Development Practice: Modern WebGL Technology Application",
    "url": "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod",
    "date": "2025-07-21",
    "text": "g Pipeline\n\nShader System\n\nPhysics System Design\n\nCollision Detection System\n\nAI System Implementation\n\nEnemy Tank AI\n\nGame System Integration\n\nMain G"
  },
  "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod#2": {
    "title": "WebGL 3D Tank Battle Game Development Practice: Modern WebGL Technology Application",
    "url": "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod",
    "date": "2025-07-21",
    "text": "Reduce texture switching\n\n2. Physics Optimization\n- **Spatial Partitioning**: Use spatial grid to accelerate collision detection\n- **Sleep System**: S"
  },
  "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod#3": {
    "title": "WebGL 3D Tank Battle Game Development Practice: Modern WebGL Technology Application",
    "url": "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod",
    "date": "2025-07-21",
    "text": "different frames to distribute computational load\n- **Hierarchical Decision Making**: Coarse decisions + fine adjustments\n\nProject Features and Innova"
  },
  "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod#4": {
    "title": "WebGL 3D Tank Battle Game Development Practice: Modern WebGL Technology Application",
    "url": "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod",
    "date": "2025-07-21",
    "text": "lligent AI System\n- Behavior tree-driven AI logic\n- A* pathfinding algorithm\n- Realistic perception and decision system\n\n4. Immersive Gaming Experienc"
  },
  "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod#5": {
    "title": "WebGL 3D Tank Battle Game Development Practice: Modern WebGL Technology Application",
    "url": "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod",
    "date": "2025-07-21",
    "text": "optimization techniques\n\nGame Engine Architecture\n- Designed extensible engine architecture\n- Implemented efficient inter-system communication\n- Estab"
  },
  "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod#6": {
    "title": "WebGL 3D Tank Battle Game Development Practice: Modern WebGL Technology Application",
    "url": "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod",
    "date": "2025-07-21",
    "text": "layer Online**: WebSocket for real-time battles\n2. **Terrain Editor**: Visual level editing tools\n3. **Particle System**: Richer visual effects\n4. **V"
  },
  "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod#7": {
    "title": "WebGL 3D Tank Battle Game Development Practice: Modern WebGL Technology Application",
    "url": "/content/posts/legacy/webgl-3d-tank-battle-game-development-practice-mod",
    "date": "2025-07-21",
    "text": "n Web technologies in complex 3D game development. Through self-developed engine architecture, intelligent AI system, and meticulous performance optim"
  },
  "/content/posts/legacy/使用paddlepaddle2复现deeplabv3-1#0": {
    "title": "使用 PaddlePaddle 2.x 复现 DeepLabV3+（1）：从构建到训练",
    "url": "/content/posts/legacy/使用paddlepaddle2复现deeplabv3-1",
    "date": "2025-04-03",
    "text": "使用 PaddlePaddle 2.x 复现 DeepLabV3+（1）：从构建到训练\n\n- ✅ 模块化重构 DeepLabV3+，包含 SeparableConv、ASPP、XceptionBlock\n- ✅ 兼容动态图与标准 Layer 接口\n- ✅ 编写训练脚本，可扩展至真实数据集\n\n2. 模"
  },
  "/content/posts/legacy/使用paddlepaddle2复现deeplabv3-1#1": {
    "title": "使用 PaddlePaddle 2.x 复现 DeepLabV3+（1）：从构建到训练",
    "url": "/content/posts/legacy/使用paddlepaddle2复现deeplabv3-1",
    "date": "2025-04-03",
    "text": "，可直接输出等大小的分割图。\n\n**代码结构示例：**\n\n3. 训练脚本：高效训练 + 模型保存\n\n训练脚本使用 `paddle.io.DataLoader` 与标准 `nn.Layer` 接口完成：\n\n**特点：**\n\n- 动态创建模型实例与优化器\n- 支持 ignore_index 的自定义交叉"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#0": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "Java Static Blog Converter Development Practice and Technical Summary\n\n- **Language**: Java 8\n- **Build Tool**: Maven 3.x\n- **Core Libraries**: FlexMa"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#1": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "t formats:\n- **Markdown**: Primary content format\n- **Office Documents**: PDF, DOC, DOCX, XLS, XLSX, PPT, PPTX\n- **Plain Text**: TXT, MD\n\nEach file ge"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#2": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "- Responsive layout support\n\n4. Security Design\n\n- **XSS Protection**: Input content filtering and escaping\n- **Input Validation**: Strict file path a"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#3": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "Usage\n\nCommand Line Interface\n\nOutput Structure\n\nThe generated static website includes:\n- HTML page files\n- CSS style files  \n- JavaScript scripts\n- S"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#4": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "sing\n- `StaticSiteGenerator`: Core business logic\n- `MarkdownConverter`: Dedicated Markdown conversion\n- `TemplateEngine`: Template processing and ren"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#5": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "- Integration testing\n- Multi-scenario test cases\n- Automated testing workflow\n\nVersion Iteration and Optimization\n\nThe project has gone through multi"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#6": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "n**: Improved processing speed and memory usage\n5. **Test Enhancement**: Increased test coverage and exception handling\n\nTechnical Insights and Reflec"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#7": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "nagement**: Reasonable dependency version control\n- **Build Optimization**: Efficient compilation and packaging workflow\n- **Plugin Usage**: Shade plu"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#8": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "nal Blogs**: Quickly set up personal tech blogs\n2. **Documentation Sites**: Convert Markdown documents to websites\n3. **Content Management**: Batch co"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#9": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "I Interface**: Develop web management interface\n4. **Plugin System**: Support for third-party plugin extensions\n5. **Cloud Deployment**: Support for c"
  },
  "/content/posts/legacy/java-static-blog-converter-development-practice-an#10": {
    "title": "Java Static Blog Converter Development Practice and Technical Summary",
    "url": "/content/posts/legacy/java-static-blog-converter-development-practice-an",
    "date": "2025-07-22",
    "text": "rocessing tool using modern Java technology stack. Through reasonable architectural design, comprehensive test coverage, and continuous version iterat"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#0": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications\n\n-   **In Machine Learning: The Final Gatekeeper**\n    For ML models"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#1": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "ion accuracy, direct revenue from a new strategy). It is the ultimate validation that a model delivers value after overcoming real-world challenges li"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#2": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "seasonality, market trends, and unforeseen events. A/B testing uses live user interactions for evaluation, naturally incorporating the current data di"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#3": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "count for Engineering and Operational Realities**\n    A model's online success depends not just on the algorithm but also on the entire engineering pi"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#4": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "ne.\n\n3.  **To Ensure Decision-Making Confidence**\n    A/B testing is about \"letting the data speak.\" Through rigorous experimental design and statisti"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#5": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "hese six steps:\n\n1.  **① Formulate a Hypothesis**\n    A good hypothesis must be specific and measurable. It should clearly state the variable, the exp"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#6": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "ng as the main criterion for success (e.g., CTR).\n    -   **Guardrail Metrics:** Metrics monitored to ensure the experiment doesn't negatively impact "
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#7": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "ower (1-β).\n\n3.  **③ Implement Random Bucketing**\n    Bucketing is the technical core of A/B testing. The key principles are **consistency** and **ran"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#8": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "ssic split is 50/50 to maximize statistical power. In practice, smaller allocations like 90/10 are often used for canary releases or to mitigate the r"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#9": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "ge out periodic effects like weekends or holidays. During this time, monitor primary and guardrail metrics in real-time via dashboards (e.g., Grafana)"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#10": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "s test (e.g., Z-test or t-test) to get a p-value.\n    -   Calculate the 95% confidence interval of the difference.\n    The final decision should combi"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#11": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "ountermeasures\n\n6. Python Implementation Example\n\nHere is a simplified Python example demonstrating consistent bucketing and a Z-test for a proportion"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#12": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "ference and explaining the \"why\" behind a result.\n-   **Offline Replay + A/B Testing**: Use historical logs to run offline simulations (replays) to qu"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning-en#13": {
    "title": "The Ultimate Guide to A/B Testing: From Statistical Principles to ML Applications",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning-en",
    "date": "2024-01-01",
    "text": "ramatically improving experimentation efficiency.\n-   **Experimentation Platforms**: Mature platforms, whether commercial (Optimizely, VWO) or open-so"
  },
  "/content/posts/legacy/claude-automation-platform-zh#0": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "使用 Claude 自动更新知识管理平台的技术方案调研\n\n- `POST https://api.notion.com/v1/pages` - 在指定数据库下创建新页面条目\n- `PATCH https://api.notion.com/v1/blocks/{block_id}/children` "
  },
  "/content/posts/legacy/claude-automation-platform-zh#1": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "入。\n\n以下是使用 Notion Python SDK 创建数据库页面并添加文本段落内容的示例：\n\n其中 `parent` 指定目标数据库 ID，`properties` 设置页面属性（如标题、标签、日期），`children` 部分承载实际笔记内容。需要注意的是，Notion API 在一次请求中"
  },
  "/content/posts/legacy/claude-automation-platform-zh#2": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "d_page` - 追加内容\n- `notion_query_database` - 查询数据库\n\n使用时需在 Auto-GPT 的环境配置中提供 Notion 集成令牌和数据库 ID，并将插件加入白名单。启用后，AI 代理就能自动把搜索到的信息或生成的笔记保存到指定的 Notion 数据库中。\n\n"
  },
  "/content/posts/legacy/claude-automation-platform-zh#3": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "成操作。这种方案充分利用了 Claude 的自动化能力，将 Notion 用作外部内存或任务板。\n\n**小结：** Notion 是支持自动化程度最高的平台。通过官方 API，可以批量创建 Markdown 笔记，前提是将内容转换为 Notion 块结构并获取适当权限。无论使用轻量脚本还是复杂 AI"
  },
  "/content/posts/legacy/claude-automation-platform-zh#4": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "md) 文件。最直接的方法是让自动化脚本直接在文件系统上创建/修改这些 Markdown 文件。\n\n只要在 Obsidian 打开该 Vault 时，新增或修改的 .md 文件会被实时检测到并加载。这种方法不需要 Obsidian 提供接口，但要求自动化程序对本地磁盘有写权限。\n\n2. Advanc"
  },
  "/content/posts/legacy/claude-automation-platform-zh#5": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "，会在本地启动一个 HTTPS 服务器（默认端口 27123/27124）提供 REST 接口：\n\n该插件支持执行 Obsidian 命令、创建日记等高级功能，使 Obsidian 成为一个可编程的平台。由于采用标准 HTTP 接口，非常适合与各种编程语言和 AI Agent 集成。\n\n集成工具与 "
  },
  "/content/posts/legacy/claude-automation-platform-zh#6": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "件（利用 obsidiantools 库封装的接口）来实现这些功能。\n\nClaude MCP 集成\n类似 Notion 的 MCP 方案，也有人将 Obsidian 的本地 REST API 封装为 MCP Server。例如\"MCP Obsidian Server\"允许 Claude 调用工具：\n"
  },
  "/content/posts/legacy/claude-automation-platform-zh#7": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "，理论上 Claude Agent 也可通过适当的工具指令来创建或更新 Obsidian 笔记。\n\n**小结：** Obsidian 的自动内容更新需要通过本地插件或脚本实现。社区提供的本地 REST API 插件是较通用的方案，结合 AutoGPT 或 Claude 等 Agent 可以实现对 O"
  },
  "/content/posts/legacy/claude-automation-platform-zh#8": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "一个相对封闭的系统，没有官方接口可供外部程序直接创建或更新笔记卡片。\n\n间接方法：导入/导出机制\n\n虽然无法通过编程接口实时写入，Heptabase 支持从其他笔记工具导入数据：\n\nMarkdown 导入功能\nHeptabase 内置了从 Markdown 文件导入笔记的功能。用户可以：\n\n1. 将"
  },
  "/content/posts/legacy/claude-automation-platform-zh#9": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "转换为自有的卡片结构，Wiki 链接会转为 Heptabase 支持的标准链接。\n\n数据同步与导出\nHeptabase 会自动将用户数据同步到云，并在本地写入备份。支持将笔记导出为 Markdown 或 PDF，以保证数据可迁移。但这些都是人工触发的导入导出操作，用于数据迁移和备份，并非可编程的持续"
  },
  "/content/posts/legacy/claude-automation-platform-zh#10": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "：\n\nGUI 脚本模拟\n通过模拟用户界面操作的方法\"自动输入\"内容到 Heptabase。例如：\n\n社区已有用户分享了利用 AppleScript + Raycast 来快速向 Heptabase 今日页面追加日志的脚本。该脚本通过 AppleScript 调用 Heptabase 应用窗口，在当前"
  },
  "/content/posts/legacy/claude-automation-platform-zh#11": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "3. 再导入 Heptabase\n\n不过这种流程无法实时、细粒度地更新，更多是批量导入思路。\n\n**小结：** 现阶段无法直接通过 Claude 或其他自动化 Agent 编程式地更新 Heptabase 笔记。可以利用的只有手动导入和一些界面层的脚本辅助。Heptabase 团队明确表示短期内不会"
  },
  "/content/posts/legacy/claude-automation-platform-zh#12": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "*：\n   - 安装并配置 Local REST API 插件\n   - 设置 API 密钥和端口\n   - 开发或配置 Agent 调用接口\n   - 实现 Markdown 内容的自动写入\n\n对于 Heptabase 集成\n1. **当前方案**：间接导入 + GUI 自动化辅助\n2. **实施"
  },
  "/content/posts/legacy/claude-automation-platform-zh#13": {
    "title": "使用 Claude 自动更新知识管理平台的技术方案调研",
    "url": "/content/posts/legacy/claude-automation-platform-zh",
    "date": "2025-01-24",
    "text": "本地自动化方案**，虽然需要一定的配置工作，但一旦设置完成，可以实现与 AI 工作流的无缝集成。\n\n**Heptabase 目前在自动化方面最为受限**，主要依赖手动导入和界面模拟脚本。用户需要等待官方 API 的推出，或采用间接的工作流来实现部分自动化需求。\n\n对于追求高度自动化的知识管理工作流，"
  },
  "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归#0": {
    "title": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归",
    "url": "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归",
    "date": "2025-07-24",
    "text": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归\n\n我的核心目标是解决当前AI代码助手的一个痛点：它们通常是\"一次性\"的，缺乏对代码质量和后续优化的持续关注。我希望我的系统能模拟一个微型的开发小组。\n\n1. 系统设计：三位一体的AI开发团队\n\n我设计了三个高度专业化的"
  },
  "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归#1": {
    "title": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归",
    "url": "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归",
    "date": "2025-07-24",
    "text": "能正确、质量达标后，它会从更高层面审视代码，提出关于算法效率、代码结构、可读性等方面的优化建议。\n\n为了让这三个智能体能\"智能地\"协同工作，我选择了AutoGen中强大的 `GroupChat` 模式，并特别使用了`SelectorGroupChat`，期望它能像一个项目经理，根据当前的对话上下文，"
  },
  "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归#2": {
    "title": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归",
    "url": "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归",
    "date": "2025-07-24",
    "text": "不去的\"沉重感\"。这种感觉并非来自单一问题，而是多个因素叠加的结果。\n\n1. 交互延迟与效率黑洞\n\n对于一个简单的斐波那契函数，整个流程下来耗时数分钟。每一次智能体之间的交接，都是一次完整的LLM调用。`SelectorGroupChat`为了决定下一个发言者，本身也需要一次LLM推理。这意味着，完"
  },
  "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归#3": {
    "title": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归",
    "url": "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归",
    "date": "2025-07-24",
    "text": "alyzerAgent` 之间可能来回\"拉扯\"，一个修改，一个又挑出新问题，迟迟无法进入优化阶段。\n*   **错误调度：** 有时，在`CoderAgent`刚写完代码后，`OptimizerAgent`会\"抢话\"，跳过质量分析环节，直接开始谈优化，打乱了预设的流程。\n*   **过早终止：** "
  },
  "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归#4": {
    "title": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归",
    "url": "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归",
    "date": "2025-07-24",
    "text": "`QualityAnalyzerAgent`应该基于`CoderAgent`的最新代码进行分析。\n\n但`GroupChat`的状态是通过不断增长的消息历史来维护的。当对话轮次增多，上下文窗口会迅速膨胀，不仅增加了token成本，还可能因为信息过载导致后续的Agent\"注意力不集中\"，忽略了关键的代码"
  },
  "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归#5": {
    "title": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归",
    "url": "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归",
    "date": "2025-07-24",
    "text": "nt的Prompt出了问题，还是`Selector`的决策逻辑有误。这种调试难度远高于传统代码。\n\n这些前期投入和后期维护的成本，对于解决一个\"写斐波那契函数\"级别的问题来说，显然是不成比例的。\n\n三、反思：什么场景真正需要\"重装上阵\"？\n\n这次失败的尝试并非毫无价值，它让我更深刻地理解了多智能体系"
  },
  "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归#6": {
    "title": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归",
    "url": "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归",
    "date": "2025-07-24",
    "text": "这类任务没有固定流程，需要信息搜集、整合、分析等多个复杂步骤，且对最终结果的创造性有一定要求。\n2.  **端到端的自动化项目：** 例如，\"根据用户需求文档，自动生成项目框架、编写核心代码、配置部署脚本\"。这类任务周期长、步骤多、异步执行，多智能体系统可以像一个自主项目团队一样，在后台默默推进。\n"
  },
  "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归#7": {
    "title": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归",
    "url": "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归",
    "date": "2025-07-24",
    "text": "需求，那么什么是更好的替代方案？答案是回归简单，利用AutoGen提供的其他模式，或者转变思路。\n\n方案一：两阶段智能体流水线 (Sequential Pipeline)\n\n如果你的流程是确定的，比如\"先编码，后审查\"，那么完全可以用有序的方式组织Agent。AutoGen的`register_ne"
  },
  "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归#8": {
    "title": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归",
    "url": "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归",
    "date": "2025-07-24",
    "text": "分析\"、\"代码优化\"等能力封装成它可以调用的**工具**。\n\n**这种模式的优势是压倒性的：**\n\n*   **低延迟：** 没有多Agent间的通信开销。\n*   **高可控：** 流程由LLM调用工具的决策驱动，比Agent间的自由对话更可预测。\n*   **易于扩展和维护：** 增加新能力只需"
  },
  "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归#9": {
    "title": "AutoGen多智能体实践反思：从\"上下文编程\"的重装上阵到轻量级AI助手的回归",
    "url": "/content/posts/legacy/autogen多智能体实践反思-从-上下文编程-的重装上阵到轻量级ai助手的回归",
    "date": "2025-07-24",
    "text": "能体协作\"、\"有序流水线\"和\"单智能体+工具\"之间做出明智的选择，才是一名成熟AI工程师的标志。\n\n未来，人与AI的协作、AI与AI的协作，必将更加深入。而我们的任务，就是在不断涌现的新技术中，保持清醒的头脑，找到那个连接技术与价值的最佳平衡点。"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#0": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "扬帆起航：深度学习工程师的cuda远征\n\n* **C/C++ 编程基础：** CUDA以 C/C++ 语言为基础进行扩展，因此需要熟练掌握C/C++语法和编程。包括指针和内存管理等知识，以便理解CUDA中的内存操作和数据传递。\n* **并行计算概念：** 了解基本的并行编程模型和多线程概念，理解串行"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#1": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "GPU加速的算法本质上是矩阵运算和微分计算，扎实的数学基础有助于理解深度学习中的CUDA实现原理。\n* **GPU基础认知： 了解一些GPU相关的基础，例如GPU上的显存**  (Device Memory)与主机内存(Host Memory)区别，数据在二者间的传输机制，以及GPU计算能力（Com"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#2": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "握CUDA并行编程的核心概念和基本用法，包括线程组织模型、内存模型以及核函数的编写和执行流程等。\n\n* **线程、线程块、网格模型：CUDA采用层次化的并行模型。最基本的执行单元是线程 (Thread)** ，许多线程组成 **线程块 (Block)** ，多个线程块组成 **网格 (Grid)**"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#3": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "数据并进行同步，而不同块之间相互独立，这样的设计利于大规模并行和可扩展性。\n\n*Output:*\n\n* **CUDA 内存类型与层次结构：CUDA设备上存在多层次内存，包括全局内存 (Global Memory)** 、**共享内存 (Shared Memory)** 、 **局部内存 (Local"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#4": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "储对于编写高性能CUDA代码至关重要——比如将重复使用的数据放入共享内存以减少全局内存访问次数等。\n* **CUDA 核函数编写与调用：CUDA程序由在CPU上运行的主机代码和在GPU上并行运行的设备代码两部分组成。设备上的并行代码被称为核函数 (Kernel)** 。编写核函数时需要使用`__gl"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#5": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "udaMalloc`)、将数据从主机传输到设备 (`cudaMemcpy`)，启动核函数进行并行计算，然后将结果拷回主机 (`cudaMemcpy`)并释放内存。这些步骤构成了CUDA程序的基本执行流程。通过实现简单示例（如向量加法、矩阵相加等）可以熟悉这一流程，并验证GPU并行加速的效果。\n\n进阶"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#6": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "建显式流并将核函数和内存拷贝分配到不同流中，CUDA就可以**异步**地并行执行它们。例如，可以在一个流中让GPU计算当前批次数据的核函数，同时在另一个流中将下一个批次的数据从CPU传输到GPU，从而重叠通信和计算。这种异步并发能够显著提高整体吞吐。需要注意的是，不同流之间默认是彼此独立的，开发者可"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#7": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "daMemcpyAsync`进行异步数据传输、以及利用**流优先设备设置**提高并发度等高级技巧。\n* **性能优化技巧：GPU性能优化是CUDA进阶的重要组成部分。在编写正确的CUDA代码之后，往往需要考虑内存访问模式**和**线程调度效率**来提升性能。首先是**合并内存访问 (Memory C"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#8": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "线程访问位于同一内存银行的不同地址，就会发生银行冲突，导致这些访问被拆分成多批次串行执行，降低吞吐。为避免bank冲突，应了解数据在共享内存中的布局方式，例如在访问模式不友好时通过**填充 (Padding)** 数组元素来改变不同线程访问地址的分布，从而减少冲突。除了内存优化，CUDA优化还包括减"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#9": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "殊技巧和库。深度学习的训练和推理涉及大量线性代数运算，CUDA为此提供了专门的优化手段和库支持。\n\n* **GPU上的矩阵乘法与基础算子：矩阵乘法（GEMM，General Matrix Multiply）是深度学习和科学计算中最常见的计算之一，也是神经网络层（如全连接层、卷积层经过展开后的计算）的"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#10": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "DA并行实现来加速。例如，实现大型向量点积时，可让每个线程处理部分乘加，然后使用并行归约得到结果。\n* **卷积运算与CUDA实现：卷积是深度学习中特别是CNN中的关键操作。直接实现二维卷积涉及嵌套循环，计算量巨大，适合GPU加速。CUDA加速卷积有多种方法，例如利用Im2col+GEMM**的方式"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#11": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "习框架的底层原理。当然，自己从零实现高效卷积非常具有挑战性，好在NVIDIA提供了专业的库来实现。\n* **CUDA深度学习库（cuBLAS 与 cuDNN）：NVIDIA为加速深度学习提供了成熟的库。其中cuBLAS**是CUDA的基本线性代数库，实现了在GPU上的BLAS函数接口（如矩阵乘法、向"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#12": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "DNN和cuBLAS等库，这使得框架开发者能将精力集中在模型构建上，而将性能优化交给底层库去做。在学习CUDA的过程中，了解并学会调用这些库可以让你事半功倍。例如，尝试用cuBLAS实现矩阵乘法，或用cuDNN实现卷积神经网络的前向传播，并与自己写的核函数性能对比，从实践中体会专业库的优化程度。\n*"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#13": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "速度的技术基础。虽然使用TensorRT不需要手写CUDA代码，但作为CUDA学习的延伸，了解TensorRT的原理会让你对GPU加速深度学习的全貌有更深入的认识。对于有实时性能要求的深度学习项目，掌握TensorRT的使用能够大幅降低延迟并提高吞吐量。\n\n实践\n\n理论结合实践是掌握CUDA的最佳途"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#14": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "本结构：内存分配/数据传输/核函数调用/结果验证。尝试修改线程块大小等参数观察对结果和性能的影响。\n* **矩阵乘法优化对比：实现一个手写矩阵乘法** 的CUDA核函数，用于相乘两个大矩阵，计时并分析性能。然后调用cuBLAS库的矩阵乘法（如`cublasSgemm`）进行相同计算，将结果和性能进行"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#15": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "积或矩阵**归约**（如计算向量范数、所有元素之和）并优化其并行性能，对比CPU单线程实现的速度。\n  - 编写CUDA核函数实现简化的**卷积神经网络前向传播**：如实现一个小型卷积层+ReLU的计算，将输入图像映射到输出特征图。可先用直接卷积实现，再尝试优化（如使用shared memory缓存"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#16": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "量数据。通过这个过程，既能熟悉框架与CUDA的结合，也能将学到的优化技巧应用到实际深度学习任务中。\n* **阅读开源GPU代码：挑选一些优秀的开源项目或库，阅读其CUDA相关源码以学习高手的编程技巧。例如NVIDIA开源的CUTLASS** 库是用于构建高性能矩阵乘法内核的模板库，其中包含了张量核心"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#17": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "入了解CUDA的工作原理。在反复调试和优化的过程中，CUDA编程能力会得到显著提升。\n\n学习资料\n\n**官方文档与教程：** 首先是 NVIDIA 官方提供的文档和教程，包括《CUDA C 编程指南》和《CUDA 最佳实践指南》等。这些权威文档详细描述了CUDA的编程模型和各项特性，并提供了优化指南"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#18": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "的相关培训课程。这些课程通常包含视频讲解、示例代码和编程作业，有助于逐步掌握从基础到高级的技能。\n\n**书籍资料：** 经典的书籍有《*CUDA By Example*》（中文译名《CUDA实例详解》）和《*Programming Massively Parallel Processors*》（《G"
  },
  "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征#19": {
    "title": "扬帆起航：深度学习工程师的cuda远征",
    "url": "/content/posts/legacy/01-扬帆起航-深度学习工程师的cuda远征",
    "date": "2025-05-07",
    "text": "和应用的读者，《CUDA优化技巧与并行算法实践》《GPU并行算法设计模式》之类的书籍也值得一阅。\n\n**技术博客与社区：** 利用社区资源获取他人经验和最新资讯。例如NVIDIA官方博客经常发布CUDA优化技巧、案例分析（包括中文技术博客等），开发者论坛可以提问交流。中文社区中，CSDN、知乎上有大"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#0": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成\n\n在处理前，需确保服务器已安装ImageMagick（如Ubuntu下执行apt-get install imagemagick）。接下来，我们编写一个简单的Shell脚本batch_watermark.sh，遍历目标目录下的所有图片文件，并"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#1": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "要调整水印大小或位置，可修改ImageMagick命令参数后再批量运行。\n\n离线压缩与SCP传输\n\n完成水印添加后，我们得到了一批已加水印的图片文件。下一步准备将这些文件上传到远程的对象存储服务器。考虑到直接逐文件传输效率较低，我们选择先在本地将所有图片打包压缩，然后通过scp一次性传输。在压缩过程"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#2": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "的rsync工具进行传输，以避免中途中断造成重复耗时 。\n\n图片上传至对象存储（Java 工具）\n\n图片文件抵达服务器并解压后，需要批量上传到对象存储（如公司内部的云存储服务）。在本次实践中，我们编写了一个简单的Java小工具来完成批量上传。之所以使用Java，是因为项目现有的对象存储SDK和权限控"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#3": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "ps://files.example.com/`, 某张图片文件`store001_license.jpg`上传后的访问路径可能为`https://files.example.com/store001_license.jpg`。这种命名策略使我们在生成SQL时无需额外查询映射，减少了工作量。\n\n批量"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#4": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "、图片URL等字段。由于图片数量多，手工编写SQL既繁琐又容易出错，因此再度借助脚本来批量生成。\n\n假设我们的数据库表结构为：store_certificates(store_id, cert_type, image_url, upload_date)，每条记录存储一个门店的一张证照图片及其类型。我"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#5": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "文件名中如果含特殊字符导致SQL语法错误。另外，大批量插入操作建议在业务低峰期进行，并做好备份。\n\n遇到的问题及解决方案\n\n在实际执行上述批处理流程时，我们也遇到了一些问题，以下列举几个典型问题和解决方案：\n\n* 脚本兼容性问题： 起初编写的Shell脚本在处理文件名包含空格或特殊符号的图片时失败。"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#6": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "composite命令后加上错误捕获（如上述脚本中用$?判断），出错时记录日志而不中断整个批处理。\n* SCP中断： 在第一次尝试传输时，由于网络波动导致scp中途中断，需重新传输整个压缩包。正如前文所述，scp无法断点续传 ，这种情况下只能重新开始或换用其他工具。解决方案： 改用rsync替代sc"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#7": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "跳过并在最后汇总失败文件名单。这些失败文件稍后可重新运行工具专门上传，或人工检查网络环境后再处理。\n* SQL导入问题： 在将生成的SQL文件导入数据库时，发现个别记录插入失败。检查发现是由于少数字段内容超长或格式不符数据库约束（比如证照类型字段长度不够）。解决方案： 提前在生成SQL阶段校验字段长"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#8": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "尝试使用更高效的图像处理库或命令参数（如ImageMagick的mogrify直接批量处理目录）。\n* 使用更高级语言统筹：  Shell脚本虽然方便，但在复杂流程和错误处理上有局限。可以使用Python脚本替代，将加水印、上传和SQL生成整合到一个脚本中。Python的Pillow库可以方便地添加"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#9": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "。同时考虑极端情况下的容错，例如某步骤多次失败则跳过并标记处理结果，以免整批任务卡死在个别文件上。\n* 性能与资源利用： 如果图片总量巨大，需要考虑批处理对系统IO和内存的影响。可以在非业务高峰时段执行，或者分批多次执行以降低单次压力。另外，对象存储的上传也可以考虑启用并发或分片上传提高速度。\n\n经"
  },
  "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成#10": {
    "title": "批量处理证照图片的实战笔记：加水印、上传与批量SQL生成",
    "url": "/content/posts/legacy/批量处理证照图片的实战笔记-加水印-上传与批量sql生成",
    "date": "2021-01-25",
    "text": "运行。批处理脚本应尽量通用和可复用，同时增加必要的日志输出，方便在无人值守执行时也能事后追溯过程。\n* 关注数据和安全： 处理涉及证照等重要文件时，要注意文件权限和传输安全。采用scp/rsync等通过SSH的方式传输保证了安全性，上线前也需确保对象存储的访问权限正确配置，避免敏感图片泄露。此外，加"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#0": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "内容检索平台的 Solr 监控实践与可观测性优化\n\n在内容搜索系统中，Solr 的性能和稳定性至关重要，监控 Solr 的各项指标能帮助我们及时发现问题并优化服务表现。我们通常通过 Prometheus 收集 Solr 指标（使用 Solr 官方的 solr-prometheus-exporter）"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#1": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "* gc_time – GC 耗时，JVM 垃圾回收暂停时间（如总耗时或最近一次 GC 耗时）。\n* cpu_load – CPU 负载，Solr服务器的CPU使用率或负载指数。\n* mem_usage – 内存使用，特别是 JVM 堆内存使用量。\n\n这些指标对应着关键问题：查询快不快？负载高不高？"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#2": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "seconds\\_total}}{\\Delta \\text{requests\\_total}}$\n\n用 PromQL 表达即：\n\n这会得到过去 5 分钟内查询的平均耗时。然而，仅看平均值会掩盖部分慢请求的影响，这就需要关注 P95 延迟（95% 分位数延迟）。\n\nP95 延迟原理： P95 表示 9"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#3": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "按耗时分桶），我们可以使用 PromQL 的 histogram_quantile 函数，例如：\n\n这将计算过去5分钟内查询延迟的95分位值。如果 Solr 的导出器未配置输出直方图，我们只有上述总耗时和次数计数器，那么只能算平均值，无法直接得出 P95。这种情况下建议调整导出器配置采集分位信息，或"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#4": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "0ms——意味少数请求很慢。如果只看平均值，会误以为“一切正常”，而实际上部分用户在忍受高延迟。\n\n索引与系统指标： 除了查询性能，索引规模和系统资源同样要监控。index_size 的变化体现索引数据量的增长，过快增长可能影响查询性能或耗尽磁盘空间；doc_count 可以验证索引是否持续增加、有"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#5": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "count 的趋势，了解索引是否按预期增长，有无异常激增或停滞。索引大小也影响检索速度和资源占用。\n* 系统资源：监控 cpu_load、mem_usage、gc_time 等 JVM/操作系统指标，确保 Solr 运行环境充足稳定（CPU 不长时间100%，内存不频繁触顶触发 Full GC 等）"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#6": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "了监控 Solr 的基础。接下来看看如何结合代码和工具来利用这些指标。\n\nPython 示例代码\n\n监控不仅仅是看图表，有时我们需要编写脚本做自动检查或数据分析。下面通过两个简单的 Python 脚本示例，展示如何进行 Solr 健康检查和指标趋势统计。这些示例使用 requests 库与 Solr"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#7": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "是否为 OK。如果 Solr 在 5 秒内未响应或返回了非正常结果，脚本会打印出失败信息或异常。\n\n这种健康检查脚本可以定期运行（比如用 cron 每隔几分钟执行一次）。结合报警系统，当脚本检测到异常时触发告警（或者直接在脚本中发邮件/微信提醒）。相比 Prometheus 主动拉取，这种直接检查从"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#8": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "标在过去7天内的数据，每天一个数据点。然后计算第一个值和最后一个值的差值和百分比增长。输出示例：\n\n表示一周前索引15GB，现在18GB，一周增长了3GB，涨幅20%。通过这样的脚本，我们可以直观了解索引数据量的趋势，如果发现增长率过高，可以提前扩容存储或优化索引策略。\n\n类似地，我们可以用脚本分析"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#9": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "fana 仪表板，更高效地呈现 Solr 指标。\n\nGrafana Dashboard 优化建议\n\n一个设计良好的 Grafana 仪表板可以让我们快速定位问题。根据我们的经验（以及用户提供的 Solr 监控仪表板 JSON），这里有一些优化建议：\n* 使用模板变量 (Template Variab"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#10": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "ng{zk_host=\"$zk_host\"}, collection) 获取该集群下所有集合名）。\n* 类似地还有 shard 和 replica 变量，用于 SolrCloud 分片和副本的选择。\n通过这些变量，一个仪表板即可监控不同集群、不同 collection。选择 “All” 时，还能聚合"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#11": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "rease(...[1m]) 得到过去1分钟请求数。我们的仪表板中就使用了 increase(...[1m]) 曲线来表示每分钟的请求次数。两种方法各有优劣，但都比直接使用 solr_metrics_core_requests_total 累积值要有意义。\n对于延迟，如前所述，如果只能用总耗时/总次"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#12": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "后端完成。例如，不要在 Grafana 中获取到一长串原始数据再算分位，这样开销大且实时性差。\n\n* 合理布局和单位标识： 将相关指标放在相邻面板便于关联分析。例如将 search_rate（吞吐）和 search_latency（延时）图表放一起，这样当 QPS 峰值时是否引起延迟上升一目了然。如"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#13": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "没有单位或说明，导致读图者不知道 0.1 是0.1秒还是0.1毫秒。清晰的标签和单位可以避免误解。\n* 充分利用提示信息和图例： Grafana 的鼠标悬停提示和图例能够自定义格式。在仪表板 JSON 中，我们看到 legendFormat 使用了 {{base_url}}/{{collection"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#14": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "。Grafana 还可以对某些度量设定固定的阈值颜色，比如延迟超过某值时曲线变红，以强调异常状态。\n* 层次化的仪表板设计： 前面提到的变量联动实际上就是一种层次钻取。比如我们顶层概览仪表板可以不过滤 collection，观察整体情况；一旦某指标异常，比如某集合延迟高，再用变量下钻到具体 coll"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#15": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "集合X延迟高”时，我们点几下就能从总览跳转到该集合的详图甚至对应节点的系统指标，大大加快排查速度。\n* 查询性能和数据量控制： 当监控数据很多时，务必注意 PromQL 写法和 Grafana 刷新频率。尽量避免使用高开销的正则匹配或 without/by 大范围分组。如果需要合并不同 handle"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#16": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "在搭建 Solr 监控和告警的过程中，我们也踩过一些坑。以下是几个常见误区和盲区，要特别注意：\n* 只看平均值而忽视高分位： 前面已经强调过这一点。我们曾吃过亏：平均查询延时一直很低，然而少数查询偶尔超过1秒但未引起重视，直到用户投诉某些搜索很慢才发现问题。原因是当时告警只盯平均值，漏掉了长尾延迟。"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#17": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "ate 或错误总数。可以统计每分钟错误次数，或计算错误率=错误数/请求数，一旦超过某阈值马上告警。\n* 忽视 JVM 内部指标（GC、线程等）： 我们一开始关注点都在 QPS、延迟这些直接指标上，而忽视了 JVM 本身的状态。后来有一次 Solr 实例频繁 Full GC 导致长时间停顿，但由于平均"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#18": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "，应及时告警。此外，监控线程池队列、文件句柄等在特定场景下也很重要，避免 Solr 达到资源上限。\n* SolrCloud 副本状态的盲区： 在 SolrCloud 集群中，可能某个 replica 挂掉了，但是查询仍有其它副本支撑，表面指标（QPS、延迟）不受影响。这种情况下如果没有对集群状态的监"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#19": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "时间不是 ACTIVE 状态。一旦发现有 replica DOWN多分钟，就发出告警进行运维干预。\n* 告警阈值和策略不当： 告警配置需要平衡敏感度和噪音。我们曾经把 CPU 使用率 >90% 就告警，结果在索引导入或短暂查询高峰时频繁触发，属于“假警”。另一种错误是阈值过高或缺失，导致真正出问题时"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#20": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "言，Solr 的监控与可观测性建设是一个持续迭代的过程。最后，根据我们的实践，给出几点总结和建议：\n* 指标覆盖全面，视角相互佐证： 监控时尽量做到“既见树木，亦见森林”。既要有单节点详细指标，也要有集群整体视图；既关注查询性能，也别忘了索引和资源利用。将不同类别的指标联系起来看效果最好——例如当延"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#21": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "出问题的 collection 变量，这样一点击就能看到相关图表。这种联动大大缩短了故障诊断时间。\n* 定期复盘和调整： 将监控纳入持续改进流程。每次事故或性能问题过后，问自己：哪些指标能提前预警这次问题？有没有遗漏的监控点？例如发生过一次磁盘打满导致 Solr 无法写索引后，我们就加入了磁盘使用量"
  },
  "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化#22": {
    "title": "内容检索平台的 Solr 监控实践与可观测性优化",
    "url": "/content/posts/legacy/内容检索平台的-solr-监控实践与可观测性优化",
    "date": "2019-10-24",
    "text": "文档，了解某个指标的确切含义或最佳采集方法。在此基础上结合自己业务特点扩展监控，就能事半功倍。\n\n总而言之，一个健壮的 Solr 监控体系不仅能防患于未然，还能指导优化。通过深入理解 Solr 指标、使用代码提高监控自动化、避免常见误区并实践最佳策略，我们把内容检索平台的 Solr 从一个“黑盒”变"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#0": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice\n\n2. Core Concepts and Differences\n\n2.1 Supervised Learning\n\nThe core idea of "
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#1": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "earn a mapping function `f` such that `f(x) ≈ y`.\n-   **Objective**: To minimize a **measurable error** between the model's predictions and the true l"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#2": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "a cat, dog, or bird (multi-class classification).\n    -   **Regression**: Predicting a continuous numerical value. For example, predicting the price o"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#3": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "pervised learning deals with **\"unlabeled\" data**. It does not require manually annotated answers; instead, it strives to discover the inherent struct"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#4": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "sity, or latent factors**.\n-   **Typical Tasks**:\n    -   **Clustering**: Grouping similar data points into the same cluster. For example, segmenting "
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#5": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "user profiles into a 2D plane for visualization.\n    -   **Density Estimation/Generative Modeling**: Learning the distribution of the data to generate"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#6": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "ect follows a relatively standardized process:\n\n1.  **Data Annotation and Splitting**: Obtain or annotate high-quality labeled data and split it into "
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#7": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "on the training set and tune hyperparameters (e.g., learning rate, tree depth) on the validation set.\n4.  **Evaluation and Deployment**: Evaluate the "
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#8": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "th new data.\n\n3.2 Unsupervised Learning Pipeline\n\nThe unsupervised learning process is more exploratory:\n\n1.  **Data Preprocessing**: Data standardiza"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#9": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "DBSCAN) and explore its key hyperparameters (e.g., number of clusters `k`, neighborhood radius `ε`).\n3.  **Result Visualization and Business Validatio"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#10": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "earning often serve as input for downstream tasks. For example, using cluster assignments as user tags or using reduced-dimension features for a subse"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#11": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "ce, many powerful hybrid paradigms have emerged:\n\n-   **Semi-supervised Learning**: When you have a small amount of labeled data and a large amount of"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#12": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "mage contains a cat, but not its exact location).\n-   **Self-supervised Learning**: Creates \"pseudo-tasks\" from the data itself to generate labels. Fo"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#13": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "an environment and receiving rewards or penalties. It is often combined with supervised learning, as in AlphaGo.\n\n7. Selection Guide & Practical Tips\n"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#14": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "supervised methods to reduce label dependency.\n\n2.  **Consider Model Scale and Data Complexity**:\n    -   **Large-scale perceptual tasks (images, spee"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#15": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": ".\n\n3.  **Balance Interpretability and Accuracy**:\n    -   **High-stakes or regulated scenarios (finance, healthcare)?** Linear models, logistic regres"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#16": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "ne Offline Exploration with Online Application**:\n    -   A common pattern is to first use **unsupervised learning** for exploratory analysis on offli"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#17": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "for real-time prediction online.\n\n8. Conclusion\n\nSupervised and unsupervised learning are two powerful tools for solving different kinds of problems, "
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#18": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "learning excels at \"discovering unknown questions.\"** Without prior knowledge, it can reveal hidden structures, patterns, and insights in the data.\n\nI"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#19": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "e cycle from data insight to value creation.**\n\n9. Code Examples\n\n9.1 Environment Setup\n\n9.2 Supervised Learning Examples\n\nLinear Regression (Californ"
  },
  "/content/posts/legacy/supervised-vs-unsupervised-learning-en#20": {
    "title": "Supervised vs. Unsupervised Learning: Concepts, Algorithms, and Practice",
    "url": "/content/posts/legacy/supervised-vs-unsupervised-learning-en",
    "date": "2024-01-01",
    "text": "not a complete training script.\n\n10. References\n\n-   *Pattern Recognition and Machine Learning* — Christopher M. Bishop\n-   *Deep Learning* — Ian Good"
  },
  "/content/posts/legacy/feature-normalization-deep-dive#0": {
    "title": "特征归一化完整指南：从概念到代码的全面解析",
    "url": "/content/posts/legacy/feature-normalization-deep-dive",
    "date": "2024-01-01",
    "text": "特征归一化完整指南：从概念到代码的全面解析\n\n在 scikit-learn 中，我们可以用一行 `Pipeline` 代码优雅地将特征缩放与模型训练串联起来，实现高效、无数据泄漏的预处理流程：\n\n本文将带你完整地走过特征归一化的方方面面，从基础概念到代码实践，再到高级话题，助你彻底掌握这一数据科学的"
  },
  "/content/posts/legacy/feature-normalization-deep-dive#1": {
    "title": "特征归一化完整指南：从概念到代码的全面解析",
    "url": "/content/posts/legacy/feature-normalization-deep-dive",
    "date": "2024-01-01",
    "text": "n)** 和 **标准化 (Standardization)**。它们的目标和实现方式有所不同。\n\n简单来说，Normalization 关注的是“范围”，而 Standardization 关注的是“分布”。\n\n2. 归一化的动机\n\n为什么我们需要不厌其烦地对数据进行缩放？主要有以下四大动机：\n\n"
  },
  "/content/posts/legacy/feature-normalization-deep-dive#2": {
    "title": "特征归一化完整指南：从概念到代码的全面解析",
    "url": "/content/posts/legacy/feature-normalization-deep-dive",
    "date": "2024-01-01",
    "text": "（如 `height_m`），那么距离的计算将几乎完全由这个高方差特征所主导，这显然是不公平的。\n\n- **保证正则化公平性**：L1 和 L2 正则化通过惩罚模型的权重大小来防止过拟合。如果特征尺度不一，那么尺度较大的特征所对应的权重值本身就会偏小，导致正则化项无法对所有特征进行“一视同仁”的惩罚"
  },
  "/content/posts/legacy/feature-normalization-deep-dive#3": {
    "title": "特征归一化完整指南：从概念到代码的全面解析",
    "url": "/content/posts/legacy/feature-normalization-deep-dive",
    "date": "2024-01-01",
    "text": "**: 最常用的“标准化”，将数据转换为均值为 0，标准差为 1 的分布。它假设数据近似高斯分布。\n- **Max-Abs Scaler**: 类似于 Min-Max，但它将数据缩放到 [-1, 1] 区间，保留了数据的稀疏性（0 还是 0）。\n- **Robust Scaler**: 使用中位数（"
  },
  "/content/posts/legacy/feature-normalization-deep-dive#4": {
    "title": "特征归一化完整指南：从概念到代码的全面解析",
    "url": "/content/posts/legacy/feature-normalization-deep-dive",
    "date": "2024-01-01",
    "text": "**结果解读**:\n- 观察 `income_cny` 为 49131 的样本（第 3 行）：\n  - 它的 `income_mm` 值为 1.00，因为它是样本中的最高收入。\n  - 它的 `income_z` 值为 1.49，表示这个值远高于样本均值（约 1.49 个标准差）。\n- 观察 `he"
  },
  "/content/posts/legacy/feature-normalization-deep-dive#5": {
    "title": "特征归一化完整指南：从概念到代码的全面解析",
    "url": "/content/posts/legacy/feature-normalization-deep-dive",
    "date": "2024-01-01",
    "text": "的决策边界是基于特征的分割点，它们关心的是特征的序关系而非数值大小，因此对单调的缩放变换不敏感。\n\n**特别提示**：在回归任务中，如果你的目标变量 `y` 本身的数值跨度非常大（例如房价预测），对 `y` 进行对数变换 (`np.log1p`) 或标准化也是一种常见的优化技巧。预测后，记得使用逆变"
  },
  "/content/posts/legacy/feature-normalization-deep-dive#6": {
    "title": "特征归一化完整指南：从概念到代码的全面解析",
    "url": "/content/posts/legacy/feature-normalization-deep-dive",
    "date": "2024-01-01",
    "text": "观。\n\n2.  **Pipeline 一体化**：强烈推荐使用 `sklearn.pipeline.Pipeline` 或 `make_pipeline`。它能将预处理步骤和模型训练步骤打包，确保在交叉验证和部署时，每一步都严格遵守“先 `fit` 训练集，再 `transform` 所有数据”的原"
  },
  "/content/posts/legacy/feature-normalization-deep-dive#7": {
    "title": "特征归一化完整指南：从概念到代码的全面解析",
    "url": "/content/posts/legacy/feature-normalization-deep-dive",
    "date": "2024-01-01",
    "text": "常见误区\n\n- **在整个数据集上 `fit` 缩放器**：如上所述，这是最严重的数据泄漏错误。\n- **对类别特征做数值归一化**：归一化只适用于数值型特征。对于已经通过 One-Hot 编码转换的 0/1 特征，通常不需要再次缩放。\n- **在树模型上强行缩放**：对于决策树、随机森林等模型，归"
  },
  "/content/posts/legacy/feature-normalization-deep-dive#8": {
    "title": "特征归一化完整指南：从概念到代码的全面解析",
    "url": "/content/posts/legacy/feature-normalization-deep-dive",
    "date": "2024-01-01",
    "text": "**联邦学习、对抗训练下的缩放策略**：在分布式或安全性要求高的场景下，如何安全有效地进行归一化？\n- **多模态数据的统一归一化思路**：当数据包含图像、文本、数值等多种类型时，如何设计一个统一的归一化框架？\n- **归一化对模型可解释性的影响**：归一化会如何影响 SHAP、LIME 或 Per"
  },
  "/content/posts/legacy/feature-normalization-deep-dive#9": {
    "title": "特征归一化完整指南：从概念到代码的全面解析",
    "url": "/content/posts/legacy/feature-normalization-deep-dive",
    "date": "2024-01-01",
    "text": "图。现在，你可以在你的下一个项目中，更加自信地选择和应用最适合的缩放策略了。\n\n**扩展阅读**:\n- scikit-learn Preprocessing-Documentation\n- Feature Scaling for Machine Learning: Understanding the"
  },
  "/content/posts/legacy/python高德定位实践-逆地理编码与顺地理编码详解#0": {
    "title": "Python高德定位实践：逆地理编码与顺地理编码详解",
    "url": "/content/posts/legacy/python高德定位实践-逆地理编码与顺地理编码详解",
    "date": "2024-06-23",
    "text": "Python高德定位实践：逆地理编码与顺地理编码详解\n\n高德地图API的使用\n\n高德地图提供了RESTful接口来实现地理编码和逆地理编码的功能。要在Python中使用这些接口，首先需要通过高德开发者平台注册并获取一个API Key（Web端或移动端API Key均可）。接下来，我们将讲解如何通过P"
  },
  "/content/posts/legacy/python高德定位实践-逆地理编码与顺地理编码详解#1": {
    "title": "Python高德定位实践：逆地理编码与顺地理编码详解",
    "url": "/content/posts/legacy/python高德定位实践-逆地理编码与顺地理编码详解",
    "date": "2024-06-23",
    "text": "括地址和API Key。\n* requests.get()：发送GET请求。\n* response.json()：将返回的JSON数据解析为Python字典。\n* 如果响应成功并且找到了匹配的地址，就从geocodes中提取第一个匹配的结果，并返回经纬度坐标。\n\n常见问题：\n\n* 地址不准确：高德的"
  },
  "/content/posts/legacy/python高德定位实践-逆地理编码与顺地理编码详解#2": {
    "title": "Python高德定位实践：逆地理编码与顺地理编码详解",
    "url": "/content/posts/legacy/python高德定位实践-逆地理编码与顺地理编码详解",
    "date": "2024-06-23",
    "text": "itude,latitude。\n* radius：查询范围，单位为米，表示在此半径内进行地址匹配。\n* extensions：扩展信息，设置为all时会返回详细的地址信息以及周围的POI信息。\n* 如果响应成功并且找到了匹配的地址，就从regeocode中提取formatted_address并返回"
  },
  "/content/posts/legacy/python高德定位实践-逆地理编码与顺地理编码详解#3": {
    "title": "Python高德定位实践：逆地理编码与顺地理编码详解",
    "url": "/content/posts/legacy/python高德定位实践-逆地理编码与顺地理编码详解",
    "date": "2024-06-23",
    "text": "逆地理编码请求可能会导致性能瓶颈，尤其是高德地图API的调用有次数限制。为了解决这个问题，建议：\n\n* 请求节流：对于频繁变化的定位信息，可以设置适当的间隔时间，避免每次定位变化都发起请求。比如，在连续定位更新中每秒或每10秒发送一次请求，而不是每次坐标更新都调用API。\n* 批量处理：对于多个地址"
  },
  "/content/posts/legacy/python高德定位实践-逆地理编码与顺地理编码详解#4": {
    "title": "Python高德定位实践：逆地理编码与顺地理编码详解",
    "url": "/content/posts/legacy/python高德定位实践-逆地理编码与顺地理编码详解",
    "date": "2024-06-23",
    "text": "纬度转换为地址。通过高德API，开发者可以方便地实现这些功能，并在地图应用中提供精准的位置信息。\n\n在实践中，我们要注意如何高效管理API请求，合理控制请求频率，避免超限，同时处理常见的精度误差和服务异常。希望这篇文章能帮助开发者在Python中实现高效、准确的地理编码和逆地理编码功能，提升用户的地"
  },
  "/content/posts/legacy/mcp-blog-automation-en#0": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages\n\n1. After writing a new post in my blog project `geyuxu.com`\n2. Run `git add .`, `git comm"
  },
  "/content/posts/legacy/mcp-blog-automation-en#1": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "irectory to the `gh-pages` branch for deployment\n\nThis process not only involves multiple commands but is also prone to issues, especially if the `dis"
  },
  "/content/posts/legacy/mcp-blog-automation-en#2": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": ".\n\nThis led me to create the **MCP-Blog** project. Its core goal is to: **Automate the entire commit-and-deploy workflow for one project directory fro"
  },
  "/content/posts/legacy/mcp-blog-automation-en#3": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": ", keeping the blog repository clean and focused\n2. **Process Automation**: Simplifies a multi-step process into a single action, reducing human error "
  },
  "/content/posts/legacy/mcp-blog-automation-en#4": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "signed for this project. Its core philosophy is:\n\n> Enable an independent execution script (Model) to understand and operate on a target project withi"
  },
  "/content/posts/legacy/mcp-blog-automation-en#5": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "pt execution logic we define. For example, `./mcp.sh \"commit message\"` is an implementation of this protocol\n\nArchitecture Diagram\n\nThe workflow is st"
  },
  "/content/posts/legacy/mcp-blog-automation-en#6": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "**Project Structure:**\n\n1. Core Script `mcp.sh`\n\nThis is the heart of our automation. It handles parameter reception, directory switching, command exe"
  },
  "/content/posts/legacy/mcp-blog-automation-en#7": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "the current working directory to the blog project. This way, all subsequent `git` and `npm` commands execute as if they were run directly in the `geyu"
  },
  "/content/posts/legacy/mcp-blog-automation-en#8": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "lity.\n\n- **Astro Integration (`npm run build`)**:\n  Every Astro project has a `build` script defined in `package.json`. Our automation script calls it"
  },
  "/content/posts/legacy/mcp-blog-automation-en#9": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "l it in your **Astro project (`geyuxu.com`)**:\n  \n  Then, add a `deploy` command to your `geyuxu.com/package.json` scripts:\n  \n  The `gh-pages -d dist"
  },
  "/content/posts/legacy/mcp-blog-automation-en#10": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "needed once):\n   \n\n2. **One-command publishing**:\n   After finishing your writing in `geyuxu.com`, open the terminal and run:\n   \n\nThen, grab a coffee"
  },
  "/content/posts/legacy/mcp-blog-automation-en#11": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "cy Boost**: Reduces 5-6 steps to a single command\n- **Error Reduction**: Automated operations prevent manual omissions or mistakes\n- **Clean Code**: S"
  },
  "/content/posts/legacy/mcp-blog-automation-en#12": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": ": Upgrade from Shell script to a more robust Node.js or Python CLI tool with richer interaction and error handling\n3. **CI/CD Integration**: While loc"
  },
  "/content/posts/legacy/mcp-blog-automation-en#13": {
    "title": "MCP-Blog: One-Command Astro Blog Deployment to GitHub Pages",
    "url": "/content/posts/legacy/mcp-blog-automation-en",
    "date": "2024-01-01",
    "text": "workflow\n\nI hope this small project inspires you. Automation is second nature to us engineers—by delegating repetitive work to machines, we can focus "
  },
  "/content/posts/legacy/openai-o3-与-o4-mini-模型详解#0": {
    "title": "OpenAI O3 与 O4-mini 模型详解",
    "url": "/content/posts/legacy/openai-o3-与-o4-mini-模型详解",
    "date": "2025-04-28",
    "text": "OpenAI O3 与 O4-mini 模型详解\n\n基准测试成绩： O3 和 O4-mini 在众多基准上均刷新了纪录，展现出卓越的推理与问题求解能力。其中，在著名的数学竞赛 AIME 基准上，O4-mini 的表现甚至超过了更大的 O3：在无需借助工具的情况下，O4-mini 在 AIME 202"
  },
  "/content/posts/legacy/openai-o3-与-o4-mini-模型详解#1": {
    "title": "OpenAI O3 与 O4-mini 模型详解",
    "url": "/content/posts/legacy/openai-o3-与-o4-mini-模型详解",
    "date": "2025-04-28",
    "text": "率高达99.5%，而 O3 也提升至98.4% 。这说明新模型善于充分利用计算工具来提高准确率。\n\n在编码和科学问题上，O3 作为更大的模型展现了绝对领先。据 OpenAI 官方介绍，O3 在编程挑战 Codeforces、软件工程基准 SWE-bench 以及多学科综合测评 MMMU 等方面创下新"
  },
  "/content/posts/legacy/openai-o3-与-o4-mini-模型详解#2": {
    "title": "OpenAI O3 与 O4-mini 模型详解",
    "url": "/content/posts/legacy/openai-o3-与-o4-mini-模型详解",
    "date": "2025-04-28",
    "text": "编码以及数据科学等领域表现突出，全面超越了其前身 O3-mini，在非STEM任务上也有提升 。\n\n响应质量与缺陷： 得益于更深的推理链，新模型在复杂问题上的答案准确性和详尽程度都有明显提升。在考试类、逻辑推理类任务中，O3 往往能给出比前代模型更严谨的推导过程和结论，早期测试者称赞其在科学研究和工"
  },
  "/content/posts/legacy/openai-o3-与-o4-mini-模型详解#3": {
    "title": "OpenAI O3 与 O4-mini 模型详解",
    "url": "/content/posts/legacy/openai-o3-与-o4-mini-模型详解",
    "date": "2025-04-28",
    "text": "ni 有时会更加自信地给出错误的内容，如何降低高阶推理模型的幻觉仍是需持续关注的问题。\n\n技术特点\n* 多模态与视觉推理： O3 和 O4-mini 首次引入了真正的视觉推理能力。模型可以将图像作为思考链的一部分进行分析，不再局限于简单的图像识别，而是能像人类一样“看图思考” 。例如，O3 能够解析"
  },
  "/content/posts/legacy/openai-o3-与-o4-mini-模型详解#4": {
    "title": "OpenAI O3 与 O4-mini 模型详解",
    "url": "/content/posts/legacy/openai-o3-与-o4-mini-模型详解",
    "date": "2025-04-28",
    "text": "套件，模型可以访问最新的网络信息、运行代码进行计算、生成所需图像等，从而极大拓展了AI的能力边界。\n* 深度思考链： O3 和 O4-mini 属于推理模型，强调内部的多步推理过程。与一般LLM一次性生成回答不同，O系列模型会在生成最终答复前进行一系列链式推理步骤 。模型能够自动将复杂问题分解为子问"
  },
  "/content/posts/legacy/openai-o3-与-o4-mini-模型详解#5": {
    "title": "OpenAI O3 与 O4-mini 模型详解",
    "url": "/content/posts/legacy/openai-o3-与-o4-mini-模型详解",
    "date": "2025-04-28",
    "text": "证性 。总的来说，思维链技术赋予了模型更强的逻辑一致性和问题分解能力，是迈向通用人工智能的一大步。\n* 性能与效率优化： 虽然O3拥有庞大的架构和极高的推理精度，但其推理速度和资源开销也相对高昂。OpenAI因此对 O4-mini 进行了特别的优化，使其成为一个高效的推理引擎。O4-mini 通过精"
  },
  "/content/posts/legacy/openai-o3-与-o4-mini-模型详解#6": {
    "title": "OpenAI O3 与 O4-mini 模型详解",
    "url": "/content/posts/legacy/openai-o3-与-o4-mini-模型详解",
    "date": "2025-04-28",
    "text": "近 O3 的性能水平。同时，两款模型均采用OpenAI最新的安全机制和微调策略，以确保在输出高质量答案的同时，尽可能减少不当内容和偏见。\n\n应用场景\n* 高级助理与复杂问答： 凭借强大的多步推理和工具调用能力，O3 非常适合用来充当复杂任务的AI助理。例如，在商业分析、科研决策、法律咨询等需要多方面"
  },
  "/content/posts/legacy/openai-o3-与-o4-mini-模型详解#7": {
    "title": "OpenAI O3 与 O4-mini 模型详解",
    "url": "/content/posts/legacy/openai-o3-与-o4-mini-模型详解",
    "date": "2025-04-28",
    "text": "。它能够结合Python工具执行单元测试或数据分析，因此非常适合用作开发者日常使用的高效编码助手。\n* 数学求解与逻辑推理： 两款模型在数学、逻辑推理方面展现出远超一般模型的能力，可用于自动解题、定理证明辅助手段等场景。O4-mini 尤其以数学推理见长，在数学竞赛题、工程计算上往往能够快速给出高正"
  },
  "/content/posts/legacy/openai-o3-与-o4-mini-模型详解#8": {
    "title": "OpenAI O3 与 O4-mini 模型详解",
    "url": "/content/posts/legacy/openai-o3-与-o4-mini-模型详解",
    "date": "2025-04-28",
    "text": "报表中的图表数据并给出结论。这种**“看图思考”**的能力拓宽了 AI 在现实世界中的应用边界 。\n* 泛化型聊天与内容创作： 作为 ChatGPT 平台上的最新模型，O3 与 O4-mini 均可用于日常对话、写作辅导和内容创作。O3 在创造性写作和复杂话题讨论上表现出色，能够提出新颖观点并进行批"
  },
  "/content/posts/legacy/openai-o3-与-o4-mini-模型详解#9": {
    "title": "OpenAI O3 与 O4-mini 模型详解",
    "url": "/content/posts/legacy/openai-o3-与-o4-mini-模型详解",
    "date": "2025-04-28",
    "text": "入式部署或移动端应用中更可行的选项，因为它对硬件要求相对较低，能够在受限的计算资源环境下运行推理。\n* 工具型Agent系统： 利用模型的自主工具调用功能，我们可以构建各种AI Agent系统。例如，打造一个自动化的研究助理：由O3负责理解复杂研究问题，自动搜索文献和数据，调用代码工具分析数据，最后"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-zh#0": {
    "title": "用Python脚本快速实现MCP服务器：Astro博客自动化实践",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-zh",
    "date": "2025-07-27",
    "text": "用Python脚本快速实现MCP服务器：Astro博客自动化实践\n\n在深入代码之前，我们先来认识一下核心库 `fastmcp`。你可以把它想象成一根魔法棒，只要对着一个普通的Python函数挥舞一下（即使用一个装饰器），这个函数就能立刻被封装成一个符合MCP协议标准的工具，可供AI客户端调用。\n\n`"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-zh#1": {
    "title": "用Python脚本快速实现MCP服务器：Astro博客自动化实践",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-zh",
    "date": "2025-07-27",
    "text": "目标非常明确：让AI能够独立完成发布一篇新博客文章的完整流程。这个流程可以分解为三个核心动作：\n1. **保存文章**：将AI生成的Markdown内容保存到Astro项目指定的目录中。\n2. **提交代码**：将新添加的文章文件通过Git进行暂存（add）、提交（commit）和推送（push）。"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-zh#2": {
    "title": "用Python脚本快速实现MCP服务器：Astro博客自动化实践",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-zh",
    "date": "2025-07-27",
    "text": "重复编写执行命令行指令的代码，我们定义了一个辅助函数 `_run`。它使用 `subprocess.run` 在指定的 `ASTRO_DIR` 目录中执行命令，并捕获其标准输出和错误流。返回的日志中包含了执行的命令本身，这对于调试和追踪非常有帮助。\n\n2. 工具一：`save_article` - "
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-zh#3": {
    "title": "用Python脚本快速实现MCP服务器：Astro博客自动化实践",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-zh",
    "date": "2025-07-27",
    "text": "自动生成包含标题、当前日期、描述和作者的Frontmatter，并将其添加到文章内容的最前面。\n\n这个小小的功能极大地提升了AI生成文章的规范性，无需AI客户端操心Frontmatter的格式细节。\n\n3. 工具二：`commit_code` - 自动化版本控制\n\n文章保存后，下一步就是将其纳入版本"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-zh#4": {
    "title": "用Python脚本快速实现MCP服务器：Astro博客自动化实践",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-zh",
    "date": "2025-07-27",
    "text": "最终临门一脚的工具。它只做一件事：执行部署命令。\n\n该工具假设你的Astro项目 `package.json` 文件中已经定义了一个名为 `deploy` 的脚本，该脚本负责处理所有构建和部署到生产环境的逻辑（例如，推送到Vercel、Netlify或你自己的服务器）。这种设计将部署的复杂性与MCP"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-zh#5": {
    "title": "用Python脚本快速实现MCP服务器：Astro博客自动化实践",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-zh",
    "date": "2025-07-27",
    "text": "行脚本：\n  \n\n执行后，脚本不会有任何输出，它会静默地在后台等待来自标准输入的MCP指令。\n\n3. 与MCP客户端交互\n\n这个脚本本身是一个\"服务器\"，它需要一个\"客户端\"来与之对话。这个客户端通常是AI智能体所在的执行环境。客户端会启动 `astro_mcp_server.py` 作为一个子进程"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-zh#6": {
    "title": "用Python脚本快速实现MCP服务器：Astro博客自动化实践",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-zh",
    "date": "2025-07-27",
    "text": "脚本，无复杂的框架或配置。\n- **职责单一**：专注于提供与博客交互的工具，不处理其他无关逻辑。\n- **善用现有工具**：通过 `subprocess` 巧妙地封装了 `git` 和 `npm` 等成熟的命令行工具，而不是在Python中重新发明轮子。\n- **高度可扩展**：需要新功能？只需添"
  },
  "/content/posts/legacy/神经网络与深度学习入门书籍整理#0": {
    "title": "神经网络与深度学习入门书籍整理",
    "url": "/content/posts/legacy/神经网络与深度学习入门书籍整理",
    "date": "2025-04-22",
    "text": "神经网络与深度学习入门书籍整理\n\n* **线性代数基础**：矩阵、向量、点积等概念在神经网络中经常出现。因此，掌握这些基本概念有助于理解网络的结构（例如用矩阵表示权重）和计算原理。\n* **微积分基础**：神经网络中的许多关键过程都离不开微积分知识。例如，损失函数的优化需要对参数求导，反向传播算法用"
  },
  "/content/posts/legacy/神经网络与深度学习入门书籍整理#1": {
    "title": "神经网络与深度学习入门书籍整理",
    "url": "/content/posts/legacy/神经网络与深度学习入门书籍整理",
    "date": "2025-04-22",
    "text": "与正则化等概念。如果你已经接触过简单的模型（如线性回归或逻辑回归），再来学习神经网络会更容易上手。\n* **编程基础**：最后，良好的编程能力也是必不可少的。虽然很多神经网络教材（尤其是入门书）主要关注概念和原理，但将这些理论应用于实践通常需要编程实现。熟悉 Python 语言会让你在实现和调试神经"
  },
  "/content/posts/legacy/神经网络与深度学习入门书籍整理#2": {
    "title": "神经网络与深度学习入门书籍整理",
    "url": "/content/posts/legacy/神经网络与深度学习入门书籍整理",
    "date": "2025-04-22",
    "text": "Networks and Deep Learning)** - Michael Nielsen  \n  作为入门神经网络的首选书籍，这本免费开放的教材采用通俗易懂的语言介绍了神经网络的基本概念和原理。作者以手写数字识别（MNIST）任务为贯穿全书的实例，配合简洁明了的 Python 代码，逐步讲解从"
  },
  "/content/posts/legacy/神经网络与深度学习入门书籍整理#3": {
    "title": "神经网络与深度学习入门书籍整理",
    "url": "/content/posts/legacy/神经网络与深度学习入门书籍整理",
    "date": "2025-04-22",
    "text": "Deep Learning with Python)** - François Chollet  \n  由 Keras 框架的作者 François Chollet 所著，这本书通过 Python 和 Keras 库来实践深度学习。作者以直观易懂的方式讲解如何用简洁的代码实现各种常见的深度学习模型，"
  },
  "/content/posts/legacy/神经网络与深度学习入门书籍整理#4": {
    "title": "神经网络与深度学习入门书籍整理",
    "url": "/content/posts/legacy/神经网络与深度学习入门书籍整理",
    "date": "2025-04-22",
    "text": "然语言处理原理与实践》** - Andrej Karpathy, Richard Socher  \n  这本书深入讲解了循环神经网络（RNN）的理论，并特别关注其在自然语言处理（NLP）中的实际应用。书中涵盖了语言模型、文本生成、机器翻译等丰富的示例，阐释了 RNN 如何处理序列数据和上下文信息。对"
  },
  "/content/posts/legacy/神经网络与深度学习入门书籍整理#5": {
    "title": "神经网络与深度学习入门书籍整理",
    "url": "/content/posts/legacy/神经网络与深度学习入门书籍整理",
    "date": "2025-04-22",
    "text": "orcement Learning: An Introduction)** - Richard S. Sutton, Andrew G. Barto  \n  强化学习是机器学习的另一个重要分支，它关注智能体如何通过与环境的交互来学习决策。本书由强化学习领域的两位奠基人撰写，系统介绍了强化学习的基本概"
  },
  "/content/posts/legacy/神经网络与深度学习入门书籍整理#6": {
    "title": "神经网络与深度学习入门书籍整理",
    "url": "/content/posts/legacy/神经网络与深度学习入门书籍整理",
    "date": "2025-04-22",
    "text": "解。例如，在学习完某章反向传播算法后，可以尝试自己用代码实现一个简化的神经网络模型来巩固所学知识。\n* **循序渐进，不断迭代**：不必急于一次看完所有书或钻研所有细节。可以先通读入门书获得整体认识，再回过头深入研究细节。学习深度学习常常是个循环反复的过程，每一遍回顾都会有新的收获。\n* **善用社"
  },
  "/content/posts/legacy/神经网络与深度学习入门书籍整理#7": {
    "title": "神经网络与深度学习入门书籍整理",
    "url": "/content/posts/legacy/神经网络与深度学习入门书籍整理",
    "date": "2025-04-22",
    "text": "技术的原理和应用。不要担心自己“一开始就落后”，因为扎实的基础会让你在面对新知识时更加游刃有余。\n\n最后，保持好奇心和耐心非常重要。神经网络的学习之旅开始时可能有些陡峭，但只要坚持下去，随着理解的深化，你一定会体会到掌握这一强大技术所带来的成就感。希望这篇入门指南能够帮助你少走弯路，顺利踏入深度学习"
  },
  "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染#0": {
    "title": "Astro 官方模版集成 KaTeX 实现 LaTeX 公式渲染",
    "url": "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染",
    "date": "2025-04-24",
    "text": "Astro 官方模版集成 KaTeX 实现 LaTeX 公式渲染\n\n1.\t安装必要依赖：\n首先，需要安装支持 Markdown 数学公式的 remark 和 rehype 插件，以及 KaTeX 本身。这两个插件分别是 remark-math（解析 Markdown 中的数学公式语法）和 rehyp"
  },
  "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染#1": {
    "title": "Astro 官方模版集成 KaTeX 实现 LaTeX 公式渲染",
    "url": "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染",
    "date": "2025-04-24",
    "text": "o 在处理 Markdown 时，会先通过 remark-math 解析 $...$ 和 $$...$$ 之间的内容为数学公式节点，然后通过 rehype-katex 将这些节点渲染为对应的 HTML 和 MathML。这一步是公式渲染的核心。如果项目中已有其他 remarkPlugins 或 re"
  },
  "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染#2": {
    "title": "Astro 官方模版集成 KaTeX 实现 LaTeX 公式渲染",
    "url": "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染",
    "date": "2025-04-24",
    "text": "件的 frontmatter 中直接引入 import 'katex/dist/katex.min.css'; 来加载本地的 KaTeX CSS。无论采用哪种方式，确保构建后页面的 <head> 确实加载了 katex.min.css。\n\n4.\t（可选）调整暗色模式样式：\n如果你的博客支持深色模式或"
  },
  "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染#3": {
    "title": "Astro 官方模版集成 KaTeX 实现 LaTeX 公式渲染",
    "url": "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染",
    "date": "2025-04-24",
    "text": "架构调整相应的选择器和属性。如果没有使用暗色模式或 Tailwind 的排版插件，此步骤可忽略。\n\n完成以上步骤后，我们已经把所需的插件和样式集成进 Astro 项目。现在可以编写含有 LaTeX 公式的 Markdown 内容并验证效果。\n\n在 Markdown 中书写 LaTeX 公式\n\n配置完"
  },
  "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染#4": {
    "title": "Astro 官方模版集成 KaTeX 实现 LaTeX 公式渲染",
    "url": "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染",
    "date": "2025-04-24",
    "text": "TeX 数学符号和环境都可以直接在 Astro Markdown 中使用。\n\n踩坑记录与经验总结\n\n在集成 KaTeX 支持的过程中，我也遇到了一些小问题和注意点：\n\n•\t公式不渲染或原样显示：初次尝试时，我发现页面中的 $E = mc^2$ 仍然以文本形式显示，没有变成美观的公式。这通常是因为 r"
  },
  "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染#5": {
    "title": "Astro 官方模版集成 KaTeX 实现 LaTeX 公式渲染",
    "url": "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染",
    "date": "2025-04-24",
    "text": "min.css，可以打开浏览器开发者工具检查网络面板或元素面板，确认 CSS 文件成功加载、生效。\n•\t深色模式下公式不可见：正如前文提到的，如果启用了深色模式，务必调整 KaTeX 公式的文字颜色以适配深色背景。我当时在暗色模式下发现公式“消失”了，实际上是颜色与背景融为一体。通过在 CSS 中设"
  },
  "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染#6": {
    "title": "Astro 官方模版集成 KaTeX 实现 LaTeX 公式渲染",
    "url": "/content/posts/legacy/astro-官方模版集成-katex-实现-latex-公式渲染",
    "date": "2025-04-24",
    "text": "中的公式语法是否正确（括号是否闭合，命令拼写是否准确）。修正公式语法错误即可解决构建失败的问题。\n\n经过以上配置和调整，我顺利地在 Astro 博客中集成了 KaTeX，并成功渲染出所需的数学公式。在实际写作时，感觉就像在 LaTeX 文档中编写数学公式一样自然流畅。总结一下，Astro 本身作为静"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#0": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide\n\nBefore diving into the code, let's get to know the core library, `fastmcp`. You c"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#1": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "ilosophy of `FastMCP` is \"minimalist yet powerful.\" It handles all the low-level details of the MCP protocol for you, such as JSON-RPC communication, "
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#2": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "is demonstrated in these two core lines of code:\n\nThe `name` and `instructions` fields are metadata that tell the MCP client the purpose of this serve"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#3": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "y.\n\nThe Goal: Automating the Astro Blog Workflow\n\nOur goal is clear: to enable an AI to independently complete the entire process of publishing a new "
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#4": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "`push`) the newly added article file using Git.\n3. **Publish the Website**: Execute the deployment command to publish the latest blog content to the l"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#5": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": ". Environment Configuration and Helper Functions\n\nThe script's first task is to determine the root directory of the Astro blog project. By reading the"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#6": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "best practice for handling file paths in Python.\n\nTo avoid repetitive code for executing command-line instructions in each tool function, we define a "
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#7": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": ": `save_article` - Intelligently Saving Articles\n\nThis is one of the most crucial tools. It accepts a directory, filename, and article content as para"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#8": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "n date. The logic in this script is as follows:\n1. Check if the file is a Markdown file (`.md` or `.mdx`).\n2. Check if the content already includes fr"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#9": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "the article, it will use that H1 as the title.\n4. It automatically generates frontmatter containing the title, current date, a description, and the au"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#10": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": ", the next step is to get it into version control. The `commit_code` tool encapsulates the standard Git workflow.\n\nThis function executes `git add -A`"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#11": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "mmit\"), thus avoiding unnecessary push operations. The function's return value is the complete output of all Git commands, allowing the AI client to u"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#12": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "s tool assumes that your Astro project's `package.json` file has a script named `deploy` defined, which handles all the logic for building and deployi"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#13": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "ools, how do we get it working?\n\n1. Prerequisites\n- Ensure you have Python 3 installed on your system.\n- Install the `fastmcp` library: `pip install f"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#14": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "riable to point to your blog's root directory:\n  \n- Run the script:\n  \n\nAfter execution, the script will not produce any output; it will wait silently"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#15": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "resides. The client will launch `astro_mcp_server.py` as a subprocess, then send JSON-RPC formatted requests through the process's standard input (std"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#16": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "N data like the following to the script's stdin:\n\nUpon receiving the instruction, the script will execute the corresponding `save_article` function an"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#17": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "rates the \"less is more\" engineering philosophy:\n\n- **Simple and Direct**: A pure Python script with no complex frameworks or configuration.\n- **Singl"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#18": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "cess` instead of reinventing the wheel in Python.\n- **Highly Extensible**: Need a new feature? Just add a new function decorated with `@app.tool()`.\n\n"
  },
  "/content/posts/legacy/python-mcp-server-astro-automation-en#19": {
    "title": "Automating an Astro Blog with a Python MCP Server: A Hands-On Guide",
    "url": "/content/posts/legacy/python-mcp-server-astro-automation-en",
    "date": "2025-07-27",
    "text": "ating databases, or controlling local IoT devices. MCP and `FastMCP` open a door for us, allowing AI to integrate more deeply and seamlessly into our "
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#0": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度\n\n在为任务分派资源时，我们需要区分工作量与持续时间这两个概念。工作量指完成任务所需的总工作量单位（如人员小时、天数），表示“做这件事到底要花多少人力时间” 。持续时间则是从任务开始到结束所经过的日历时间，它基于资源配置来决定长短 。简单来说"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#1": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "，需要尽早发现并通过重新调配或削减范围来应对进度风险  。\n\n安排任务顺序：认识四种任务依赖关系\n\n有效的进度计划离不开对任务先后顺序的安排。项目中任务之间常见四种依赖关系，理解它们有助于我们合理排列任务顺序：\n\n- 结束-开始（Finish-to-Start, FS）：前一任务结束，下一任务才能开"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#2": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "于前置任务何时完成。例如，文档编写完成后，文档的编辑才能算完成 。经常用于需要同步完成的任务情境。\n- 开始-结束（Start-to-Finish, SF）：前一任务开始后，后一任务才能结束。这个关系相对少见但也有应用场景，表示后续任务的结束依赖于前序任务的开始。例如，只有第二班保安开始值班，第一班"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#3": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "中的路标或休息站：每到达一个里程碑，就意味着我们完成了一个阶段性目标，也清楚了还剩多少路要走 。\n\n里程碑的作用在于里程碑节点管理：项目启动和收尾往往各有一个里程碑，以标识项目正式开始和圆满结束；在项目中途，可以为阶段结束（如需求冻结、设计完成、测试通过等）设立里程碑，用于监控进度并向干系人汇报  "
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#4": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "需考虑休假、培训、日常杂务等。若忽视了人员的实际可用工时，计划看似紧凑，执行却可能发现人手不够用。\n- 个人效率差异：不同成员的工作速度和效率不同，即使都是8小时工作，一天的产出也可能有差异。还要考虑任务的学习曲线——新手上路可能比有经验者慢。因此在估算持续时间时，应当参考历史数据或类似任务经验，避"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#5": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "能排队等待。制定计划时要检查资源负荷，通过调整任务顺序、增配资源或修改计划来解决过度分配的问题 。\n- 缓冲与意外：在现实中总会有意料之外的延误，例如需求变更、技术难题或外部依赖延迟。因此，进度表中应预留缓冲时间以应对风险 。过于紧绷的计划一遇到风吹草动就崩盘，所以合理的缓冲让计划更有弹性。比如可以"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#6": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "划与现实同步。记住，计划是为现实服务的，纸上漂亮不如地上踏实。\n\n理解关键路径：项目进度的生命线\n\n在复杂项目中，关键路径（Critical Path）概念能帮助我们识别影响总工期的关键任务。关键路径是项目网络图中从开始到结束最长的一条任务路径，它决定了完成整个项目所需的最短时间 。换句话说，项目的"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#7": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "那条路就是整个取经任务的关键路径。这故事说明，无论其他人多快，项目完成时间取决于最长的那条路径。\n\n那么如何判断哪些任务在关键路径上呢？可以通过计算浮动时间（Float）来辨别。总浮动时间是指任务在不影响项目完工日期的前提下可自由延迟的时间。如果一个任务的浮动为零（或非常小），意味着它没有可以拖延的"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#8": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "可能转移到别的路径 。因此在执行过程中要动态监控关键路径的变化，及时调整计划以确保项目按时完成。\n\n*某项目的网络图及其关键路径示例：红色加粗线路即为关键路径（耗时最长的任务序列），其总持续时间决定项目工期；蓝色线路为非关键路径，可有一定浮动时间。不论其他路径有多快，项目必须等关键路径走完才能完成。"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#9": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "是关键路径法的进化版：在考虑资源限制的情况下制定进度计划，并通过缓冲管理来确保项目按期完成  。\n\n运用关键链法，首先根据任务技术依赖画出项目网络图，然后引入资源限制因素，对网络进行调整，得到考虑资源约束的进度计划 。在这个计划中，找到从项目开始到结束耗时最长且受资源限制的任务链，这就是项目的关键链"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#10": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "来吸收关键链上任务可能的延误，确保项目最终完工不受影响 。相当于在项目交付期限前加一道“安全垫”。\n- 馈入缓冲（Feeding Buffer）：加在非关键链任务汇入关键链之前的缓冲时间。因为非关键链的延误只要超过其浮动，就可能影响关键链进度，馈入缓冲用于防止非关键任务的延迟传递到关键链 。\n- 资"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#11": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "项目经理统一管理风险缓冲。这种方法在一些实践中取得了不错效果，可缩短工期并提高按期交付的几率 。\n\n*关键链法示意：上图为关键路径法下的计划，各任务都按较保守估计为1天，关键路径总耗时5天；下图为关键链法应用后，各任务用激进工期0.5天计划，提取出的剩余时间集中成项目缓冲（蓝色部分）置于末端。这样一"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#12": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "通常有三种手段可以加快项目进度：快速跟进、赶工和缩减范围。它们各有适用情境和利弊，下文分别介绍：\n\n- 快速跟进（Fast Tracking）：指将原本顺序进行的任务改为并行或部分重叠进行，以压缩项目总工期  。举个例子，本来应该先完成详细设计再开始开发，但为了抢时间，我们可能在设计尚未完成时就并行"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#13": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "行带来的沟通协调挑战。在工期非常紧迫又无法增加预算时，快速跟进是不缩减范围前提下压缩工期的首选 。\n- 赶工（Crashing）：指通过投入更多资源来压缩关键路径上任务的工期 。通俗地说，就是“花钱买时间”：增加人手、加班加点、使用更高效设备，甚至支付加急费用等，以缩短任务持续时间 。例如，让团队周"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#14": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "景：项目处于关键路径上的任务延误或工期紧张，且还有额外预算可投入的时候可以考虑赶工来把时间抢回来。\n- 缩减范围（Scope Reduction）：即减少项目的工作范围或降低要求，从源头上减少工作量以缩短工期。这往往意味着砍掉一些次要需求、降低一些非核心功能或品质要求，仅满足基本目标 。通过要做的事"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#15": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "调整范围来实现目标日期。不过，最好将其作为Plan B，平时应尽量通过更高效的方式完成全部范围。\n\n需要注意的是，无论采用哪种压缩策略，都只应针对关键路径上的任务来实施，才会真正缩短总工期。如果对非关键路径做快速跟进或赶工，可能只是把那条路径变短而不影响整体完工时间。进度压缩还可能带来新的问题，比如"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#16": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "的方法，只在时间压力极大时使用，可见选择任何压缩手段都需谨慎。\n\n记录基准：用基准跟踪和控制进度\n\n在项目进度计划制定完成并获得批准后，我们通常会将其固化为进度基准（Schedule Baseline）。基准就是项目的官方计划版本，作为后续监控和变更控制的依据 。具体来说，进度基准是经过批准的进度计"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#17": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "现了偏差 。这些偏差信息非常重要：它让我们及时识别进度落后或超前，从而决定是否需要采取纠偏措施。\n\n基准还在变更控制中扮演核心角色。当干系人提出变更请求（比如要求调整某任务工期或增加新任务）时，项目经理需要评估变更对进度基准的影响 。若变更被批准，就需更新进度基准以反映新的计划，否则任何未经批准的变"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l5#18": {
    "title": "项目管理基础知识（第五课）学习笔记：如何制定和管理项目进度",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l5",
    "date": "2025-06-13",
    "text": "范围基准、进度基准和成本基准，它们共同构成项目管理计划的重要部分，用于项目的整体监控和控制  。\n\n简单来说，没有基准就无法判断项目是提前还是落后。制定合理的进度计划并将其冻结为基准后，项目经理应定期对照基准检查实际进展。如果发现与基准偏差过大，要么采取措施赶上计划，要么提交变更请求调整基准（比如项"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#0": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "2025年主流大模型厂商大模型一览\n\n- GPT-3：发布于2020年，拥有约1750亿参数，是首个让业界震撼的大模型。它能写文章、写代码、翻译对话，展现了惊人的语言生成能力。当时你让它续写一句话，它往往能给出几段通顺的文本，这在之前是难以想象的。\n- GPT-3.5：这是GPT-3的改进版，出现于"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#1": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "。可以把GPT-3.5看作“GPT-3的加强版”，就像手机的“S”升级款——功能更完善但架构不变。\n- GPT-4：发布于2023年，是OpenAI真正的下一代旗舰模型。参数具体数量没有公开，但业界猜测可能高达数万亿级别，远超GPT-3。GPT-4的一大突破是多模态能力：不仅能读写文本，还能“看图说"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#2": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "，4.5在各种任务上的表现进一步提升，尤其是在非英语语言和创意性任务上更胜一筹。据报道，GPT-4.5在15种语言的基准测试中全面超越了原始GPT-4 。当然，能力提升也意味着计算开销大增——使用GPT-4.5的API费用是GPT-4的数倍 。因此GPT-4.5主要面向高端付费用户和企业客户，而GP"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#3": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "过它是封闭商用模式，模型细节不公开。\n\nAnthropic 的 Claude：安全至上的后起之秀\n\nAnthropic是由OpenAI前几位研究员创立的AI公司，也加入了大模型竞赛。他们的模型系列叫做Claude（克劳德），这个名字不像GPT那样带数字，反而像人名，体现了一种定位：做“AI助手”，希"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#4": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "，扩展版也32k左右，相比之下Claude可以记忆和分析的内容要多得多。更长的上下文非常适合需要长文档分析的场景，比如让AI阅读法律合同、技术文档然后总结。第二个提升是Claude 2支持直接上传PDF等文件 ，模型可以读取文件内容进行摘要或问答，就好比一个AI秘书能帮你读报告再做笔记。\n\nClau"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#5": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "操作）  。不过这些更高级的版本主要在专业领域测试，普通用户接触较多的还是Claude 2系列。\n\n总体来说，Anthropic的Claude在对话安全性和长文本处理上独具特色。Claude往往语气温和、有礼貌，严格遵守安全原则（有时甚至因为过于谨慎被批评过“过度防范”）。在性能上，Claude 2"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#6": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "命名，Gemini寓意集合多种能力于一身，就像双子星座那样拥有“双胞胎”特质。\n\nGemini 1.0在2023年底公布，包括了三个等级的模型：【Gemini Ultra】（超高性能级），【Gemini Pro】（通用性能级），以及【Gemini Nano】（移动设备级） 。Ultra面向最复杂的任"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#7": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "手机中 。可以说，谷歌的策略是多线部署：不同规模的模型针对不同场景，从云端服务到终端设备都覆盖。\n\nGemini的一大卖点是原生的多模态能力。据谷歌介绍，Gemini在训练时不仅看文本，还学习了图像、音频、视频、代码等多种数据 。这意味着Gemini生成文本的同时，天生就具备理解图像、处理声音甚至编"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#8": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "在2024年中期面向开发者测试，Gemini 2.0于2024年12月正式发布 。Gemini 2.0进一步增强了实时多模态处理能力，可以进行实时音频、视频交互（例如在语音助手中更聪明地响应） 。同时，谷歌在Gemini中引入了“Agentic AI”的概念，探索让模型驱动软件代理去帮用户完成任务。"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#9": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "等）。这可能让普通人有点眼花缭乱，但本质上Gemini每次大版本升级都是能力飞跃，比如从1.0到2.0在多模态实时性上进步显著 。谷歌也倾向于把模型直接融入自家产品，而不是单独开放API收费。因此很多人可能直接在Google的搜索、翻译、助手等产品中受益于Gemini模型，却未必察觉背后是哪一版。总"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#10": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "内掀起了不小的风浪 。可以说，DeepSeek扮演了鲶鱼的角色，给原本由巨头主导的格局带来冲击。\n\nDeepSeek的模型命名体系有点不一样。他们主要有两条产品线：一是基础通用模型系列，以“V”加数字标识版本（如V1、V2、V3）；二是强化推理能力的模型系列，以“R”标识（如R1）。其中DeepSe"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#11": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "而R系列是在发动机基础上加装了导航系统和工具箱，让AI不仅会思考还能主动查资料、用工具解决问题。\n\nDeepSeek的出现令同行感受到巨大压力。据媒体报道，DeepSeek-R1以颠覆性的姿态杀入市场，它开源+低价的模式引发了“鲇鱼效应”，迫使全球大模型厂商重新调整竞争策略 。因为DeepSeek将"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#12": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "epSeek模型在能力上已经相当强大。DeepSeek-V3的通用自然语言表现被认为接近GPT-4.5水平，甚至在某些基准上持平或超越。DeepSeek-R1则率先引入了深度思考和自主行动能力，支持联网搜索、插件工具使用等。R1目前在多模态方面稍显不足，比如只能处理文本附件，对图像的识别还有限 。\n"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#13": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "了这一需求，用开源社区的方式打造高质量模型，成为大模型版图中不可忽视的新势力。\n\n百度文心大模型\n\n在中国本土，大模型研发同样如火如荼，其中以百度最具代表性。百度很早就布局了预训练模型技术，推出了“文心”系列模型（英文名ERNIE）。2023年，当OpenAI的ChatGPT引发国内关注时，百度迅速"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#14": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "T-4的水准 。文心一言的APP也在4.0版时改名为“文小言”，强化其产品定位。\n- 文心大模型4.5：最新发布于2025年3月。4.5号称是百度首个原生多模态大模型 。也就是说，4.5从训练阶段便融合了图像、语音、文本等多种模态数据，能够优于以往版本地理解和生成不同类型的信息。百度官方表示，文心4"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#15": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "文本创作能力优于DeepSeek-V3和GPT-4.5等最新国外模型 。\n- 文心大模型X1：和4.5一同发布的还有一个特别型号X1。X1被称为“深度思考模型”，关注的是AI的推理、工具使用和自主进化能力 。它运用了诸如递进式强化学习、思维链+行动链训练、多元统一奖励机制等前沿技术，让模型学会“反思"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#16": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "t或思考（X思））。这种命名方式直观地告诉用户模型侧重点的不同。对于应用场景，基础版（如4.0、4.5）适合对话问答、内容创作等常规需求，而X1这种深度思考版更适合复杂推理、多工具协同的场景，比如专业问答、复杂决策支持等。\n\n作为中国的AI巨头，百度也在积极推动文心模型的开源和产业落地。2024年底"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#17": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "制解决方案。在中文领域和本土场景下，百度文心系列无疑是领头羊。\n\n其他玩家：Meta与国内新秀们\n\n除了上述公司，Meta和国内其他科技公司也在大模型领域占有一席之地。Meta在2023年开放发布了LLaMA系列大模型（如LLaMA 1、LLaMA 2），虽然这些模型没有直接提供公众聊天服务，但因为"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#18": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "。\n\n在国内，除了百度之外，阿里巴巴、腾讯、科大讯飞、华为、字节跳动等公司都推出了自家的大模型：\n\n- 阿里巴巴的通义千问（简称Qwen）系列，是阿里云开发的大模型。阿里在2023年开源了Qwen-7B、Qwen-14B和Qwen-70B等模型 。2024年阿里还发布了一个名为“新夸克”的AI对话应"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#19": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "是在中文问答和教育场景有深耕。讯飞强调让大模型赋能教育、办公软件，如实现AI实时翻译、作文批改等。\n- 华为则侧重于基础研究和行业模型。华为云推出了“盘古”系列大模型，包括盘古NLP、CV（计算机视觉）等模型，用于产业AI。2024年华为还组建团队推动医疗大模型在临床上的应用 ，利用AI帮助医生进行"
  },
  "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览#20": {
    "title": "2025年主流大模型厂商大模型一览",
    "url": "/content/posts/legacy/2025年主流大模型厂商及其代表模型一览",
    "date": "2025-04-22",
    "text": "稍占优势，而开源和国产模型正快速追赶，在本地化应用和定制方面有独特优势。\n\n群雄逐鹿下的AI未来\n\n2025年的大模型江湖，既有巨头之间的巅峰对决，也有开源新秀的搅局参与。对普通人来说，关注这些大模型厂商及其代表作，并不需要钻研技术细节——正如上文所示，我们可以用生活化的比喻去理解它们的特点。多模态"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh#0": {
    "title": "图像分类：数据稀缺、样本增强与欠拟合/过拟合",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh",
    "date": "2024-01-01",
    "text": "图像分类：数据稀缺、样本增强与欠拟合/过拟合\n\n3. 数据稀缺下的样本增强\n\n在所有解决过拟合的策略中，数据增强是最直接、最有效的方法之一。它通过对现有训练数据进行一系列随机变换，创造出更多样的、模型“未曾见过”的样本，从而在不增加标注成本的情况下，扩充了数据的信息量。\n\n3.1 几何变换\n\n这类变"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh#1": {
    "title": "图像分类：数据稀缺、样本增强与欠拟合/过拟合",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh",
    "date": "2024-01-01",
    "text": ") 或椒盐噪声 (Salt-and-Pepper Noise, e.g., ratio=0.3-0.5%)，以及应用高斯模糊 (GaussianBlur, kernel size=3 or 5) 或运动模糊 (MotionBlur)。\n\n3.3 颜色空间变换\n\n颜色空间的变换可以增强模型对光照、对比"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh#2": {
    "title": "图像分类：数据稀缺、样本增强与欠拟合/过拟合",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh",
    "date": "2024-01-01",
    "text": "法变得非常流行，它们能创造出在真实世界中不存在但对模型正则化非常有益的样本。\n\n3.5 自动增强\n\n手动设计增强策略组合费时费力，因此自动增强应运而生。**RandAugment** 是一种简单高效的方法，它从一个预设的变换池中随机挑选 N 种变换，并以一个统一的强度 M 应用。对于小数据集，它通常"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh#3": {
    "title": "图像分类：数据稀缺、样本增强与欠拟合/过拟合",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh",
    "date": "2024-01-01",
    "text": "模型所使用的数据集（如 ImageNet）来设定。\n\n4.2 可插拔的 Mixup/CutMix\n\n在训练循环中，你可以从 DataLoader 中取出 `inputs` 和 `targets`，调用 `mixup_data` 生成混合数据，然后用 `mixup_criterion` 计算混合后的损"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh#4": {
    "title": "图像分类：数据稀缺、样本增强与欠拟合/过拟合",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh",
    "date": "2024-01-01",
    "text": "作为基准。\n2.  **阶段一**: 加入基础的几何和颜色变换，学习率可以保持不变或适当调大。\n3.  **阶段二**: 引入 Mixup 或 CutMix，通常需要配合标签平滑 (Label Smoothing) 来获得更好效果。\n4.  **阶段三**: 如果计算资源允许，尝试使用 RandAu"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh#5": {
    "title": "图像分类：数据稀缺、样本增强与欠拟合/过拟合",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh",
    "date": "2024-01-01",
    "text": "几何变换时，必须对边界框 (bounding box) 或掩码 (mask) 执行完全相同的变换。\n- **验证集纯净度**: 验证集应尽可能保持“干净”，以真实反映模型在原始数据分布上的性能。通常只对其进行必要的缩放 (Resize) 和中心裁剪 (Center Crop)，不做“重口味”的增强。"
  },
  "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh#6": {
    "title": "图像分类：数据稀缺、样本增强与欠拟合/过拟合",
    "url": "/content/posts/legacy/data-augmentation-underfitting-overfitting-zh",
    "date": "2024-01-01",
    "text": "拟合与过拟合的斗争，本质上是在模型的**容量**与数据的**信息量**之间寻找一个精妙的平衡点。\n\n本文所介绍的策略是解决这一问题的经典起点。在此基础上，你还可以进一步探索更前沿的方向，例如：利用无标签数据进行自监督预训练 (Self-supervised Pre-training)、使用生成模型（"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#0": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "项目管理基础知识学习笔记L3\n\n在实际工作中，我学会罗列项目中的关键角色，并为每类角色想一想他们关心什么：\n\n- 项目客户（需求方）：提出问题或需求的人或团队，他们提供项目资金，对项目范围有发言权，并参与验收 。例如，一个酒店会议中心升级项目的客户可能是会议中心部门的总监，由他出资并审核项目成果。\n"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#1": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "响的人。例如市场部可能不是直接参与项目，却因为项目产出需要他们后续推广，也是利益相关者的一种 。\n\n识别完“谁”是干系人后，我会进一步了解“他们有什么诉求”和“能带来什么影响”。为此，我常使用利益相关者登记表（或分析文档）来记录每个干系人的详细信息 。这个登记表通常包括：干系人所属部门及职位、对项目"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#2": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "理的基础，它帮助我建立良好的关系网，平衡不同干系人的期望，促进项目顺利推进  。\n\n如何启动项目\n\n在识别完主要干系人后，我会着手启动项目。项目启动阶段的一项关键工作是指定项目经理——也就是明确由谁来负责这个项目的推进。我在实际中体会到，尽早确定项目经理非常重要，因为后续很多决策和沟通都需要项目经理"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#3": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "中心竞争力”。\n- 项目范围的初步描述：项目大概要做哪些事，包括的主要可交付成果和关键工作内容 。\n- 初步里程碑和时间表：大概的项目进度安排，如主要阶段的完成时间。\n- 粗略的成本预算：预估项目所需投入的资金或资源规模 。\n- 主要项目利益相关者清单：列出项目的客户、发起人、核心团队等 。\n- 项"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#4": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "本范围达成共识，也明确各自的角色和责任。之后，项目就算正式进入执行准备阶段了。\n\n明确问题或机会\n\n项目之所以存在，通常是为了解决一个问题或者抓住一个机会。老师在课上强调，正确定义项目要解决的根本问题非常关键，因为它会指导项目后续的每个决策 。为此，我会先写一份问题陈述 (Problem State"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#5": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "上新系统”这样的表述时，就不停地问：“为什么要上？是想解决什么痛点？” 多问几个为什么，层层剥茧才能找出问题的根源 。在刚才的例子中，我们继续问下去，可能会发现真正的问题是“现有协作平台功能落后，导致跨部门沟通效率低下”。于是，正确的问题陈述可以表述为：“目前公司的跨部门协作效率低，影响了项目交付速"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#6": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "。这个陈述言简意赅地点出了问题——市场需求在涨，我们份额在跌。这为项目指明了要解决的核心问题。\n\n我体会到，写问题陈述有两个注意事项：一是尽量简洁，能一句话说明白绝不用一段话；二是明确区分问题和方案，杜绝把想要的方案错当成了问题。 如果实在拿不准，我就反复检查：“我写的这句到底是在描述现状困境，还是"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#7": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "混淆，觉得好像都是说“想达到什么”。后来明白，项目目的和项目目标既有区别又有关联，可以这么理解：\n\n- 项目目的（Goal）：项目最终想实现的大方向、大效果，是对预期成果的高度概括 。通常只用一两句话描述，不一定量化，但要指明一种期望的改善。例如，“提升会议中心的市场竞争力”或者“改善客户满意度”。"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#8": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "的标准 。\n\n在制定项目目标时，我还了解到目标可以分成几种常见类型，每一类关注不同的绩效方面 ：\n\n- 业务目标：支持公司战略或战术的目标。例如提升市场份额、提高品牌知名度、客户留存率等。这类目标体现项目对业务发展的贡献，如“会议中心年预订场次增加15%”。\n- 财务目标：与金钱直接相关的目标。例如"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#9": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "是广义的“绩效”概念。例如“项目必须在明年旺季开始前完成改造” ，这就是一个进度方面的绩效目标。\n\n列出这些目标后，我还需要确保目标本身定义得合理、清晰。这里就用到著名的SMART原则：Specific（具体明确）、Measurable（可衡量）、Achievable（可实现）、Relevant（相"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#10": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "的和组织战略密切相关。设定无关紧要的目标只会浪费资源。所以我会检查每个目标是否确实支撑了总体目的。\n- *有时限*：目标要有明确的截止日期或时间框架 。有了时间约束，团队才知道努力的节奏。例如“在明年3月底前完成改造” 就是给目标加上了期限。\n\n遵循SMART原则，我把项目目标写出来后，基本上就勾勒"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#11": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "有了它们，我们就知道这条路要通向哪里 。在这个方向指引下，我们才能继续规划实现路径。\n\n制定战略\n\n当项目的目的和目标都明确后，我发现往往实现这些目标的路径不止一条。也就是说，可以有不同的方案或战略来完成项目。那么选哪种方案最好呢？第三课介绍了一个理性选择策略的方法，我也在工作中应用过，就是头脑风暴"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#12": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "套餐”，还有人提“与大型会展合作打包促销”等等。重点是先罗列出尽可能多的想法，然后再逐一评估 。\n\n第二步，使用决策矩阵评估选项。在有了一堆备选战略后，就进入评估和筛选阶段。这里课程推荐使用“决策矩阵”，我尝试过，确实很有帮助。决策矩阵简而言之就是列出选项和评价标准的表格，通过打分来比较方案优劣 。"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#13": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "“提升知名度”更重要，那前者权重大一些。然后计算每个方案的综合得分，得分最高的自然就脱颖而出了 。\n- 可行性：除了看“想不想要”，还得看“能不能做到”。小组会问：“这个战略技术上、资源上可行吗？” 如果某方案需要采用从未检验的新技术或者严重依赖外部条件，那可行性就存疑 。遇到这种情况，我会考虑做可"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#14": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "失败，那我会谨慎考虑是否放弃它 。策略选择就像下棋，走一步看三步，不能只盯着眼前利益忽视长远隐患。\n- 文化契合度：这一点常被忽略，但老师特别提到要问：“该战略是否符合公司的文化和现状？” 我深有同感。一个方案再完美，如果不符合组织文化，实施起来也会阻力重重 。比如公司文化保守，却硬推激进颠覆式的变"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#15": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "，或者结合领导偏好、资源机会来拍板。但不管怎样，这个过程可以保证我们考虑周全，而不是拍脑门决定。\n\n当最终方案选定后，我感觉项目一下进入了一个新阶段。此时，我们就对“要做什么”和“怎么做”有了一个清晰的蓝图。接下来很多细节（例如分解具体任务、安排资源等）都会以此为基础逐步展开 。课程中建议我们把这个"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#16": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "终成果很可能无法让利益相关者满意；反之，如果加了一堆不必要的需求，就会无端增加项目时间和成本 。\n\n为了更好地理解，我会将目标和需求的关系举个例子来说明：在会议中心升级项目中，有一个目标是“使用最新型的计算机和视听设备来提升会议体验” 。围绕这个目标，我们可以进一步明确出几个具体需求，比如：“在所有"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#17": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "语言描述需求。甚至不同干系人各说各话，给出不一致甚至矛盾的需求 。这种情况下需要我们去梳理、澄清。\n- 遗漏需求：有些关键需求可能没人提及，可能因为想当然地以为不必说，或者干脆忘了。这些遗漏如果不及时发现，后期会变成大问题。\n- 超出范围的需求：也叫“需求蔓延”或“愿望清单”。有时干系人会提出一些n"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#18": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "吧”。这种情况下，需求搜集更需要我们主动引导。\n\n面对这些挑战，我一般分三个步骤来“发现需求”：\n\n第一步：收集需求信息。这一步就是想方设法把需求挖掘出来。课上介绍了几种常见的方法，我结合自身经验，总结如下几种有效的需求获取手段：\n\n- 访谈：这是我最常用的方法之一。找到合适的干系人一对一深度访谈，"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#19": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "各自提他们认为需要的功能。大家边提边讨论，有分歧的当场对质，往往能明确哪些需求是共识，哪些存争议。\n- 观察：有时候干系人自己说不清需求，这时我会采用“实地观察”的方法 。亲自去看用户是如何工作、如何使用现有系统，从他们日常行为中发现痛点。例如，观察酒店会议销售人员接单流程，也许能发现一些系统改进需"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#20": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "或者分析现有系统的功能清单，可能会揭示出需求线索。这种方法可以作为其他手段的补充，提供背景信息。\n\n第二步：分析和澄清需求。当第一轮收集到一堆需求后，工作还远没完——其实才刚开始 。接下来我会对原始需求进行整理和分析 。首先检查有没有不合理或缺失的地方：有时候干系人提的需求可能前后矛盾，或者讲得含糊"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#21": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "想起新的点子或者否定之前的想法。所以要有耐心，通过多轮问答和验证，逐渐把需求雕琢得一致、无遗漏。\n\n第三步：记录和确认需求。当感觉需求信息已经相对稳定、合理，我就会开始编写需求文档 。记录需求时，我遵循几个原则：一是用清晰、无歧义的语言描述 。尽量避免行话和模棱两可的词，确保不同的人读起来理解相同。"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#22": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "们需要的就是这些”，项目才算真正有了明确的蓝图。后续设计、开发、测试都将严格对照这些需求来进行。\n\n总的来说，需求阶段是项目计划中最磨人的环节之一，但也是决定项目成败的基础。我在实践中越来越体会到，花时间把需求搞清楚是值得的：与其等项目后期发现偏离了客户期待，不如一开始就把事情问明白、想清楚。毕竟项"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#23": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "的方法或指标 ——换句话说，就是对“成功”的定义。 \n\n在第三课中，讲师强调了几点让我印象深刻：\n\n- 明确最终和中间可交付成果：我现在列计划时，喜欢先写下项目的最终可交付成果是什么，也就是项目结束时要交出什么 。然后，再列出中间可交付成果 。中间可交付成果是项目过程中交付的阶段性成果，用于逐步迈向"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#24": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "没概念。适当拆解大的交付物，用工作分解结构（WBS）的方法把它们分成小块，可以更好地管理和跟踪 。\n- 范围说明：有趣的是，可交付成果和项目范围还有紧密联系。项目范围其实由要交付的内容决定——包括什么，不包括什么 。当我明确了要交付哪些成果，自然而然就确定了范围边界 。在编写范围陈述（下一节详细谈）"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#25": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "项都向客户交付或解释。不过在阶段评审会上，我还是会和客户沟通我们完成了哪些里程碑成果，以增强信心。\n- 设定可衡量的成功标准：这是重中之重。写下交付清单后，更关键的是如何判断“我们交付的是不是客户真正想要的？” 这里就需要给每个交付成果定义验收/成功标准 。成功标准往往是量化的，越具体越好，比如“一"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#26": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "升的衡量方法 。成功标准=成功的定义，有了它，我们在项目结束时就能客观评估交付成果是不是达标了 。\n- 确保标准清晰可量化：有些成功标准容易确定，比如“签署了供应商合同”或“取得了建筑完工证书”这种一看就知道是否完成的 。但也有一些标准比较主观、不易衡量，这时就要想办法转化为量化指标 。否则团队和客"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#27": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "筑公司签署施工合同 \n\n  成功标准：合同盖章生效，施工方进场准备。\n\n- …（其他中间成果略）\n\n通过这样的清单，我对整个项目要交付的东西和衡量标准一目了然。这也方便和干系人沟通他们关心的结果。可交付成果清单告诉我们项目应该交付哪些结果，成功标准则帮助判断这些结果是否达到了我们想要的品质 。在执行"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#28": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "项目成功的关键因素之一就是尽早明确项目的假设和风险 。听完后我马上应用到自己的项目中，效果很好。\n\n假设（Assumptions）可以理解为那些我们暂时认为为真的前提 。因为项目在启动时很多情况还不确定，我们往往会假定一些条件来进行规划。例如假设“关键技术人员一直可用”“供应商能按期交货”“市场环境"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#29": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "。只有把假设亮出来公开讨论，我们才能避免日后互相埋怨“我以为你会做”“我以为不用做”之类的问题。\n\n风险（Risks）则是项目中可能发生的不确定事件，分为威胁（负面影响）和机会（正面影响）两类，不过多数时候我们更关注负面风险 。风险的特点在于不确定：也许会发生也许不会，但一旦发生就会影响项目目标 。"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#30": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "目 。\n\n在实践中，我通常会在项目章程或范围说明书里，加一个章节列出关键假设和风险。具体做法是：\n\n- 头脑风暴假设清单：和团队一起回顾项目计划，想想有哪些我们理所当然认为是真的东西，其实值得打个问号。把这些都列出来作为假设条件。然后我会努力验证这些假设是否成立，比如给相关方发邮件确认责任归属等。如"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#31": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "如规避、缓解、应急计划等。对那些概率极低或者影响很小的琐碎风险，我们记录在案即可，不用花太多精力。\n- 公开讨论并获取共识：假设和风险列表我都会拿到项目启动会上分享，或者通过邮件发给干系人，请大家知情并补充 。这个举动有两方面好处：一是万一遗漏了什么，别人可以提醒补充；二是让所有人有心理准备，知道项"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#32": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "整计划；风险如果临近发生就触发应对措施。通过不断跟踪，我们可以确保假设和风险始终在掌控范围内 。\n\n总之，假设和风险管理让我对项目的底牌更心中有数。明确假设可以防止沟通误区，明确风险可以未雨绸缪。虽然我们无法消除所有不确定性，但至少可以提前想到并做好准备。说到底，项目管理很大程度上就是管理不确定性，"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#33": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "控制项目边界、防止范围蔓延有极大的作用。\n\n编写范围陈述时，我通常提炼前面已经明确的信息： \n\n1. 包含的范围：根据之前确定的需求和可交付成果，我会在范围陈述里列出项目团队将要完成的主要工作和产出 。这部分可以看作项目的“包括项”。例如，对于会议中心升级项目，范围陈述可能写：“本项目包括会议室多媒"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#34": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "容易被认为应该做但我们其实不做的工作，或者可能在界限处模糊的事项。例如，实施新软件系统项目中，可能要声明“不包括旧数据的历史清洗”之类。不写出来，别人可能以为你会做。\n3. 范围描述：有时我还会在范围陈述开头用一两句话概括项目的整体范围，等于是给包含项和排除项做个总结。比如：“本项目旨在改造提升会议"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#35": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "场宣传另做打算，那我们就把市场宣传列为范围外 。通过核对假设，我可以确保范围陈述没有遗漏关键点。\n\n完成初稿后，我会请主要干系人（客户、发起人等）审阅确认范围陈述。这就像画了一条大家都能看见的“楚河汉界”，确认过后谁也不能轻易越界。如果后续有人提出新需求或任务，我就可以拿出范围陈述来对照：“这个在我"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l3#36": {
    "title": "项目管理基础知识学习笔记L3",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l3",
    "date": "2025-06-11",
    "text": "防止过度承诺，也确保了客户得到该得的成果，不会少交付东西 。它是项目计划阶段非常重要的基准文件。\n\n总之，在项目规划启动的过程中，编写范围陈述是最后把所有信息收拢成一个清晰定义的步骤。我通常在完成它之后，感觉项目的“框架”已经扎实搭好——干系人清单、目标、需求、可交付成果、成功标准、假设、风险、范围"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning#0": {
    "title": "A/B测试核心指南：从统计原理到机器学习应用",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning",
    "date": "2024-01-01",
    "text": "A/B测试核心指南：从统计原理到机器学习应用\n\n-   **在机器学习场景中的角色：最后的守门员**\n    对于机器学习模型，A/B 测试是连接离线评估与全量上线的最后一道、也是最重要的一道闸门。它评估的不仅是宏观业务指标（如转化率、CTR、用户平均收益），也关注模型级指标（如预测准确率的提升、策"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning#1": {
    "title": "A/B测试核心指南：从统计原理到机器学习应用",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning",
    "date": "2024-01-01",
    "text": "及它们对最终业务 KPI（如人均停留时长、付费转化率、投诉率）的影响，是离线评估无法计算或模拟的。\n\n3.  **提供可信的决策依据**\n    A/B 测试的核心是“用数据说话”。通过严谨的实验设计和统计检验，我们能得到一个量化的结论，如 p-value 或置信区间。这为产品或算法的上线决策提供了"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning#2": {
    "title": "A/B测试核心指南：从统计原理到机器学习应用",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning",
    "date": "2024-01-01",
    "text": "rics)**: 用于确保实验不会对其他方面产生负面影响的指标（如页面加载时长、跳出率、投诉率）。\n    在确定指标后，使用功效分析 (Power Analysis) 或在线计算器，根据预期的最小可检测效应、显著性水平（α）和统计功效（1-β），估算出每组所需的最少样本量 N。\n\n3.  **③ "
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning#3": {
    "title": "A/B测试核心指南：从统计原理到机器学习应用",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning",
    "date": "2024-01-01",
    "text": "来的风险。流量分配策略需综合考虑业务敏感度、风控需求和系统容量。\n\n5.  **⑤ 运行与监控**\n    实验应至少运行一个完整的业务周期（通常是一周或两周），以消除节假日或周末带来的周期性偏差。在此期间，需通过仪表盘（如 Grafana）实时监控核心指标和护栏指标，设置异常报警，以便在出现严重负"
  },
  "/content/posts/legacy/ab-testing-guide-for-machine-learning#4": {
    "title": "A/B测试核心指南：从统计原理到机器学习应用",
    "url": "/content/posts/legacy/ab-testing-guide-for-machine-learning",
    "date": "2024-01-01",
    "text": "分桶和比例类指标的 Z 检验。\n\n7. 延伸话题\n\n-   **多臂老虎机 (Bandit) vs. A/B 测试**: Bandit 算法在实验期间会动态地将更多流量分配给表现更优的组，从而减少机会成本，适合探索性强的场景。而传统的 A/B 测试在因果推断和效果解释上更为严谨，适合核心、稳定的业务"
  },
  "/content/posts/legacy/python应用日志采集到elk排查实录#0": {
    "title": "Python应用日志采集到ELK排查实录",
    "url": "/content/posts/legacy/python应用日志采集到elk排查实录",
    "date": "2022-03-25",
    "text": "Python应用日志采集到ELK排查实录\n\n* 「文件有 – ES 无」= 中间 Filebeat / Logstash 链路有问题  \n* 先看 Filebeat 是否 **“看见”** 文件  \n* 再看 Logstash 是否 **“接到”** 事件  \n* 最后看 Elasticsearch"
  },
  "/content/posts/legacy/python应用日志采集到elk排查实录#1": {
    "title": "Python应用日志采集到ELK排查实录",
    "url": "/content/posts/legacy/python应用日志采集到elk排查实录",
    "date": "2022-03-25",
    "text": "my_service`\n\n> **工程名改动** 如果没同步到所有配置，就一定埋雷。\n\n根因分析\n\n* 单节点可写日志 → Python `logging` 配置 OK  \n* Filebeat 不认路径 → 采集规则老化  \n* 上游自动化脚本、K8s ConfigMap 同样硬编码了旧路径\n\n解"
  },
  "/content/posts/legacy/python应用日志采集到elk排查实录#2": {
    "title": "Python应用日志采集到ELK排查实录",
    "url": "/content/posts/legacy/python应用日志采集到elk排查实录",
    "date": "2022-03-25",
    "text": "p=my_service-neo` 标签，日志就能被采集  \n* 彻底去掉硬编码\n\n日志落 ES\n\n* Logstash 保持 `json` codec，按日期走 ILM  \n* Elasticsearch 索引命名：`my_service-neo-%{+yyyy.MM.dd}`  \n* Kiban"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#0": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler\n\n- **🤖 AI-Driven Scheduling**: Integrates OpenAI GPT and the Gra"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#1": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "execution patterns and optimize based on context.\n- **🏗️ Enterprise-Grade Architecture**: Built on FastAPI with a microservices design, supporting hi"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#2": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "itoring from the application to the system level.\n- **🔒 Multi-Layered Security**: Offers comprehensive security mechanisms, including JWT, API keys, "
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#3": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "++\n    \n          +>[Prometheus]-->[Grafana]\n    \n          +>[AI Layer: OpenAI, Graphiti]\n    \n    |      +>[AI Agent]\n    |      +>[Execution Logs]\n"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#4": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "at 5 PM,\" this module calls the OpenAI GPT model. It not only parses the Cron expression `0 17 * * 5` but also extracts the core task \"generate and se"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#5": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "Each task is executed by an independent AI Agent. Before execution, this Agent queries the **Graphiti knowledge graph** to retrieve relevant historica"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#6": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "pabilities.\n\n3.  **Task Scheduler (APScheduler)**\n    We chose APScheduler as the underlying execution engine. It provides stable and reliable distrib"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#7": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "We use SQLModel to define our data structures. It combines the advantages of Pydantic and SQLAlchemy, providing type-safe ORM operations that signific"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#8": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "system returns a structured task definition:\n\n**3. Create and schedule the task:**\n\nAfter user confirmation, the task is persisted to the database and"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#9": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "M last week,\" so it prioritizes checking Server B. After completing the health check, it generates a report and sends it via email. All execution deta"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en#10": {
    "title": "Unveiling Project Nighthawks: Building the Next-Generation AI-Powered Task Scheduler",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler-en",
    "date": "2024-01-01",
    "text": "flection on the future of automated work patterns. It demonstrates that by combining large language models, knowledge graphs, and traditional software"
  },
  "/content/posts/legacy/01-numpy-basics#0": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "NumPy 基础与实战入门\n\n上述代码中，我们分别从列表和元组创建了一维数组 a 和 b。NumPy 自动将元素转换为同一种类型（这里都是整数型 int64），并将它们存储为连续内存。a.dtype 表示数组的元素类型，b.shape 则是数组的形状。输出结果表明两个数组都是长度为5的一维数组，元素"
  },
  "/content/posts/legacy/01-numpy-basics#1": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "np.zeros_like(e) 则是基于现有数组形状创建全1或全0的新数组。\n- 等差数列：np.linspace(start, end, num) 用于在指定范围生成指定个数的等间隔点，常用于生成连续函数的自变量数组。上例中 h 从1到10生成4个值，而 x 和 y 示范了利用 np.arang"
  },
  "/content/posts/legacy/01-numpy-basics#2": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "用到每个元素上，充分利用底层的优化。\n\n例如，我们创建一个二维数组，然后对它进行加法和比较运算：\n\n可以看到，ary + 1 将数组中每个数都加上了1，得到的新数组仍是相同形状。同时，ary > 3 会对每个元素进行比较判断，返回一个同样形状的布尔数组，表示对应位置上元素是否大于3。这种逐元素的运算"
  },
  "/content/posts/legacy/01-numpy-basics#3": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "要属性，例如形状、维度、数据类型等等。了解和使用这些属性可以帮助我们更好地掌握数组的结构和特性。\n\n以下代码创建了一个 2x4 的数组，演示了 ndarray 的常见属性：\n\n我们创建了 arr 包含0到7的 8个元素，并reshape成2x4形状。输出中：\n\n- shape：数组的形状，用一个元组"
  },
  "/content/posts/legacy/01-numpy-basics#4": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "信息。例如，当检查数据读入是否正确，或调优存储和性能时，这些属性都非常有用。\n五、数组的索引和切片\nNumPy 数组的索引（indexing）和切片（slicing）操作与 Python 列表类似，但也有一些值得注意的区别和特性。\n1. 基本索引\n一维数组可以用与列表相同的语法通过索引访问元素，例如"
  },
  "/content/posts/legacy/01-numpy-basics#5": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "可以对每一维分别进行切片，例如 arr2d[0:2, 1:3] 可以同时在行和列两个维度上切片。\n\n需要注意，数组切片返回的是原数组的视图（view），并不拷贝数据。也就是说，修改切片结果会影响到原数组对应的部分。这一点与 Python 列表的切片不同（列表切片会生成新的列表）。如果需要获得一份独立"
  },
  "/content/posts/legacy/01-numpy-basics#6": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "的子数组进行操作但不影响原数据，可以在切片时加上 .copy() 来生成副本。\n六、数据类型与转换\nNumPy 支持多种数据类型（dtype），不仅有常见的数值类型（int、float），还有布尔型、字符串，甚至日期时间和复合类型。灵活地运用数据类型有时能提高效率或方便地处理特殊数据。下面我们分几类"
  },
  "/content/posts/legacy/01-numpy-basics#7": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "lse 为0。布尔数组经常用于作为掩码筛选数据。布尔型的存储比较节省，每个元素通常占用1个字节。\n\nNumPy 的字符串类型（通常显示为 <U<n>）表示定长的 Unicode 字符串，其中 <U 表示Unicode字符串，n表示字符长度上限。NumPy 会根据数组中最长的字符串长度来确定 n 的大"
  },
  "/content/posts/legacy/01-numpy-basics#8": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "umPy’ 长度5，‘数据分析’ 长度4（两个汉字长度为2，每个汉字算一个字符），‘Python3.9’ 长度8。但是 NumPy 为整个数组统一分配了长度6（能够容纳最长的8字符吗？这里汉字两个可能占2字符位置，各实现不同，但dtype给出<U6可能基于最长unicode code points数"
  },
  "/content/posts/legacy/01-numpy-basics#9": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "来方便地进行时间相关的数据运算。例如，我们可以把字符串表示的日期转换为 datetime64：\n\n上例中，我们定义了三个日期字符串：'2023'（只有年份）、'2024-01-01'（年月日）、'2025-03-07 15:30:21'（完整日期时间）。转换为 datetime64[s] 后，Num"
  },
  "/content/posts/legacy/01-numpy-basics#10": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "化dtype理解为“元素为元组的数组”，每个元素包含多个不同类型的值，类似于数据库或表格的一行。\n\n我们可以通过 dtype 参数来定义结构化类型。比如，定义一个 dtype 包含姓名(name)、三个科目成绩(scores)和年龄(age)三个字段：\n\n在这个例子中，我们构建了一个列表，每个元素是"
  },
  "/content/posts/legacy/01-numpy-basics#11": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "的姓名字段组成新的数组，arr['age'] 则是所有年龄的数组。因此我们可以对年龄字段直接调用 .mean() 来计算平均年龄。结构化数组让我们可以在NumPy中方便地处理表格化的数据，但需要注意它的元素是复合类型，某些NumPy通用函数并不直接支持逐字段操作，在使用时要仔细选择和处理。\n七、读取"
  },
  "/content/posts/legacy/01-numpy-basics#12": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "期保持字符串，价格用 float 转换，成交量用 int 转换。将所有元组收集到列表后，通过 np.array(..., dtype=自定义dtype) 一次性转换为结构化的 NumPy 数组。这里我们定义了 dtype 包含6个字段，对应日期（10位以内字符串），开盘、最高、最低、收盘价（32位浮"
  },
  "/content/posts/legacy/01-numpy-basics#13": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "从而减少手动解析的代码。不过，上述例子有助于理解数据读入和dtype指定的过程。\n八、数组形状变换\n多维数组的形状（shape）可以通过多种方式改变，例如改变维度的排列组合，或增加/减少维度。NumPy 提供的操作主要有 reshape、flatten/ravel 以及 resize 等。需要注意的"
  },
  "/content/posts/legacy/01-numpy-basics#14": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "原数组 a，第一个元素也变为了 99。说明 a 和 b 实际上共享底层的数据内存，只是视图不同。\n\n需要注意，如果 a 在内存中不是连续存储（比如对非连续切片调用reshape），那么可能会触发复制行为或报错。但对于像上例这样由连续数组得到的新形状，reshape 是高效且安全的。\n2. flatt"
  },
  "/content/posts/legacy/01-numpy-basics#15": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "(-1) 达到展平效果，这种方式等价于 ravel。\n3. resize：就地变维\nndarray.resize(new_shape) 方法会直接在原数组上改变其形状。与 reshape 不同，resize 是就地操作，会修改原数组本身。如果新尺寸比原来的总元素数少，后面的元素会被截断；如果新尺寸更"
  },
  "/content/posts/legacy/01-numpy-basics#16": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "视图，或者 np.copy 后再 reshape，以免无意中修改原始数据。\n九、布尔索引与位置索引\n在前面第三节我们已经看过布尔数组的用法，现在来详细介绍布尔索引和位置索引。这两者都是 NumPy 中强大的索引机制，可用于从数组中筛选出我们需要的元素或重排数组顺序。\n1. 布尔索引（Boolean "
  },
  "/content/posts/legacy/01-numpy-basics#17": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "须和 ary 相同，其中 True 的位置有0,2,5,7（对应元素1,3,6,8）被筛选出来。\n\n布尔索引常用的一个场景是直接对数组施加条件筛选，如上例所示。而对于更复杂的条件，可以结合位运算符逐步构造。例如筛选同时是3和7的倍数的元素，可以这样：\n\n这里 & 表示逐位与运算，相当于逻辑上的“且”"
  },
  "/content/posts/legacy/01-numpy-basics#18": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "3, 1, 2]。通过这种方法可以实现对数组的任意重排。\n\n位置索引也支持重复取相同位置。例如：\n\n结果 [1, 1, 2, 2] 中，原数组第0元素1和第1元素2各被取了两次。可见，索引得到的新数组和原数组的元素个数无关，而取决于索引列表的长度。\n3. 利用布尔索引修改值\n布尔索引不但可以用于筛选"
  },
  "/content/posts/legacy/01-numpy-basics#19": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "务必要确定这样做是安全且符合预期的。如果只想得到一个标记矩阵而不修改原数据，可以先用 scores.copy() 复制一份再操作，或者直接使用 astype 生成，如 (scores >= 60).astype(int)，这会返回一个新的0/1数组，不影响原来的 scores。\n十、数组的组合与拆分"
  },
  "/content/posts/legacy/01-numpy-basics#20": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "ate((a,b), axis=1)。\n- 深度组合：使用 np.dstack((a, b, ...)) 可以在第三维度上堆叠数组，要求待组合数组形状相同。结果数组维度会加一（例如两个2x2矩阵深度组合得到 shape=(2,2,2) 的三维数组）。\n- 不规则组合：如果组合的数组在目标轴长度不同，"
  },
  "/content/posts/legacy/01-numpy-basics#21": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "d 本身，可以看到它其实相当于把 a 和 b 当作两层“叠”在一起。\n2. 数组的拆分 (分割)\n与组合相反，NumPy 提供了对应的拆分函数：\n\n- 垂直拆分：np.vsplit(array, sections) 将数组在行方向拆分为若干部分。通常 sections 是一个可以整除行数的整数，表示"
  },
  "/content/posts/legacy/01-numpy-basics#22": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "x2 的小数组，以及将其垂直拆分为两块：\n\n我们创建了 c 为 2x6 矩阵，内容是1到12。np.hsplit(c, 3) 将其按列切成3份，每份2列，结果是包含三个 2x2 数组的列表（可以看到输出被分成了三部分）。np.vsplit(c, 2) 则将矩阵按行一分为二，得到两个 1x6 的行向量"
  },
  "/content/posts/legacy/01-numpy-basics#23": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "高维数组的 .transpose() 方法也可以按指定轴顺序转置。\n- 平展迭代 (.flat)：.flat 属性提供了一个迭代器，可以用来逐元素遍历数组（依次按行展开）。\n- 转列表 (.tolist())：将数组转换为嵌套的 Python 列表，常用于将结果数据传递给不支持 ndarray 的接"
  },
  "/content/posts/legacy/01-numpy-basics#24": {
    "title": "NumPy 基础与实战入门",
    "url": "/content/posts/legacy/01-numpy-basics",
    "date": "2024-01-30",
    "text": "ray 的操作更加便捷。例如，如果需要把 NumPy 数组传给纯 Python 代码处理，可以用 .tolist() 转换。如果需要逐元素地处理数组（尽管一般应避免 Python 层面的循环），.flat 提供了方便的遍历手段。而对复数数组进行运算时，.real 和 .imag 则可以轻松地分离出实"
  },
  "/content/posts/legacy/cassandra索引重建实践#0": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "Cassandra 索引重建实践\n\n值得注意的是，Cassandra 二级索引并不适合所有查询场景。如果滥用，可能导致写入性能下降（因为每次写入还需更新索引表），查询延迟增大，甚至给集群增加负担。在 Cassandra 3.x 中，引入了 SAI（Storage-Attached Indexing）"
  },
  "/content/posts/legacy/cassandra索引重建实践#1": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "实际存在的数据，或者已经删除的数据仍通过索引查询出现。这种索引数据不一致的情况需要重建索引来修复。\n*  性能下降：长时间运行后，索引表可能积累大量过期或无效条目（例如对应已删除或过期的数据），从而充斥大量墓碑（tombstone）记录，影响查询性能。如果索引列上的数据分布发生显著变化（例如大量插入"
  },
  "/content/posts/legacy/cassandra索引重建实践#2": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "情况下重建索引，但在某些版本中可能不稳定。所以，删除后重新创建 often 是更直接可靠的做法。\n\n总之，当出现索引无法正常服务（查询结果不正确或超时）或者索引本身导致写入/读取性能显著下降时，手动重建索引是一种有效的修复手段。\n\n索引重建的实践步骤\n\n下面以实际案例为背景，介绍 Cassandra"
  },
  "/content/posts/legacy/cassandra索引重建实践#3": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "ata/<keyspace>/<table> `下，其中二级索引数据会存储在类似 `<table>.<index_name>` 的子目录中。通过如下一条命令可以查看索引相关目录大小：\n\n如果发现索引数据文件异常庞大（例如数十GB），或与预期不符，说明索引可能累积了大量历史数据。这进一步佐证了需要重建"
  },
  "/content/posts/legacy/cassandra索引重建实践#4": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "n Driver 脚本连接。这里以 cqlsh 为例：\n\n连接后，切换到目标 Keyspace：\n\n备份表模式（可选）\n\n在删除索引前，建议使用 DESCRIBE TABLE table_xxx; 保存表的 schema 定义。这有助于了解表结构和索引信息，防止误操作。如果需要，也可以备份当前索引的"
  },
  "/content/posts/legacy/cassandra索引重建实践#5": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "直到重建完成。\n\n监控重建进度\n\n索引创建语句提交后，需等待索引重建完成。可以通过以下方式监控：\n\n*  日志观察：检查各节点的 Cassandra 日志（system.log），搜索关于索引重建的消息。例如 Cassandra 会记录索引建立完成的时间点。我们的实践中，从开始到索引构建完毕耗时约数"
  },
  "/content/posts/legacy/cassandra索引重建实践#6": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "能恢复正常。对于数值类型的字段查询时无需加引号，这里要根据字段类型调整查询语句。\n\n恢复应用服务\n\n确认索引功能恢复后，重新启动先前暂停的应用服务。例如：\n\n让应用重新与 Cassandra 建立连接，并验证业务查询正常。此时索引重建流程全部完成。\n\n经过上述步骤，我们成功修复并重建了 Cassan"
  },
  "/content/posts/legacy/cassandra索引重建实践#7": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "sandra 集群（支持指定节点地址列表）。\n*  删除指定索引（若存在）。\n*  创建指定索引。\n*  （可选）使用给定的测试值查询索引列，验证索引是否有效。\n\n在使用该脚本之前，请确保已通过 pip install cassandra-driver 安装 Cassandra Python 驱动，"
  },
  "/content/posts/legacy/cassandra索引重建实践#8": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "台异步进行，因此脚本返回后索引可能还在构建中；如果数据量大，可能需要等待一段时间才能查询出结果。\n\n在验证环节中，若提供了 --test-value 参数，脚本会使用该值对索引列执行一次查询（等价于 SELECT ... WHERE column = 'value' LIMIT 1），并输出是否查找"
  },
  "/content/posts/legacy/cassandra索引重建实践#9": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "行脚本：\n\n运行后，脚本会依次输出连接信息、索引删除/创建进度以及验证结果。例如，预期输出如下：\n\n从输出可以看到索引已成功重建，并且能够通过索引查询到测试值。此时，我们还需要留意实际集群中索引重建的完成情况。如果数据量很大，脚本可能在索引完全建好之前就返回了“查询成功”（因为刚好测试值所在的部分已"
  },
  "/content/posts/legacy/cassandra索引重建实践#10": {
    "title": "Cassandra 索引重建实践",
    "url": "/content/posts/legacy/cassandra索引重建实践",
    "date": "2022-04-01",
    "text": "需要注意的是，重建索引对集群有一定性能影响，应在业务低谷期进行，并做好应用停机或流量切换的准备。\n\n通过对 Cassandra 索引重建实践 的深入了解，我们可以更从容地应对分布式数据库运维中的索引挑战，保障数据库服务的稳定可靠运行。"
  },
  "/content/posts/legacy/astro-news-bot-技术实践#0": {
    "title": "Astro-News-Bot：构建 AI 驱动的自动化新闻聚合与发布系统",
    "url": "/content/posts/legacy/astro-news-bot-技术实践",
    "date": "2024-01-01",
    "text": "Astro-News-Bot：构建 AI 驱动的自动化新闻聚合与发布系统\n\n在架构设计之初，我遵循了几个核心原则：\n\n1. **模块化**：每个功能（抓取、去重、AI 处理、发布）都是独立模块，易于维护和替换\n2. **自动化**：整个流程无需人工干预，实现\"一次设置，永远运行\"\n3. **幂等性*"
  },
  "/content/posts/legacy/astro-news-bot-技术实践#1": {
    "title": "Astro-News-Bot：构建 AI 驱动的自动化新闻聚合与发布系统",
    "url": "/content/posts/legacy/astro-news-bot-技术实践",
    "date": "2024-01-01",
    "text": "** → 推送到博客仓库 → 触发自动部署\n\n核心技术实现\n\n1. 向量去重：告别简单的标题匹配\n\n项目初期，我使用文章标题或 URL 进行去重，但很快发现问题：\n- 不同新闻源对同一事件的报道标题不同\n- URL 可能因包含追踪参数而不同\n\n解决方案是**基于语义的向量去重**：\n\n这种方法能有效"
  },
  "/content/posts/legacy/astro-news-bot-技术实践#2": {
    "title": "Astro-News-Bot：构建 AI 驱动的自动化新闻聚合与发布系统",
    "url": "/content/posts/legacy/astro-news-bot-技术实践",
    "date": "2024-01-01",
    "text": "以清晰看到变更记录\n- **解耦和安全**：机器人只需要 Git 仓库写权限，无需暴露博客后台凭证\n- **利用现有 CI/CD**：复用 Vercel/Netlify 等平台的 Git-Triggered CI/CD\n\nAstro 博客配套修改\n\n要让 `astro-news-bot` 与 Ast"
  },
  "/content/posts/legacy/astro-news-bot-技术实践#3": {
    "title": "Astro-News-Bot：构建 AI 驱动的自动化新闻聚合与发布系统",
    "url": "/content/posts/legacy/astro-news-bot-技术实践",
    "date": "2024-01-01",
    "text": "部署环境，我设计了多种执行方式：\n\n1. 直接运行（开发调试）\n\n2. Shell 脚本执行\n\n3. 守护进程模式（推荐）\n\n4. Cron 定时任务\n\n运维经验与最佳实践\n\n配置文件管理\n\n成本控制\n\n- 每日处理约 6 篇文章\n- 预计 Token 消耗：~4000 tokens/天\n- Ope"
  },
  "/content/posts/legacy/astro-news-bot-技术实践#4": {
    "title": "Astro-News-Bot：构建 AI 驱动的自动化新闻聚合与发布系统",
    "url": "/content/posts/legacy/astro-news-bot-技术实践",
    "date": "2024-01-01",
    "text": "📱 移动技术  \n- 🚗 自动驾驶\n- ☁️ 云计算\n- 💾 芯片技术\n- 💰 创业投资\n- 🔒 网络安全\n- ⛓️ 区块链\n- 🔬 科学研究\n\n输出格式示例\n\n未来规划\n\n1. **更智能的信源发现**：让机器人自动发现和推荐新的高质量新闻源\n2. **趋势分析与主题聚合**：识别特定"
  },
  "/content/posts/legacy/astro-news-bot-技术实践#5": {
    "title": "Astro-News-Bot：构建 AI 驱动的自动化新闻聚合与发布系统",
    "url": "/content/posts/legacy/astro-news-bot-技术实践",
    "date": "2024-01-01",
    "text": "**后端**：Python + OpenAI API + SentenceTransformers\n- **前端**：Astro + TypeScript + Content Collections\n- **部署**：GitOps + Shell Scripts + Cron Jobs\n- **数据"
  },
  "/content/posts/legacy/mcp-server-development-reflection#0": {
    "title": "从混乱到清晰：一次MCP服务器开发的反思与总结",
    "url": "/content/posts/legacy/mcp-server-development-reflection",
    "date": "2024-01-01",
    "text": "从混乱到清晰：一次MCP服务器开发的反思与总结\n\n选择了Python和FastMCP框架来实现MCP服务器。FastMCP的优势在于：\n- 极简的API设计\n- 通过装饰器即可将普通函数转换为MCP工具\n- 内置的stdio通信支持\n\n2. 核心功能实现\n\n最终实现了一个整合的`publish_bl"
  },
  "/content/posts/legacy/mcp-server-development-reflection#1": {
    "title": "从混乱到清晰：一次MCP服务器开发的反思与总结",
    "url": "/content/posts/legacy/mcp-server-development-reflection",
    "date": "2024-01-01",
    "text": "目本质，强调Python脚本的简洁性，用不到100行代码就实现了完整功能。\n\n问题2：测试的困境\n\n尝试测试MCP工具时遇到了FastMCP装饰器导致的调用问题：\n\n**原因**：`@app.tool()`装饰器将函数包装成了`FunctionTool`对象，不能直接调用。\n\n**解决**：在MCP"
  },
  "/content/posts/legacy/mcp-server-development-reflection#2": {
    "title": "从混乱到清晰：一次MCP服务器开发的反思与总结",
    "url": "/content/posts/legacy/mcp-server-development-reflection",
    "date": "2024-01-01",
    "text": "个函数调用\n   - 实现了真正的\"一键发布\"\n\n五、技术细节与最佳实践\n\n1. 环境配置的灵活性\n\n2. 命令执行的封装\n\n3. 时间格式的规范化\n从简单的日期格式演进到包含时分秒：\n\n六、经验教训\n\n1. **清晰沟通的重要性**：技术实现再好，如果不能清晰地传达价值，就是失败的。\n\n2. **"
  },
  "/content/posts/legacy/mcp-server-development-reflection#3": {
    "title": "从混乱到清晰：一次MCP服务器开发的反思与总结",
    "url": "/content/posts/legacy/mcp-server-development-reflection",
    "date": "2024-01-01",
    "text": "身就是一次宝贵的学习经历。它提醒我们：好的技术方案不仅要功能强大，更要简洁明了、易于理解和使用。\n\n正如这个项目的标题所示，从混乱到清晰，不仅是代码的演进，更是认知的提升。"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh#0": {
    "title": "Nighthawk项目完整解析：一个自我进化Agent OS的宏大愿景与技术核心",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh",
    "date": "2024-01-01",
    "text": "Nighthawk项目完整解析：一个自我进化Agent OS的宏大愿景与技术核心\n\n技术核心：自我完善的四大基石\n\n为了将这一宏大愿景付诸实践，我们设计了四大核心子系统，它们共同构成了Agent自我完善能力的技术基石。这些机制源自我们详尽的《nighthawk多Agent自我完善功能技术实施方案》，"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh#1": {
    "title": "Nighthawk项目完整解析：一个自我进化Agent OS的宏大愿景与技术核心",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh",
    "date": "2024-01-01",
    "text": "nt总结当前Prompt的具体缺陷，例如：“提示中未明确要求分步输出，导致结果缺少推理过程。”\n4.  **生成候选方案**：Agent请求LLM根据问题生成一个或多个改进后的Prompt版本。\n5.  **评估与选择**：Agent通过内部评估（如模拟执行或规则判断）选出最佳的新Prompt。\n6"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh#2": {
    "title": "Nighthawk项目完整解析：一个自我进化Agent OS的宏大愿景与技术核心",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh",
    "date": "2024-01-01",
    "text": "身执行频率和触发条件的能力，在避免资源浪费和任务延迟之间找到最佳平衡点。\n\n**实施步骤**：\n1.  **数据监控**：Agent持续收集调度相关数据，如任务队列长度、空闲时间、资源占用率等。\n2.  **问题诊断**：基于监控数据，Agent判断当前调度策略是否最优。例如，长时间空转意味着频率过"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh#3": {
    "title": "Nighthawk项目完整解析：一个自我进化Agent OS的宏大愿景与技术核心",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh",
    "date": "2024-01-01",
    "text": "界**：为Agent的调度频率设定一个安全的上下限，防止其“停摆”或进行“DDoS式”的自我调用。\n- **关键任务保障**：对于承载关键任务的Agent，限制其自动降低频率的能力，确保核心流程不受影响。\n- **协同谦让**：在多Agent协作中，一个Agent的调度调整需考虑对依赖方的影响，必要"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh#4": {
    "title": "Nighthawk项目完整解析：一个自我进化Agent OS的宏大愿景与技术核心",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh",
    "date": "2024-01-01",
    "text": "**格式化与存储**：将信息整理为结构化条目（如知识图谱中的节点和边），并写入相应的存储介质。\n4.  **更新索引**：写入长期记忆后，更新向量索引或知识图谱关联，确保未来能够被高效检索。\n5.  **记忆应用**：在后续任务开始时，Agent主动检索记忆库，将相关知识融入新的任务上下文，从而指导"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh#5": {
    "title": "Nighthawk项目完整解析：一个自我进化Agent OS的宏大愿景与技术核心",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh",
    "date": "2024-01-01",
    "text": "意味着Agent能够从根本上修复缺陷、提升性能，实现真正的“自我进化”。\n\n**实施步骤**：\n1.  **问题定位**：通过深度反思，Agent将问题的根源定位到自身代码的具体位置（如逻辑漏洞、算法低效）。\n2.  **生成补丁提案**：Agent调用编码能力（通常由一个专门的编程LLM辅助），以"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh#6": {
    "title": "Nighthawk项目完整解析：一个自我进化Agent OS的宏大愿景与技术核心",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture-zh",
    "date": "2024-01-01",
    "text": "。一旦发现由补丁引发的严重异常，立即触发紧急回滚机制，恢复到上一个稳定版本。\n\n**安全策略**：\n- **最高权限限制**：仅Level 3权限的Agent可提议代码修改，且**必须**经过独立审核。\n- **强制审核与授权**：任何代码补丁的应用都必须有明确的、可追溯的审批记录。\n- **完备的"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality#0": {
    "title": "超越死亡的AI：Nighthawks v2.0如何用知识图谱实现数字生命的永恒传承",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality",
    "date": "2024-01-01",
    "text": "超越死亡的AI：Nighthawks v2.0如何用知识图谱实现数字生命的永恒传承\n\n**v1.0的局限性**：\n- 传统的任务调度机制\n- Agent之间缺乏深度交互\n- 知识无法有效传承\n- 缺乏真正的\"生命周期\"概念\n\n**v2.0的革命性转变**：\n- 完整的数字生命周期：诞生 → 成长 →"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality#1": {
    "title": "超越死亡的AI：Nighthawks v2.0如何用知识图谱实现数字生命的永恒传承",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality",
    "date": "2024-01-01",
    "text": "传统数据库更智能、更灵活的知识存储和检索系统**。这就是Graphiti知识图谱发挥作用的地方。\n\n🧠 Graphiti集成：构建AI的\"永生记忆\"\n\n架构设计：三层记忆体系\n\n核心组件实现\n\n1. GraphitiCollectiveMemory：增强集体记忆系统\n\n这是整个系统的核心，继承自原"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality#2": {
    "title": "超越死亡的AI：Nighthawks v2.0如何用知识图谱实现数字生命的永恒传承",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality",
    "date": "2024-01-01",
    "text": "**智能继承的三个维度**：\n1. **上下文匹配**：根据诞生上下文选择最相关的知识聚类\n2. **关系深度**：追溯血缘关系，继承家族智慧\n3. **集体智慧**：融合系统级的最佳实践和成功模式\n\n生态系统级别的集成\n\n优雅的系统升级机制\n\n我们设计了一个向后兼容的升级机制，让现有系统可以无缝享"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality#3": {
    "title": "超越死亡的AI：Nighthawks v2.0如何用知识图谱实现数字生命的永恒传承",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality",
    "date": "2024-01-01",
    "text": "：新Agent不需要从零开始，可以继承前辈的智慧\n- **知识有血缘**：追踪知识的来源和演化路径\n- **智慧会进化**：集体记忆随着时间推移而不断优化\n\n2. 知识图谱在AI记忆中的突破性应用\n\n虽然知识图谱技术已经相对成熟，但将其应用于AI Agent的记忆管理是一个全新的领域：\n\n**传统知"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality#4": {
    "title": "超越死亡的AI：Nighthawks v2.0如何用知识图谱实现数字生命的永恒传承",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality",
    "date": "2024-01-01",
    "text": "门的连接器：\n\n**设计亮点**：\n- **渐进式增强**：有MCP服务时使用图谱，没有时本地缓存\n- **错误容忍**：网络问题不会导致功能失效\n- **统计监控**：详细的连接状态和性能指标\n\nAgent生命周期的图谱化建模\n\n我们将Agent的完整生命历程映射为图谱结构：\n\n这种建模方式让我们"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality#5": {
    "title": "超越死亡的AI：Nighthawks v2.0如何用知识图谱实现数字生命的永恒传承",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality",
    "date": "2024-01-01",
    "text": "- ✅ 15+ 个测试用例全部通过\n- ✅ 端到端工作流程验证成功\n- ✅ 错误处理和回退机制正常\n- ✅ 性能指标达到预期\n\n实际运行效果\n\n通过功能演示脚本，我们验证了系统的实际表现：\n\n🔮 未来发展方向\n\n短期优化 (1-2周)\n- **兼容性完善**：修复个别属性兼容性问题\n- **MCP"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality#6": {
    "title": "超越死亡的AI：Nighthawks v2.0如何用知识图谱实现数字生命的永恒传承",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality",
    "date": "2024-01-01",
    "text": "个项目中，我们不仅实现了技术创新，更重要的是探索了AI系统设计的哲学问题：\n\n从功能主义到生命主义\n传统AI设计遵循**功能主义**范式：定义输入输出，优化处理效率。而Nighthawks v2.0采用**生命主义**范式：模拟生命过程，追求系统的自我演进和永续发展。\n\n从个体智能到集体智慧\n单个A"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality#7": {
    "title": "超越死亡的AI：Nighthawks v2.0如何用知识图谱实现数字生命的永恒传承",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality",
    "date": "2024-01-01",
    "text": "突破**：设计了可持续演进的AI生态系统\n- **哲学探索**：重新定义了AI系统的本质和可能性\n\n**对未来的意义**：\n- 为通用人工智能(AGI)的发展提供了新的思路\n- 为AI系统的长期学习和记忆提供了技术基础\n- 为构建真正\"活着\"的AI生态系统奠定了基石\n\n在人工智能快速发展的今天，我们"
  },
  "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality#8": {
    "title": "超越死亡的AI：Nighthawks v2.0如何用知识图谱实现数字生命的永恒传承",
    "url": "/content/posts/legacy/nighthawks-v2-graphiti-digital-immortality",
    "date": "2024-01-01",
    "text": "结\n- **演示视频**: 功能演示录屏\n\n📝 作者信息\n\n本文记录了Nighthawks v2.0数字生命系统Graphiti知识图谱集成的完整技术实现过程。项目体现了对AI系统设计的深度思考和创新实践，希望能为AI技术的发展贡献微薄之力。\n\n*🤖 Generated with Claude "
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#0": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "项目管理基础知识学习笔记L2\n\n1. 制定进度管理计划： 首先要拟定一个进度管理计划，用来记录我们将如何制定、管理、执行和控制项目的进度表 。简单说，就是先想好“我要怎么规划进度”。\n2. 定义具体活动任务： 接下来，从项目的工作分解结构（WBS）的最底层——也就是那些具体的可交付成果——继续分解，"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#1": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "旅行时，要考虑每段路程需要的交通工具和时间。只有估算了资源和工期，我们才能心中有数地安排进度。\n5. 制定项目进度表： 有了任务顺序和工期估算，就可以选择合适的方法（如关键路径法等）来制定详细的进度表 。这就像把拼图的所有碎片按顺序拼起来，最终得出每项任务的最早开始、最晚完成时间，以及整个项目的里程"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#2": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "拖拖拉拉就会误场。有了科学的进度表并严格跟踪，我对按时交付项目成果就更有信心了。\n\n管理项目范围\n\n项目范围管理这一章节让我明白，项目做什么和不做什么同等重要 。以前我以为范围就是要做的任务清单，但现在认识到划定边界、防止项目内容失控更关键。范围管理的目的是确保项目涵盖完成目标所需的所有工作，既不遗"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#3": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "清楚列明包含哪些内容，同样也列明不包含哪些内容。这个文件可以让团队和客户对项目的边界有共同的认知。\n- 创建工作分解结构（WBS）： 确定范围后，项目团队要交付相应的可交付成果。但直接管理庞大的成果清单是很困难的，因此需要将大型可交付成果逐层分解成更小的、可管理的部分 。这就是建立WBS的过程。我发"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#4": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "理变更请求来防止范围蔓延 。也就是说，有新需求进来要慎重评估、审批，不能随意就把额外工作加进项目。\n- 验收范围： 当项目的工作都完成后，还需要进行范围验证 。这一点让我印象很深——不能自己觉得做好了就算完事儿，而是要请客户或项目发起人验收那些已经完成的可交付成果 。换句话说，要由相关方正式确认这些"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#5": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "不超预算地完成 。我的心得是，做项目就像过日子，要精打细算，花钱有计划、有监督，才能不入不敷出。\n\n根据课程所述，处理项目成本和预算包含以下要点：\n\n- 制定成本管理计划： 先要确定我们将如何在项目中处理成本问题 。这有点像列家庭财务计划：先定下规则，比如哪些开支需要审批、超出多少要预警等等。项目中"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#6": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "推进、了解加深，我们会不断调整这些数字，使估算越来越精确，误差范围逐步缩小到±10%甚至±5% 。\n- 确定预算： 在很多项目中，成本估算会演变成最终的项目预算。但也有许多项目是一开始就给定了硬性预算上限，不允许超支 。这种情况下，我学到应该“量入为出”，让项目的范围、资源投入和进度安排在可行的范围"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#7": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "了，要赶紧减少不必要的消费一样。通过及时监督和调整，成本管理能够帮助项目始终在预算范围内完成 。\n\n学完这一章节，我对“钱要花在刀刃上”这句话有了更深理解。以前做项目总担心钱不够用，现在明白了科学的成本管理其实给予我们很多控制权——我们可以通过调整范围和资源来平衡收支。对我来说，最大的收获是懂得了用"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#8": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "擅自提高标准做无用功。\n\n课程中将质量管理分为三个主要部分，让我对如何“管质量”有了全面的认识：\n\n- 质量规划： 首先要在规划阶段确定项目和可交付成果需要达到哪些质量标准 。这些标准可以是产品的技术规范、允许的缺陷率，或者尺寸公差范围等等 。例如，如果在开发一个手机APP，质量标准可以包括响应时间"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#9": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "质量合格。我意识到，这一步就像给项目设定“及格线”和验收的方法，为后续的质量保证和控制指明了方向。\n- 质量保证（QA）： 有了标准和计划，接下来就是在执行过程中实施质量保证工作，以确保项目过程符合之前制定的质量标准 。课程提到，质量保证的活动可以包括预先检查、审核，或者制作原型等 。这些措施相当于"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#10": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "深刻——原来不仅要看产品质量，还要审视我们的工作流程是否高效、可靠，这样才能从根本上提升质量水平。\n- 质量控制（QC）： 最后是质量控制，也就是对项目可交付成果进行测试检验，并记录测试结果 。这一部分更侧重结果的检测。当产品开发出来后，要按照之前定义的标准一项项测试，看是否符合要求，把发现的缺陷或"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#11": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "准。只有这样，才能既让客户满意，又不至于因质量失控而牺牲项目的其他目标。\n\n如何管理项目人力资源\n\n学到项目人力资源管理时，我不禁联想起以前做过团队成员的经历。这一节让我意识到：项目的成败离不开人，作为项目经理既要懂得选人用人，还要学会带人 。哪怕团队成员在公司里各有直属部门经理，项目进行中我也需要"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#12": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "、设计等角色，各自需要什么技能水平。基于这些，我会制定一份项目的人员配备计划，心里有个用人的盘子。\n- 获取团队成员： 确定了需要什么样的人，下一步就是找到合适的人来填这些角色 。团队成员可以来自公司内部，也可能需要从外部招聘或外包 。这一环节有点像组建一支球队：得选对队员、招兵买马。现实中，有时人"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#13": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "能通过团队培训、团建活动或者定期会议来实现。目标是打造良好的团队氛围，让每个人都朝着共同目标努力。\n- 管理团队与人员绩效： 在项目运作过程中，我的角色更像教练，要管理团队日常运作，关注每个人的表现 。具体来说，我需要跟踪团队成员的工作进度和绩效，及时给予反馈和指导，帮助他们改进 。如果有人遇到困难"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#14": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "分知识让我以后在项目中会更加注重团队建设和人员关怀，不再只是埋头盯进度表了。\n\n如何管理项目沟通\n\n俗话说“不打无准备之仗”，但我觉得再充分的准备，如果沟通不到位，项目也很难成功。课程中特别指出，沟通是项目成功的关键，项目经理有大量的时间都在与他人交流项目情况 。通过学习项目沟通管理，我意识到自己今"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#15": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "知项目发起人等等。把这些约定俗成的沟通事项写在计划里，大家日后就有据可依，不会漏掉重要的信息分享。\n- 管理沟通过程： 当项目进入执行阶段，我需要按照沟通计划实施沟通 。具体而言，就是创建项目相关的信息（如撰写报告、制作报表）、分发信息（例如发送邮件、召开会议）、检索信息（保存和查找项目资料）并妥善"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#16": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "时调整沟通方式。我觉得这就像维修工定期检查电路是否畅通一样，确保信息这条“线”在项目中不出故障。\n\n项目沟通管理这一节，让我真正意识到自己的角色有点像一个“通信枢纽”。对我来说最有收获的是：沟通并非想到才做的事，而是需要提前规划并持续管理。好的沟通能让团队上下同心、利益相关者放心支持；反之，消息不透"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#17": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "件做，就得学会跟外面的供应商打交道，这就是采购管理的范畴。\n\n课程将采购管理分成了几个主要步骤：\n\n- 规划采购： 首先，要搞清楚项目哪些东西需要从公司外部获得 。可能是产品、服务，或者专业人员等。我要明确列出外部采购清单，并确定潜在的供应商或卖方有哪些 。同时，在采购计划里记录好将采用的采购流程和"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#18": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "，只不过对象变成了供应商。签合同是个关键节点，我明白了合同既是法律保障也是合作指南，必须谨慎对待。\n- 管理合同履行： 项目执行过程中，如果有外包或采购部分，我还需要持续管理这些合同 。这意味着监督供应商的绩效，确保他们按照合同要求提供产品或服务 。如果过程中发生任何变化（比如供货延期、需求修改），"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#19": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "件等收尾工作。课程提醒我们，这一步很容易被忽视，但却很重要——善始还要善终，给采购划上圆满的句号。\n- 整体把控采购内容： 课程的最后一句话点出了采购管理的意义：如果项目需要公司内部无法提供的产品或服务，采购管理能帮助我们掌控所采购的内容 。这句话对我启发很大。想象一下，我在家装修房子，电力改造自己"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#20": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "也多了几分谨慎。毕竟，项目的短板可能就出在外购的那一环，一定不能掉以轻心。\n\n如何管理利益相关者\n\n关于利益相关者管理，我此前有所耳闻，但并未真正理解其中的门道。这一课让我豁然开朗：项目的成功往往取决于让相关的所有人都满意 。项目中涉及的人可不只是团队成员和客户，还包括了方方面面——上级领导、用户、"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#21": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "我明白应该如何一步步做好利益相关者管理。\n\n我的理解是，管理利益相关者主要包括以下几个步骤：\n\n1. 识别利益相关者： 第一个任务就是把项目的利益相关者都找出来 。这不仅仅是列出名字，我还要尽可能了解每位相关者背后的信息 。课程强调，光知道名字远远不够，为了建立并管理好关系，我需要了解他们对项目的期"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#22": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "中不断更新 。这一过程让我感觉像在绘制“人物关系网”，把每个人物的重要诉求和利害关系标注清楚。\n2. 制定参与策略： 识别完毕后，我的下一个任务是制定策略让利益相关者参与进来 。也就是说，我需要想办法与各个利益相关者建立良好关系，让他们对项目保持满意和支持 。在课程案例里，讲师提到要“让他们参与到项"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#23": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "我感受到这一环节很考验情商和沟通艺术，仿佛是在为每位利益相关者量身定做一套“沟通与互动方案”。\n3. 执行参与计划： 策略定好后，就要进入实战阶段——把利益相关者管理计划付诸行动 。在项目进行过程中，我会按照计划与利益相关者互动，目的就是赢得他们的支持，化解他们的反对 。现实中，这可能意味着：定期向"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#24": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "案 。这一步需要的技能很多：沟通、谈判、冲突管理、说服力……可以说是对项目经理综合能力的考验。\n4. 监控利益相关者关系： 最后一项任务是持续监测利益相关者的动态 。项目是动态发展的，人心也会变。某个之前支持项目的关键人物也许因为外部因素态度转变，或者新的利益相关者出现影响局面。我需要保持敏锐，定期"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#25": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "。毕竟，项目不是在真空中运行的，得到各方的支持和配合，才有最大的成功可能。\n\n什么是项目综合管理\n\n当我第一次听到“项目综合管理”这个概念时有点迷糊，不确定它具体指什么。通过课程的讲解，我逐渐明白，综合管理就是站在全局高度，把项目的方方面面整合起来。项目的各要素（范围、进度、成本、质量、风险等等）其"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#26": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "项目走向成功。\n\n项目综合管理涉及项目从开始到结束的各个阶段和活动，我把课程内容归纳为以下几点：\n\n- 项目章程（启动）： 在项目一开始，我就会遇到综合管理的第一个任务：制定项目章程 。项目章程是一个高层次文件，它概述了项目的目的和存在的理由，同时赋予项目经理正式的权限 。通常章程里会包括初步确定的"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#27": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "在编写章程的过程中，我要把目标、范围、资源、风险等各方面的初步信息整合进来，为项目奠定统一的方向。\n- 项目规划： 课程提到，“综合意味着把各个部分组成一个整体”，而项目规划正是项目综合管理的典范 。确实，制定项目管理计划需要把范围计划、进度计划、成本计划、质量计划、人力资源计划、沟通计划、风险计划"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#28": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "。我感受到，在规划阶段运用综合管理思想，可以提前发现各要素之间的冲突并做出调整，把矛盾消化在早期。\n- 执行与监控： 规划完成后，就进入项目的执行和监控阶段。这部分依然高度考验综合管理能力。指导和管理项目执行意味着我要确保整个团队按照综合计划投入工作，把计划变成现实 。而监督和控制项目工作则要求我持"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#29": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "拒绝，同意的要如何实施，直到变更落实完成都要跟踪管理 。通过严格的整体变更控制，才能让项目即使在变化中仍保持方向不偏、节奏不乱。\n- 收尾阶段： 最后，当项目的工作全部完成，就进入项目收尾这个综合管理的收官环节 。综合管理的最后一项任务就是正式结束项目 。这并不只是宣布“项目完了”那么简单，而是要确"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#30": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "。对项目来说，收尾做得好，可以为后续项目提供宝贵的经验和教训，也让客户对项目的结束有明确的交代。\n\n经过这一章的学习，我深刻体会到项目经理就是项目的大总管，得把面面俱到。综合管理强调的是全局观和整合力，这是对之前所有知识领域的一种统筹应用。对我来说最有价值的体会是：当发生变化时，不要头疼某一处出了问"
  },
  "/content/posts/legacy/项目管理基础知识学习笔记l2#31": {
    "title": "项目管理基础知识学习笔记L2",
    "url": "/content/posts/legacy/项目管理基础知识学习笔记l2",
    "date": "2025-06-10",
    "text": "局。虽然这对新人来说有难度，但我相信只要在实践中不断锻炼，这种“大局掌控”的能力一定会逐渐提升。\n\n以上就是我在《项目管理基础知识》第二课学习过程中对九大知识领域的理解和总结。这一课让我对项目管理有了一个全面的框架认识：从时间、范围、成本、质量，到人力、沟通、采购、干系人，再到最后的综合管理，每一环"
  },
  "/content/posts/legacy/probability-deep-dive-en#0": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "A Deeper Dive into Probability: From Convergence to Core Concepts\n\nAlmost Sure Convergence: The Strongest Form\n\n**Almost sure convergence** means that"
  },
  "/content/posts/legacy/probability-deep-dive-en#1": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "close to $X$ and eventually stay close forever.\n\nFor coin flipping, this is the **Strong Law of Large Numbers**: the sample proportion of heads almost"
  },
  "/content/posts/legacy/probability-deep-dive-en#2": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "d curves) illustrates almost sure convergence:**\n\nEach curve represents one complete experiment—repeatedly flipping a fair coin, where the x-axis show"
  },
  "/content/posts/legacy/probability-deep-dive-en#3": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "ns are enormous (some curves even reach 0 or 1)\n2. As $n$ increases, all paths gradually stabilize and *permanently* stay within the gray band\n3. They"
  },
  "/content/posts/legacy/probability-deep-dive-en#4": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "orever—but you'd essentially never observe them.\n\nConvergence in Probability: The Practical Standard\n\n**Convergence in probability** means that as $n "
  },
  "/content/posts/legacy/probability-deep-dive-en#5": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "rge $n$, occasional deviations are still possible. The **Weak Law of Large Numbers** proves that sample means converge in probability to their expecte"
  },
  "/content/posts/legacy/probability-deep-dive-en#6": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "n \\xrightarrow{p} 0$ (convergence in probability). However, since $\\sum_n 1/n$ diverges, there will almost surely be infinitely many moments where $X_"
  },
  "/content/posts/legacy/probability-deep-dive-en#7": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "ccasionally (with probability $1/n$) jumping to 1. The **red curve** shows how this probability $1/n$ decreases with $n$.\n\n- As $n$ increases, **the p"
  },
  "/content/posts/legacy/probability-deep-dive-en#8": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "vergence in probability**: $X_n\\xrightarrow{p}0$\n\n- However, observing individual paths reveals: **The spikes become sparser but never disappear**—no "
  },
  "/content/posts/legacy/probability-deep-dive-en#9": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "bution function of $X_n$ converges to that of $X$. Roughly speaking, the probability distributions gradually become similar in shape, but we don't car"
  },
  "/content/posts/legacy/probability-deep-dive-en#10": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "distribution to a standard normal distribution.\n\n**Key Relationship:** Almost sure convergence $\\implies$ convergence in probability $\\implies$ conver"
  },
  "/content/posts/legacy/probability-deep-dive-en#11": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "nce of variance**. Consider this counterexample:\n\nDefine $X_n$ as: with probability $1/n$, $X_n = \\sqrt{n}$; otherwise $X_n = 0$.\n\n- **Expectation:** "
  },
  "/content/posts/legacy/probability-deep-dive-en#12": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "\\operatorname{Var}(X_n) = 1 - \\frac{1}{n} \\to 1$\n\nThis $X_n$ converges to 0 in probability (since $\\Pr(X_n \\neq 0) = 1/n \\to 0$), yet its variance app"
  },
  "/content/posts/legacy/probability-deep-dive-en#13": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "careful analysis of what exactly is converging.\n\nPart 2: The Limit Theorems That Shape Our World\n\nThe Central Limit Theorem: Why Standardization Matte"
  },
  "/content/posts/legacy/probability-deep-dive-en#14": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "n suggests the sum will approach a \"bell curve.\"\n\nThis intuition is formalized by the **Central Limit Theorem (CLT)**: the sum (or average) of many in"
  },
  "/content/posts/legacy/probability-deep-dive-en#15": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "n—regardless of the original distribution shape.\n\n**Why Standardization?** Without standardization, the sum $S_n = X_1 + \\cdots + X_n$ would have mean"
  },
  "/content/posts/legacy/probability-deep-dive-en#16": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "= \\frac{\\overline{X}_n - \\mu}{\\sigma/\\sqrt{n}}$$\n\nThe CLT states that as $n \\to \\infty$, $Z_n$ converges in distribution to $N(0,1)$.\n\n**Practical Imp"
  },
  "/content/posts/legacy/probability-deep-dive-en#17": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "a normal distribution. Top left: 1 die (uniform). Top right: 2 dice (triangular). Bottom left: 3 dice (more concentrated). Bottom right: smooth curves"
  },
  "/content/posts/legacy/probability-deep-dive-en#18": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "h unknown distribution but $\\mu=0$, $\\sigma=2$ mm. For $n=36$ parts, the average error $\\overline{X}_{36}$ satisfies $\\sqrt{36}(\\overline{X}_{36}-0)/2"
  },
  "/content/posts/legacy/probability-deep-dive-en#19": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "ing some action (e.g., logging in on a given day). How many users will perform this action?\n\nWhen $n$ is large and $p$ is small while $np = \\lambda$ r"
  },
  "/content/posts/legacy/probability-deep-dive-en#20": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "t:** Let $X_n \\sim \\text{Binomial}(n, \\lambda/n)$. We have $\\mathbb{E}[X_n] = \\lambda$ and $\\operatorname{Var}(X_n) \\approx \\lambda$ (since $(1-p) \\ap"
  },
  "/content/posts/legacy/probability-deep-dive-en#21": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "{n!}{(n-k)!} = n(n-1)\\cdots(n-k+1) \\approx n^k$\n2. Thus $\\binom{n}{k} \\left(\\frac{\\lambda}{n}\\right)^k \\approx \\frac{\\lambda^k}{k!}$\n3. $\\left(1-\\frac"
  },
  "/content/posts/legacy/probability-deep-dive-en#22": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "approximation to the binomial is quite accurate.\n\nPart 3: A Practical Toolkit for Bounding Uncertainty\n\nWhen we know little about a random variable's "
  },
  "/content/posts/legacy/probability-deep-dive-en#23": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": ":\n$$\\Pr(X \\geq a) \\leq \\frac{\\mathbb{E}[X]}{a}$$\n\n**Pros:** Requires only knowledge of the mean. **Cons:** Often provides very loose bounds.\n\n**Exampl"
  },
  "/content/posts/legacy/probability-deep-dive-en#24": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "eq \\frac{\\operatorname{Var}(X)}{\\varepsilon^2}$$\n\n**Advantages:** Doesn't require non-negativity or boundedness, and typically gives tighter bounds th"
  },
  "/content/posts/legacy/probability-deep-dive-en#25": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "ariables $X_1, \\ldots, X_n$ with $X_i \\in [0,1]$:\n$$\\Pr( \\geq \\varepsilon) \\leq 2\\exp(-2n\\varepsilon^2)$$\n\nThis provides **exponential concentration**"
  },
  "/content/posts/legacy/probability-deep-dive-en#26": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "g $\\frac{0.25}{n(0.1)^2} < 0.05$ gives $n > 500$\n\nAs $n$ increases, Hoeffding's exponential advantage becomes dramatic: it provides $e^{-cn}$ decay ve"
  },
  "/content/posts/legacy/probability-deep-dive-en#27": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "ail control for any finite-variance distribution.\n- **Hoeffding:** When variables are bounded and independent. Gives exponential concentration bounds,"
  },
  "/content/posts/legacy/probability-deep-dive-en#28": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "You've been waiting at a bus stop for 30 minutes. Someone says, \"Don't worry, you've waited so long that the bus must come soon!\" Is this comfort math"
  },
  "/content/posts/legacy/probability-deep-dive-en#29": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "geq 0$:\n$$\\Pr(X > s+t \\mid X > s) = \\Pr(X > t)$$\n\nThe probability of waiting an additional $t$ time units, given you've already waited $s$ units, equa"
  },
  "/content/posts/legacy/probability-deep-dive-en#30": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "e^{-\\lambda t} = \\Pr(X > t)$$\n\n**Implications:**\n- In queueing systems with exponential service times, the system has no \"memory\" of how long you've w"
  },
  "/content/posts/legacy/probability-deep-dive-en#31": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "n $X \\sim N(\\mu, \\sigma^2)$, find $\\Pr(X \\leq a)$.\" Since normal distributions lack closed-form CDFs, we rely on standardization and tables.\n\n**The St"
  },
  "/content/posts/legacy/probability-deep-dive-en#32": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "nd $\\Phi(z) = \\Pr(Z \\leq z)$\n\n**Key Techniques:**\n- **For negative values:** Use symmetry: $\\Pr(Z \\leq -z) = \\Pr(Z \\geq z) = 1 - \\Pr(Z \\leq z)$\n- **Fo"
  },
  "/content/posts/legacy/probability-deep-dive-en#33": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "espectively\n\nPart 5: The Linear Algebra Backbone\n\nMany advanced probability concepts, especially in multivariate settings or machine learning applicat"
  },
  "/content/posts/legacy/probability-deep-dive-en#34": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "hat properties characterize this transformation?\n\n- **Rank:** The number of linearly independent rows/columns, measuring the dimensionality of the tra"
  },
  "/content/posts/legacy/probability-deep-dive-en#35": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "mpresses space to zero volume (rank deficiency).\n\n- **Eigenvalues and Eigenvectors:** Special directions where the transformation only scales: $Av = \\"
  },
  "/content/posts/legacy/probability-deep-dive-en#36": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "with eigenvalues $\\lambda_1, \\ldots, \\lambda_n$:\n- $\\operatorname{tr}(A) = \\lambda_1 + \\lambda_2 + \\cdots + \\lambda_n$ (sum of eigenvalues)\n- $\\det(A)"
  },
  "/content/posts/legacy/probability-deep-dive-en#37": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "deficiency ⟺ some directions compressed to zero.\n\n**Geometric Insight:** For a diagonal matrix $A = \\begin{pmatrix}3 & 0\\\\0 & 2\\end{pmatrix}$, the x-a"
  },
  "/content/posts/legacy/probability-deep-dive-en#38": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": ") = 5$, $\\det(A) = 6$, and rank = 2.\n\nConclusion\n\nThis journey through probability theory reveals how seemingly simple concepts like \"convergence\" hid"
  },
  "/content/posts/legacy/probability-deep-dive-en#39": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "ls for modern data science and machine learning.\n\nThe interconnections between these concepts—from convergence modes through limit theorems to practic"
  },
  "/content/posts/legacy/probability-deep-dive-en#40": {
    "title": "A Deeper Dive into Probability: From Convergence to Core Concepts",
    "url": "/content/posts/legacy/probability-deep-dive-en",
    "date": "2025-01-24",
    "text": "needed to transform data into reliable insights.\n\nAs we continue to grapple with increasingly complex data and models, returning to these fundamental "
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler#0": {
    "title": "Nighthawks项目揭秘：构建下一代AI智能任务调度系统",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler",
    "date": "2024-01-01",
    "text": "Nighthawks项目揭秘：构建下一代AI智能任务调度系统\n\n- **🤖 AI驱动的调度**：集成OpenAI GPT和Graphiti知识图谱，实现从自然语言到Cron表达式的智能转换。\n- **🧠 上下文感知执行**：任务执行不再是孤立的，系统能够记忆历史执行模式，并根据上下文进行优化。\n"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler#1": {
    "title": "Nighthawks项目揭秘：构建下一代AI智能任务调度系统",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler",
    "date": "2024-01-01",
    "text": "++\n    \n          +>[Prometheus]-->[Grafana]\n    \n          +>[AI智能层: OpenAI, Graphiti]\n    \n    |      +>[AI Agent]\n    |      +>[执行日志]\n    |\n    +>["
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler#2": {
    "title": "Nighthawks项目揭秘：构建下一代AI智能任务调度系统",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler",
    "date": "2024-01-01",
    "text": "gineering，使其解析准确率达到了95%以上。\n\n2.  **AI Agent与知识图谱**\n    每个任务都由一个独立的AI Agent负责执行。这个Agent在执行前会查询**Graphiti知识图谱**，获取与该任务相关的历史信息、用户偏好或上下文数据。例如，如果之前的报告因数据源延迟"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler#3": {
    "title": "Nighthawks项目揭秘：构建下一代AI智能任务调度系统",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler",
    "date": "2024-01-01",
    "text": "到现实：一个使用示例\n\n让我们通过一个具体的例子，看看Nighthawks是如何工作的。\n\n**1. 用户输入自然语言指令：**\n\n**2. Nighthawks的AI进行解析：**\n\n系统返回结构化的任务定义：\n\n**3. 创建并调度任务：**\n\n用户确认后，该任务被持久化到数据库，并由APSch"
  },
  "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler#4": {
    "title": "Nighthawks项目揭秘：构建下一代AI智能任务调度系统",
    "url": "/content/posts/legacy/project-nighthawks-ai-powered-task-scheduler",
    "date": "2024-01-01",
    "text": "通过将大型语言模型、知识图谱与传统软件工程相结合，我们能够创造出远比以往更智能、更人性化的工具。\n\n我们相信，未来的软件将不再仅仅是冰冷的指令执行者，而是能够理解、学习并与人类高效协作的智能伙伴。Nighthawks正是朝着这个方向迈出的坚实一步。"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive#0": {
    "title": "回归模型评估指标深度解析：从MAE到R²，选对指标才能优化模型",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "回归模型评估指标深度解析：从MAE到R²，选对指标才能优化模型\n\n2. 常见补充指标\n\n除了上述核心指标，以下几个补充指标在特定场景下也极为有用。\n\n3. Python 实战快速计算\n\n`scikit-learn` 提供了计算上述大部分指标的便捷工具。下面是一个模板化示例，可以快速在你的项目中使用。"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive#1": {
    "title": "回归模型评估指标深度解析：从MAE到R²，选对指标才能优化模型",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "，说明加入离群点后，模型的预测效果甚至比“直接取所有真实值的平均数”这个最简单的基线模型还要差。\n\n这个实验告诉我们：当业务极度关注“大错不能犯”时，MSE/RMSE 是更灵敏的监控哨兵；而如果希望评估模型的整体表现，不受少数异常值干扰，MAE/MedAE 是更稳健的选择。\n\n5. 如何为你的项目挑"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive#2": {
    "title": "回归模型评估指标深度解析：从MAE到R²，选对指标才能优化模型",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "得 MSE/RMSE 对大误差和离群点极为敏感，就像一个警报器，任何重大偏离都会导致指标急剧恶化。\n    -   **适用行业**：金融风控（如预测违约损失）、工业制造（如预测设备故障时间）、天气预报等。在这些领域，一个极端错误的代价非常高昂。\n\n-   **如果你更关注“平均错1度” (稳定性优"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive#3": {
    "title": "回归模型评估指标深度解析：从MAE到R²，选对指标才能优化模型",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "个问题关系到指标的最终受众和业务沟通的便利性。\n\n-   **如果汇报对象关心“相对百分比”**：\n    -   **首选指标：MAPE / SMAPE**\n    -   **原因**：平均绝对百分比误差（MAPE）直接以百分比形式呈现误差，非常直观，尤其适合向非技术背景的管理层汇报。例如，“我"
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive#4": {
    "title": "回归模型评估指标深度解析：从MAE到R²，选对指标才能优化模型",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "，如“模型平均误差是 1000 元，在我们的可接受范围内”。\n\n场景三：我的数据分布有什么特点？\n\n数据本身的特性是选择指标的关键技术前提。\n\n-   **如果数据呈长尾分布（如房价、网站流量、个人收入）**：\n    -   **首选指标：RMSLE (Root Mean Squared Log "
  },
  "/content/posts/legacy/regression-evaluation-metrics-deep-dive#5": {
    "title": "回归模型评估指标深度解析：从MAE到R²，选对指标才能优化模型",
    "url": "/content/posts/legacy/regression-evaluation-metrics-deep-dive",
    "date": "2024-01-01",
    "text": "时，直接评估绝对误差的 MAE 或 RMSE 是最安全、最直接的选择。\n\n总结：一个决策流程\n\n1.  **定性分析（业务对话）**：首先与业务方沟通，明确误差容忍度和汇报习惯，完成场景一和场景二的判断。\n2.  **定量分析（数据探索）**：绘制数据分布直方图，检查是否存在长尾、离群点或 0 值，"
  },
  "/content/posts/legacy/probability-deep-dive-zh#0": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "深入探索概率论：从收敛性到核心概念\n\n几乎必然收敛 (Almost Sure Convergence)：最强的收敛形式\n\n**几乎必然收敛** 指的是，随机变量序列 $X_n$ 在概率空间中\"几乎所有\"的样本路径上都收敛于 $X$。直观地说，就是有 100% 的概率（Probability = 1）"
  },
  "/content/posts/legacy/probability-deep-dive-zh#1": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "$\n- **灰色带：** 0.45–0.55 的区间，代表直观上的\"稳定\"范围\n\n关键观察点：\n1.  初期，波动非常剧烈（有些曲线甚至触及 0 或 1）。\n2.  随着 $n$ 的增加，所有路径都逐渐稳定下来，并**永久地**停留在灰色带内。\n3.  它们再也不会偏离 0.5 太远——这就是**强"
  },
  "/content/posts/legacy/probability-deep-dive-zh#2": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "varepsilon$ 的概率趋近于零：$\\Pr( > \\varepsilon) \\to 0$。\n\n这比几乎必然收敛要弱。虽然对于很大的 $n$ 来说，$X_n$ 通常非常接近 $X$，但偶尔的巨大偏离仍然是可能发生的。**弱大数定律 (Weak Law of Large Numbers)** 证明"
  },
  "/content/posts/legacy/probability-deep-dive-zh#3": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "/n$ 的概率）跳到 1。**红色曲线**显示了这个概率 $1/n$ 是如何随 $n$ 减小的。\n\n-   随着 $n$ 的增加，**取到 1 的概率越来越小**，满足：\n    $$\\Pr(>\\tfrac{1}{2}) = \\Pr(X_n=1) = \\tfrac{1}{n} \\longrighta"
  },
  "/content/posts/legacy/probability-deep-dive-zh#4": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "数。通俗地说，就是随机变量的概率分布**形状**逐渐变得相似，但我们不关心单次实现的值是否接近。\n\n这是最弱的收敛形式。**中心极限定理 (Central Limit Theorem)** 就是一个最好的例子：无论原始分布是什么（只要方差有限且观测是独立同分布的），标准化后的样本均值都会依分布收敛于"
  },
  "/content/posts/legacy/probability-deep-dive-zh#5": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "\\cdot (1-\\frac{1}{n}) = \\frac{1}{\\sqrt{n}} \\to 0$\n-   **方差：** 由于 $X_n$ 要么是 0 要么是 $\\sqrt{n}$，我们有 $\\mathbb{E}[X_n^2] = n \\cdot \\frac{1}{n} = 1$。因此 $\\ope"
  },
  "/content/posts/legacy/probability-deep-dive-zh#6": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "仔细分析收敛的具体对象。\n\n第二部分：塑造我们世界的极限定理\n\n中心极限定理：为何标准化至关重要\n\n**场景：** 想象一下，你投掷很多个骰子并记录它们的点数之和。掷 1 个骰子时，结果是均匀分布（1-6）。掷 2 个骰子时，和的分布变成三角形（2-12，中心在 7）。那么掷 10 个骰子呢？直觉告"
  },
  "/content/posts/legacy/probability-deep-dive-zh#7": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "过减去均值 $n\\mu$ 来中心化，再通过除以标准差 $\\sqrt{n}\\sigma$ 来缩放：\n\n$$Z_n = \\frac{S_n - n\\mu}{\\sigma\\sqrt{n}} = \\frac{\\overline{X}_n - \\mu}{\\sigma/\\sqrt{n}}$$\n\n中心极限定理指出"
  },
  "/content/posts/legacy/probability-deep-dive-zh#8": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "骰子点数和的平滑曲线与标准正态曲线（黑色）叠加。随着骰子数量增加，和的分布越来越接近正态分布。*\n\n**例子：** 假设我们测量一批机器零件的误差 $X$，其分布未知，但已知均值 $\\mu=0$，标准差 $\\sigma=2$ 毫米。对于 $n=36$ 个零件，其平均误差 $\\overline{X}_"
  },
  "/content/posts/legacy/probability-deep-dive-zh#9": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "布可以用泊松分布来近似。这就是**稀有事件定律**，在通信、排队论和可靠性工程中是基础性的理论。\n\n**数学推导：** 设 $X_n \\sim \\text{Binomial}(n, \\lambda/n)$。我们有 $\\mathbb{E}[X_n] = \\lambda$ 且 $\\operatornam"
  },
  "/content/posts/legacy/probability-deep-dive-zh#10": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "{n!}{(n-k)!} = n(n-1)\\cdots(n-k+1) \\approx n^k$\n2.  因此 $\\binom{n}{k} \\left(\\frac{\\lambda}{n}\\right)^k \\approx \\frac{n^k}{k!} \\left(\\frac{\\lambda}{n}\\r"
  },
  "/content/posts/legacy/probability-deep-dive-zh#11": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "p \\leq 10$，用泊松分布近似二项分布通常相当准确。\n\n第三部分：量化不确定性的实用工具箱\n\n当我们对一个随机变量的分布知之甚少时，**概率不等式**为我们估算其尾部概率提供了至关重要的边界。不同的不等式需要不同的假设，并提供不同紧密度的界。\n\n马尔可夫不等式 (Markov's Inequa"
  },
  "/content/posts/legacy/probability-deep-dive-zh#12": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "式 (Chebyshev's Inequality)：利用方差信息\n\n对于任意方差有限的随机变量：\n$$\\Pr( \\geq \\varepsilon) \\leq \\frac{\\operatorname{Var}(X)}{\\varepsilon^2}$$\n\n**优点：** 不需要变量非负或有界，当方差已"
  },
  "/content/posts/legacy/probability-deep-dive-zh#13": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "ilon^2)$$\n\n这个不等式提供了**指数级集中**的性质，使其在 $n$ 很大时极为强大。\n\n**示例对比：** 假设我们希望样本均值与真实均值的偏差超过 $\\varepsilon = 0.1$ 的概率低于 5%：\n-   **霍夫丁不等式：** 解 $2e^{-2n(0.1)^2} < 0."
  },
  "/content/posts/legacy/probability-deep-dive-zh#14": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "比雪夫：** 当你知道方差但不能保证变量有界时使用。为任何方差有限的分布提供了通用的尾部概率控制。\n-   **霍夫丁：** 当变量有界且独立时使用。给出指数级集中的界，对大样本量尤其有效。在机器学习的泛化分析和 A/B 测试中至关重要。\n\n第四部分：基础分布的核心性质\n\n无记忆性：等待越久，机会越"
  },
  "/content/posts/legacy/probability-deep-dive-zh#15": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "间的前提下，还需要再等待 $t$ 单位时间的概率，等于一开始就需要等待 $t$ 单位时间的概率。\n\n**指数分布的验证：** 设累积分布函数 $F(x) = 1 - e^{-\\lambda x}$，则生存函数为 $\\Pr(X>x) = e^{-\\lambda x}$：\n$$\\Pr(X > s+t \\"
  },
  "/content/posts/legacy/probability-deep-dive-zh#16": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "。\" 由于正态分布没有封闭形式的累积分布函数，我们依赖于标准化和查表。\n\n**标准化流程：**\n1.  转换为标准正态分布：$Z = \\frac{X - \\mu}{\\sigma}$，其中 $Z \\sim N(0,1)$。\n2.  重写概率：$\\Pr(X \\leq a) = \\Pr\\left(Z \\l"
  },
  "/content/posts/legacy/probability-deep-dive-zh#17": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "99.7% 的数据落在距离均值 1、2、3 个标准差的范围内。\n\n第五部分：线性代数的支柱作用\n\n许多高级概率概念，尤其是在多变量分析或机器学习应用（如主成分分析 PCA）中，都严重依赖线性代数。以下是对关键概念的直观回顾。\n\n通过几何直觉理解矩阵性质\n\n**场景：** 想象一个线性变换 $A$ 作"
  },
  "/content/posts/legacy/probability-deep-dive-zh#18": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "\\lambda v$。特征值 $\\lambda$ 是缩放因子；特征向量 $v$ 是不变的方向。\n\n-   **迹 (Trace)：** 矩阵对角线元素之和，它也等于所有特征值之和：$\\operatorname{tr}(A) = \\lambda_1 + \\lambda_2 + \\cdots + \\la"
  },
  "/content/posts/legacy/probability-deep-dive-zh#19": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "这些关系揭示了深刻的联系：存在零特征值 ⟺ 行列式为零 ⟺ 秩亏损 ⟺ 某些方向被压缩为零。\n\n**几何直观：** 对于对角矩阵 $A = \\begin{pmatrix}3 & 0\\\\0 & 2\\end{pmatrix}$，x 轴被拉伸 3 倍，y 轴被拉伸 2 倍。在这里，坐标轴就是特征向量，对应"
  },
  "/content/posts/legacy/probability-deep-dive-zh#20": {
    "title": "深入探索概率论：从收敛性到核心概念",
    "url": "/content/posts/legacy/probability-deep-dive-zh",
    "date": "2025-01-24",
    "text": "、构建机器学习模型，还是设计科学实验，这些工具都能提供严谨的框架，帮助你将数据转化为可靠的洞见。\n\n随着我们处理日益复杂的数据和模型，回归这些基本原理，能确保我们的结论是建立在坚实的数学基础之上，而不是依赖于那些直观但可能误导人的经验法则。"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#0": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践\n\n路径 A 的思路是开发一个自定义“读取器”（Reader），使其能够直接从 Keynote 文件中提取结构化的内容，而不需要中间转换为其他格式。由于 Keynote .key 文件采用苹果的专有压缩二进制格式，内部实际是一个"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#1": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "文本形式（例如 YAML 文件）供我们提取信息 。具体而言，keynote-parser 支持将 .key 文件拆解为独立文件夹，其中包括解析后的 YAML 文件，我们可以从中提取幻灯片的文本、备注，以及表格单元格等内容。下面是一个简单的示例流程：\n\n执行上述命令后，会生成一个名为 MySlides"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#2": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "对于流程图和形状，我们可以提取形状中的文字（尽管形状之间的连线关系在纯文本中可能无法直接反映）。\n\n使用自定义 Reader 时，我们可以选择将提取到的内容组装成结构化文本（例如以 Markdown 或特定标记表示表格），或者直接生成用于索引的文本块。在 LangChain 或 LlamaIndex"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#3": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "们就能够获取 Keynote 幻灯片中的文字说明、表格数据等原生文本内容，而无需转换为中间格式。\n\n优点：路径 A 避免了转换可能带来的信息损失，理论上可以提取出更多结构信息。例如，表格可以保持行列对应关系，幻灯片的备注（notes）也能被抓取到（前提是 .key 文件中有存储）。对于流程图，虽然自"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#4": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "的来说，路径 A 适合对解析质量要求很高且具备开发能力的团队，能够最大程度定制对复杂内容的处理。\n\n路径 B：Keynote 转 PDF 再利用解析工具\n\n路径 B 是更通用且直接的方法：先将 Keynote 文件批量转换为 PDF，然后使用成熟的文档解析工具提取 PDF 中的信息。许多文档解析库和"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#5": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "下面是一段简单的 AppleScript 脚本示例，将某个 Keynote 文档导出为 PDF：\n\n这段脚本调用了 Keynote 的export命令，将第一个文档导出为 PDF 文件 。我们可以通过 macOS 的终端 osascript 命令批量执行类似的脚本，对一个目录下的所有 .key 文件"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#6": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "t命令也支持一些属性，比如是否包含跳过的幻灯片、导出备注等  ）。确保需要的所有信息都进入PDF。\n* 图像质量设置： Keynote 导出 PDF 时可以选择图像质量（如标准/更好/最佳）。如果文件中有精细的流程图图片，需要高质量以便后续OCR或识别，可以在 AppleScript 中指定 PDF"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#7": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "无异了。\n\n解析 PDF 内容\n\n目前有许多工具可以高效解析 PDF 文档的内容，常见选择包括：\n* Unstructured：一个开源的Python库，支持将PDF解析为文本及元素列表。它能识别段落、标题、表格等元素，输出结构化的文本块。例如使用 unstructured.partition.pd"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#8": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "及一定费用。\n\n举例来说，如果选择使用 Unstructured，可以按以下方式获取PDF文本：\n\n上述代码利用 partition_pdf 将 PDF 文件拆解成元素列表，然后提取其中的文本部分拼接起来。对于表格元素，unstructured 通常会将其转换成Markdown格式的表格文本，保证结"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#9": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "作为单独一段，可以在导出 PDF 时选择每张幻灯片为一页，然后每页即对应一个 Document。\n\n解析效果：Keynote 转 PDF 再解析的效果取决于 PDF 中内容的表达方式。大多数情况下，幻灯片上的文字在PDF中仍是文本（可选中复制），因此解析工具能抓取到所有文本。对于流程图，连线和图形本"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#10": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "的是，在RAG应用中，我们更关注文字本身的检索，结构次之，因此这种方法已经能满足大部分检索需求。\n\n工程实现提示：如果需要对解析出的结果做后续处理（如存入向量数据库），可以考虑在解析阶段就添加元数据。例如添加每个文本块对应的幻灯片编号、标题，或者对表格里的内容添加标签（如来自第X页表格）。这样在检索"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#11": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "见误区与注意事项\n\n在尝试解析 Keynote 这类复杂文档用于索引时，有一些常见的误区值得注意：\n* 误区1：调高 RAG 检索的 chunk 数量能弥补解析不全的问题。 有些开发者在检索不到正确内容时，倾向于增加返回的文档片段数量（例如从 top-5 提高到 top-10）。然而，如果解析阶段内"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#12": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "错或返回空结果。例如，阿里云的 DashScope Parse 明确仅支持 .doc、.docx、.pdf 等常见文档格式，不接受 Keynote 原生格式 。因此，无论使用何种解析工具，首先要确保输入是受支持的格式。对于不支持的格式，需要我们预处理转换（这正是路径 B 的意义所在）。切勿将未处理的"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#13": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "note 应用后测试解析是否仍然正常。路径 B 则相对不受此影响，因为 PDF 是稳定通用的格式。\n* OCR 及图像识别： 在某些极端情况下，幻灯片上的内容可能以图像形式存在（例如扫描件或手写笔记嵌入在Keynote中）。对于这部分纯图像内容，PDF 解析也无法直接获得文字，需要集成 OCR（光学"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#14": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "te-parser 批量解包，再并行处理文本提取。合理的批处理和缓存机制能加速整体流程。\n\n结论\n\n对于含有复杂结构（流程图、表格、备注等）的 Keynote 文档，构建高质量的索引以支持 RAG 应用，需要我们在解析阶段下功夫。本文讨论了两种实践路径：其一，通过自定义 Reader 直接解析 .k"
  },
  "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践#15": {
    "title": "复杂结构文档解析：Keynote 转换与自定义 Reader 双路径实践",
    "url": "/content/posts/legacy/复杂结构文档解析-keynote-转换与自定义-reader-双路径实践",
    "date": "2024-10-06",
    "text": "这个过程中，避免常见误区，关注工具支持情况和转换细节，才能最终提升复杂文档的可解析性和检索质量。\n\n通过上述指南，希望读者能够清晰了解如何处理 Keynote 这类复杂文档的解析任务。从导出脚本的编写到解析代码的实现，我们提供了具体的示例和经验教训。实践中根据项目需要选择合适的路径，并不断迭代优化解"
  },
  "/content/posts/legacy/claude-code-pricing-comparison#0": {
    "title": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？",
    "url": "/content/posts/legacy/claude-code-pricing-comparison",
    "date": "2025-07-24",
    "text": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？\n\n¹ **动态消息限制**: Pro 和 Max 的消息限制并非固定数值，而是基于对话上下文长度和当前系统负载动态调整。Max 套餐明确提供至少 5 倍于 Pro 的使用容量。\n\n**API 定价示例 (Claude 3 模型"
  },
  "/content/posts/legacy/claude-code-pricing-comparison#1": {
    "title": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？",
    "url": "/content/posts/legacy/claude-code-pricing-comparison",
    "date": "2025-07-24",
    "text": "。\n  - **批量代码转换或现代化**：例如，将旧版框架代码升级到新版。\n\n3. 成本效益分析\n\n这是决策的核心，我们通过一个量化模型来分析。\n\n**假设**:\n- 一次典型的中等复杂度的编码交互（例如，粘贴一个 200 行的文件，提出一个问题，获得一段代码和解释）消耗大约 **10,000 To"
  },
  "/content/posts/legacy/claude-code-pricing-comparison#2": {
    "title": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？",
    "url": "/content/posts/legacy/claude-code-pricing-comparison",
    "date": "2025-07-24",
    "text": "de Pro ($20/月)**:\n  - $20 / $0.60 ≈ **33 次交互/月**。\n  - 如果你每月与 Claude 的高质量编码交互少于 33 次（平均每天 1-2 次），直接使用 API 可能更便宜。超过这个频率，Pro 订阅更具成本效益。\n\n- **Claude Max ($"
  },
  "/content/posts/legacy/claude-code-pricing-comparison#3": {
    "title": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？",
    "url": "/content/posts/legacy/claude-code-pricing-comparison",
    "date": "2025-07-24",
    "text": "户**: Pro/Max 订阅是明确的赢家。你无需担心每次提问的成本，可以更自由地进行探索和迭代。\n- **企业/自动化用户**: API 是唯一选择。成本是可变的运营支出 (OpEx)，与业务价值直接挂钩。使用更便宜的 Sonnet 或 Haiku 模型可以大幅降低成本。例如，使用 Sonnet "
  },
  "/content/posts/legacy/claude-code-pricing-comparison#4": {
    "title": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？",
    "url": "/content/posts/legacy/claude-code-pricing-comparison",
    "date": "2025-07-24",
    "text": "普遍。下面，我们将从成本和体验两个维度，为这类用户进行详细的分析。\n\n4.1 核心：成本效益分析\n\n要进行成本对比，我们首先需要量化一次\"编程交互\"的消耗。一个典型的编程任务可能包含：\n\n- **输入 (Input)**: 粘贴一段代码（例如200行Python代码）、一个错误日志、功能需求描述。\n"
  },
  "/content/posts/legacy/claude-code-pricing-comparison#5": {
    "title": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？",
    "url": "/content/posts/legacy/claude-code-pricing-comparison",
    "date": "2025-07-24",
    "text": "成本:**\n- 输入成本: `(4,000 / 1,000,000) * $15 = $0.06`\n- 输出成本: `(1,000 / 1,000,000) * $75 = $0.075`\n- **总计: $0.135 / 次**\n\n**月度成本计算:**\n该用户的使用频率为\"中等到重度\"，我们取其"
  },
  "/content/posts/legacy/claude-code-pricing-comparison#6": {
    "title": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？",
    "url": "/content/posts/legacy/claude-code-pricing-comparison",
    "date": "2025-07-24",
    "text": "得比Opus API更划算。** 对于绝大多数中等频率的用户来说，API模式的成本优势非常明显。\n\n*补充：如果使用更经济的Claude 3 Sonnet模型（API价格约为Opus的1/5），API的成本优势会更加巨大，每月成本可能仅为2-3美元，但代码生成能力会略有下降。*\n\n4.2 关键差异："
  },
  "/content/posts/legacy/claude-code-pricing-comparison#7": {
    "title": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？",
    "url": "/content/posts/legacy/claude-code-pricing-comparison",
    "date": "2025-07-24",
    "text": "中安装一个支持Claude 3的插件，将API Key配置进去，立即开始享受原生的编程体验。\n\n2. **选择Claude Pro的特定场景**\n   尽管API优势明显，但在以下情况，Pro订阅可能是更合适的选择：\n   - **极高频使用者**：如果你确信自己每天会进行超过5次以上的大型、复杂的"
  },
  "/content/posts/legacy/claude-code-pricing-comparison#8": {
    "title": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？",
    "url": "/content/posts/legacy/claude-code-pricing-comparison",
    "date": "2025-07-24",
    "text": "中。\n\n5. 实际使用场景推荐\n\n6. 选择与升级路径建议\n\n6.1 基于使用频率的选择指南\n\n1. **探索与偶尔使用**: 从 **API 按量付费**开始。设置一个较低的预算（如 $10/月），体验不同模型的能力。\n2. **每日依赖的编程伙伴**: 选择 **Claude Pro**。这是性"
  },
  "/content/posts/legacy/claude-code-pricing-comparison#9": {
    "title": "Claude Code付费模式深度解析：订阅制 vs API 如何选择？",
    "url": "/content/posts/legacy/claude-code-pricing-comparison",
    "date": "2025-07-24",
    "text": "PI Key (用于CI/CD) -> 建立内部网关统一管理 API 调用 (企业级)`\n\n结论\n\n选择 Claude Pro/Max 订阅还是 API，并非一个非此即彼的决定，而是一个基于**使用模式**（交互式 vs. 程序化）和**使用强度**的战略选择。\n\n- **订阅制**为你购买的是一个"
  },
  "/content/posts/legacy/02-cuda-开发必备的-cc-语法#0": {
    "title": "CUDA 开发必备的 C/C++ 语法",
    "url": "/content/posts/legacy/02-cuda-开发必备的-cc-语法",
    "date": "2025-05-08",
    "text": "CUDA 开发必备的 C/C++ 语法\n\n数据类型与变量\n\nC/C++ 提供了丰富的基本数据类型用于声明变量。常见的数据类型及用途包括：\n\n- **`int`：** 整型，一般占用32位，用于循环计数、数组索引等。\n- **`float`：** 单精度浮点数（32位），CUDA 中常用来表示GPU上"
  },
  "/content/posts/legacy/02-cuda-开发必备的-cc-语法#1": {
    "title": "CUDA 开发必备的 C/C++ 语法",
    "url": "/content/posts/legacy/02-cuda-开发必备的-cc-语法",
    "date": "2025-05-08",
    "text": "int n, float a`），以让编译器知道数据的大小和含义。\n\n指针与数组的关系，指针算术\n\n**指针** 是 C/C++ 中的独特概念，用于保存内存地址。数组与指针关系密切：在大多数表达式中，数组名为指向其第一个元素的指针。这意味着我们可以用指针来遍历或操作数组。"
  },
  "/content/posts/legacy/studentcrud-swift-swiftui-macos-student-management#0": {
    "title": "StudentCRUD：基于Swift和SwiftUI的macOS学生管理系统开发实践",
    "url": "/content/posts/legacy/studentcrud-swift-swiftui-macos-student-management",
    "date": "2025-07-23",
    "text": "StudentCRUD：基于Swift和SwiftUI的macOS学生管理系统开发实践\n\n核心技术栈\n- **开发语言**: Swift 5\n- **UI框架**: SwiftUI\n- **数据库**: SQLite（本地存储）\n- **数据库操作**: SQLite.swift\n- **架构模式*"
  },
  "/content/posts/legacy/studentcrud-swift-swiftui-macos-student-management#1": {
    "title": "StudentCRUD：基于Swift和SwiftUI的macOS学生管理系统开发实践",
    "url": "/content/posts/legacy/studentcrud-swift-swiftui-macos-student-management",
    "date": "2025-07-23",
    "text": "- 完整的数据一致性保证\n- 支持数据导入导出\n- 本地数据存储，保护隐私\n\n技术实现亮点\n\n1. MVVM架构实现\n使用**ObservableObject**和**@Published**属性实现响应式状态管理：\n\n2. DAO设计模式\n通过DAO层抽象数据访问逻辑，提高代码的可维护性和可测试性"
  },
  "/content/posts/legacy/studentcrud-swift-swiftui-macos-student-management#2": {
    "title": "StudentCRUD：基于Swift和SwiftUI的macOS学生管理系统开发实践",
    "url": "/content/posts/legacy/studentcrud-swift-swiftui-macos-student-management",
    "date": "2025-07-23",
    "text": "本地化\n\n国际化支持\n\n项目完全支持中文本地化：\n- 界面文本全中文显示\n- 符合中国教育管理习惯\n- 支持中文数据输入和显示\n\n开发实践总结\n\n项目结构优化\n在开发过程中，对项目结构进行了重构：\n- 删除了Swift Package Manager文件\n- 重新组织Xcode项目结构\n- 将文件按"
  },
  "/content/posts/legacy/studentcrud-swift-swiftui-macos-student-management#3": {
    "title": "StudentCRUD：基于Swift和SwiftUI的macOS学生管理系统开发实践",
    "url": "/content/posts/legacy/studentcrud-swift-swiftui-macos-student-management",
    "date": "2025-07-23",
    "text": "ift中的最佳实践\n3. **架构设计**: 深入理解了MVVM和DAO模式在实际项目中的应用\n4. **macOS开发**: 熟悉了macOS应用的沙盒配置和部署流程\n\n未来规划\n\n1. **功能扩展**: 添加数据统计分析功能\n2. **性能优化**: 大数据量场景下的性能优化\n3. **测试完"
  },
  "/content/posts/legacy/基于摘要认证的第三方接口调用方案#0": {
    "title": "基于摘要认证的第三方接口调用方案",
    "url": "/content/posts/legacy/基于摘要认证的第三方接口调用方案",
    "date": "2022-01-05",
    "text": "基于摘要认证的第三方接口调用方案\n\n上述请求体中的 `credential` 字段即为摘要凭证，其中 `key:...=version:v1` 由两部分组成：`key` 后紧跟的一长串十六进制字符串是通过 SHA-256 算法计算的 client_id 摘要值（即哈希值），`version:v1` "
  },
  "/content/posts/legacy/基于摘要认证的第三方接口调用方案#1": {
    "title": "基于摘要认证的第三方接口调用方案",
    "url": "/content/posts/legacy/基于摘要认证的第三方接口调用方案",
    "date": "2022-01-05",
    "text": "56 摘要比对）。若提供的摘要与某个已注册 client_id 的摘要匹配，则说明请求者身份有效。\n  * 授权阶段：服务器查验调用方的权限配置。如果身份与权限均满足，则允许执行后续业务逻辑；否则拒绝请求。\n\n通过以上流程，实现了对第三方接口调用的身份验证和权限控制。整个方案设计轻量简洁，只需一次摘"
  },
  "/content/posts/legacy/基于摘要认证的第三方接口调用方案#2": {
    "title": "基于摘要认证的第三方接口调用方案",
    "url": "/content/posts/legacy/基于摘要认证的第三方接口调用方案",
    "date": "2022-01-05",
    "text": "C 提升权限管理  \n* 区分公开ID与私密密钥  \n* 定期轮换密钥并全程使用 TLS\n\n总结\n\n该摘要认证方案以最小代价满足了基础身份验证和授权需求，适用于对性能和集成成本敏感、受信环境相对可控的接口调用场景。如需更高安全性，可按需引入时间戳、HMAC、签名以及细粒度权限模型等防护措施。"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#0": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core\n\nThe Technical Core: Four Pillars of Self-Improvement\n\nTo"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#1": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "ly 'adjusting behavior' to 'reforming itself'.\n\n1. Prompt Iteration Subsystem: Optimizing Self-Expression\n\n**Goal**: To enable an agent to automatical"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#2": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "es if a poor result is related to the prompt (e.g., irrelevant answer, missing key points).\n2.  **Enter Improvement Mode**: Once a prompt issue is con"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#3": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "ading to a result without a reasoning process.\"\n4.  **Generate Candidates**: The agent requests the LLM to generate one or more improved prompt versio"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#4": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "data for future learning.\n\n**Security Policies**:\n- **Intent Lock**: Modifications must focus on improving clarity and must not deviate from the user'"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#5": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "this action, with limits on the scope of change.\n- **Audit Trail**: All prompt changes must be fully logged for tracking and analysis.\n\n2. Schedule Se"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#6": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "on and task latency.\n\n**Implementation Steps**:\n1.  **Data Monitoring**: The agent continuously collects scheduling-related data, such as task queue l"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#7": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "stantly backlogged queue implies it's too low).\n3.  **Formulate Adjustment Plan**: The agent creates a plan, such as \"Extend trigger interval from 1 m"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#8": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "n (e.g., timer frequency, event subscriptions).\n6.  **Continuously Evaluate and Rollback**: After application, the agent monitors the outcome. If perf"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#9": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "ting\" or creating a self-inflicted \"DDoS\" attack.\n- **Critical Task Guarantee**: Agents responsible for critical tasks have restricted ability to auto"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#10": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "higher permissions can modify their schedule.\n\n3. Memory Writing Subsystem: Experience Crystallization and Inheritance\n\n**Goal**: To allow an agent to"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#11": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "ion in future tasks.\n\n**Implementation Steps**:\n1.  **Extract Memory Content**: During the reflection phase, the agent identifies information worth sa"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#12": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "ormat and Store**: Information is structured (e.g., as nodes and edges in the knowledge graph) and written to the appropriate medium.\n4.  **Update Ind"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#13": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "ext to guide its actions.\n\n**Security Policies**:\n- **Privacy and Compliance**: Storing sensitive user information in long-term memory without authori"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#14": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "ding verification\" or require human confirmation.\n- **Consistency Maintenance**: When writing new knowledge, the agent must check for conflicts with e"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#15": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "eneration Subsystem: The Ultimate Self-Evolution\n\n**Goal**: To grant the highest-level agents the ability to repair and optimize their own code. This "
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#16": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "(e.g., a logic flaw, an inefficient algorithm).\n2.  **Propose Patch**: The agent uses its coding capabilities (often assisted by a specialized program"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#17": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "human developer) to ensure quality and safety.\n4.  **Sandbox Testing**: The approved patch is deployed in an isolated sandbox environment where it run"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#18": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "nd formally deployed via an automated pipeline.\n6.  **Continuous Monitoring and Emergency Rollback**: Post-deployment, the agent's performance is clos"
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#19": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "ns, and they **must** undergo independent review.\n- **Mandatory Review and Authorization**: Every code patch application must have a clear, traceable "
  },
  "/content/posts/legacy/project-nighthawk-vision-and-architecture#20": {
    "title": "Project Nighthawk Complete Guide: A Self-Evolving Agent OS's Grand Vision and Technical Core",
    "url": "/content/posts/legacy/project-nighthawk-vision-and-architecture",
    "date": "2024-01-01",
    "text": "to prevent large-scale, hard-to-evaluate changes.\n- **Sandbox Isolation**: All testing must be conducted in a sandbox strictly isolated from the produ"
  },
  "/content/posts/legacy/gemini-cli-graphiti-mcp-integration#0": {
    "title": "Gemini CLI 对接 Graphiti MCP：实战指南",
    "url": "/content/posts/legacy/gemini-cli-graphiti-mcp-integration",
    "date": "2024-01-01",
    "text": "Gemini CLI 对接 Graphiti MCP：实战指南\n\n在开始配置之前，请确保完成以下准备工作：\n\n1.  **安装 Gemini CLI**：\n    \n\n2.  **获取并启动 Graphiti MCP Server**：\n    您可以选择以下任一方式启动 Graphiti 服务。\n"
  },
  "/content/posts/legacy/gemini-cli-graphiti-mcp-integration#1": {
    "title": "Gemini CLI 对接 Graphiti MCP：实战指南",
    "url": "/content/posts/legacy/gemini-cli-graphiti-mcp-integration",
    "date": "2024-01-01",
    "text": "**WebSocket 端点**: `http://localhost:8000/ws`\n\n3. 配置方法 A：Gemini CLI 本地启动 Graphiti (stdio)\n\n这种方法让 Gemini CLI 托管 Graphiti 进程，适合快速本地集成。\n\n打开 Gemini CLI 的配置"
  },
  "/content/posts/legacy/gemini-cli-graphiti-mcp-integration#2": {
    "title": "Gemini CLI 对接 Graphiti MCP：实战指南",
    "url": "/content/posts/legacy/gemini-cli-graphiti-mcp-integration",
    "date": "2024-01-01",
    "text": "成功。\n\n4. 配置方法 B：Gemini CLI 连接常驻 Graphiti 服务 (SSE)\n\n如果 Graphiti 已经作为一个独立服务在运行，可以使用此方法连接。\n\n同样，在 `~/.gemini/settings.json` 中添加配置：\n\n*   **`url`**: 这是关键字段。请"
  },
  "/content/posts/legacy/gemini-cli-graphiti-mcp-integration#3": {
    "title": "Gemini CLI 对接 Graphiti MCP：实战指南",
    "url": "/content/posts/legacy/gemini-cli-graphiti-mcp-integration",
    "date": "2024-01-01",
    "text": "如果能看到持续输出的心跳事件（如 `event: ping`），说明 SSE 服务正常。\n\n2.  **在 Gemini CLI 中检查**:\n    启动 `gemini`，然后运行 `/mcp desc graphiti`。如果成功列出了 Graphiti 提供的工具列表，则连接成功。\n\n5. "
  },
  "/content/posts/legacy/01-matplotlib-basics#0": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "matplotlib学习笔记\n\n上面的代码绘制了三条函数曲线。plt.plot 是最基本的绘图命令，我们传入 x 和 y 数组即可绘制折线。我们还能通过可选参数调整线条样式：\n\t* linestyle 指定线型，比如 '-' 实线、'--' 虚线、'-.' 点划线、':' 点线等。\n\t* color"
  },
  "/content/posts/legacy/01-matplotlib-basics#1": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "默认情况下，这些曲线会绘制在同一个坐标系中，不同颜色和线型让它们彼此区分开来。此时如果调用 plt.show()，Matplotlib 会弹出一个窗口显示我们绘制的图形。不过在展示最终效果之前，我们还需要进一步“调味”来美化图表。\n\n如果一次绘制多条曲线，适当使用不同颜色、线型区分它们是必要的；当曲"
  },
  "/content/posts/legacy/01-matplotlib-basics#2": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "] 范围内、y 在 [0, 1.1] 的部分，可以这样设置：\n\n上述 plt.xlim 和 plt.ylim 会剪裁我们之前绘制的曲线，只显示指定的区间。在实际使用中，这种操作相当于给“镜头”拉近或移动焦点，让我们更专注于感兴趣的部分。不过在本例中，我们希望完整展示 $-π$ 到 $π$ 的曲线，因"
  },
  "/content/posts/legacy/01-matplotlib-basics#3": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "2,; π$，并通过列表传入对应的刻度标签字符串。注意，这些字符串前面有前缀 r，并包裹在 $...$ 中，这是 Matplotlib 支持的 LaTeX 数学语法，可以直接在标签中显示数学符号，例如 -\\frac{\\pi}{2}。这样我们的 x 轴刻度就以 π 的倍数形式呈现，更加直观。fonts"
  },
  "/content/posts/legacy/01-matplotlib-basics#4": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "大了字体；这里没有特别指定标签列表，因此默认使用这些值的数字形式作为标签。\n\n接下来，通过 plt.gca() 获取当前的 Axes 对象（即绘图的坐标系），我们可以对坐标轴的外观做细节调整。Matplotlib 每个坐标轴有上下左右四条脊(line)，默认情况下绘制在图表边框。上述代码将 top "
  },
  "/content/posts/legacy/01-matplotlib-basics#5": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "时已经给每条曲线指定了 label，现在只需一行代码就能让 Matplotlib 自动生成图例：\n\nplt.legend 会在图表上绘制一个小框，展示每种线型颜色对应的标签。在上面的调用中，我们手动提供了标签列表 ['sinx', 'cosx', 'sin2x']，对应之前绘制的三条曲线，并将图例的"
  },
  "/content/posts/legacy/01-matplotlib-basics#6": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "提供了多种方法，比如 plt.annotate 可以添加箭头和文本说明；这里我们用更简单的 plt.scatter 来绘制特殊标记符号。假设我们想强调 sin(x) 在 x=pi/2 处的峰值 1.0，以及 -sin(x) 在 x=-pi/2 处的谷值 -1.0（对应图中的两个极值点）。可以使用散点"
  },
  "/content/posts/legacy/01-matplotlib-basics#7": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "整的图表应该包含三条曲线、中心的坐标轴、精美的刻度标记、右上的图例，以及用星星标出的两个特殊点。\n\n图 1：使用 Matplotlib 绘制 sin x、cos x 和 sin 2x 函数曲线的效果图。绿色半透明实线表示 sin x，黑色点划线表示 cos x，蓝灰色粗虚线表示 sin 2x。坐标轴"
  },
  "/content/posts/legacy/01-matplotlib-basics#8": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "加图例和注释，最后再显示或保存图表。这样思路清晰，也方便逐步调试图表的外观。\n\n四、多窗口与布局\n\nMatplotlib 不仅能在一个坐标系里绘制多条曲线，还允许我们创建多个图形窗口同时显示不同的图表。这在需要对比不同数据集，或者分别展示不同步骤的结果时非常有用。接下来，我们通过一个简单示例来体验如"
  },
  "/content/posts/legacy/01-matplotlib-basics#9": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "小和背景），并在上面绘制另一条折线（(1,1), (2,2), (3,3)）。然后再次调用 plt.figure('A')，由于名为 A 的窗口已经存在，这行代码的作用是将当前绘图对象切换回 A。于是接下来的 plt.plot([1,2,3],[1,2,3]) 会添加一条新曲线到窗口 A 原有的图表"
  },
  "/content/posts/legacy/01-matplotlib-basics#10": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "到 B 时分别设置属于它自己的标题和标签）。\n\n为了让图表阅读起来更方便，我们打开了网格线：plt.grid(linestyle=':') 在图表背景添加了网格辅助线，这些虚点线可以帮助对齐和估读数值，又不会过于显眼干扰主图形。最后调用 plt.tight_layout() 自动调整子图布局。这一步"
  },
  "/content/posts/legacy/01-matplotlib-basics#11": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "调用了一次 plt.show()，所以所有尚未显示的图形窗口都会同时显示出来。\n\n需要注意，plt.figure() 如果不指定名称，Matplotlib 会使用默认编号 (如 Figure 1, Figure 2 …) 来标识不同窗口。我们在这里用字母 ‘A’ 和 ‘B’ 来命名窗口，直观且便于在"
  },
  "/content/posts/legacy/01-matplotlib-basics#12": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "轴标签被截掉。如果需要在一张窗口里绘制多张子图，可以使用 plt.subplots() 或 plt.subplot() 创建网格布局的子图，然后分别绘制；每个子图也能用 set_title 设置标题。无论是多窗口还是多子图，合理安排布局和标题都能让读者更容易比较和理解图中的信息。\n\nmatplotl"
  },
  "/content/posts/legacy/01-matplotlib-basics#13": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "多个窗口，就能在一张图里以矩阵布局展示多幅图表。\n\n创建子图布局有几种方法，最常用的是使用 plt.subplots 或 plt.subplot：\n* plt.subplots 一次性创建整个子图网格，并返回 Figure 对象和包含各子图 Axes 对象的数组。推荐使用这种方法，代码结构清晰便于后"
  },
  "/content/posts/legacy/01-matplotlib-basics#14": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "**\n\n上面的代码中，我们首先使用 plt.figure() 新建了一个画布，然后通过两次 plt.subplot(2, 1, i) 分别创建了上下两个子图。参数 (2, 1, i) 表示总共2行1列的网格，i 表示当前激活的是第几个子图（按行优先顺序编号）。在第一个子图上，我们绘制了 sin(x)"
  },
  "/content/posts/legacy/01-matplotlib-basics#15": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "ts 用法。\n\n**方法2：使用 plt.subplots 一次性创建网格**\n\n可以看到，plt.subplots(2, 1) 直接生成了包含2行1列子图的图表。它返回了一个 fig（Figure对象）和一个 axes 数组。这里 axes 是Python的数组类型（当只有一行或一列时，axes为"
  },
  "/content/posts/legacy/01-matplotlib-basics#16": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "可同时获取Figure：返回的 fig 对象可用于设置整体属性（如总体标题、保存图像文件等）。\n\n值得注意的是，如果我们创建多行多列的网格布局，例如 plt.subplots(2, 2)，得到的 axes 将是一个 2x2 的数组，此时访问右上角的子图要用 axes[0, 1]，左下角则是 axes"
  },
  "/content/posts/legacy/01-matplotlib-basics#17": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "plt.subplots 时通过参数设定，也可以在使用 fig.add_subplot 或 plt.subplot 创建子图时传入已有 Axes 来共享。\n\n最常用的用法是在 plt.subplots 中指定：\n\n这样生成的两个子图将共享同一套 X 轴刻度。对于上下排列的子图，共享 X 轴后，上方子"
  },
  "/content/posts/legacy/01-matplotlib-basics#18": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "$，右边绘制 $2\\sin(x)$（振幅是前者的两倍）。我们让它们共享Y轴，以方便对比振幅差异：\n\n以上代码生成了左右两个子图。由于设置了 sharey=True，两幅图共用相同的Y轴刻度范围。这样一来，即使右侧函数的振幅是左侧的两倍，两张图的Y轴刻度对齐后，我们可以直接观察到右侧曲线在纵向上是左侧"
  },
  "/content/posts/legacy/01-matplotlib-basics#19": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "要对子图的刻度进行更多自定义，也可以手动调整哪些刻度标签可见，例如通过 axes[i].xaxis.set_visible() 等高级用法，但这超出了本篇讨论范围。\n\n小贴士：共享坐标轴在数据交互分析中特别有用。例如在交互模式下（如Jupyter Notebook中），当我们缩放或移动其中一个共享轴"
  },
  "/content/posts/legacy/01-matplotlib-basics#20": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "或Y轴表示的都是相同的量（例如时间、频率等），可以只在最下方或最左侧的子图注明即可，避免重复标注。\n* 刻度美化：根据需要调整刻度标签的格式和密度。例如多个子图共享X轴时，上面的子图我们通常去掉X轴刻度标签，只保留底部，以免拥挤。Matplotlib已经在 sharex/sharey 时为我们做了这"
  },
  "/content/posts/legacy/01-matplotlib-basics#21": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "时，往往还需要一个总标题来概括说明整个图表的主题。这可以使用 plt.suptitle 或 fig.suptitle() 来添加。此外，为了防止子图之间的元素重叠、保证整体美观，我们可以使用 plt.tight_layout() 或 plt.subplots_adjust() 来调整子图间的间距。t"
  },
  "/content/posts/legacy/01-matplotlib-basics#22": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "拥挤。接下来，我们通过一个综合示例来实战演练这些技巧。\n\n3.1 矩阵式布局（subplots）\n\n在 Matplotlib 中，最常用也最简单的多子图布局方式就是“矩阵式”网格布局。所谓矩阵式布局，就是把整张图像划分成若干行×列的网格，每个网格区域放置一个子图，排列方式就像矩阵一样整齐对齐。我们通"
  },
  "/content/posts/legacy/01-matplotlib-basics#23": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "。下面的代码演示了创建一个2×2矩阵子图布局，并在每个子图上绘制一条简单的直线（斜率各不相同）：\n\n上图演示了一个2×2的矩阵式子图布局。其中每个子图大小相等，彼此之间自动留有默认间距。我们使用返回的 axes 数组来逐个访问和控制各子图，例如给每个子图设置了标题“子图 1/2/3/4”。像这样矩阵"
  },
  "/content/posts/legacy/01-matplotlib-basics#24": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "无法直接实现。此外，当子图数量较多时，矩阵布局可能会显得拥挤，调节子图间的间距需要手动调用 plt.subplots_adjust() 等方法。不过，对于大多数常规用途，矩阵式布局已经足够简洁实用，是绘制多子图时的首选方案。\n\n适用场景：矩阵式布局适合用于简单规整的多图对比场景，例如同类指标在不同条"
  },
  "/content/posts/legacy/01-matplotlib-basics#25": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "的 GridSpec 网格布局来自定义更灵活的子图排列。GridSpec 是 matplotlib.gridspec 模块中的一个类，用于细粒度地控制子图所在网格的位置和跨越范围。它的原理是先将整个图形按照指定的行列数划分成更细的网格单元，然后通过指定某个子图占用哪些单元格（可以是一个或多个相邻单元"
  },
  "/content/posts/legacy/01-matplotlib-basics#26": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "网格位置。可以使用 Figure.add_subplot(GridSpec[pos]) 或 plt.subplot(GridSpec[pos]) 来创建子图，其中 pos 可以是类似切片的索引（比如 spec[0, :] 表示第0行所有列）。GridSpec 允许通过切片语法让一个子图跨越多行或多列"
  },
  "/content/posts/legacy/01-matplotlib-basics#27": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "也是细分网格，只不过允许我们自由组合这些网格单元，从而突破了矩阵式布局“每个子图同尺寸”的限制。\n\nGridSpec 优势在于高度的灵活性：我们可以定制子图的相对大小（通过设定 width_ratios 和 height_ratios 参数来调整每列每行的宽度比例），也可以精确控制子图间的间隔（通过"
  },
  "/content/posts/legacy/01-matplotlib-basics#28": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "里，如果用普通的 subplots 是很难直接实现这种布局的，而 GridSpec 则轻松完成。\n\nGridSpec 的劣势主要是使用稍显复杂。相较于 subplots 一行代码生成网格，GridSpec 需要先创建网格规格再逐个添加子图，代码量增加的同时也需要对布局有更清晰的规划。此外，GridS"
  },
  "/content/posts/legacy/01-matplotlib-basics#29": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "但布局一复杂还是直接使用 GridSpec 更直观明了。\n\n3.3 自由布局（add_axes）\n\n除了以上按网格划分区域的方式，有时候我们希望对子图的位置和大小进行完全自由地控制。Matplotlib 提供的底层方法 Figure.add_axes()（或者等价的 plt.axes() 函数）允许"
  },
  "/content/posts/legacy/01-matplotlib-basics#30": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": ".8, 0.8] 就表示在距离图形左边10%、下边10%的位置放置一个宽80%、高80%的子图。\n\n自由布局的最大特点就是灵活性：不拘泥于任何网格，你想把子图放在哪儿、多大，都由你来决定。常见用法之一是在主图中嵌入小图（inset）以展示局部放大细节。这种情形下，小图往往需要精确地放置在主图某个角落"
  },
  "/content/posts/legacy/01-matplotlib-basics#31": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "细节放大图、局部区域对比图，或者在图中某处添加特殊的辅助坐标系（如色彩条、示意图等）时非常有用。\n\n自由布局给予了最大限度的控制，但也意味着需要开发者自己计算和调整位置，因此有一些注意点和不足：首先，所有数值都是相对比例，如果日后更改图形尺寸或者保存为不同大小，可能需要重新调整这些参数以达到理想布局"
  },
  "/content/posts/legacy/01-matplotlib-basics#32": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "表、绘制不规则排版的可视化作品等。当需要完全自定义子图的位置（甚至允许子图区域彼此重叠）时，fig.add_axes() 是唯一的选择。此外，一些Matplotlib附加功能（如双Y轴、极坐标与笛卡尔坐标混合等）背后也是通过自由布局原理实现的。\n\n**优点：**最大程度的灵活，想放哪就放哪，能够实现"
  },
  "/content/posts/legacy/01-matplotlib-basics#33": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "布局调整功能（如 tight_layout 对手动添加的轴作用有限），需要用户自行保证美观对齐。\n\n以上我们介绍了三种 Matplotlib 中常见的子图布局方式：从简单易用的矩阵式布局，到灵活强大的网格布局，再到完全自定义位置的自由布局。在实际绘图中，应根据需求选择合适的方法：规则排列的多子图优先"
  },
  "/content/posts/legacy/01-matplotlib-basics#34": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "、图例等，并给整张图加一个总标题。以下是示例代码（对应 02_figure.py 文件的功能）：\n\n生成的2x2子图布局示例：分别绘制 $\\sin(x)$、$\\cos(x)$、$\\sin(2x)$ 和 $\\sin(x)+\\cos(x)$ 曲线，每个子图都有自己的标题和图例，且共享横轴。总标题显示在顶"
  },
  "/content/posts/legacy/01-matplotlib-basics#35": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "的宽高比。\n* 添加总标题：调用 fig.suptitle(\"Subplots Demo\", ...) 增加了整个图的标题。在本例中我们用了英文，为的是避免中文显示可能遇到的字体问题。如果需要中文标题（例如“多个子图综合示例”），可以在代码开头通过 matplotlib.rcParams 设置中文字"
  },
  "/content/posts/legacy/01-matplotlib-basics#36": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "，我们在中文后加了“曲线”二字，以示该图所表示的是函数曲线；你也可以根据实际内容起更有意义的标题。\n* 图例说明：每个子图我们都调用了 legend(loc='best')。由于我们在 plot 时传入了 label 参数，Matplotlib 会自动创建相应的图例条目。对于只有一条线的子图，图例并"
  },
  "/content/posts/legacy/01-matplotlib-basics#37": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "白用于放置总标题（否则总标题可能会被压缩到看不见）。紧接着 plt.show() 显示最终效果。\n\n运行这段代码，你将得到一个包含4个子图的综合图表。每个子图都有清晰的标题和刻度，底部共享的X轴刻度为 -3.14（-π）到 3.14（π），整体标题位于顶部中央。通过这样的布局，我们可以在一张图中方便"
  },
  "/content/posts/legacy/01-matplotlib-basics#38": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "标轴能够避免观众被不同的刻度迷惑。最后，善用标题和注释，让读者一眼就能抓住重点。\n\n六、统计图形\n\n在数据可视化中，统计图形用于展示数据的分布、比较及关系。本节将介绍 Matplotlib 中几种常用的统计图形，包括散点图、填充图、条形图和直方图的用法。我们将通过示例代码演示如何绘制这些图形，并结合"
  },
  "/content/posts/legacy/01-matplotlib-basics#39": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "点图广泛应用于聚类结果可视化、异常检测等场景，因为它能够直观展示不同组数据的聚集程度和离散情况。\n\n下面的示例代码模拟了两个类别的人群样本数据。我们生成了两个正态分布集群（Group A 和 Group B），并假设每个样本点有三个特征：二维平面坐标 (x, y)、年龄值 age（用于映射颜色）、以"
  },
  "/content/posts/legacy/01-matplotlib-basics#40": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "rbar() 添加的颜色栏，我们可以直观地看到颜色与年龄数值的对应关系。\n\n图4.1：使用 plt.scatter 绘制的散点图示例。图中蓝色圆点和绿色三角分别代表两类不同人群样本（Group A 和 Group B），颜色由年龄特征映射（右侧颜色栏表示年龄大小），点的面积大小也有所区别。可以看出，"
  },
  "/content/posts/legacy/01-matplotlib-basics#41": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "过亮或过暗难以分辨。【注意】如果类别是离散的，可以预先将不同类别映射为固定颜色，而不使用连续色谱。\n* 标记样式 (marker)： 常用的 marker 形状有圆圈 'o'、三角形 '^'、方形 's' 等。选择不同的标记可以区分不同类别，但标记种类不宜过多，避免图形过于杂乱。一般来说，两三种形状"
  },
  "/content/posts/legacy/01-matplotlib-basics#42": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "点的透明度（参数如 alpha=0.7）来缓解遮挡问题，使密集区域的颜色更深，从而辨识分布密度。\n\n散点图在工程上非常有用。例如，在聚类分析中，我们可以将不同簇的样本用不同颜色或形状的散点表示出来，观察簇间的分离情况；在异常检测中，散点图能帮助发现远离主要簇的离群点（outliers）。总之，当我们"
  },
  "/content/posts/legacy/01-matplotlib-basics#43": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "y1 = sin(x) 和 y2 = cos(x/2)/2 两条曲线作为上、下边界，通过 plt.fill_between 将两曲线围成的区域填充颜色，并区分出哪条曲线在上、哪条在下：\n\n在这段代码中，我们通过两次调用 plt.fill_between，分别填充了 y1 在上方和 y2 在上方这两种"
  },
  "/content/posts/legacy/01-matplotlib-basics#44": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "polate=True 参数设为 True，以确保在交点处颜色正确衔接。\n\n图4.2：使用 plt.fill_between 绘制两条曲线之间的填充图示例。黄色曲线为 $y=\\sin(x)$，橙红色曲线为 $y=\\cos(x/2)/2$。淡蓝色区域表示在该区域内 $\\sin(x)$ 曲线高于 $\\c"
  },
  "/content/posts/legacy/01-matplotlib-basics#45": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "区域涂色，直观表示出可能的变化范围。例如，传感器读数的最大值-最小值区间、算法预测的置信区间带等。\n* 在比较两条曲线时，填充它们之间的区域可以突出显示它们的差异。正如上例所示，不同颜色的填充清楚地告诉读者在哪些区间哪条曲线占据更高的值。\n* 可以用于表示不等式解集。例如，对于满足 $f(x) > "
  },
  "/content/posts/legacy/01-matplotlib-basics#46": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "的数据大小。例如，不同产品的销量比较，不同时段的统计值比较等。Matplotlib 提供了 plt.bar 函数来绘制条形图，通过传入类别的位置和对应的值即可绘制出竖直的柱形。在实际应用中，我们经常会需要比较多组数据在相同类别下的差异，例如不同年份、不同类别下若干指标的并列比较。这时，可以采用分组条"
  },
  "/content/posts/legacy/01-matplotlib-basics#47": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "idth 的两个柱子正好以类别中心为对称分布。我们选择 width = 0.4（意味着每个柱子占0.4的单位宽度），柱子之间会留有一定间隔，视觉上更清晰。plt.xticks 用于将数值型的 x 轴刻度替换为我们定义的月份字符串，使读者能够看懂每个柱子对应的类别。\n\n图4.3：分组条形图示例。每个月"
  },
  "/content/posts/legacy/01-matplotlib-basics#48": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "用于这种离散类别下不同组数据的对比分析。\n\n在使用条形图进行多组数据对比时，有以下技巧和注意事项：\n* **分组柱状图的偏移计算：** 如果有更多组数据，需要将它们均匀地分布在该类别位置附近。比如有3组数据时，可以用 x - width, x, x + width 三个位置（或 x - width,"
  },
  "/content/posts/legacy/01-matplotlib-basics#49": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "橘子”）。颜色选择上尽量保持一致的风格，比如都用饱和度相近但色调不同的颜色，避免过于花哨影响阅读。\n* **柱子样式：** 可以通过参数控制柱子的外观，例如 edgecolor='black' 给柱子加黑色边框，让不同柱子之间界线更清晰；alpha 参数可以调整透明度，如果柱子有重叠（如堆叠柱状图的"
  },
  "/content/posts/legacy/01-matplotlib-basics#50": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "确显示中文，需要配置支持中文的字体。例如，可以在代码最前设置 plt.rcParams['font.sans-serif']=['SimHei'] 来指定使用黑体字体（需确保系统已安装），或者使用 matplotlib.font_manager 找到可用的中文字体。配置好字体后，再设置中文标签，就能"
  },
  "/content/posts/legacy/01-matplotlib-basics#51": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "据是否满足某种分布假设（如正态分布）、检测异常值、或为后续处理（如阈值选择、分箱决策）提供依据。\n\n我们通过一个图像像素亮度分布的例子来说明直方图的绘制和参数调节。假设有一幅灰度图像，我们想了解其像素强度值的分布情况。下面的代码首先构造了一幅100×100的人工图像：左半部分像素偏暗（接近灰度值50"
  },
  "/content/posts/legacy/01-matplotlib-basics#52": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "使用 edgecolor='black' 给每个柱加黑色边框，以便在相邻柱子紧贴时仍能分辨边界。\n\n图4.4：图像像素亮度值的直方图。可以看到直方图呈现出双峰特征：一处峰值在大约50附近（对应图像中偏暗的左半部分像素强度），另一处峰值在大约200附近（对应偏亮的右半部分）。Y轴上的高度表示拥有该灰度"
  },
  "/content/posts/legacy/01-matplotlib-basics#53": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "认是10）；也可使用诸如 'auto'、'fd' 等规则让 Matplotlib 自动决定分箱数。\n可以多尝试几个不同的分箱数，选择能够清晰反映分布特征的那一个。同时确保所选的 bins 覆盖了数据的完整范围，必要时可以用 range=(min, max) 明确指定区间范围。\n*  颜色与边框：为了"
  },
  "/content/posts/legacy/01-matplotlib-basics#54": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "ty=True。在统计分析中查看分布形状时，有时使用密度更直观，可以方便地与概率密度函数进行比较。\n*  数据分布形状分析：绘制直方图后，我们可以根据其形状来判断数据分布的特征。例如，单峰且对称的直方图可能表示数据接近正态分布；若峰偏向一侧且尾部拖长，表示分布存在偏态（skewness）；直方图的峰"
  },
  "/content/posts/legacy/01-matplotlib-basics#55": {
    "title": "matplotlib学习笔记",
    "url": "/content/posts/legacy/01-matplotlib-basics",
    "date": "2024-01-01",
    "text": "是基于亮度分布进行像素值映射）。通过直方图了解数据的分布形态，往往是数据分析和特征工程的第一步。\n\n最后需要指出的是，条形图（柱状图）和直方图虽然外观相似，但用途不同：条形图针对分类数据，每根柱子独立表示一个类别的数值；直方图针对连续数据，每根柱子表示一个区间的频数。绘制直方图前通常需要有大量样本数"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#0": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": "使用R-Tree实现2D点去重与可视化优化\n\nR-Tree（矩形树）是一种常用的空间索引数据结构，其原理类似于B树，但针对多维空间进行了优化。R-Tree的基本思想是用**最小外接矩形（MBR, Minimum Bounding Rectangle）**来近似表示数据对象（例如点或多边形）的空间范围"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#1": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": "象及其对应的MBR。节点的容量有限，当插入新对象导致节点满溢时，会触发节点拆分（类似B树的分裂）。\n* 操作效率：得益于其分层的空间划分，R-Tree在平均情况下可以做到查询复杂度为O(log N)（N为对象数量），这远优于线性扫描全部对象。插入和删除操作的平均性能也接近O(log N)。当然，在最"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#2": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": "en:rtree库来创建和操作R-Tree。使用Maven的项目可以通过添加以下依赖来引入该库：\n\n引入依赖后，我们就可以使用R-Tree的数据结构。在这个库中，R-Tree被实现为泛型类，我们可以指定存储对象的类型和几何范围的类型。例如，我们要存储自定义的二维点对象MapPoint，并使用R-Tr"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#3": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": "碰撞区域视为以该点为中心的一个极小的矩形（例如一个零宽度零高度的矩形，或给定半径范围的正方形）。\n\n下面的代码演示了如何向R-Tree中插入若干个MapPoint对象，以及为每个点创建对应的矩形范围。这里为了模拟点的重叠，我们为每个点创建了一个1x1大小的正方形区域（使用Geometries.rec"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#4": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": "界点）。通过这些范围的设置，点3与点1、点2都发生了碰撞（重叠）。\n\n2D点去重与隐藏的算法实现\n\n有了上述数据结构，我们就可以基于R-Tree来实现二维点的去重与隐藏逻辑。问题描述：对于任意两个或多个位置重叠的点，只保留其中ID最大的那个点，其余点标记为隐藏。最后需要输出所有未被隐藏（可见）的点列"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#5": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": "步骤3：遍历完所有点后，所有被标记为隐藏的点将被排除，剩余未被隐藏的点就是最终的可见点集合。\n\n这样的逻辑确保对于每一组重叠在一起的点集合来说，我们最终只会保留其中ID最高的那个点。在实现中，我们需要一个数据结构（例如Set）来记录被隐藏的点ID，然后再过滤原始点列表。\n\n代码实现：下面的代码展示了"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#6": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": "围相交的所有条目。由于我们在创建范围时已经包括了点本身的位置，这个查询结果会至少包含当前点自己。\n\n接下来，我们遍历查询到的冲突点集合，找出其中ID最大的点(maxIdPoint)。如果当前点不是ID最大的那个，那么根据规则它应该被隐藏，我们将其加入pointsToHide集合中。反之，如果当前点就"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#7": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": ")\n* 点3：ID=3，坐标(1.5, 1.5)，范围矩形(1.5,1.5)-(2.5,2.5)\n\n可以看出，点3的范围同时与点1和点2的范围发生了重叠。因此，根据算法，{点1, 点2, 点3}构成了一个重叠集合，其ID最大的点是点3。那么，点1和点2将被标记为隐藏，最终可见的点只有点3（ID=3）"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#8": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": "使用R-Tree后，我们能够将大部分无关的点排除在查询之外，每次查询只遍历那些在空间上相近的点。\n\n对于每个点执行一次范围查询的复杂度平均约为O(log N)，加上遍历冲突点集合的时间。如果空间中点的分布比较均匀且每个点的碰撞范围较小，那么大部分查询只会返回很少的结果，整体算法的平均复杂度接近O(N"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#9": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": "来提升性能。\n\n实际应用场景\n\n上述基于R-Tree的二维点去重与隐藏技术在实际中有多种应用场景：\n* \t大规模地图标注优化：在数字地图或GIS系统中，同一地点可能存在多个兴趣点（POI）标记，或不同层级的数据叠加。在高缩放级别下，这些标记会重叠在一起，造成界面混乱。通过R-Tree索引，我们可以快"
  },
  "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化#10": {
    "title": "使用R-Tree实现2D点去重与可视化优化",
    "url": "/content/posts/legacy/使用r-tree实现2d点去重与可视化优化",
    "date": "2024-09-30",
    "text": "结构也常用于实现碰撞检测和区域查询（比如检索一定范围内的敌人等），这些都与本文介绍的方法异曲同工。\n* \t传感器与监控数据：在物联网或监控系统中，如果多个传感器安装在非常接近的位置，它们报告的数据点可能在地图上重合。通过去重，可以在界面上只保留一个测点，避免重复显示。同时如果引入时间维度，我们也可以"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#0": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "Java RAG 开发环境准备\n\n* 环境验证： 打开终端，运行命令 docker --version 检查 Docker 是否安装成功，会输出版本信息。然后运行官方测试容器：\n\n正常情况下该命令会从 Docker Hub 拉取一个测试镜像并运行，输出类似 “Hello from Docker! T"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#1": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "ompose 文件： 在项目目录下新建文件 docker-compose.yml，填入以下内容：\n\n* 启动服务： 在终端执行 docker compose up -d（或 docker-compose up -d）启动容器。第一次运行会自动下载所需镜像，请耐心等待完成。运行后可用 docker p"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#2": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "drant 默认使用6333端口，访问该地址应显示欢迎页面 ）。如果需要进一步验证，可使用命令：\n\n正常情况下会返回 Qdrant 的健康检查状态信息 JSON。至此，向量数据库 Qdrant 和全文检索引擎 Elasticsearch 的环境已就绪。\n\n3. 安装 Java JDK（推荐版本）和 "
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#3": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "Apache Maven 官网下载二进制发行包手动安装，或者继续使用 Homebrew 安装：\n\n验证 Maven 是否安装成功，运行 mvn -v 将输出 Maven 版本及 Java 环境等信息。如果能看到版本号说明 Maven 配置成功。\n\n注意： 安装完成后，确保 java 和 mvn 命令"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#4": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "ect” -> Spring Initializr。填写项目的基本信息（如 Group 填写com.example，Artifact 填写rag-demo 等）。选择合适的 Spring Boot 版本（建议 3.1+ 或最新版本），项目类型为 Maven 项目。\n* 添加依赖： 在 Initial"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#5": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "rant 向量库的 Starter 依赖。例如，在 <dependencies> 节点中加入： \n\n提示： Spring AI 可能提供了 BOM (Bill of Materials) 进行版本管理，如果有需要也可以引入 Spring AI 的 BOM 来简化依赖版本的管理。但上述直接指定依赖坐标"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#6": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "由于默认开发环境下 Qdrant 没有启用API秘钥认证，这里无需配置 api-key 字段 。\n\n* （可选）配置 Embedding 模型： Spring AI 的向量库使用需要一个 EmbeddingModel 来将文本转换为向量。如果后续需要插入文本并进行相似度搜索，必须配置一个Embedd"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#7": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "odel Bean，用于将文本转为向量，供 Qdrant VectorStore 存储和搜索使用。\n如果没有可用的 OpenAI Key，也可以跳过Embedding模型配置，改为自行实现一个简单的 EmbeddingModel bean（例如返回固定向量用于测试），或暂时直接调用 Qdrant 接"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#8": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "建控制器类： 在 src/main/java 下新建包（如 com.example.ragdemo.controller），创建一个名为 VectorTestController 的类，并添加如下内容：\n\n在上述代码中，我们通过 @Autowired 注入了先前配置的 VectorStore（Spr"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#9": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "这里我们使用查询词“向量检索示例”，因为它与插入的示例文本在语义上接近，理应检索出我们插入的文档。\n注意： 若之前未配置 EmbeddingModel，这一步在运行时会报错（因为无法将文本转换为向量）。确保已按照前述步骤配置 OpenAI 或其他 Embedding 模型。如果不使用文本生成向量，也"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#10": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "nes 或 Snapshots 仓库源，或者直接通过 Spring AI BOM 管理依赖版本。\n\n完成控制器编写后，项目代码方面的准备就绪。最后一步是启动应用并验证整个流程。\n\n6. 启动应用并验证整条链路\n\n现在我们启动 Spring Boot 应用程序，以及已经运行的 Elasticsearc"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#11": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "RagDemoApplication in [time] seconds 则表示服务已成功启动。\n\n* 验证服务接口： 打开浏览器访问 http://localhost:8080/test-vector （假设 Spring Boot 默认端口未修改仍为8080）。该请求会触发我们在 VectorT"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#12": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "量数据库完成存储和检索，全链路通畅。\n\n* 检查各组件状态： 若接口未正常返回，需检查以下几方面：\n  * 应用日志： 查看 Spring Boot 控制台日志，有无连接 Qdrant 的错误（如找不到主机或端口）。若有，确认 Docker Compose 中 Qdrant 容器是否在运行，端口映射"
  },
  "/content/posts/legacy/2-java-rag-开发环境准备#13": {
    "title": "Java RAG 开发环境准备",
    "url": "/content/posts/legacy/2-java-rag-开发环境准备",
    "date": "2025-04-30",
    "text": "API Key 是否正确配置且未过期；或者自定义的 EmbeddingModel 实现是否注入。\n  * Elasticsearch 容器： 本示例未直接使用 ES，但在实际RAG中ES通常用于存储索引文本。如果需要也可以类似方式写一个简单测试（如使用 RestHighLevelClient 索引一"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#0": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践\n\n在 RAG 系统中，可以在不同阶段对用户的提问进行敏感内容检测。常见的四个关键时间点及其优劣对比如下：\n1.\t用户输入阶段（前置检测）：在用户提交问题的瞬间立即进行敏感词过滤。这种方式最大的优点是即时性，可以第一时间拦截违规提问，避"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#1": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "但总体而言，前置检测可以将风险扼杀在源头，是最直接有效的方案 。本方案也是本文重点推荐的策略。\n2.\t知识检索前检测：在接收到用户输入后、执行 RAG 检索之前进行检测。它与前置检测在流程上仅一步之隔，如果未在输入阶段拦截，可以在向向量数据库或检索库查询之前再做一次检查。这样做依然能避免不必要的后续"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#2": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "检测可以补充前置策略的不足。然而，如果可以在更早的输入阶段检测，通常没有必要等到检索前才拦截。\n3.\tLLM生成前检测：在检索到相关知识文档后、发送给大型语言模型生成回答之前进行检测。此时系统已经完成了向量检索、文档获取等工作，再检查一次提问（或连同检索结果一并检查）是否包含敏感内容。这样做的劣势在"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#3": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "。总体而言，将检测放在生成前并不是理想方案，因为用户已经等待了较长时间，而最终仍然得不到回答。\n4.\t模型生成后审核（输出后审核）：在 LLM 给出回答之后，对回答内容进行审核过滤。这属于后置审核，常用于补充前置策略，确保最终输出没有违规信息。对于聊天机器人而言，输出审核可以拦截模型试图生成的不良内"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#4": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "并不排除在最终输出处再加一道审核保险，但前置拦截应作为第一道防线。\n\n敏感词词表的设计与维护方法\n\n要实现前置敏感词检测，一个高质量的敏感词词库至关重要。词库的设计需要考虑格式、匹配策略以及维护更新机制：\n* 词表格式与结构：敏感词库通常采用结构化的格式存储，便于程序快速加载和查询。可以使用文本文件"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#5": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "\": \"高\"}。词表加载后通常会转换为方便查询的数据结构（比如哈希集合或前缀树），以支持高效匹配。\n* 分类标签与策略：为词表中的敏感词打上分类标签，可以帮助系统根据不同类别采取不同策略。例如，金融违法类（内幕消息、操纵市场等）一旦匹配直接拒答；不当言论类（辱骂、骚扰等）可以提示用户文明用语；隐私数"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#6": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "回复。然而，分类仍有意义：它方便后续统计分析哪些类别的违规咨询最常出现，以及在日志中明确拦截原因。\n* 模糊匹配与正则支持：用户往往会想方设法绕过简单的敏感词匹配，例如使用同音字、变形拼写、符号替换甚至拼音等手段。为提高检出率，词库设计需要考虑模糊匹配策略。常见做法包括：加入同义词和常见变体（例如“"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#7": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "减少漏网之鱼。当然，这也需要权衡性能开销，必要时可借助算法优化（如 AC 自动机）提升匹配效率 。\n* 词库的维护更新（人工 + 自动）：敏感词列表不是一成不变的，而需要随着业务和违规手段的演进不断更新。一方面，需要有人工运营/安全团队定期审查词库，增删调整词条。例如监管机构可能颁布新的禁止事项，或"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#8": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "上验证新词库的效果，避免误伤正常用户。总之，只有持续的维护迭代，敏感词词表才能真正发挥长期作用。\n\n工业界常用基于 Trie字典树/AC自动机 的算法来实现高性能的敏感词匹配服务。这种算法能够在构建含所有敏感词的自动机后，以近似线性的时间复杂度扫描输入文本，找出其中出现的所有敏感关键词。对于词库规模"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#9": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "交给大语言模型生成答案 → 返回答案给用户。我们要在这个链路中加入敏感词拦截，可以这样改造：\n\n1.\t插入前置拦截节点：在用户提问进入检索组件之前，增加一个敏感词检测节点。这个节点接收用户输入文本，利用前述的词表和匹配算法进行检测。\n2.\t判断是否违规：如果检测节点发现输入中包含受保护的敏感词或命中"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#10": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "提及了不应提供的信息（这通常针对输出中的敏感、违规内容，属于另一层面的安全检查，不是本文重点）。\n\n上述流程确保了当用户提出非法咨询时，系统会短路掉主要流程，既保障了响应及时，又避免了模型可能产生不良回答。从系统结构上看，这种实现相当于给 RAG pipeline 加了一层Gate（闸门）。只有输入"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#11": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "LangChain、Haystack 等现成框架的项目，也可以在调用链之前手动加这一判断逻辑。\n\n* 链路中集成拦截节点：如果希望将逻辑整合到 RAG 流程内部，可以自定义一个链（Chain）或工具（Tool）用于敏感词检测，然后将其插入到多步骤流程中。例如在 LangChain 中，可以创建一个自"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#12": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "中间件函数。我们可以利用这种机制在进入主要逻辑前进行敏感词过滤。例如 `LangChain 0.0.**` 系列提供了 Runnable 序列功能，可以将多个步骤用管道拼接。我们可以将敏感词检测封装为一个 Runnable，在管道最前面执行 。如果结果显示不通过，则管道直接输出预设响应；如果通过，则"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#13": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "为您提供帮助。” 这样的回应既礼貌又坚定，既向用户传达了无法服务的原因，也避免透露任何多余信息。\n\n值得一提的是，除了自建敏感词拦截机制，一些现有的大模型内容安全方案也可以在输入阶段发挥作用。例如 Meta 的 LlamaGuard 等工具，可以对用户输入进行有害内容检测 。这些通用方案可以作为辅助"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#14": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "问答链（如 RetrievalQA）以及相应的向量检索器和 LLM，重点在于插入敏感词过滤逻辑。\n\n上述代码首先定义了一个简单的敏感词列表和检测函数contains_sensitive。实际应用中，这个函数可以扩展为支持正则、大小写忽略、谐音转换等复杂匹配逻辑，并可从外部配置加载词库。然后，我们构建"
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#15": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "unnableLambda 或自定义 Chain 将上述逻辑封装，使之成为流水线的一部分。例如：\n\n以上片段中，我们构建了一个 filter_runnable，当输入含敏感词时直接输出固定回复，否则原样返回输入。然后利用 RunnableSequence 将过滤和QA链串联成流水线。需要注意，如果 "
  },
  "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践#16": {
    "title": "RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践",
    "url": "/content/posts/legacy/rag-系统中的敏感词防护策略-从前置检测到即时拦截的全链路实践",
    "date": "2024-10-19",
    "text": "场景的智能投顾系统筑起了一道坚实的安全屏障，在保障合规的同时也提升了系统效率和用户体验。\n\n结语\n\n在大型语言模型赋能的金融智能投顾应用中，内容安全与合规性是不容忽视的重点。本文通过“RAG 系统中的敏感词防护策略：从前置检测到即时拦截的全链路实践”这一主题，详细探讨了如何在系统中部署敏感词过滤机制"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#0": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "OpenAI、Deepseek模型横向对比\n\n性能与推理能力：据公开测试，GPT-4o的综合表现比之前的GPT-4更上一层楼。在Chatbot评测Arena(LMArena)基准上，最新的GPT-4o模型（2025年3月版本）已经跃升到榜单第二名，甚至超过了上个月推出的GPT-4.5 。相较于年初时"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#1": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "来说，GPT-4o的API费用每百万Token输入约2.5美元，输出约10美元 （相对于GPT-4.5那高达75美元/百万Token的输入费用，可谓良心价了 ）。\n\n上下文长度：GPT-4o延续了GPT-4的长上下文窗口，支持最大约32K Tokens的上下文。这意味着它可以处理相当长的文本输入，在"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#2": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "、解释图表甚至读手写字。但需要注意，多模态功能通常只向付费用户开放，而且对图像内容也有一些限制。\n\n工具使用：在GPT-4o时代，ChatGPT已经支持插件、代码执行和联网浏览等功能。不过GPT-4o本身还并非一个“自主代理型”模型，它是否使用工具主要取决于我们是否调用相应插件或API功能。例如，在"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#3": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "查资料或算代码。这一点在后面会看到，OpenAI更新的o系列才真正实现了AI主动调用工具的能力。\n\n特别版：GPT-4o Tasks：值得一提的是，OpenAI基于GPT-4o还推出了一个带“已安排任务”能力的特殊版本。这可以看作是GPT-4o的一个细化应用：让ChatGPT变身为你的“24小时智能"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#4": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "说，GPT-4o Tasks功能标志着ChatGPT开始迈向智能代理的新阶段，拥有了一点自动化“魔法”。对于需要定时提醒、后台运行任务的场景，这个版本非常实用。\n\n总结GPT-4o：作为GPT-4的优化版，GPT-4o在保持原有强大通用能力的同时，实现了更强的推理表现和更高的响应效率，成本也降下来了"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#5": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "PT-4.5的特点。\n\n模型规模与能力：GPT-4.5据推测拥有2~3万亿参数，比GPT-4的约1.7万亿参数大了不少 。如此庞大的规模，使它在一些方面展现出更胜以往的能力。OpenAI CEO Sam Altman兴奋地表示：“这是第一个让人感觉像在和有思想的人对话的模型” 。换句话说，GPT-4"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#6": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "评显示，GPT-4.5在ARC、AGI评估等基准中的表现与GPT-4o旗鼓相当 。这说明GPT-4.5并不是全面碾压前代，它更像是在某些方面做加法（更大的知识面、更自然的对话），但在严格逻辑推理上并没有质变。因此，GPT-4.5的定位有点类似“参数怪兽”，擅长大而全的知识和创意生成，但如果让它老老实"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#7": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "来说，这个价格几乎是劝退的。需要说明的是，ChatGPT网页端并未直接向Plus用户提供GPT-4.5模型（Plus用户默认用的是GPT-4o系列）。GPT-4.5更多是通过API和专门的高端订阅（比如传闻中的ChatGPT Pro每月200美元档）提供。如果你不是特别需求GPT-4.5的长处，其实"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#8": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "中，GPT-4.5没有因为“变胖”而明显拖慢节奏。\n\n上下文和多模态：得益于庞大的架构，GPT-4.5的上下文窗口进一步扩大。有推测称它的上下文长度达到了64K tokens左右 （虽然OpenAI官方未明说，但从技术趋势看可能性很大）。这意味着GPT-4.5可以吃下超长文档而不丢信息，对于需要处理"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#9": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "方面的飞跃，正是留给后面要讲的o3模型。\n\n总结GPT-4.5：作为一款“超大杯”模型，GPT-4.5提供了极高质量的对话体验，知识面更广且回复更贴近真人，对内容创作、复杂写作需求表现出色。如果你在意的是输出文字的自然度、丰富度，以及偶尔需要非常长的上下文处理，GPT-4.5是理想选择。但它的性价比"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#10": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "-4.x系列有显著区别，主要在于引入了更深的思考链和自主工具使用。让我们逐项看看o3的厉害之处。\n\n推理能力：o3的最大卖点就是超强的推理和分析能力。OpenAI在开发o3时，采用了一套新的训练范式，鼓励模型在作答前“深度思考更久”。可以理解为，o3在内部会进行更长的推理链条，权衡不同解法，直到找到"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#11": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "的伙伴，尤其擅长在生物学、数学、工程等场景中提出新颖见解 。这些都印证了o3作为推理之王的地位。\n\n工具调用与Agent能力： o3实现了一个里程碑式的功能：能够自主使用并组合ChatGPT内的所有工具  。这是以前的GPT-4等模型所不具备的。具体来说，o3在回答你的问题时，如果觉得需要，可以自主"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#12": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "们第一次体验到了ChatGPT有点像“自己会上网查资料、动手实验”的感觉，解决问题更加精准高效。\n\n多模态与视觉推理：o3在多模态上的能力也达到新的高度。OpenAI特别强调，o3不仅能看图, 而且会“把图像融入思考过程” 。也就是说，给o3一张图，它不会只浅层描述，而是可以将图像作为推理的一部分，"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#13": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "3可以被视为一个视觉分析专家，以前许多需要人眼和大脑配合才能解决的问题，现在o3也能独立完成了。\n\n速度与效率：如此强大的o3，运行效率如何呢？OpenAI在训练中采用了大规模强化学习来强化模型推理路径，同时通过让模型思考更久来换取性能提升 。他们发现，允许模型花更多计算步骤思考，确实能持续提高答案"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#14": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "要低一些（据社区消息，o3输入每百万token约10美元，输出40美元左右 ），性价比反而更优。\n\n使用门槛：目前o3已经向ChatGPT Plus、Pro和团队版用户开放试用，API也同步上线 。老一代的o1模型被新模型取代，企业版和教育版用户也会逐步获得o3的使用权限 。需要注意的是，由于o3功"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#15": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "，用于更高精度需求场景 。总的来说，o3现阶段主要面向付费深度用户和开发者，用于攻坚高难度任务。\n\n总结OpenAI o3：o3堪称OpenAI目前的巅峰之作，尤其在复杂推理、多工具协同解决问题方面树立了新标杆。它将ChatGPT带入“自己会上网查资料做实验”的新时代，对于科研、工程、商业分析等高要"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#16": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "面媲美大模型。可以把o4-mini理解为前述o系列的“轻量版”，用更少的资源跑出令人惊艳的成绩。\n\n性能与推理：o4-mini的表现远超一般预期。在一些基准测试中，它的成绩令人眼前一亮。举例来说，在美国数学竞赛AIME的2024和2025测试中，o4-mini获得了接近满分的成绩（2025题目在有P"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#17": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "类任务上表现尤为突出 。这些通常也是需要逻辑推演的任务类型，说明OpenAI对o4-mini的调教非常到位，让它在擅长领域发挥出最大实力。\n\n速度与成本：作为“mini”模型，o4-mini的推理速度更快、延迟更低。对于需要大批量调用的业务来说，这点至关重要。OpenAI透露o4-mini支持的使用"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#18": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "ni就是奔着降本增效去的。如果你有成千上万条请求需要AI处理，o4-mini会是非常经济的选择。\n\n上下文与多模态：o4-mini在上下文长度和多模态上也保持了与大模型看齐的能力。虽然具体上下文大小未明确公布，但可以推测至少在8K到16K Token级别，不会比前代的3.5差。另外，o4-mini同"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#19": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "推理方面表现极佳。可能因为小模型反而可以更快地尝试多种对图像的解读，加上工具辅助，从而效果更好。\n\n工具使用：不要以为只有o3会自己用工具，o4-mini同样具备完整的工具使用能力。OpenAI通过强化学习，让o4-mini也学会了何时调用浏览器、何时运行Python、何时生成图像等 。在这方面，o"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#20": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "，从而提高答案准确率。在官方评测中，o4-mini-high在代码编辑任务上的整体准确率达到约68.9%，相比标准模式有明显提升 。对于要求高严谨度的应用，启用high模式可以让小模型迸发大智慧。当然，high模式会稍微降低响应速度和增加计算成本，但在可控范围内。ChatGPT界面中可能把o4-mi"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#21": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "（解决复杂问题）。而o4-mini-high则像加装了涡轮增压，在需要时爆发更强动力。所以在OpenAI的产品线上，o4-mini系列扮演了一个非常务实的角色：用更小的模型覆盖80%的需求，只有剩下20%再交给旗舰模型处理。这一战略也难怪会受到开发者的欢迎。\n\nDeepSeek R1：开源阵营的有力"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#22": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "式免费开放，并且运行成本只是商业模型的零头。下面我们具体看看DeepSeek R1的定位和实力。\n\n模型能力：DeepSeek R1专注于高级推理能力的打磨。它的开发团队在先前自研的大模型基础上，引入大规模强化学习技术，对模型进行后期训练，提高其在数学、代码、逻辑推理方面的水平 。结果非常惊人：官方"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#23": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "R1代表了开源社区向OpenAI这类巨头发起挑战的实力——“我们用开源也能做出不输你的模型”。\n\n推理与工具使用：作为推理导向的模型，DeepSeek R1擅长一步步思考、给出连贯的推理过程。事实上，DeepSeek R1在其API中直接开放了模型的思维链（Chain-of-Thought）输出 。"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#24": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "主要还是在对话中给出详尽的推理步骤和答案，对于数学证明、代码生成这种需要多步推导的任务尤为拿手。\n\n性能与速度：DeepSeek R1的基础模型参数量非常庞大，据透露在千亿级别以上（有消息称达6600亿参数，是混合专家架构） 。如此大的规模在推理时自然需要强劲的算力支持。不过DeepSeek官方也提"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#25": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "eek可能只要几美分。当然，这种比较可能针对的是开发者API价，而如果你自己有硬件，跑R1模型除了电费几乎不要钱。总之，成本优势是DeepSeek R1最大卖点之一。借助开源的力量，大家可以以极低代价使用顶级模型能力，这对整个行业都是良性推动。\n\n多模态与局限：目前的DeepSeek R1主要训练在"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#26": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "eepSeek V3等版本升级），社区也在围绕R1构建生态。这些都让人对开源模型的未来充满期待。\n\n总结DeepSeek R1： DeepSeek R1作为开源界的扛鼎之作，用实际表现证明了“开源也能卷赢商业”。它在推理任务上的表现直逼OpenAI顶级模型，但使用成本却低得多 。对于那些希望自主掌控"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#27": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "谈谈如何在不同场景下做选择。根据以上分析，每个模型都有自己的长处和适用面，下面是一些建议供参考：\n\n- 日常通用对话与问答：如果你需要一个全能而高效的助手来回答各种问题，GPT-4o 是首选。它具有强大的综合能力，响应速度和成本也都令人满意。相较之下，GPT-4.5虽然更“聪明”一点点，但代价过高，"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#28": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "模型目前还没有类似的官方定时功能。所以凡是带有时间表、重复任务的场景，果断用GPT-4o任务模式。\n- 复杂推理、多步骤问题：比如写代码调试、数学证明、商业决策分析这种高难度问题，推荐使用 OpenAI o3。它拥有最强的推理深度，还能自主调用工具来查资料和计算，等于是给你配了一个会上网和编程的超级"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#29": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "管。这种“梯度使用”可以极大降低开销。总之，需要跑量的应用场景下，o4-mini的性价比无出其右。\n- 视觉相关任务：如果你的需求涉及图像（识图、看图回答、解析截图内容等），那么o4-mini-high 可能是最佳选项。根据实测，o4-mini在视觉推理上甚至比o3表现更好 。使用high模式还能进"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#30": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "用GPT-4.5尝尝鲜。\n- 创意写作和情感交流：如果你在意AI的文笔、创意和情绪理解，GPT-4.5相对更擅长这方面。比如写小说大纲、设计剧本对白、做心理疏导聊天，GPT-4.5因为“情商”更高，输出会更贴近人类思维，有时甚至让人怀疑背后是不是坐了个人。但请记住这是建立在它庞大参数和训练的基础上，"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#31": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "合那些有一定机器学习能力储备的团队，用它可以省下巨额的API费用，同时打造一个量身定制的AI助手。\n- 数学、代码等理科场景：在这些场景下，DeepSeek R1的表现几乎不输OpenAI最强模型，却几乎免费 。所以如果你的应用主要是解数学题、代码自动化、算法验证这类，相信我，用R1你不会失望。从简"
  },
  "/content/posts/legacy/openai-deepseek模型横向对比#32": {
    "title": "OpenAI、Deepseek模型横向对比",
    "url": "/content/posts/legacy/openai-deepseek模型横向对比",
    "date": "2025-04-21",
    "text": "1的方案，省去了繁琐配置。所以理工科领域的开发者非常乐于尝试R1，称它为“开源免费的最强大脑”。\n\n没有万能的模型，只有合适的模型。OpenAI的GPT-4o系列和o系列在闭源领域一路领先，不论是顶尖的o3还是高效的o4-mini，都提供了不同层次的选择，让用户在性能和成本之间找到平衡。而开源的De"
  },
  "/content/posts/2026/ai-assistant-rag#0": {
    "title": "Building a RAG-Powered AI Assistant for My Personal Website",
    "url": "/content/posts/2026/ai-assistant-rag",
    "date": "2026-01-28",
    "text": "Building a RAG-Powered AI Assistant for My Personal Website\n\nI recently added an AI chat assistant to my personal website that can answer questions ab"
  },
  "/content/posts/2026/ai-assistant-rag#1": {
    "title": "Building a RAG-Powered AI Assistant for My Personal Website",
    "url": "/content/posts/2026/ai-assistant-rag",
    "date": "2026-01-28",
    "text": "ration)\n- Provides friendly technical discussions\n- Handles sensitive topics gracefully\n- Works entirely on static hosting (GitHub Pages) with Cloudfl"
  },
  "/content/posts/2026/ai-assistant-rag#2": {
    "title": "Building a RAG-Powered AI Assistant for My Personal Website",
    "url": "/content/posts/2026/ai-assistant-rag",
    "date": "2026-01-28",
    "text": "re injected dynamically, no external dependencies\n- **ESC to close**: Keyboard accessibility\n- **Mobile responsive**: Adapts to screen size\n\n2. Hybrid"
  },
  "/content/posts/2026/ai-assistant-rag#3": {
    "title": "Building a RAG-Powered AI Assistant for My Personal Website",
    "url": "/content/posts/2026/ai-assistant-rag",
    "date": "2026-01-28",
    "text": "at widget reuses this existing infrastructure:\n\n3. Cloudflare Worker (API Proxy)\n\nThe Worker handles two endpoints:\n\n**`/api/embedding`** - Converts q"
  },
  "/content/posts/2026/ai-assistant-rag#4": {
    "title": "Building a RAG-Powered AI Assistant for My Personal Website",
    "url": "/content/posts/2026/ai-assistant-rag",
    "date": "2026-01-28",
    "text": "ystem prompt (stored as environment variable):\n\n5. Conversation History with localStorage\n\nFor better UX, the chat widget persists conversation histor"
  },
  "/content/posts/2026/ai-assistant-rag#5": {
    "title": "Building a RAG-Powered AI Assistant for My Personal Website",
    "url": "/content/posts/2026/ai-assistant-rag",
    "date": "2026-01-28",
    "text": "button**: Manual clear via trash icon in header\n\nThis is a pragmatic choice over server-side storage (Cloudflare KV) because:\n- Most visitors have one"
  },
  "/content/posts/2026/ai-assistant-rag#6": {
    "title": "Building a RAG-Powered AI Assistant for My Personal Website",
    "url": "/content/posts/2026/ai-assistant-rag",
    "date": "2026-01-28",
    "text": "lows prompt iteration without code deployment.\n\n2. **Reuse existing search infrastructure**: Building RAG on top of an existing hybrid search system s"
  },
  "/content/posts/2026/ai-assistant-rag#7": {
    "title": "Building a RAG-Powered AI Assistant for My Personal Website",
    "url": "/content/posts/2026/ai-assistant-rag",
    "date": "2026-01-28",
    "text": "r bold and links. No need for heavy libraries.\n\n5. **Start simple with state management**: localStorage is sufficient for conversation history. Server"
  },
  "/content/posts/2026/ai-assistant-rag#8": {
    "title": "Building a RAG-Powered AI Assistant for My Personal Website",
    "url": "/content/posts/2026/ai-assistant-rag",
    "date": "2026-01-28",
    "text": "thly cost: < $5 for moderate traffic\n\nNext Steps\n\n- [ ] Add streaming responses for better UX\n- [x] ~~Implement conversation memory~~ (Done with local"
  },
  "/content/posts/2026/staticflow-engineering-en#0": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "One Night of Vibe Coding: Migrating Static Site Generator to Deno\n\nStarted last night, finished today. One night of vibe coding, and I've successfully"
  },
  "/content/posts/2026/staticflow-engineering-en#1": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "some external program dependencies\n\nWhy Migrate?\n\nI've been using my own shell script-based static blog generator (powering yuxu.ge) for a while, and "
  },
  "/content/posts/2026/staticflow-engineering-en#2": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "ll all these? Unacceptable.\n\nDeno Migration Plan\n\nThe goal is clear:\n\nFeature parity with Astro/Gatsby. UX parity with Hugo.\n\nWhy Deno\n\nGenerates a si"
  },
  "/content/posts/2026/staticflow-engineering-en#3": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "ntrols everything.\n\nUnified Configuration Design\n\nFrontend reads config via `features.json` to dynamically enable/disable feature modules:\n\nDeployment"
  },
  "/content/posts/2026/staticflow-engineering-en#4": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "n cloning and copying files.\n\nSolution: Worktree\n\nGit Worktree allows checking out multiple branches to different directories in the same repo:\n\nNow `"
  },
  "/content/posts/2026/staticflow-engineering-en#5": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "omatically detect and setup on first deploy:\n\n**3. setupDeploy implementation**\n\n**4. Skip .git during build**\n\nCritical: Must skip `.git` when copyin"
  },
  "/content/posts/2026/staticflow-engineering-en#6": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "rkdown, Jupyter Notebook, LaTeX, Office documents\n- **Hybrid search** - BM25 keyword + Voy vector semantic search (WASM)\n- **AI chat assistant** - RAG"
  },
  "/content/posts/2026/staticflow-engineering-en#7": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "e to WASM, embedding into a single ~15MB binary.\n\nFor example, HEIC decoding: plan to trim libde265 (HEVC decoder) from 50K lines of C code to 15K lin"
  },
  "/content/posts/2026/staticflow-engineering-en#8": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "of file copying\", AI suggests worktree approach\n2. **Incremental iteration** - Implement basic functionality first, optimize after tests pass\n3. **Imm"
  },
  "/content/posts/2026/staticflow-engineering-en#9": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "s Learned\n\n1. Compiled binary needs regeneration\n\nAfter code changes, `staticflow` command still runs old version:\n\nI configured auto-deletion of old "
  },
  "/content/posts/2026/staticflow-engineering-en#10": {
    "title": "One Night of Vibe Coding: Migrating Static Site Generator to Deno",
    "url": "/content/posts/2026/staticflow-engineering-en",
    "date": "2026-02-03",
    "text": "Open source release coming soon! Stay tuned 🔜\n\n*#Deno #TypeScript #StaticSiteGenerator #VibeCoding #OpenSource*"
  },
  "/content/posts/2026/geocoding-client#0": {
    "title": "Building a Production-Ready Geocoding Client: Coordinate Hacks, Connection Pools, and Rate Limiting",
    "url": "/content/posts/2026/geocoding-client",
    "date": "2026-01-26",
    "text": "Building a Production-Ready Geocoding Client: Coordinate Hacks, Connection Pools, and Rate Limiting\n\nGeocoding looks simple: send an address, get coor"
  },
  "/content/posts/2026/geocoding-client#1": {
    "title": "Building a Production-Ready Geocoding Client: Coordinate Hacks, Connection Pools, and Rate Limiting",
    "url": "/content/posts/2026/geocoding-client",
    "date": "2026-01-26",
    "text": "e seen each of these take down production systems. This article shows how to build a geocoding client that handles all three.\n\nArchitecture Overview\n\n"
  },
  "/content/posts/2026/geocoding-client#2": {
    "title": "Building a Production-Ready Geocoding Client: Coordinate Hacks, Connection Pools, and Rate Limiting",
    "url": "/content/posts/2026/geocoding-client",
    "date": "2026-01-26",
    "text": "—which applies a non-linear offset to every point. This isn't a simple translation; it's a deliberate obfuscation involving trigonometric functions th"
  },
  "/content/posts/2026/geocoding-client#3": {
    "title": "Building a Production-Ready Geocoding Client: Coordinate Hacks, Connection Pools, and Rate Limiting",
    "url": "/content/posts/2026/geocoding-client",
    "date": "2026-01-26",
    "text": "ap is wrong.\"\n\nThe Solution: Iterative Inversion\n\nThe GCJ-02 transformation has no closed-form inverse. We solve it numerically:\n\n1. Guess that WGS-84"
  },
  "/content/posts/2026/geocoding-client#4": {
    "title": "Building a Production-Ready Geocoding Client: Coordinate Hacks, Connection Pools, and Rate Limiting",
    "url": "/content/posts/2026/geocoding-client",
    "date": "2026-01-26",
    "text": "geocoding request creates a new TCP connection:\n\nAt 500 QPS, this creates 500 connections per second. Each closed connection enters TIME_WAIT state fo"
  },
  "/content/posts/2026/geocoding-client#5": {
    "title": "Building a Production-Ready Geocoding Client: Coordinate Hacks, Connection Pools, and Rate Limiting",
    "url": "/content/posts/2026/geocoding-client",
    "date": "2026-01-26",
    "text": "lution: Connection Pooling + Exponential Backoff\n\nReplace stateless requests with a persistent session that reuses TCP connections:\n\n**Connection pool"
  },
  "/content/posts/2026/geocoding-client#6": {
    "title": "Building a Production-Ready Geocoding Client: Coordinate Hacks, Connection Pools, and Rate Limiting",
    "url": "/content/posts/2026/geocoding-client",
    "date": "2026-01-26",
    "text": "es—then return HTTP 429 for the rest of the day.\n\nThe Solution: Token Bucket Rate Limiting\n\nThe token bucket algorithm enforces average rate while tol"
  },
  "/content/posts/2026/geocoding-client#7": {
    "title": "Building a Production-Ready Geocoding Client: Coordinate Hacks, Connection Pools, and Rate Limiting",
    "url": "/content/posts/2026/geocoding-client",
    "date": "2026-01-26",
    "text": "s. The code above handles all three.\n\nNext Steps\n\n- **Multi-provider failover**: Route to backup API on errors\n- **Response caching**: Addresses rarel"
  },
  "/content/posts/2026/hybrid-search-static-blog-zh#0": {
    "title": "静态博客的混合搜索方案：BM25 + 向量检索 + Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog-zh",
    "date": "2026-01-26",
    "text": "静态博客的混合搜索方案：BM25 + 向量检索 + Cloudflare Workers\n\n静态网站生成器很好用，直到你需要搜索功能。大多数方案要么需要后端服务器，要么只能做简单的客户端文本匹配。本文介绍如何构建一个**混合搜索系统**——结合即时 BM25 关键词匹配和语义向量搜索，同时保持网站完"
  },
  "/content/posts/2026/hybrid-search-static-blog-zh#1": {
    "title": "静态博客的混合搜索方案：BM25 + 向量检索 + Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog-zh",
    "date": "2026-01-26",
    "text": "过滤停用词\n- **中文**：字符单元 + 二元组（无需分词库）\n\n调用 OpenAI 获取向量\n\n**为什么选择 512 维？** OpenAI 的 text-embedding-3-small 支持降维。使用 512 而非 1536 维可以减少约 65% 的索引体积，质量损失极小。\n\nEmbed"
  },
  "/content/posts/2026/hybrid-search-static-blog-zh#2": {
    "title": "静态博客的混合搜索方案：BM25 + 向量检索 + Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog-zh",
    "date": "2026-01-26",
    "text": "ge/api/*` → 你的 Worker\n3. 设置环境变量：`OPENAI_API_KEY`\n\n现在前端调用 `/api/embedding` 接口，永远不会暴露 API 密钥。\n\n第三部分：混合搜索客户端\n\n魔法发生在浏览器端。我们并行运行两种搜索：\n\n为什么选择 Reciprocal Ran"
  },
  "/content/posts/2026/hybrid-search-static-blog-zh#3": {
    "title": "静态博客的混合搜索方案：BM25 + 向量检索 + Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog-zh",
    "date": "2026-01-26",
    "text": "两者优势：\n- **精确匹配** via 关键词搜索（搜\"Docker\"立即找到\"Docker\"）\n- **语义匹配** via 向量搜索（搜\"容器安全\"也能找到 Docker 文章）\n\n部署清单\n\n1. **构建索引**：`OPENAI_API_KEY=sk-xxx node scripts/in"
  },
  "/content/posts/2026/hybrid-search-static-blog-zh#4": {
    "title": "静态博客的混合搜索方案：BM25 + 向量检索 + Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog-zh",
    "date": "2026-01-26",
    "text": "**质量**：语义搜索理解用户意图\n- **成本**：只为实际搜索请求付费，无需服务器运行费用\n\n完整源代码：github.com/geyuxu/yuxu.ge\n\n*技术栈：OpenAI text-embedding-3-small、Voy WASM、Cloudflare Workers、原生 Ja"
  },
  "/content/posts/2026/multi-language-translation-zh#0": {
    "title": "为博客添加多语言 AI 翻译功能",
    "url": "/content/posts/2026/multi-language-translation-zh",
    "date": "2026-01-28",
    "text": "为博客添加多语言 AI 翻译功能\n\n在实现了 RAG 驱动的 AI 助手之后，我希望让博客内容能被全球读者访问。与其手动翻译每篇文章，我构建了一个按需 AI 翻译系统，支持 10 种语言。\n\n目标\n\n创建无缝的翻译体验：\n- 按需将任何博客文章翻译成 10 种主要语言\n- 保留 Markdown 格"
  },
  "/content/posts/2026/multi-language-translation-zh#1": {
    "title": "为博客添加多语言 AI 翻译功能",
    "url": "/content/posts/2026/multi-language-translation-zh",
    "date": "2026-01-28",
    "text": "处理翻译请求：\n\n5. 智能语言检测\n\n前端自动检测原始语言以设置正确的默认值：\n\n关键设计决策\n\n1. **翻译 Markdown 而非 HTML**：在可用时，我翻译原始 Markdown 源码并重新渲染。这比翻译渲染后的 HTML 能更好地保留格式。\n\n2. **低温度值（0.3）**：翻译需"
  },
  "/content/posts/2026/multi-language-translation-zh#2": {
    "title": "为博客添加多语言 AI 翻译功能",
    "url": "/content/posts/2026/multi-language-translation-zh",
    "date": "2026-01-28",
    "text": "月不超过 $5。\n\n未来改进\n\n- [ ] 构建时预翻译热门文章\n- [ ] 为长文章添加流式传输\n- [ ] 支持 RTL 语言（阿拉伯语）的正确 CSS\n- [ ] 添加翻译质量反馈\n\n完整实现在我的网站仓库中。"
  },
  "/content/posts/2026/hybrid-search-static-blog#0": {
    "title": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog",
    "date": "2026-01-26",
    "text": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers\n\nStatic site generators are great until you need search. Most so"
  },
  "/content/posts/2026/hybrid-search-static-blog#1": {
    "title": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog",
    "date": "2026-01-26",
    "text": "tic.\n\nThe Architecture\n\n**Key design decisions:**\n- **No backend required** - everything runs in the browser or edge\n- **API key protection** - OpenAI"
  },
  "/content/posts/2026/hybrid-search-static-blog#2": {
    "title": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog",
    "date": "2026-01-26",
    "text": "The bilingual tokenizer is crucial - it handles:\n- **English**: standard word tokenization with stopword removal\n- **Chinese**: character unigrams + b"
  },
  "/content/posts/2026/hybrid-search-static-blog#3": {
    "title": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog",
    "date": "2026-01-26",
    "text": "OpenAI API on every rebuild is slow and expensive. Content hashing enables incremental updates:\n\n**Result**: First build requires full embedding (~93 "
  },
  "/content/posts/2026/hybrid-search-static-blog#4": {
    "title": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog",
    "date": "2026-01-26",
    "text": "Worker at `api-embedding.your-worker.workers.dev`\n2. Add route: `yuxu.ge/api/*` → your Worker\n3. Set environment variable: `OPENAI_API_KEY`\n\nNow your "
  },
  "/content/posts/2026/hybrid-search-static-blog#5": {
    "title": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog",
    "date": "2026-01-26",
    "text": "mple: `score = Σ 1/(k + rank)` for each retriever. It doesn't require score normalization and handles the different scales of BM25 scores vs vector di"
  },
  "/content/posts/2026/hybrid-search-static-blog#6": {
    "title": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog",
    "date": "2026-01-26",
    "text": "Each result shows badges indicating its source:\n- **`keyword`** (blue) - matched via BM25\n- **`AI`** (pink) - matched via vector similarity\n- Both bad"
  },
  "/content/posts/2026/hybrid-search-static-blog#7": {
    "title": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog",
    "date": "2026-01-26",
    "text": "\" finds Docker articles)\n\nDeployment Checklist\n\n1. **Build indexes**: `OPENAI_API_KEY=sk-xxx node scripts/index-builder.mjs`\n2. **Deploy Worker**: Set"
  },
  "/content/posts/2026/hybrid-search-static-blog#8": {
    "title": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog",
    "date": "2026-01-26",
    "text": "'t need a backend server for sophisticated search. By splitting the work between build-time indexing, edge compute (Cloudflare Worker), and browser-si"
  },
  "/content/posts/2026/hybrid-search-static-blog#9": {
    "title": "Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers",
    "url": "/content/posts/2026/hybrid-search-static-blog",
    "date": "2026-01-26",
    "text": "code is available at github.com/geyuxu/yuxu.ge.\n\n*Built with: OpenAI text-embedding-3-small, Voy WASM, Cloudflare Workers, vanilla JavaScript*"
  },
  "/content/posts/2026/staticflow-engineering#0": {
    "title": "一夜 Vibe Coding：将静态站点生成器迁移到 Deno",
    "url": "/content/posts/2026/staticflow-engineering",
    "date": "2026-02-03",
    "text": "一夜 Vibe Coding：将静态站点生成器迁移到 Deno\n\n昨天晚上开始，今天完成。一夜的 vibe coding，我成功将自己的静态站点生成器从 Shell 脚本迁移到了 Deno 平台。\n\n迁移成果\n\n- ✅ 完全移除所有 Shell 脚本依赖\n- ✅ 彻底消除 Node.js 代码\n- "
  },
  "/content/posts/2026/staticflow-engineering#1": {
    "title": "一夜 Vibe Coding：将静态站点生成器迁移到 Deno",
    "url": "/content/posts/2026/staticflow-engineering",
    "date": "2026-02-03",
    "text": "，无需安装任何运行时。这正是我需要的。\n\n代码重构\n\n重构前的混乱状态\n\nShell 和 Node.js 混用，依赖管理混乱，跨平台兼容性差。\n\n重构后的清晰结构\n\n所有代码统一用 TypeScript，一个配置文件控制所有行为。\n\n统一配置设计\n\n前端通过 `features.json` 读取配置"
  },
  "/content/posts/2026/staticflow-engineering#2": {
    "title": "一夜 Vibe Coding：将静态站点生成器迁移到 Deno",
    "url": "/content/posts/2026/staticflow-engineering",
    "date": "2026-02-03",
    "text": "内容类似：\n\n**2. 自动设置 worktree**\n\n首次 deploy 时自动检测并设置：\n\n**3. setupDeploy 实现**\n\n**4. build 时跳过 .git**\n\n关键：复制主题文件时必须跳过 `.git`，否则会破坏 worktree：\n\n**5. deploy 流程（"
  },
  "/content/posts/2026/staticflow-engineering#3": {
    "title": "一夜 Vibe Coding：将静态站点生成器迁移到 Deno",
    "url": "/content/posts/2026/staticflow-engineering",
    "date": "2026-02-03",
    "text": "下一步计划：将核心格式转换代码精简并编译为 WASM，嵌入到单个约 15MB 的二进制文件中。\n\n比如 HEIC 解码，计划将 libde265（HEVC 解码器）从 5 万行 C 代码精简到 1.5 万行，移除多线程、SIMD、编码器模块，编译成约 300KB 的 WASM。\n\nAI 辅助开发\n\n"
  },
  "/content/posts/2026/staticflow-engineering#4": {
    "title": "一夜 Vibe Coding：将静态站点生成器迁移到 Deno",
    "url": "/content/posts/2026/staticflow-engineering",
    "date": "2026-02-03",
    "text": "在 `deno.json` 中配置了自动删除旧文件：\n\n2. Worktree 残留导致创建失败\n\n如果上次 worktree 没清理干净，新建会失败：\n\n3. WASM MIME 类型\n\n开发服务器必须正确配置 MIME 类型，否则浏览器拒绝加载：\n\n开源计划\n\n项目即将开源，敬请期待！🔜\n\n*"
  },
  "/content/posts/2026/ai-assistant-rag-zh#0": {
    "title": "为个人网站构建 RAG 驱动的 AI 助手",
    "url": "/content/posts/2026/ai-assistant-rag-zh",
    "date": "2026-01-28",
    "text": "为个人网站构建 RAG 驱动的 AI 助手\n\n最近我为个人网站添加了一个 AI 聊天助手，它可以回答关于博客文章、项目和个人背景的问题。本文记录了从架构设计到安全考虑的完整实现过程。\n\n目标\n\n创建一个浮动聊天组件：\n- 使用 RAG（检索增强生成）回答博客相关问题\n- 提供友好的技术交流\n- 优雅"
  },
  "/content/posts/2026/ai-assistant-rag-zh#1": {
    "title": "为个人网站构建 RAG 驱动的 AI 助手",
    "url": "/content/posts/2026/ai-assistant-rag-zh",
    "date": "2026-01-28",
    "text": "实现 RAG\n\n我已有一套搜索系统：\n- **BM25 关键词搜索**：本地倒排索引，精确词项匹配\n- **Voy WASM 语义搜索**：使用预计算 embeddings 的向量相似度\n- **RRF 融合**：使用 Reciprocal Rank Fusion 合并两路结果\n\n聊天组件复用这套现"
  },
  "/content/posts/2026/ai-assistant-rag-zh#2": {
    "title": "为个人网站构建 RAG 驱动的 AI 助手",
    "url": "/content/posts/2026/ai-assistant-rag-zh",
    "date": "2026-01-28",
    "text": "功能特性：\n- **自动保存**：每次助手响应后保存\n- **自动恢复**：页面加载时恢复对话\n- **24小时过期**：自动清除过期对话\n- **手动清除**：头部垃圾桶按钮可手动清空\n\n选择 localStorage 而非服务端存储（Cloudflare KV）的原因：\n- 大多数访客是一次性对"
  },
  "/content/posts/2026/ai-assistant-rag-zh#3": {
    "title": "为个人网站构建 RAG 驱动的 AI 助手",
    "url": "/content/posts/2026/ai-assistant-rag-zh",
    "date": "2026-01-28",
    "text": "down**：简单的正则表达式 Markdown 解析对于粗体和链接已经足够，不需要重型库。\n\n5. **状态管理从简单开始**：localStorage 对于对话历史已经足够。服务端存储（KV）增加复杂度，但对个人网站没有明显收益。\n\n成本分析\n\n使用 `gpt-4o-mini` 和 `text-"
  },
  "/content/posts/2026/neuroevo-life#0": {
    "title": "From Conway's Game of Life to Digital Darwinism: Building a GPU-Accelerated Neuroevolutionary Ecosystem",
    "url": "/content/posts/2026/neuroevo-life",
    "date": "2026-01-28",
    "text": "From Conway's Game of Life to Digital Darwinism: Building a GPU-Accelerated Neuroevolutionary Ecosystem\n\nAs I approach the second semester of my AI Ma"
  },
  "/content/posts/2026/neuroevo-life#1": {
    "title": "From Conway's Game of Life to Digital Darwinism: Building a GPU-Accelerated Neuroevolutionary Ecosystem",
    "url": "/content/posts/2026/neuroevo-life",
    "date": "2026-01-28",
    "text": "ted Artificial Life (ALife) evolutionary system.\n\n**Video Demo**: YouTube\n\nCore Architecture: When Neural Networks Have \"Genes\"\n\nIn my simulator, **Ne"
  },
  "/content/posts/2026/neuroevo-life#2": {
    "title": "From Conway's Game of Life to Digital Darwinism: Building a GPU-Accelerated Neuroevolutionary Ecosystem",
    "url": "/content/posts/2026/neuroevo-life",
    "date": "2026-01-28",
    "text": "s, determining the agent's decision-making style.\n*   **Chemical Affinity (4D)**: Determines inter-species signal transmission, compatibility, and pre"
  },
  "/content/posts/2026/neuroevo-life#3": {
    "title": "From Conway's Game of Life to Digital Darwinism: Building a GPU-Accelerated Neuroevolutionary Ecosystem",
    "url": "/content/posts/2026/neuroevo-life",
    "date": "2026-01-28",
    "text": "le simulations lies in computational efficiency.\n\n*   The system is built entirely upon **PyTorch vectorized operations** (such as `einsum` and convol"
  },
  "/content/posts/2026/neuroevo-life#4": {
    "title": "From Conway's Game of Life to Digital Darwinism: Building a GPU-Accelerated Neuroevolutionary Ecosystem",
    "url": "/content/posts/2026/neuroevo-life",
    "date": "2026-01-28",
    "text": "Evolutionary Results: 100% Ecological Dominance\n\nBy introducing a **hybrid evolutionary paradigm** (combining individual adaptation from reinforcement"
  },
  "/content/posts/2026/neuroevo-life#5": {
    "title": "From Conway's Game of Life to Digital Darwinism: Building a GPU-Accelerated Neuroevolutionary Ecosystem",
    "url": "/content/posts/2026/neuroevo-life",
    "date": "2026-01-28",
    "text": "e\" demonstrated extreme environmental plasticity.\n*   In competition with populations of randomly weighted agents, this lineage ultimately occupied **"
  },
  "/content/posts/2026/neuroevo-life-zh#0": {
    "title": "从康威生命游戏到数字达尔文主义：构建 GPU 加速的神经演化生态系统",
    "url": "/content/posts/2026/neuroevo-life-zh",
    "date": "2026-01-28",
    "text": "从康威生命游戏到数字达尔文主义：构建 GPU 加速的神经演化生态系统\n\n我即将迎来约克大学人工智能硕士第二学期的课程，其中一门选课 **Evolutionary Intelligence** 引起了我极大的兴趣。利用假期这段时间，我将经典的\"康威生命游戏\"推向了一个全新的维度：一个由神经网络驱动、G"
  },
  "/content/posts/2026/neuroevo-life-zh#1": {
    "title": "从康威生命游戏到数字达尔文主义：构建 GPU 加速的神经演化生态系统",
    "url": "/content/posts/2026/neuroevo-life-zh",
    "date": "2026-01-28",
    "text": "如 `einsum` 和卷积内核）构建，将数以万计智能体的决策和化学场扩散全部卸载到 GPU 上。\n* 这种设计允许我们在极高的种群密度下，观察到实时发生的物种漂移和演化竞争。\n\n演化结果：100% 的生态统治\n\n通过引入 **混合演化范式**（结合强化学习的个体适应与遗传算法的族群突变），我观察到"
  },
  "/content/posts/2026/multi-language-translation#0": {
    "title": "Adding Multi-Language AI Translation to My Blog",
    "url": "/content/posts/2026/multi-language-translation",
    "date": "2026-01-28",
    "text": "Adding Multi-Language AI Translation to My Blog\n\nAfter implementing the RAG-powered AI assistant, I wanted to make my blog content accessible to a glo"
  },
  "/content/posts/2026/multi-language-translation#1": {
    "title": "Adding Multi-Language AI Translation to My Blog",
    "url": "/content/posts/2026/multi-language-translation",
    "date": "2026-01-28",
    "text": "links)\n- Cache translations to minimize API costs\n- Show loading feedback during translation\n\nArchitecture\n\nSupported Languages\n\nThe system supports 1"
  },
  "/content/posts/2026/multi-language-translation#2": {
    "title": "Adding Multi-Language AI Translation to My Blog",
    "url": "/content/posts/2026/multi-language-translation",
    "date": "2026-01-28",
    "text": "API costs, I implemented caching at two levels:\n\n**Frontend (localStorage)** - 7 day TTL:\n\n**Backend (Cloudflare KV)** - 30 day TTL:\n\n4. Translation A"
  },
  "/content/posts/2026/multi-language-translation#3": {
    "title": "Adding Multi-Language AI Translation to My Blog",
    "url": "/content/posts/2026/multi-language-translation",
    "date": "2026-01-28",
    "text": "ranslate the raw Markdown source and re-render it. This preserves formatting better than translating rendered HTML.\n\n2. **Low temperature (0.3)**: Tra"
  },
  "/content/posts/2026/multi-language-translation#4": {
    "title": "Adding Multi-Language AI Translation to My Blog",
    "url": "/content/posts/2026/multi-language-translation",
    "date": "2026-01-28",
    "text": "ranslation cache is automatically invalidated.\n\n4. **Optional KV binding**: The worker works without KV storage - it just won't have server-side cachi"
  },
  "/content/posts/2026/multi-language-translation#5": {
    "title": "Adding Multi-Language AI Translation to My Blog",
    "url": "/content/posts/2026/multi-language-translation",
    "date": "2026-01-28",
    "text": "month in translation costs.\n\nFuture Improvements\n\n- [ ] Pre-translate popular posts at build time\n- [ ] Add streaming for long articles\n- [ ] Support "
  },
  "/content/posts/notebooks/R_010_numpy_basics#0": {
    "title": "R_010 — NumPy Basics (Reproducible)",
    "url": "/content/posts/notebooks/R_010_numpy_basics",
    "date": "2026-02-03",
    "text": "R_010 — NumPy Basics (Reproducible)\n\nPurpose: reproduce key NumPy operations from the note.  \nOutputs: small arrays + sanity prints (shape/dtype) + si"
  },
  "/content/posts/notebooks/R_010_numpy_basics#1": {
    "title": "R_010 — NumPy Basics (Reproducible)",
    "url": "/content/posts/notebooks/R_010_numpy_basics",
    "date": "2026-02-03",
    "text": "= np.zeros((2, 3))\nones = np.ones((2, 3))\nar = np.arange(0, 10, 2)\n\nprint(\"zeros:\\n\", zeros)\nprint(\"ones:\\n\", ones)\nprint(\"arange:\", ar)\n\nx = np.arang"
  },
  "/content/posts/notebooks/R_010_numpy_basics#2": {
    "title": "R_010 — NumPy Basics (Reproducible)",
    "url": "/content/posts/notebooks/R_010_numpy_basics",
    "date": "2026-02-03",
    "text": "[1, 10, 100, 1000])\n\nout = m + v\nprint(\"m:\\n\", m)\nprint(\"v:\", v)\nprint(\"m + v:\\n\", out)\n\nt = np.linspace(0, 2*np.pi, 200)\ns = np.sin(t)\n\nplt.figure()\n"
  },
  "/content/posts/notebooks/R_001_sanity_check#0": {
    "title": "R_001 — Environment Sanity Check",
    "url": "/content/posts/notebooks/R_001_sanity_check",
    "date": "2026-02-03",
    "text": "R_001 — Environment Sanity Check\n\nPurpose: verify the repo environment is runnable and basics work.  \nOutputs: package versions + a simple plot.\n\nimpo"
  },
  "/content/posts/notebooks/R_001_sanity_check#1": {
    "title": "R_001 — Environment Sanity Check",
    "url": "/content/posts/notebooks/R_001_sanity_check",
    "date": "2026-02-03",
    "text": "_)\n\ndf = pd.DataFrame({\n    \"x\": [1, 2, 3, 4, 5],\n    \"y\": [1, 4, 9, 16, 25],\n})\ndf\n\nplt.figure()\nplt.plot(df[\"x\"], df[\"y\"], marker=\"o\")\nplt.title(\"Sa"
  },
  "/content/posts/notebooks/R_001_sanity_check#2": {
    "title": "R_001 — Environment Sanity Check",
    "url": "/content/posts/notebooks/R_001_sanity_check",
    "date": "2026-02-03",
    "text": "))\n\nfrom LABS.src.text_chunker import chunk_text\n\nsample = \"Hello world! \" * 80\nchunks = chunk_text(sample, chunk_size=60, overlap=10)\nlen(chunks), ch"
  },
  "/content/posts/notebooks/R_002_minimal_retrieval#0": {
    "title": "R_002 - Minimal Retrieval (TF-IDF)",
    "url": "/content/posts/notebooks/R_002_minimal_retrieval",
    "date": "2026-02-03",
    "text": "R_002 - Minimal Retrieval (TF-IDF)\n\nGoal: build a tiny retrieval pipeline (chunk → index → query → top-k evidence).  \nNo LLM. Focus on reproducibility"
  },
  "/content/posts/notebooks/R_002_minimal_retrieval#1": {
    "title": "R_002 - Minimal Retrieval (TF-IDF)",
    "url": "/content/posts/notebooks/R_002_minimal_retrieval",
    "date": "2026-02-03",
    "text": ".src.text_chunker import chunk_text\nfrom LABS.src.retrieval_tfidf import TfidfRetriever\n\ndocs = {\n    \"doc_york_ai\": \"\"\"\nUniversity of York offers an "
  },
  "/content/posts/notebooks/R_002_minimal_retrieval#2": {
    "title": "R_002 - Minimal Retrieval (TF-IDF)",
    "url": "/content/posts/notebooks/R_002_minimal_retrieval",
    "date": "2026-02-03",
    "text": "cuments\nand injecting them into a model's context. Typical components include chunking, retrieval, reranking,\nand evaluation for faithfulness.\n\"\"\",\n  "
  },
  "/content/posts/notebooks/R_002_minimal_retrieval#3": {
    "title": "R_002 - Minimal Retrieval (TF-IDF)",
    "url": "/content/posts/notebooks/R_002_minimal_retrieval",
    "date": "2026-02-03",
    "text": "etrics like precision@k, recall@k, MRR, and nDCG.\nFor RAG, you also care about citation faithfulness and answer correctness on held-out queries.\n\"\"\".s"
  },
  "/content/posts/notebooks/R_002_minimal_retrieval#4": {
    "title": "R_002 - Minimal Retrieval (TF-IDF)",
    "url": "/content/posts/notebooks/R_002_minimal_retrieval",
    "date": "2026-02-03",
    "text": "s)\n\ndef show_results(query: str, top_k: int = 5):\n    print(\"Query:\", query)\n    results = retriever.search(query, top_k=top_k)\n    for r in results:\n"
  },
  "/content/posts/notebooks/R_002_minimal_retrieval#5": {
    "title": "R_002 - Minimal Retrieval (TF-IDF)",
    "url": "/content/posts/notebooks/R_002_minimal_retrieval",
    "date": "2026-02-03",
    "text": "(\"rag components chunking retrieval\", \"doc_rag\"),\n    (\"self attention transformer backbone\", \"doc_transformer\"),\n    (\"precision recall mrr ndcg eval"
  },
  "/content/posts/notebooks/R_002_minimal_retrieval#6": {
    "title": "R_002 - Minimal Retrieval (TF-IDF)",
    "url": "/content/posts/notebooks/R_002_minimal_retrieval",
    "date": "2026-02-03",
    "text": "print(\"recall@\", k, \"=\", recall_at_k(k))\n\nNotes\n- This is a minimal baseline (TF-IDF cosine).\n- Next step: add a tiny evaluation set + compute recall@"
  },
  "/content/posts/notebooks/R_020_pandas_basics#0": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/notebooks/R_020_pandas_basics",
    "date": "2026-02-03",
    "text": "Pandas Basics: Core Objects & Common Operations\n\n**Purpose**: Demonstrate the basic usage of Pandas Series and DataFrame, including creation, indexing"
  },
  "/content/posts/notebooks/R_020_pandas_basics#1": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/notebooks/R_020_pandas_basics",
    "date": "2026-02-03",
    "text": "30, 40])\nprint(\"s1 (default index):\")\nprint(s1)\n\nFrom list with index\ns2 = pd.Series([100, 98, 67, 23], index=['zs', 'ls', 'ww', 'sl'])\nprint(\"\\ns2 (c"
  },
  "/content/posts/notebooks/R_020_pandas_basics#2": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/notebooks/R_020_pandas_basics",
    "date": "2026-02-03",
    "text": "me(data)\nprint(\"DataFrame from dict:\")\nprint(df)\n\nFrom dict of Series (alignment)\ndata2 = {\n    'Name': pd.Series(['Tom', 'Jerry', 'Jack', 'Rose'], in"
  },
  "/content/posts/notebooks/R_020_pandas_basics#3": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/notebooks/R_020_pandas_basics",
    "date": "2026-02-03",
    "text": "print(\"\\n--- loc (label based) ---\")\nprint(\"df2.loc['a']:\")\nprint(df2.loc['a'])\n\nprint(\"\\n--- iloc (position based) ---\")\nprint(\"df2.iloc[0]:\")\nprint("
  },
  "/content/posts/notebooks/R_020_pandas_basics#4": {
    "title": "Pandas Basics: Core Objects & Common Operations",
    "url": "/content/posts/notebooks/R_020_pandas_basics",
    "date": "2026-02-03",
    "text": "nModified Math column:\")\nprint(df)\n\nDelete column\ndf.drop(['Math'], axis=1, inplace=True)\nprint(\"\\nDropped Math column:\")\nprint(df)\n\n5. CSV I/O\nCreate"
  }
}