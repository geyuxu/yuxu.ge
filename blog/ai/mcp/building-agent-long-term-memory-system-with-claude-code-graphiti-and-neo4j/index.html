<!DOCTYPE html><html lang="zh" data-astro-cid-bvzihdzo> <head><!-- Global Metadata --><meta charset="utf-8"><!--<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">--><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"><link rel="shortcut icon" href="/favicon.png" type="image/png"><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" title="Ge Yuxu • AI &#38; Engineering" href="https://geyuxu.com/rss.xml"><meta name="generator" content="Astro v5.5.6"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><!-- Canonical URL --><link rel="canonical" href="https://geyuxu.com/blog/ai/mcp/building-agent-long-term-memory-system-with-claude-code-graphiti-and-neo4j/"><!-- Primary Meta Tags --><title>Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j</title><meta name="title" content="Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j"><meta name="description"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://geyuxu.com/blog/ai/mcp/building-agent-long-term-memory-system-with-claude-code-graphiti-and-neo4j/"><meta property="og:title" content="Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j"><meta property="og:description"><meta property="og:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://geyuxu.com/blog/ai/mcp/building-agent-long-term-memory-system-with-claude-code-graphiti-and-neo4j/"><meta property="twitter:title" content="Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j"><meta property="twitter:description"><meta property="twitter:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><script src="/js/jquery-3.7.1.min.js"></script><script is:global>
	window.addEventListener('DOMContentLoaded', () => {
		$('.toc ol').css({
		'list-style': 'none',   // 隐藏 1. 2. 3.
		'margin': 0,
		'padding-left': 0,       // 可按需调整
		});
		$('.toc ol > li').css({
		'list-style': 'none',   // 隐藏 1. 2. 3.
		'padding-left': 10  
		});
        $('.sidebar').append($('.toc'));
      });
	</script><style>:root{--accent: #2337ff;--accent-dark: #000d8a;--black: 15, 18, 25;--gray: 96, 115, 159;--gray-light: 229, 233, 240;--gray-dark: 34, 41, 57;--gray-gradient: rgba(var(--gray-light), 50%), #fff;--box-shadow: 0 2px 6px rgba(var(--gray), 25%), 0 8px 24px rgba(var(--gray), 33%), 0 16px 32px rgba(var(--gray), 33%)}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-regular.woff) format("woff");font-weight:400;font-style:normal;font-display:swap}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-bold.woff) format("woff");font-weight:700;font-style:normal;font-display:swap}body{font-family:Atkinson,sans-serif;margin:0;padding:0;text-align:left;background:linear-gradient(var(--gray-gradient)) no-repeat;background-size:100% 600px;word-wrap:break-word;overflow-wrap:break-word;color:rgb(var(--gray-dark));font-size:20px;line-height:1.7}main{width:720px;max-width:calc(100% - 2em);margin:auto;padding:3em 1em}h1,h2,h3,h4,h5,h6{margin:0 0 .5rem;color:rgb(var(--black));line-height:1.2}h1{font-size:3.052em}h2{font-size:2.441em}h3{font-size:1.953em}h4{font-size:1.563em}h5{font-size:1.25em}strong,b{font-weight:700}a,a:hover{color:var(--accent)}p{margin-bottom:1em}.prose p{margin-bottom:2em}textarea{width:100%;font-size:16px}input{font-size:16px}table{width:100%;border-collapse:collapse}th,td{border:1px solid rgba(var(--gray-light));padding:8px;text-align:left}th{background-color:rgba(var(--gray-light),.5)}img{max-width:100%;height:auto;border-radius:8px}code{padding:2px 5px;background-color:rgb(var(--gray-light));border-radius:2px}pre{padding:1.5em;border-radius:8px}pre>code{all:unset}blockquote{border-left:4px solid var(--accent);padding:0 0 0 20px;margin:0;font-size:1.333em}hr{border:none;border-top:1px solid rgb(var(--gray-light))}@media (max-width: 720px){body{font-size:18px}main{padding:1em}}.sr-only{border:0;padding:0;margin:0;position:absolute!important;height:1px;width:1px;overflow:hidden;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);clip-path:inset(50%);white-space:nowrap}.title_li{list-style:none}.title_li>a,.title_li_num>a,.toc-link,.series-list>li>a,.series_title>a{color:#7a888e}.content{max-width:720px;margin:0 auto;padding:2rem 1rem;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,sans-serif;font-size:1.05rem;line-height:1.75;color:#333}.content h1,.content h2,.content h3{font-weight:600;margin-top:2rem;margin-bottom:1rem;line-height:1.3}.content p{margin-bottom:1.25rem}.content a{color:var(--accent, #0070f3);text-decoration:underline}.content img{max-width:100%;border-radius:6px;margin:1.5rem 0}.content pre,.content code{font-family:Menlo,Monaco,Consolas,Courier New,monospace;font-size:.9em;border-radius:4px}.content pre{padding:1em;overflow-x:auto}article.prose{font-size:var(--fs-base);line-height:1.7}@media (max-width: 640px){nav>div,nav>h2{font-size:.6em}ul,ol{padding-left:20px}main,.content-wrapper{padding-left:0;width:350px;max-width:60350px0px;margin:0 auto}img,table,pre{max-width:100%}table,pre{overflow-x:auto}.content{margin:0;padding:0;border:0;max-width:3350px00px;font-size:11px}h1{font-size:1.3rem}h2{font-size:1.2rem}h3{font-size:1.1rem}h4{font-size:1rem}h5{font-size:.9rem}}
a[data-astro-cid-eimmu3lg]{display:inline-block;text-decoration:none}a[data-astro-cid-eimmu3lg].active{font-weight:bolder;text-decoration:underline}header[data-astro-cid-3ef6ksr2]{margin:0;padding:0 1em;background:#fff;box-shadow:0 2px 8px rgba(var(--black),5%)}h2[data-astro-cid-3ef6ksr2]{margin:0;font-size:1em}h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2],h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none}nav[data-astro-cid-3ef6ksr2]{display:flex;align-items:center;justify-content:space-between}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{padding:1em .5em;color:var(--black);border-bottom:4px solid transparent;text-decoration:none}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none;border-bottom-color:var(--accent)}.social-links[data-astro-cid-3ef6ksr2],.social-links[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{display:flex}@media (max-width: 720px){.social-links[data-astro-cid-3ef6ksr2]{display:none}}footer[data-astro-cid-sz7xmlte]{padding:2em 1em 6em;background:linear-gradient(var(--gray-gradient)) no-repeat;color:rgb(var(--gray));text-align:center}.social-links[data-astro-cid-sz7xmlte]{display:flex;justify-content:center;gap:1em;margin-top:1em}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]{text-decoration:none;color:rgb(var(--gray))}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]:hover{color:rgb(var(--gray-dark))}
.statement[data-astro-cid-uffxixac]{font-size:10px;color:gray}@media (max-width: 640px){.statement[data-astro-cid-uffxixac]{font-size:6px;color:gray}}
main[data-astro-cid-bvzihdzo].page{display:grid;grid-template-columns:260px minmax(0,1fr);width:100%;margin:0}aside[data-astro-cid-bvzihdzo].sidebar{box-sizing:border-box;width:260px;padding:2rem 1rem;font-size:.95rem;position:sticky;top:4rem;align-self:start}.sidebar[data-astro-cid-bvzihdzo] .meta[data-astro-cid-bvzihdzo] p[data-astro-cid-bvzihdzo]{margin:.25rem 0}nav[data-astro-cid-bvzihdzo].toc li[data-astro-cid-bvzihdzo]{margin:.35rem 0 .35rem 1rem}nav[data-astro-cid-bvzihdzo].toc a[data-astro-cid-bvzihdzo]{color:var(--gray-dark,#444);text-decoration:none}nav[data-astro-cid-bvzihdzo].toc a[data-astro-cid-bvzihdzo]:hover{text-decoration:underline}.content-wrapper[data-astro-cid-bvzihdzo]{display:flex;justify-content:center;padding:2rem 1rem}article[data-astro-cid-bvzihdzo].prose{max-width:740px;width:100%}@media (max-width: 768px){main[data-astro-cid-bvzihdzo].page{grid-template-columns:1fr}aside[data-astro-cid-bvzihdzo].sidebar{position:static;width:100%;padding:1rem}.content-wrapper[data-astro-cid-bvzihdzo]{justify-content:flex-start}article[data-astro-cid-bvzihdzo].prose{max-width:100%}}.series-list[data-astro-cid-bvzihdzo]{list-style:none;margin:0;padding-left:10px}.series-list[data-astro-cid-bvzihdzo]{list-style:none;margin:0;padding-left:10px;max-height:calc(16em + .5rem);overflow-y:auto}.series-list[data-astro-cid-bvzihdzo]::-webkit-scrollbar{width:6px}.series-list[data-astro-cid-bvzihdzo]::-webkit-scrollbar-thumb{background:#0003;border-radius:3px}
</style></head> <body data-astro-cid-bvzihdzo> <header data-astro-cid-3ef6ksr2> <nav data-astro-cid-3ef6ksr2> <!--<h2><a href="/">{SITE_TITLE}</a></h2>--> <h2 data-astro-cid-3ef6ksr2><a style="padding-left:0;color:blue;" href="/" data-astro-cid-3ef6ksr2>Ge Yuxu<br data-astro-cid-3ef6ksr2>AI & Engineering</a></h2> <div class="internal-links" data-astro-cid-3ef6ksr2> <a href="/" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Home </a>  <a href="/blog/1" class="active" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Blog </a>  <a href="/series" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Series </a>  <a href="/projects" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Projects </a>  </div> <div class="social-links" data-astro-cid-3ef6ksr2> <a href="https://github.com/geyuxu" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Go to Ge Yuxu's GitHub repo</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" data-astro-cid-3ef6ksr2><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-3ef6ksr2></path></svg> </a> <a href="https://www.linkedin.com/in/geyuxu/" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Go to Ge Yuxu's LinkedIn profile</span> <svg viewBox="0 0 24 24" width="32" height="32" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" data-astro-cid-3ef6ksr2> <path fill="currentColor" d="M20.447 20.452H17.2v-5.569c0-1.328-.025-3.039-1.852-3.039-1.853 0-2.136 1.447-2.136 2.942v5.666h-3.248V9h3.122v1.561h.045c.435-.823 1.498-1.688 3.083-1.688 3.295 0 3.903 2.17 3.903 4.989v6.59zM5.337 7.433a1.882 1.882 0 110-3.764 1.882 1.882 0 010 3.764zm1.626 13.019H3.708V9h3.255v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.226.792 24 1.771 24h20.451C23.2 24 24 23.226 24 22.271V1.729C24 .774 23.2 0 22.222 0z" data-astro-cid-3ef6ksr2></path> </svg> </a> </div> </nav> <!-- Microsoft Clarity --> <script type="text/javascript">
		(function(c,l,a,r,i,t,y){
			c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
			t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
			y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
		})(window, document, "clarity", "script", "rc2w96osp6");
	</script> </header>  <main class="page" data-astro-cid-bvzihdzo> <!-- 左侧栏 --> <aside class="sidebar" data-astro-cid-bvzihdzo> <div class="meta" data-astro-cid-bvzihdzo> <b data-astro-cid-bvzihdzo>Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j</b> <p data-astro-cid-bvzihdzo><time datetime="2025-07-22T16:00:00.000Z"> 2025/07/23 00:00:00 </time></p>   </div> <hr data-astro-cid-bvzihdzo> <br data-astro-cid-bvzihdzo> </aside> <!-- 右侧正文区域（flex 居中） --> <div class="content-wrapper" data-astro-cid-bvzihdzo> <article class="prose" data-astro-cid-bvzihdzo>  <article class="content"> <nav class="toc"><ol class="toc-level toc-level-1"><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#installation-and-configuration-steps">Installation and Configuration Steps</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#usage-verification">Usage Verification</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#graphiti-memory-functionality-categories">Graphiti Memory Functionality Categories</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#usage-recommendations-and-pitfall-records">Usage Recommendations and Pitfall Records</a></li></ol></nav><h1 id="building-agent-long-term-memory-system-with-claude-code-graphiti-and-neo4j"><a aria-hidden="true" tabindex="-1" href="#building-agent-long-term-memory-system-with-claude-code-graphiti-and-neo4j"><span class="icon icon-link"></span></a>Building Agent Long-term Memory System with Claude Code, Graphiti, and Neo4j</h1>
<p>In large language model (LLM) applications, enhancing “long-term memory” for Agents is a major challenge. Regular conversation context has length limitations, and after exceeding them, models tend to forget early information. The common approach is to use RAG (Retrieval-Augmented Generation) methods to retrieve external knowledge. However, traditional RAG is mostly designed for batch processing of static documents and is not good at handling frequently changing conversational data. For this reason, we chose the combination of Claude Code, Graphiti, and Neo4j to build an AI Agent with long-term memory.</p>
<ul>
<li>Claude Code: A developer conversation platform provided by Anthropic, supporting code execution and MCP (Model Context Protocol) plugin interfaces, allowing AI to call external tools and resources. Claude Code has an ultra-large context window, making it suitable as the frontend for intelligent Agents, enabling them to dynamically store and retrieve “memory” and other external resources during conversations.</li>
<li>Graphiti: An open-source temporal knowledge graph framework by Zep company, used as “long-term memory” storage for AI. Graphiti can write conversation content and structured data as “episodes” one by one into a knowledge graph and automatically extract entities and relationships from them. It supports real-time incremental updates, dual timeline records (event occurrence and write time), and hybrid retrieval (semantic + keyword + graph traversal), enabling fast querying of historical information without recalculating all knowledge. Graphiti has been used in Zep’s AI memory layer and is proven to be the most advanced memory solution for AI Agents today.</li>
<li>Neo4j: A popular graph database used to store knowledge graphs built by Graphiti. Neo4j has ACID transactions and powerful relationship query capabilities, perfectly compatible with Graphiti. Graphiti defaults to supporting Neo4j 5.x, connecting via Bolt protocol, and storing embedding vectors and other data in Neo4j nodes. Neo4j Desktop can be used to conveniently set up a local graph database.</li>
</ul>
<p>Combined advantages: The Claude Code + Graphiti + Neo4j pipeline gives AI Agents persistent, structured memory. Each user interaction is integrated into the knowledge graph in real-time through Graphiti, and Agents can perform semantic + graph hybrid searches on knowledge, retrieving relevant history with low latency, thus maintaining “context awareness” across different sessions. Compared to relying solely on LLM context or vector databases, this solution can precisely store and access complex relationships and event evolution, providing a basis for task planning and reasoning. Additionally, Graphiti is designed for dynamic data and can handle frequently updated knowledge without the need to frequently rebuild indexes, making it very suitable for Agent applications that require continuous learning.</p>
<h2 id="installation-and-configuration-steps"><a aria-hidden="true" tabindex="-1" href="#installation-and-configuration-steps"><span class="icon icon-link"></span></a>Installation and Configuration Steps</h2>
<p>Below is a summary of the installation and configuration process based on practice:</p>
<ol>
<li>Install Neo4j Desktop: Download and install Neo4j Desktop from the official Neo4j website. Neo4j Desktop provides an intuitive interface to manage local databases, which is very suitable for getting started. Start Neo4j Desktop after installation is complete.</li>
<li>Create a database instance and set password: Create a new local graph database in Neo4j Desktop (version needs to be 5.x or higher). When starting the database for the first time, you will be asked to set a password. Please set a password for the Neo4j user (default username is neo4j) and remember this information. By default, Neo4j’s Bolt connection URI is bolt://localhost:7687, and Graphiti will connect to the database through this URI later.</li>
<li>Clone the Graphiti repository and configure the environment: Open terminal, clone the Graphiti source code repository and enter the directory:</li>
</ol>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>git clone https://github.com/getzep/graphiti.git</span></span>
<span class="line"><span>cd graphiti/mcp_server</span></span></code></pre>
<p>The repository provides a .env.example template file. Copy one as .env and fill in Neo4j and OpenAI configurations according to actual conditions:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>OPENAI_API_KEY=&#x3C;your OpenAI API key></span></span>
<span class="line"><span>MODEL_NAME=gpt-4.1-mini        # Specify LLM model name, such as OpenAI's GPT-4 mini version</span></span>
<span class="line"><span>NEO4J_URI=bolt://localhost:7687</span></span>
<span class="line"><span>NEO4J_USER=neo4j</span></span>
<span class="line"><span>NEO4J_PASSWORD=&#x3C;your Neo4j password></span></span></code></pre>
<p>Where OPENAI_API_KEY is the key used by Graphiti to call the OpenAI interface for LLM inference and embeddings, MODEL_NAME can specify OpenAI models (such as gpt-3.5-turbo or gpt-4 series, the default example uses GPT-4.1 mini model), and the Neo4j section fills in the connection information and credentials for the database just created.</p>
<ol start="4">
<li>Install required tools (uv, uvicorn, claude-cli):</li>
</ol>
<ul>
<li>uv: Graphiti recommends using the uv tool developed by Astral to manage Python environments and dependencies. First install uv through pip install uv. Then execute uv sync in the graphiti/mcp_server directory, this command will install the required Python packages according to the project’s lock file. uv is similar to pip but can synchronize dependencies faster. If not using uv, you can also manually create a virtual environment and use pip install -r requirements.txt to install dependencies.</li>
<li>uvicorn: If you plan to run the service through HTTP SSE, you need to install the ASGI server uvicorn (usually already in dependencies). Make sure uvicorn can be called from the command line (e.g., pip install uvicorn).</li>
<li>claude-cli: Claude Code provides command-line tools to manage MCP plugins. Install the claude CLI tool (e.g., through pip install anthropic or other means, see Anthropic documentation for details). After installation, the command line should be able to use the claude command for adding MCP servers and other configurations.</li>
</ul>
<ol start="5">
<li>Start Graphiti MCP Server and register plugin in Claude: The Graphiti repository comes with an MCP Server implementation, used as a bridge between frontends like Claude and the Graphiti backend. There are two startup methods:</li>
</ol>
<ul>
<li>Method A: Start through Claude Code CLI (stdio mode): This method runs Graphiti MCP Server as a subprocess of Claude, communicating through standard input/output. Execute the following command on the command line to add the Graphiti plugin to Claude Code (user scope):</li>
</ul>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>claude mcp add-json graphiti-memory '{</span></span>
<span class="line"><span>  "type": "stdio",</span></span>
<span class="line"><span>  "command": "/usr/local/bin/uv",</span></span>
<span class="line"><span>  "args": [</span></span>
<span class="line"><span>    "run", "--directory", "/path/to/graphiti/mcp_server", </span></span>
<span class="line"><span>    "graphiti_mcp_server.py", "--transport", "stdio"</span></span>
<span class="line"><span>  ],</span></span>
<span class="line"><span>  "env": {</span></span>
<span class="line"><span>    "OPENAI_API_KEY": "&#x3C;your OpenAI key>",</span></span>
<span class="line"><span>    "MODEL_NAME": "gpt-4.1-mini",</span></span>
<span class="line"><span>    "NEO4J_URI": "bolt://localhost:7687",</span></span>
<span class="line"><span>    "NEO4J_USER": "neo4j",</span></span>
<span class="line"><span>    "NEO4J_PASSWORD": "&#x3C;your Neo4j password>"</span></span>
<span class="line"><span>  }</span></span>
<span class="line"><span>}'</span></span></code></pre>
<p>Replace the paths and parameters in the above command with actual values (e.g., uv executable path, Graphiti repository location, etc.). After execution, Claude Code will register an MCP plugin called “graphiti-memory”, and Claude will automatically start this Server and communicate through stdio when memory is needed during conversations.</p>
<ul>
<li>Method B: Run Graphiti Server independently (SSE mode): In this method, Graphiti runs as an independent service, accessible to Claude through HTTP Server-Sent Events (SSE) interface. You can execute:</li>
</ul>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>cd graphiti/mcp_server</span></span>
<span class="line"><span>uv run graphiti_mcp_server.py --transport sse --model gpt-4.1-mini</span></span></code></pre>
<p>The above command will run Graphiti MCP Server in SSE mode locally (default listening on 0.0.0.0:8000). After successful startup, use Claude CLI to add this service as an MCP plugin:</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="plaintext"><code><span class="line"><span>claude mcp add --transport sse --scope user graphiti-memory http://localhost:8000/sse</span></span></code></pre>
<p>This way Claude registers a remote MCP service called “graphiti-memory” (connected via HTTP). —scope user means it’s globally available for this user (you can also use —scope project for specific projects). After completion, you can see the graphiti-memory plugin in the “MCP Servers” list in the Claude Code interface.</p>
<p>After completing the above installation and configuration, the Claude Agent now has Graphiti knowledge graph as long-term memory storage. Next, you can try conversing with Claude, recording information, and verifying the memory functionality.</p>
<h2 id="usage-verification"><a aria-hidden="true" tabindex="-1" href="#usage-verification"><span class="icon icon-link"></span></a>Usage Verification</h2>
<p>To confirm whether Graphiti memory is working properly, you can directly check from the Neo4j side whether data is written:</p>
<ul>
<li>Knowledge graph node check: Open Neo4j Browser (built into Neo4j Desktop) and connect to the database just created, execute Cypher query: MATCH (n:Episodic) RETURN n LIMIT 25;. Graphiti stores each conversation or information fragment as a node with “Episodic” label, you can view the latest written Episode nodes and their attributes through this query. If you can see the node list, it means Claude has successfully stored conversation content in Neo4j.</li>
</ul>
<p>If you cannot query any Episode nodes or Graphiti functionality is abnormal, it’s recommended to troubleshoot from the following aspects:</p>
<ul>
<li>Bolt connection issues: Confirm that Graphiti MCP Server can connect to Neo4j database. Check whether the NEO4J_URI and port configured in .env are correct, the local default should be bolt://localhost:7687. Make sure the Neo4j database is started and no firewall is blocking local Bolt connections. If Neo4j uses non-default database name or username, Graphiti configuration also needs to be adjusted accordingly.</li>
<li>OpenAI API Key status: When writing conversations, Graphiti will call OpenAI models to extract entities and generate embeddings. If the provided API Key is invalid or has insufficient balance, Graphiti may not be able to complete Episode parsing and writing. You can check the terminal output logs when running Graphiti Server. If there are OpenAI interface errors or insufficient balance messages, you need to replace with a valid API Key (OpenAI can get a certain amount of free quota daily if data sharing is enabled) or ensure the account has sufficient quota.</li>
<li>Claude plugin enablement: Confirm that Graphiti MCP plugin is enabled in Claude frontend. In Claude Code, newly added MCP Servers may need to be enabled in the conversation interface (such as in Claude Desktop, you need to check and enable in the “plugins” list in the upper right corner of the conversation window). If the plugin is not enabled, Claude will not actually call Graphiti. Also note that Claude does not automatically trigger calls to MCP functionality for resources and prompt types by default (see details below), so when testing, you can first ask questions related to already recorded content to see if Claude can use previously stored memories to answer.</li>
</ul>
<h2 id="graphiti-memory-functionality-categories"><a aria-hidden="true" tabindex="-1" href="#graphiti-memory-functionality-categories"><span class="icon icon-link"></span></a>Graphiti Memory Functionality Categories</h2>
<p>As an MCP Server, Graphiti provides three types of interface capabilities, corresponding to the three types defined by MCP: Resources, Tools, and Prompts. Understanding these three helps leverage Graphiti memory’s role:</p>
<ol>
<li>Resources: Interfaces for retrieving information. Such as getting content from internal knowledge graphs or external databases. These interfaces only read data without side effects, serving to let LLM access historical information in knowledge bases. For example, Graphiti provides resource interfaces for retrieving nodes and facts, supporting time-aware queries that can get past conversation fragments by time or conditions. Claude can call Resource-type functionality to read relevant content when needing to reference memory.</li>
<li>Tools: Interfaces for executing operations that will change external environments or data. Such as writing data through APIs, performing calculations, etc. Graphiti’s tool interfaces allow LLM to add new knowledge to graphs or call real-time search and graph operations, achieving online memory updates. Whenever users provide new information, Claude Agent can call Graphiti’s tool methods (like add_episode) to store it as new nodes, thus continuously accumulating knowledge.</li>
<li>Prompts: Predefined prompt templates or workflows that facilitate reuse of complex interaction logic between LLM and MCP Server. For example, Graphiti may provide templates for certain queries, encapsulating commonly used multi-step operations. These Prompt templates can be viewed as Agent’s “skill scripts” that are called when specific needs are triggered. Through Prompts, developers can solidify standard query patterns, allowing Claude to generate query requests to Graphiti with one click when needed.</li>
</ol>
<p>Note that in Claude Desktop’s current implementation, Tools-type MCP interfaces (like Graphiti’s write/search functions) can be automatically called based on conversation context, while Resources and Prompts types will not be automatically triggered. That is, even if Graphiti lists available resources and prompt templates, Claude doesn’t know when to use them by default unless users actively attach them. This point is particularly important in actual use, and coping strategies will be discussed in the next section.</p>
<h2 id="usage-recommendations-and-pitfall-records"><a aria-hidden="true" tabindex="-1" href="#usage-recommendations-and-pitfall-records"><span class="icon icon-link"></span></a>Usage Recommendations and Pitfall Records</h2>
<p>Based on actual experience, here are some noteworthy recommendations and possible pitfalls encountered when using Graphiti long-term memory:</p>
<ul>
<li>Debugging Graphiti writes: When you find that conversation content is not written to Neo4j, you can check the console output logs of Graphiti MCP Server. Graphiti will print information like the model name and Group ID used when starting, and if errors occur during write execution (such as OpenAI returning formats that don’t meet expectations), exception stacks are usually also printed in the logs. When debugging, you can try directly calling Graphiti’s API (such as REST interface) to add test data, or use short and clearly structured inputs to trigger add_episode to isolate problems. Make sure .env is loaded correctly (you can explicitly specify —env-file .env in the startup command just in case). If Graphiti prompts embedding or parsing schema errors, it’s usually caused by model output not conforming to expected JSON format.</li>
<li>Avoiding Schema errors: Graphiti requires that the LLM used supports structured output to ensure correct formatting when extracting entity relationships. It’s recommended to use OpenAI’s GPT-4 or new versions of GPT-3.5 that have function calling or strict JSON output capabilities. If using models that don’t support structured output (especially smaller models), you may encounter situations where Graphiti cannot parse returned content and Episode writing fails (manifested as log errors like schema mismatch). Additionally, running Graphiti for the first time will create required indexes and constraints on Neo4j, and IndexAlreadyExists prompts can be ignored. When adjusting Graphiti’s entity/relationship type definitions, try to maintain consistency with Neo4j schema to avoid write errors due to schema mismatches.</li>
<li>Correctly triggering Memory in Claude: To make Claude fully utilize Graphiti long-term memory, some guidance in conversation strategies is needed. Currently Claude doesn’t automatically use Resource/Prompt, so users or developers need to actively trigger them. There are several practical techniques: First, prompt Claude at the very beginning of conversations that Graphiti memory is available and should query the graph first when needed. For example, you can set system prompts like: “Please search existing knowledge before answering.” Second, skillfully use the <strong>“References”</strong> function provided by Claude interface: In Claude Desktop, you can click the ”+” sign to attach stored memory fragments from MCP Server as reference materials. Third, refer to official recommendations to establish conversation conventions - such as “search first, then answer” and “record new information immediately”. These rules can be used as Claude prompts, making the model develop habits of calling add_episode to save when encountering new preferences/facts, and calling search_nodes/search_facts to retrieve relevant nodes and relationships when encountering problems first. Such explicit prompts can greatly improve Graphiti memory utilization. In summary, some human guidance is currently needed, and future versions of Claude may make AI automatically aware of available memory resources and call them.</li>
</ul>
<p>Through stable configuration and adjustment of the above tool chain, the integration of Claude Code with Graphiti + Neo4j can run smoothly, and an AI Agent with long-term memory is built. In real development, we should continuously optimize prompt strategies based on logs and conversation performance to ensure AI both “remembers” knowledge provided by users and can accurately recall and utilize it when needed. This solution can effectively avoid information forgetting in complex projects and greatly improve Agent’s coherence and intelligence level for long-term tasks. In the future, if Claude plugin mechanisms are upgraded to automatically utilize Resource/Prompt, AI long-term memory will become even more handy. Hope the above pitfall experiences can help everyone more easily reproduce this powerful long-term memory Agent solution!</p> </article> <html lang="en" data-astro-cid-uffxixac> <head><!-- Global Metadata --><meta charset="utf-8"><!--<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">--><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"><link rel="shortcut icon" href="/favicon.png" type="image/png"><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" title="Ge Yuxu • AI &#38; Engineering" href="https://geyuxu.com/rss.xml"><meta name="generator" content="Astro v5.5.6"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><!-- Canonical URL --><link rel="canonical" href="https://geyuxu.com/blog/ai/mcp/building-agent-long-term-memory-system-with-claude-code-graphiti-and-neo4j/"><!-- Primary Meta Tags --><title>Ge Yuxu • AI &amp; Engineering</title><meta name="title" content="Ge Yuxu • AI &#38; Engineering"><meta name="description" content="Welcome to my blog!"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://geyuxu.com/blog/ai/mcp/building-agent-long-term-memory-system-with-claude-code-graphiti-and-neo4j/"><meta property="og:title" content="Ge Yuxu • AI &#38; Engineering"><meta property="og:description" content="Welcome to my blog!"><meta property="og:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://geyuxu.com/blog/ai/mcp/building-agent-long-term-memory-system-with-claude-code-graphiti-and-neo4j/"><meta property="twitter:title" content="Ge Yuxu • AI &#38; Engineering"><meta property="twitter:description" content="Welcome to my blog!"><meta property="twitter:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><script src="/js/jquery-3.7.1.min.js"></script></head> <body data-astro-cid-uffxixac>  <div class="statement" data-astro-cid-uffxixac> <blockquote data-astro-cid-uffxixac> <p data-astro-cid-uffxixac><strong data-astro-cid-uffxixac>脱敏说明</strong>：本文所有出现的表名、字段名、接口地址、变量名、IP地址及示例数据等均非真实，
    仅用于阐述技术思路与实现步骤，示例代码亦非公司真实代码。
    示例方案亦非公司真实完整方案，仅为本人记忆总结，用于技术学习探讨。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;文中所示任何标识符并不对应实际生产环境中的名称或编号。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;示例&nbsp;SQL、脚本、代码及数据等均为演示用途，不含真实业务数据，也不具备直接运行或复现的完整上下文。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;读者若需在实际项目中参考本文方案，请结合自身业务场景及数据安全规范，使用符合内部命名和权限控制的配置。</p> <p data-astro-cid-uffxixac><strong data-astro-cid-uffxixac>版权声明</strong>：本文版权归原作者所有，未经作者事先书面许可，任何单位或个人不得以任何方式复制、转载、摘编或用于商业用途。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;若需非商业性引用或转载本文内容，请务必注明出处并保持内容完整。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;对因商业使用、篡改或不当引用本文内容所产生的法律纠纷，作者保留追究法律责任的权利。<br data-astro-cid-uffxixac><br data-astro-cid-uffxixac> <em data-astro-cid-uffxixac>Copyright&nbsp;©&nbsp;1989–Present&nbsp;Ge&nbsp;Yuxu.&nbsp;All&nbsp;Rights&nbsp;Reserved.</em></p> </blockquote> </div></body></html>  </article> </div> </main> <footer data-astro-cid-sz7xmlte>
&copy; 2025 All rights reserved.
</footer>  </body></html>