<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers</title>
    <style>
        body { font-family: Georgia, serif; max-width: 700px; margin: 2rem auto; padding: 0 1rem; line-height: 1.7; color: #333; }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        h2 { font-size: 1.4rem; margin-top: 2rem; }
        pre { background: #f4f4f4; padding: 1rem; overflow-x: auto; border-radius: 4px; }
        code { font-family: Menlo, Monaco, monospace; font-size: 0.9em; }
        p code { background: #f4f4f4; padding: 0.2em 0.4em; border-radius: 3px; }
        img { max-width: 100%; }
        blockquote { border-left: 3px solid #ddd; margin-left: 0; padding-left: 1rem; color: #666; }
        ul { padding-left: 1.5rem; }
        hr { border: none; border-top: 1px solid #ddd; margin: 2rem 0; }
        a { color: #1a8917; }
    </style>
</head>
<body>
<hr>
<h2>date: 2026-01-26
tags: [rag, search, cloudflare, javascript]
description: Building a production-ready hybrid search for static blogs - combining BM25 keyword search with OpenAI embeddings, all without a backend server.</h2>
<h1>Building Hybrid Search for Static Blogs: BM25 + Vector Search with Cloudflare Workers</h1>
<p>Static site generators are great until you need search. Most solutions either require a backend server or rely on basic client-side text matching. This post walks through building a <strong>hybrid search system</strong> that combines instant BM25 keyword matching with semantic vector search - all while keeping your site fully static.</p>
<h2>The Architecture</h2>
<blockquote><code>┌─────────────────┐     ┌──────────────────┐     ┌─────────────────┐</code><br>
<code>│   Build Time    │     │   Cloudflare     │     │    Browser      │</code><br>
<code>│                 │     │     Worker       │     │                 │</code><br>
<code>│  Markdown       │     │                  │     │  ┌───────────┐  │</code><br>
<code>│  Posts          │     │  /api/embedding  │     │  │ Keyword   │  │</code><br>
<code>│      ↓          │     │       ↓          │     │  │ Search    │  │</code><br>
<code>│  ┌─────────┐    │     │  OpenAI API      │     │  │ (instant) │  │</code><br>
<code>│  │ Index   │    │     │  (protected)     │     │  └─────┬─────┘  │</code><br>
<code># ... (13 more lines)</code></blockquote>
<p><em>View full code: <a href="https://gist.github.com/geyuxu/634c9869d8da36e90f60708e36294701">GitHub Gist</a></em></p><p><strong>Key design decisions:</strong></p>
<ul>
<li><strong>No backend required</strong> - everything runs in the browser or edge</li>
<li><strong>API key protection</strong> - OpenAI calls go through Cloudflare Worker</li>
<li><strong>Progressive UX</strong> - keyword results appear instantly, AI results merge in</li>
<li><strong>Hybrid ranking</strong> - Reciprocal Rank Fusion combines both result sets</li>
</ul>
<h2>Part 1: Building the Search Index</h2>
<p>At build time, we generate three files:</p>
<p><img src="/blog/images/tables/table-4797f0ca.png" alt="Table"></p><h3>The Index Builder</h3>
<blockquote><code>// scripts/index-builder.mjs</code><br>
<code>import { Voy } from &#039;voy-search/voy_search.js&#039;;</code><br>
<code></code><br>
<code>const CONFIG = {</code><br>
<code>    postsDir: &#039;blog/posts&#039;,</code><br>
<code>    dimensions: 512,        // text-embedding-3-small supports 512</code><br>
<code>    model: &#039;text-embedding-3-small&#039;,</code><br>
<code>    chunkSize: 500,</code><br>
<code># ... (48 more lines)</code></blockquote>
<p><em>View full code: <a href="https://gist.github.com/geyuxu/8624315f283968f3aadf09362a7cf149">GitHub Gist</a></em></p><p>The bilingual tokenizer is crucial - it handles:</p>
<ul>
<li><strong>English</strong>: standard word tokenization with stopword removal</li>
<li><strong>Chinese</strong>: character unigrams + bigrams (no word segmentation library needed)</li>
</ul>
<h3>Getting Embeddings from OpenAI</h3>
<blockquote><code>async function getEmbeddings(texts) {</code><br>
<code>    const response = await fetch(&#039;https://api.openai.com/v1/embeddings&#039;, {</code><br>
<code>        method: &#039;POST&#039;,</code><br>
<code>        headers: {</code><br>
<code>            &#039;Authorization&#039;: `Bearer ${process.env.OPENAI_API_KEY}`,</code><br>
<code>            &#039;Content-Type&#039;: &#039;application/json&#039;,</code><br>
<code>        },</code><br>
<code>        body: JSON.stringify({</code><br>
<code># ... (8 more lines)</code></blockquote>
<p><em>View full code: <a href="https://gist.github.com/geyuxu/428d6fb3f8356571a768f33ee18264ea">GitHub Gist</a></em></p><p><strong>Why 512 dimensions?</strong> OpenAI&#39;s text-embedding-3-small supports dimension reduction. Using 512 instead of 1536 cuts index size by ~65% with minimal quality loss.</p>
<h2>Part 2: The Cloudflare Worker</h2>
<p>The Worker acts as a secure proxy, keeping your API key hidden from the browser.</p>
<blockquote><code>// workers/embed-worker.js</code><br>
<code>export default {</code><br>
<code>    async fetch(request, env) {</code><br>
<code>        const corsHeaders = {</code><br>
<code>            &quot;Access-Control-Allow-Origin&quot;: &quot;https://yuxu.ge&quot;,</code><br>
<code>            &quot;Access-Control-Allow-Methods&quot;: &quot;POST, OPTIONS&quot;,</code><br>
<code>            &quot;Access-Control-Allow-Headers&quot;: &quot;Content-Type&quot;,</code><br>
<code>        };</code><br>
<code># ... (38 more lines)</code></blockquote>
<p><em>View full code: <a href="https://gist.github.com/geyuxu/89040955999c06025fa8033bc9cbbf4d">GitHub Gist</a></em></p><p><strong>Cloudflare setup:</strong></p>
<ol>
<li>Create a Worker at <code>api-embedding.your-worker.workers.dev</code></li>
<li>Add route: <code>yuxu.ge/api/*</code> → your Worker</li>
<li>Set environment variable: <code>OPENAI_API_KEY</code></li>
</ol>
<p>Now your frontend calls <code>/api/embedding</code> and never sees the API key.</p>
<h2>Part 3: The Hybrid Search Client</h2>
<p>The magic happens in the browser. We run two searches in parallel:</p>
<blockquote><code>// components/search-client.js</code><br>
<code>export class SearchClient {</code><br>
<code>    async init() {</code><br>
<code>        // Load all indexes in parallel</code><br>
<code>        const [voyModule, indexRes, metaRes, invertedRes] = await Promise.all([</code><br>
<code>            import(&#039;/public/lib/voy-loader.js&#039;).then(m =&gt; m.getVoy()),</code><br>
<code>            fetch(&#039;/public/search.dat&#039;),</code><br>
<code>            fetch(&#039;/public/search-metadata.json&#039;),</code><br>
<code># ... (68 more lines)</code></blockquote>
<p><em>View full code: <a href="https://gist.github.com/geyuxu/00e7adb39c363c988209f6036fbadc70">GitHub Gist</a></em></p><h3>Why Reciprocal Rank Fusion?</h3>
<p>RRF is elegantly simple: <code>score = Σ 1/(k + rank)</code> for each retriever. It doesn&#39;t require score normalization and handles the different scales of BM25 scores vs vector distances gracefully.</p>
<h2>Part 4: Progressive UX</h2>
<p>The key insight: <strong>keyword search is instant, semantic search needs an API call</strong>. We show keyword results immediately, then merge in AI results with animation:</p>
<blockquote><code>async function handleSearch(query) {</code><br>
<code>    // 1. Instant keyword results</code><br>
<code>    const keywordResults = client.searchKeywordOnly(query);</code><br>
<code>    showResults(query, keywordResults, showAiLoading: true);</code><br>
<code></code><br>
<code>    // 2. AI search runs in background</code><br>
<code>    const semanticResults = await client.semanticSearch(query);</code><br>
<code></code><br>
<code>    // 3. Merge with animation</code><br>
<code>    mergeResults(semanticResults, keywordResults);</code><br>
<code>}</code></blockquote><p>The CSS animations make the experience feel polished:</p>
<blockquote><code>@keyframes slideIn {</code><br>
<code>    from { opacity: 0; transform: translateY(-10px); }</code><br>
<code>    to { opacity: 1; transform: translateY(0); }</code><br>
<code>}</code><br>
<code></code><br>
<code>.search-result-item.new {</code><br>
<code>    animation: slideIn 0.3s ease-out;</code><br>
<code>}</code></blockquote><p>Each result shows badges indicating its source:</p>
<ul>
<li><strong><code>keyword</code></strong> (blue) - matched via BM25</li>
<li><strong><code>AI</code></strong> (pink) - matched via vector similarity</li>
<li>Both badges if found by both methods</li>
</ul>
<h2>Performance Characteristics</h2>
<p><img src="/blog/images/tables/table-b299cb01.png" alt="Table"></p><p>The hybrid approach gives you the best of both worlds:</p>
<ul>
<li><strong>Exact matches</strong> via keyword search (searching &quot;Docker&quot; finds &quot;Docker&quot; immediately)</li>
<li><strong>Semantic matches</strong> via vectors (searching &quot;container security&quot; finds Docker articles)</li>
</ul>
<h2>Deployment Checklist</h2>
<ol>
<li><strong>Build indexes</strong>: <code>OPENAI_API_KEY=sk-xxx node scripts/index-builder.mjs</code></li>
<li><strong>Deploy Worker</strong>: Set up Cloudflare Worker with route mapping</li>
<li><strong>Upload static files</strong>: <code>search.dat</code>, <code>search-inverted.json</code>, <code>search-metadata.json</code></li>
<li><strong>Test</strong>: Open browser console, type in search box</li>
</ol>
<h2>Conclusion</h2>
<p>This architecture proves you don&#39;t need a backend server for sophisticated search. By splitting the work between build-time indexing, edge compute (Cloudflare Worker), and browser-side retrieval (Voy WASM), we get:</p>
<ul>
<li><strong>Security</strong>: API keys never touch the browser</li>
<li><strong>Speed</strong>: Keyword results appear instantly</li>
<li><strong>Quality</strong>: Semantic search understands intent</li>
<li><strong>Cost</strong>: Only pay for actual search queries, not server uptime</li>
</ul>
<p>The full source code is available at <a href="https://github.com/geyuxu/yuxu.ge">github.com/geyuxu/yuxu.ge</a>.</p>
<hr>
<p><em>Built with: OpenAI text-embedding-3-small, Voy WASM, Cloudflare Workers, vanilla JavaScript</em></p>

</body>
</html>