<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>RAG — Overview</title>
    <style>
        body { font-family: Georgia, serif; max-width: 700px; margin: 2rem auto; padding: 0 1rem; line-height: 1.7; color: #333; }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        h2 { font-size: 1.4rem; margin-top: 2rem; }
        pre { background: #f4f4f4; padding: 1rem; overflow-x: auto; border-radius: 4px; }
        code { font-family: Menlo, Monaco, monospace; font-size: 0.9em; }
        p code { background: #f4f4f4; padding: 0.2em 0.4em; border-radius: 3px; }
        img { max-width: 100%; }
        blockquote { border-left: 3px solid #ddd; margin-left: 0; padding-left: 1rem; color: #666; }
        ul { padding-left: 1.5rem; }
        hr { border: none; border-top: 1px solid #ddd; margin: 2rem 0; }
        a { color: #1a8917; }
    </style>
</head>
<body>
<hr>
<h2>date: 2025-11-30
tags: [rag, #rag #llm #retrieval]
legacy: true</h2>
<h1>RAG — Overview</h1>
<h2>Core</h2>
<p>RAG pipeline (high level):</p>
<ol>
<li>Ingest docs → chunk → embed → index  </li>
<li>Query → retrieve top-k chunks  </li>
<li>(Optional) rerank/filters  </li>
<li>Compose context → generate answer with citations</li>
</ol>
<p>Key design choices:</p>
<ul>
<li>Chunking: size/overlap trade-off (recall vs noise)</li>
<li>Retriever: BM25 vs dense vs hybrid</li>
<li>Reranking: improves precision when top-k is noisy</li>
<li>Context window budgeting: keep only what helps</li>
</ul>
<h2>Pitfalls</h2>
<ul>
<li>“Garbage in, garbage out”: poor docs / bad chunking dominates.</li>
<li>Over-retrieval: too many chunks → model ignores evidence.</li>
<li>Evaluation illusion: looks good on demos, fails on adversarial/long-tail queries.</li>
</ul>
<h2>Checklist (Can I…)</h2>
<ul>
<li><input disabled="" type="checkbox"> Explain why RAG reduces hallucination (but doesn’t eliminate it)</li>
<li><input disabled="" type="checkbox"> Implement a minimal RAG loop end-to-end</li>
<li><input disabled="" type="checkbox"> Design an evaluation set: answer accuracy + citation faithfulness</li>
</ul>
<h2>References</h2>
<ul>
<li>(add later) RAG survey / LangChain docs / LlamaIndex docs / relevant papers</li>
</ul>

</body>
</html>