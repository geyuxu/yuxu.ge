<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>图像分类：数据稀缺、样本增强与欠拟合/过拟合</title>
    <style>
        body { font-family: Georgia, serif; max-width: 700px; margin: 2rem auto; padding: 0 1rem; line-height: 1.7; color: #333; }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        h2 { font-size: 1.4rem; margin-top: 2rem; }
        pre { background: #f4f4f4; padding: 1rem; overflow-x: auto; border-radius: 4px; }
        code { font-family: Menlo, Monaco, monospace; font-size: 0.9em; }
        p code { background: #f4f4f4; padding: 0.2em 0.4em; border-radius: 3px; }
        img { max-width: 100%; }
        blockquote { border-left: 3px solid #ddd; margin-left: 0; padding-left: 1rem; color: #666; }
        ul { padding-left: 1.5rem; }
        hr { border: none; border-top: 1px solid #ddd; margin: 2rem 0; }
        a { color: #1a8917; }
    </style>
</head>
<body>
<hr>
<h2>date: 2024-01-01
tags: [ai, 图像分类, 数据增强, 过拟合, 欠拟合, pytorch]
legacy: true</h2>
<h1>图像分类：数据稀缺、样本增强与欠拟合/过拟合</h1>
<p><img src="/blog/images/tables/table--27c7804.png" alt="Table"></p><h3>3. 数据稀缺下的样本增强</h3>
<p>在所有解决过拟合的策略中，数据增强是最直接、最有效的方法之一。它通过对现有训练数据进行一系列随机变换，创造出更多样的、模型“未曾见过”的样本，从而在不增加标注成本的情况下，扩充了数据的信息量。</p>
<h4>3.1 几何变换</h4>
<p>这类变换模拟了物体在真实世界中可能出现的姿态、大小和位置变化。常用操作包括：随机旋转 (±15° to ±30°)、随机缩放 (0.8× to 1.2×) 和随机平移 (≤10% of image dimensions)。更复杂的变换如弹性扭曲 (Elastic Distortion) 和透视变换 (Perspective Transformation) 也能提供更强的泛化能力。</p>
<h4>3.2 像素级扰动</h4>
<p>这类变换旨在提高模型对图像质量变化的鲁棒性。例如，向图像中加入高斯噪声 (Gaussian Noise, e.g., σ=0.01-0.05 × 255) 或椒盐噪声 (Salt-and-Pepper Noise, e.g., ratio=0.3-0.5%)，以及应用高斯模糊 (GaussianBlur, kernel size=3 or 5) 或运动模糊 (MotionBlur)。</p>
<h4>3.3 颜色空间变换</h4>
<p>颜色空间的变换可以增强模型对光照、对比度和色彩变化的适应性。<code>ColorJitter</code> 是一个常用工具，它可以随机调整图像的亮度 (brightness)、对比度 (contrast) 和饱和度 (saturation)（例如，在 0.8-1.2 倍之间）。将图像转为灰度图再复制回三个通道，也是一种强制模型关注形状而非颜色的有效技巧。</p>
<h4>3.4 合成/混合方法</h4>
<p>近年来，将多张图片信息混合的增强方法变得非常流行，它们能创造出在真实世界中不存在但对模型正则化非常有益的样本。</p>
<p><img src="/blog/images/tables/table-2d9f9c2.png" alt="Table"></p><h4>3.5 自动增强</h4>
<p>手动设计增强策略组合费时费力，因此自动增强应运而生。<strong>RandAugment</strong> 是一种简单高效的方法，它从一个预设的变换池中随机挑选 N 种变换，并以一个统一的强度 M 应用。对于小数据集，它通常能带来显著收益（如 N=2, M=9）。更复杂的 <strong>AutoAugment</strong> 使用强化学习来搜索最佳策略组合，但计算成本高昂。</p>
<h3>4. 实践落地步骤 (PyTorch 示例)</h3>
<p>下面我们展示如何在 PyTorch 中构建一个包含多种增强策略的 <code>transform</code> 流水线，并实现一个可插拔的 Mixup 功能。</p>
<h4>4.1 变换流水线</h4>
<blockquote><code>import torchvision.transforms as T</code><br>
<code>import torch</code><br>
<code>import numpy as np</code><br>
<code></code><br>
<code># 自定义一个椒盐噪声类</code><br>
<code>class SaltPepperNoise:</code><br>
<code>    def __init__(self, ratio=0.003):</code><br>
<code>        self.ratio = ratio</code><br>
<code># ... (15 more lines)</code></blockquote>
<p><em>Full code available in the <a href="https://github.com/geyuxu">GitHub repository</a>.</em></p><p>这个流水线整合了多种几何和颜色变换。注意，<code>Normalize</code> 步骤通常放在最后，且其均值和标准差应基于预训练模型所使用的数据集（如 ImageNet）来设定。</p>
<h4>4.2 可插拔的 Mixup/CutMix</h4>
<blockquote><code>def mixup_data(x, y, alpha=0.2, use_cuda=True):</code><br>
<code>    &#039;&#039;&#039;Returns mixed inputs, pairs of targets, and lambda&#039;&#039;&#039;</code><br>
<code>    if alpha &gt; 0:</code><br>
<code>        lam = np.random.beta(alpha, alpha)</code><br>
<code>    else:</code><br>
<code>        lam = 1</code><br>
<code></code><br>
<code>    batch_size = x.size()[0]</code><br>
<code># ... (11 more lines)</code></blockquote>
<p><em>Full code available in the <a href="https://github.com/geyuxu">GitHub repository</a>.</em></p><p>在训练循环中，你可以从 DataLoader 中取出 <code>inputs</code> 和 <code>targets</code>，调用 <code>mixup_data</code> 生成混合数据，然后用 <code>mixup_criterion</code> 计算混合后的损失。</p>
<h4>4.3 学习曲线监控</h4>
<p>在整个训练过程中，必须持续监控训练集和验证集的准确率与损失曲线。一个关键的实践是<strong>早停 (Early Stopping)</strong>：当验证集损失连续 N 个周期（epoch）不再下降反而上升时，就应停止训练，并保存之前验证性能最好的模型权重。这能有效防止模型在训练后期陷入过拟合。</p>
<h3>5. 综合调优流程</h3>
<p>一个系统性的调优流程可以帮助你最大化数据增强的效果：</p>
<ol>
<li><strong>建立基线</strong>: 首先在没有任何数据增强的情况下训练模型，记录其准确率和损失作为基准。</li>
<li><strong>阶段一</strong>: 加入基础的几何和颜色变换，学习率可以保持不变或适当调大。</li>
<li><strong>阶段二</strong>: 引入 Mixup 或 CutMix，通常需要配合标签平滑 (Label Smoothing) 来获得更好效果。</li>
<li><strong>阶段三</strong>: 如果计算资源允许，尝试使用 RandAugment 或 AutoAugment 来自动搜索最佳的增强策略组合。</li>
<li><strong>阶段四</strong>: 最后，根据增强后的数据分布，微调模型的容量（如网络深度）和正则化参数（如 Dropout 率、权重衰减 weight decay）。</li>
</ol>
<h3>6. 常见坑 &amp; 实用 Tips</h3>
<ul>
<li><strong>过度增强</strong>: 过强的增强可能会使训练集分布与真实测试集分布产生严重漂移，反而损害性能。建议从一个较小的应用概率（如 <code>p=0.3</code>）开始试水。</li>
<li><strong>标签同步</strong>: 在目标检测或语义分割任务中，对图像进行几何变换时，必须对边界框 (bounding box) 或掩码 (mask) 执行完全相同的变换。</li>
<li><strong>验证集纯净度</strong>: 验证集应尽可能保持“干净”，以真实反映模型在原始数据分布上的性能。通常只对其进行必要的缩放 (Resize) 和中心裁剪 (Center Crop)，不做“重口味”的增强。</li>
<li><strong>小批量 Mixup</strong>: 在批量大小 (batch size) 很小的情况下使用 Mixup，可能会过度稀释原始信号。此时应考虑适当增大批量或调整学习率。</li>
</ul>
<h3>7. 结语与延伸</h3>
<p>面对数据稀缺的挑战，我们的核心目标是通过数据增强来<strong>扩充数据的多样性</strong>，而不仅仅是增加数量。欠拟合与过拟合的斗争，本质上是在模型的<strong>容量</strong>与数据的<strong>信息量</strong>之间寻找一个精妙的平衡点。</p>
<p>本文所介绍的策略是解决这一问题的经典起点。在此基础上，你还可以进一步探索更前沿的方向，例如：利用无标签数据进行自监督预训练 (Self-supervised Pre-training)、使用生成模型（如 Diffusion Models）或 3D 渲染来合成新数据、以及应用半监督学习 (Semi-supervised Learning) 等技术。</p>

</body>
</html>