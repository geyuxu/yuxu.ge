<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>图像增强在 OCR 中的实战作用</title>
    <style>
        body { font-family: Georgia, serif; max-width: 700px; margin: 2rem auto; padding: 0 1rem; line-height: 1.7; color: #333; }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        h2 { font-size: 1.4rem; margin-top: 2rem; }
        pre { background: #f4f4f4; padding: 1rem; overflow-x: auto; border-radius: 4px; }
        code { font-family: Menlo, Monaco, monospace; font-size: 0.9em; }
        p code { background: #f4f4f4; padding: 0.2em 0.4em; border-radius: 3px; }
        img { max-width: 100%; }
        blockquote { border-left: 3px solid #ddd; margin-left: 0; padding-left: 1rem; color: #666; }
        ul { padding-left: 1.5rem; }
        hr { border: none; border-top: 1px solid #ddd; margin: 2rem 0; }
        a { color: #1a8917; }
    </style>
</head>
<body>
<hr>
<h2>date: 2025-04-01
tags: [ai]
legacy: true</h2>
<h1>图像增强在 OCR 中的实战作用</h1>
<p>这篇文章就来分享一下我们实际做过的图像增强方式、效果对比、还有一些实验记录。</p>
<hr>
<p><strong>2. 为啥 OCR 更依赖图像增强？</strong></p>
<p>图像增强这件事，其实很多做分类模型的朋友可能觉得“锦上添花”，不增强也能训。但 OCR 是另一个物种。</p>
<p><strong>OCR 有几个天然硬伤：</strong></p>
<p>• <strong>输入信息量少</strong>：一张车牌、小票、票据，本来就只有几个字符，容不得你漏一个；</p>
<p>• <strong>字符很敏感</strong>：一个像素模糊都可能把 8 看成 B，或者 3 看成 5；</p>
<p>• <strong>数据变化范围大</strong>：旋转、曝光、遮挡、脏污、低清晰度……这些都是现实 OCR 系统每天要打交道的；</p>
<p>所以 OCR 模型不光得会识别清晰的字符，更得能扛住“脏图”。</p>
<p>而图像增强，恰好就是把这些“坏场景”模拟出来的最好方式。它不会直接提升你训练集的容量，但会<strong>拉高模型的认知范围和抗噪能力</strong>，很多时候，<strong>模型训练得不好，不一定是网络不够，而是数据太“单纯”。</strong></p>
<p><strong>3. 我们用过的图像增强方法（按类型分类）</strong></p>
<p>为了让模型识别能力更贴近真实环境，我们当时尝试了几种图像增强方式，基本可以分为以下几类：</p>
<p><strong>🌀 3.1 几何变换类</strong></p>
<blockquote>
<p>模拟各种角度拍摄、图像倾斜、歪斜摆放等场景。</p>
</blockquote>
<p>• <strong>轻微旋转（±10°~15°）</strong></p>
<p>模拟车辆歪着进场、小票拍摄角度不正的情况。</p>
<p>• <strong>缩放 + 裁剪</strong></p>
<p>模拟摄像头或用户拍摄时框得不准，字符被切边或者缩小。</p>
<p>• <strong>仿射/透视变换</strong></p>
<p>稍复杂，但能很好模拟斜拍、侧拍，特别实用。</p>
<p><strong>💡 3.2 光照和色彩类</strong></p>
<blockquote>
<p>现实中拍照会遇到强光、阴影、曝光不足，必须要模拟。</p>
</blockquote>
<p>• <strong>亮度增强/降低</strong></p>
<p>模拟白天阳光强烈或夜间昏暗的图像。</p>
<p>• <strong>对比度调整</strong></p>
<p>提升或压低图像对比度，模仿脏污/强光干扰。</p>
<p>• <strong>颜色扰动（HSV 偏移）</strong></p>
<p>轻微改动色调，增加模型的颜色鲁棒性。</p>
<p><strong>🌫️ 3.3 模糊/噪声类</strong></p>
<blockquote>
<p>很多图模糊并不是摄像头坏，而是运动中拍的。</p>
</blockquote>
<p>• <strong>高斯模糊</strong></p>
<p>模拟镜头没对好焦或车牌快速移动时的拖影。</p>
<p>• <strong>椒盐噪声</strong></p>
<p>模拟图像传输压缩时的噪点，车牌压缩图经常出问题。</p>
<p>• <strong>运动模糊（Motion Blur）</strong></p>
<p>模拟车辆进出过快导致的拉丝感。</p>
<p><strong>🔧 3.4 自定义遮挡/拼接类（我们项目场景特有）</strong></p>
<p>• <strong>添加局部遮挡（半透明灰块、贴条）</strong></p>
<p>模拟有灰尘、车牌被装饰物遮挡的情况。</p>
<p>• <strong>拼接错位字符图</strong></p>
<p>把不同车牌字符截出来拼成新图，制造字符间距异常的样本。</p>
<p>这些操作虽然听着都挺“基础”的，但组合起来就是一套硬核训练法——不夸张地说，模型识别能力从“只会认干净图”变成了“脏图也能八九不离十”。</p>
<hr>
<p><strong>4. 每种增强方法对效果的影响（我们实测的结果）</strong></p>
<p>我们在一批验证集中分别测试了“不开增强”和“单种增强后训练”的结果，下面是一些实测数据（基于 CRNN+CTC OCR 结构，在 5k 训练样本上训练，验证集 1k 张）：</p>
<p><img src="/blog/images/tables/table--8a8c323.png" alt="Table"></p><p>最明显的提升来自两个方向：</p>
<ol>
<li><p><strong>旋转 + 遮挡</strong>：因为现实中这两种情况最常见；</p>
</li>
<li><p><strong>增强组合使用，而不是单独用一两种</strong>。</p>
</li>
</ol>
<p>而且我们还发现一个现象：<strong>增强带来的提升，在训练数据量较小时特别明显</strong>。小数据集 + 强增强，比大数据 + 弱增强的提升还要直接。</p>
<p><strong>5. 增强组合策略与使用建议</strong></p>
<p>虽然增强方式很多，但不是所有增强都适合一起乱加，尤其在 OCR 场景里，一不小心加猛了，模型反而“学乱了”。</p>
<p>以下是我们做实验后踩出来的一些组合策略建议，适合 OCR 或小样本图像任务使用：</p>
<p><strong>✅ 实用组合一：基础耐受增强</strong></p>
<p>适合任何模型做基础鲁棒性打底。</p>
<blockquote><code>✔ 轻微旋转（±10°）  </code><br>
<code>✔ 亮度调节（+/-20%）  </code><br>
<code>✔ 色调扰动（HSV 小幅偏移）  </code><br>
<code>✔ 高斯模糊（1~2px）</code></blockquote><p>✅ 效果稳定、几乎不会破坏字符形状，是我们默认打开的一组增强。</p>
<p><strong>✅ 实用组合二：脏图专用抗压训练</strong></p>
<p>适合针对实际部署环境“画面脏、反光多、模糊严重”的场景。</p>
<blockquote><code>✔ 遮挡模拟（随机加灰块）  </code><br>
<code>✔ 运动模糊（水平或竖直）  </code><br>
<code>✔ 对比度压缩  </code><br>
<code>✔ 背景扰动（局部添加噪声）</code></blockquote><p>⚠ 这组增强会加大模型训练难度，建议在前面训练过一轮、或者模型已经“稳住”之后再加入。</p>
<p><strong>⚙ 增强策略建议（我们自己的经验）：</strong></p>
<p>• <strong>前 10 轮训练不要加太重的增强</strong></p>
<p>模型刚开始还没学会基本形状，加太多干扰会迷糊；</p>
<p>• <strong>中期可以分批加增强</strong></p>
<p>我们是每 5~10 个 epoch 动态开启一种新增强，逐步加压；</p>
<p>• <strong>后期增强可适当减弱，避免过拟合在异常图上</strong></p>
<p>最终测试集效果不好，有时不是模型退化，而是训练图太“花”了。</p>
<hr>
<p><strong>6. 增强不是万能，但在 OCR 里它几乎是刚需</strong></p>
<p>最后总结几句。</p>
<p>说实话，图像增强这个事，在很多模型训练工程师眼里都算“杂活”，不够高大上，也不像搞 Transformer 那样显得很厉害。但我们项目做完之后最大的感受是：</p>
<blockquote>
<p>在 OCR 这类任务里，增强不只是提升模型的一种方式，很多时候是它能不能「活下来」的前提。</p>
</blockquote>
<p>我们曾经尝试不加任何增强，只用“干净数据”训练，模型在验证集上表现很好，但上线不到一小时就开始疯狂识错。最后一轮带增强训练后的模型，虽然训练 loss 跌得慢了一点，但实际稳定得多——尤其在夜间、雨天、边缘图像这些“真实世界的黑暗面”。</p>
<p>所以，如果你也正在做 OCR 项目，或者是小样本图像分类，不妨认真想一想：</p>
<p>与其花三天调网络结构，可能还不如花一天，好好做做数据增强。</p>

</body>
</html>