<!DOCTYPE html><html lang="en" data-astro-cid-bvzihdzo> <head><!-- Global Metadata --><meta charset="utf-8"><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="icon" type="image/svg+xml" href="/favicon.svg"><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" title="Ge Yuxu Blog" href="https://geyuxu.com/rss.xml"><meta name="generator" content="Astro v5.5.6"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><!-- Canonical URL --><link rel="canonical" href="https://geyuxu.com/blog/ai/00/%E4%BB%8E%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E6%BC%94%E8%BF%9B%E5%AE%9E%E8%B7%B5/"><!-- Primary Meta Tags --><title>从传统图像处理到深度学习：车牌识别系统演进实践</title><meta name="title" content="从传统图像处理到深度学习：车牌识别系统演进实践"><meta name="description"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://geyuxu.com/blog/ai/00/%E4%BB%8E%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E6%BC%94%E8%BF%9B%E5%AE%9E%E8%B7%B5/"><meta property="og:title" content="从传统图像处理到深度学习：车牌识别系统演进实践"><meta property="og:description"><meta property="og:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://geyuxu.com/blog/ai/00/%E4%BB%8E%E4%BC%A0%E7%BB%9F%E5%9B%BE%E5%83%8F%E5%A4%84%E7%90%86%E5%88%B0%E6%B7%B1%E5%BA%A6%E5%AD%A6%E4%B9%A0%E8%BD%A6%E7%89%8C%E8%AF%86%E5%88%AB%E7%B3%BB%E7%BB%9F%E6%BC%94%E8%BF%9B%E5%AE%9E%E8%B7%B5/"><meta property="twitter:title" content="从传统图像处理到深度学习：车牌识别系统演进实践"><meta property="twitter:description"><meta property="twitter:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><style>.content[data-astro-cid-7jjqptxk]{max-width:720px;margin:0 auto;padding:2rem 1rem;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,sans-serif;font-size:1.05rem;line-height:1.75;color:#333}.content[data-astro-cid-7jjqptxk] h1[data-astro-cid-7jjqptxk],.content[data-astro-cid-7jjqptxk] h2[data-astro-cid-7jjqptxk],.content[data-astro-cid-7jjqptxk] h3[data-astro-cid-7jjqptxk]{font-weight:600;margin-top:2rem;margin-bottom:1rem;line-height:1.3}.content[data-astro-cid-7jjqptxk] p[data-astro-cid-7jjqptxk]{margin-bottom:1.25rem}.content[data-astro-cid-7jjqptxk] a[data-astro-cid-7jjqptxk]{color:var(--accent, #0070f3);text-decoration:underline}.content[data-astro-cid-7jjqptxk] img[data-astro-cid-7jjqptxk]{max-width:100%;border-radius:6px;margin:1.5rem 0}.content[data-astro-cid-7jjqptxk] pre[data-astro-cid-7jjqptxk],.content[data-astro-cid-7jjqptxk] code[data-astro-cid-7jjqptxk]{font-family:Menlo,Monaco,Consolas,Courier New,monospace;background:#f4f4f4;padding:.2em .4em;border-radius:4px}.content[data-astro-cid-7jjqptxk] pre[data-astro-cid-7jjqptxk]{padding:1em;overflow-x:auto}
:root{--accent: #2337ff;--accent-dark: #000d8a;--black: 15, 18, 25;--gray: 96, 115, 159;--gray-light: 229, 233, 240;--gray-dark: 34, 41, 57;--gray-gradient: rgba(var(--gray-light), 50%), #fff;--box-shadow: 0 2px 6px rgba(var(--gray), 25%), 0 8px 24px rgba(var(--gray), 33%), 0 16px 32px rgba(var(--gray), 33%)}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-regular.woff) format("woff");font-weight:400;font-style:normal;font-display:swap}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-bold.woff) format("woff");font-weight:700;font-style:normal;font-display:swap}body{font-family:Atkinson,sans-serif;margin:0;padding:0;text-align:left;background:linear-gradient(var(--gray-gradient)) no-repeat;background-size:100% 600px;word-wrap:break-word;overflow-wrap:break-word;color:rgb(var(--gray-dark));font-size:20px;line-height:1.7}main{width:720px;max-width:calc(100% - 2em);margin:auto;padding:3em 1em}h1,h2,h3,h4,h5,h6{margin:0 0 .5rem;color:rgb(var(--black));line-height:1.2}h1{font-size:3.052em}h2{font-size:2.441em}h3{font-size:1.953em}h4{font-size:1.563em}h5{font-size:1.25em}strong,b{font-weight:700}a,a:hover{color:var(--accent)}p{margin-bottom:1em}.prose p{margin-bottom:2em}textarea{width:100%;font-size:16px}input{font-size:16px}table{width:100%}img{max-width:100%;height:auto;border-radius:8px}code{padding:2px 5px;background-color:rgb(var(--gray-light));border-radius:2px}pre{padding:1.5em;border-radius:8px}pre>code{all:unset}blockquote{border-left:4px solid var(--accent);padding:0 0 0 20px;margin:0;font-size:1.333em}hr{border:none;border-top:1px solid rgb(var(--gray-light))}@media (max-width: 720px){body{font-size:18px}main{padding:1em}}.sr-only{border:0;padding:0;margin:0;position:absolute!important;height:1px;width:1px;overflow:hidden;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);clip-path:inset(50%);white-space:nowrap}
a[data-astro-cid-eimmu3lg]{display:inline-block;text-decoration:none}a[data-astro-cid-eimmu3lg].active{font-weight:bolder;text-decoration:underline}header[data-astro-cid-3ef6ksr2]{margin:0;padding:0 1em;background:#fff;box-shadow:0 2px 8px rgba(var(--black),5%)}h2[data-astro-cid-3ef6ksr2]{margin:0;font-size:1em}h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2],h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none}nav[data-astro-cid-3ef6ksr2]{display:flex;align-items:center;justify-content:space-between}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{padding:1em .5em;color:var(--black);border-bottom:4px solid transparent;text-decoration:none}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none;border-bottom-color:var(--accent)}.social-links[data-astro-cid-3ef6ksr2],.social-links[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{display:flex}@media (max-width: 720px){.social-links[data-astro-cid-3ef6ksr2]{display:none}}footer[data-astro-cid-sz7xmlte]{padding:2em 1em 6em;background:linear-gradient(var(--gray-gradient)) no-repeat;color:rgb(var(--gray));text-align:center}.social-links[data-astro-cid-sz7xmlte]{display:flex;justify-content:center;gap:1em;margin-top:1em}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]{text-decoration:none;color:rgb(var(--gray))}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]:hover{color:rgb(var(--gray-dark))}
main[data-astro-cid-bvzihdzo]{width:calc(100% - 2em);max-width:100%;margin:0}.hero-image[data-astro-cid-bvzihdzo]{width:100%}.hero-image[data-astro-cid-bvzihdzo] img[data-astro-cid-bvzihdzo]{display:block;margin:0 auto;border-radius:12px;box-shadow:var(--box-shadow)}.prose[data-astro-cid-bvzihdzo]{width:720px;max-width:calc(100% - 2em);margin:auto;padding:1em;color:rgb(var(--gray-dark))}.title[data-astro-cid-bvzihdzo]{margin-bottom:1em;padding:1em 0;text-align:center;line-height:1}.title[data-astro-cid-bvzihdzo] h1[data-astro-cid-bvzihdzo]{margin:0 0 .5em}.date[data-astro-cid-bvzihdzo]{margin-bottom:.5em;color:rgb(var(--gray))}.last-updated-on[data-astro-cid-bvzihdzo]{font-style:italic}
</style></head> <body data-astro-cid-bvzihdzo> <header data-astro-cid-3ef6ksr2> <nav data-astro-cid-3ef6ksr2> <h2 data-astro-cid-3ef6ksr2><a href="/" data-astro-cid-3ef6ksr2>Ge Yuxu Blog</a></h2> <div class="internal-links" data-astro-cid-3ef6ksr2> <a href="/" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Home </a>  <a href="/blog" class="active" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Blog </a>  <a href="/series" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Series </a>  <a href="/projects" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Projects </a>  <!-- <HeaderLink href="/about">About</HeaderLink> --> </div> <div class="social-links" data-astro-cid-3ef6ksr2> <a href="https://github.com/geyuxu" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Go to Ge Yuxu's GitHub repo</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" data-astro-cid-3ef6ksr2><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-3ef6ksr2></path></svg> </a> <a href="https://www.linkedin.com/in/geyuxu/" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Go to Ge Yuxu's LinkedIn profile</span> <svg viewBox="0 0 24 24" width="32" height="32" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" data-astro-cid-3ef6ksr2> <path fill="currentColor" d="M20.447 20.452H17.2v-5.569c0-1.328-.025-3.039-1.852-3.039-1.853 0-2.136 1.447-2.136 2.942v5.666h-3.248V9h3.122v1.561h.045c.435-.823 1.498-1.688 3.083-1.688 3.295 0 3.903 2.17 3.903 4.989v6.59zM5.337 7.433a1.882 1.882 0 110-3.764 1.882 1.882 0 010 3.764zm1.626 13.019H3.708V9h3.255v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.226.792 24 1.771 24h20.451C23.2 24 24 23.226 24 22.271V1.729C24 .774 23.2 0 22.222 0z" data-astro-cid-3ef6ksr2></path> </svg> </a> </div> </nav> </header>  <main data-astro-cid-bvzihdzo> <article data-astro-cid-bvzihdzo> <div class="prose" data-astro-cid-bvzihdzo> <!--
					<div class="title">
						<div class="date">
							<FormattedDate date={pubDate} />
							{
								updatedDate && (
									<div class="last-updated-on">
										Last updated on <FormattedDate date={updatedDate} />
									</div>
								)
							}
						</div>
						<h1>{title}</h1>
						<hr /> 
					</div>
					-->  <article class="content" data-astro-cid-7jjqptxk> <p><strong>1. 项目背景简介</strong></p>
<p>这几年智能停车场越来越多，很多商场和写字楼都在把原来那套人工登记、人工收费的系统换成自动识别的。我们当时也正好接到一个需求，要做一个支持<strong>车牌自动识别 + 自动计费 + 自动放行</strong>的系统，用来提升停车场的出入口通行效率。</p>
<p>其实一开始要求还挺高的：识别准确率要能稳定在 95% 以上，识别+计费流程整体耗时不能超过 1.5 秒，而且最好支持多种车牌样式——蓝的黄的新能源的全都得识别，还得能部署在本地边缘设备上，不能太吃资源。</p>
<p>当时想着，先用一些传统图像处理手段快速搭一套试试看，成本低、见效快。于是我们就先搞了一版基于 OpenCV 的实现。</p>
<hr>
<p><strong>2. 初版方案：传统图像处理路线</strong></p>
<p>我们最早的一版系统，其实没有用任何深度学习，就是靠图像处理+逻辑判断“硬撸”出来的。虽然精度不高，但原型很快就能跑起来。</p>
<p><strong>2.1 滑窗 + OpenCV 做车牌区域检测</strong></p>
<p>我们用 OpenCV 把图像先做一波预处理，主要流程是灰度化 → 高斯滤波 → Canny 边缘检测，然后就开始滑窗遍历整张图，去找那些长宽比像车牌的矩形区域。</p>
<p>为了过滤掉噪声，我们还加了一些颜色和形状上的判断，比如常见的蓝底白字车牌，在 HSV 色彩空间里很容易就能分出来。靠这些规则，基本能把车牌位置框出来，虽然偶尔也会误框一些广告牌或者后车灯。</p>
<p><strong>2.2 字符分割 + 模板匹配做识别</strong></p>
<p>框出来之后，我们用图像切割把车牌字符一个个分出来，然后做模板匹配。简单说就是和一堆已有的字母、数字图片做对比，看哪个最像，就认成哪个。</p>
<p>说实话，这一步就是纯靠像素比对，样式稍微变一点它就认不出来了。比如字体粗细变了、字歪了、背景有点反光，全都容易识错。</p>
<p><strong>2.3 实际遇到的问题</strong></p>
<p>我们内部测试的时候觉得还凑合，但真上线了就开始掉链子——</p>
<p>• 下雨天车牌有水渍，识别率暴跌；</p>
<p>• 晚上光线暗，边缘提不出来；</p>
<p>• 有些车歪着进场，角度一偏字符就分不准了；</p>
<p>• 模板匹配对字形太敏感，新版新能源车牌基本识别失败。</p>
<p>还有个致命问题是速度太慢了。滑窗处理一整张图耗时很久，尤其分辨率一高，CPU 根本跑不过来。那时候我们就知道，再优化也有限，得换思路了——考虑上深度学习。</p>
<p><strong>3. 升级阶段一：引入 CTPN 做字符区域检测</strong></p>
<p>传统方法在定位车牌区域这一步已经吃力了，但更麻烦的其实是<strong>字符切割</strong>。一旦车牌有点歪，或者字符之间间距不一致，传统的按列投影法基本就挂了。我们团队那时候几乎一半时间都花在调字符分割上，怎么调都不稳定。</p>
<p>所以后来我们决定直接上深度学习，第一步就是换掉字符定位的部分，用一个更鲁棒的检测模型：<strong>CTPN（Connectionist Text Proposal Network）</strong>。</p>
<p><strong>3.1 为什么选 CTPN？</strong></p>
<p>那时候还没有像现在这么多轻量级的 OCR 模型。CTPN 虽然不是最新的，但它是专门做<strong>自然场景中的文本检测</strong>的，特别适合处理那些角度稍歪、背景有干扰的文字区域。而且它的原理比较有意思：不是把整行字符当成一个框，而是把字符行“切”成一段段的小 proposal，然后再把它们串起来，最终框出整段文本。</p>
<p>这种“横向连通”的思想，恰好适合车牌这种一行排开的字符。</p>
<p><strong>3.2 模型使用流程</strong></p>
<p>我们当时复用了别人开源的 CTPN TensorFlow 实现，拿过来以后先在公开数据集上验证能跑起来，再用我们自己采集的车牌图像进行 finetune（微调）。</p>
<p>训练过程倒没太多坑，就是数据标注有点费劲——每张图都要标出字符区域的小框，后来我们写了个半自动工具，先用传统边缘检测预选，再人工微调，大大提高了效率。</p>
<p>训练好之后模型效果立竿见影：</p>
<p>• 哪怕车牌轻微倾斜，也能正确框出整行字符；</p>
<p>• 遇到遮挡或者局部模糊的车牌，也能保证字符区域尽量完整；</p>
<p>• 最关键的是，字符行出来了之后就<strong>不用再手动分割字符</strong>了！</p>
<p>这对我们后面的字符识别环节简直是质的飞跃。</p>
<p><strong>3.3 性能表现</strong></p>
<p>CTPN 本身不算轻量，尤其是在当年的设备环境下（主要是边缘侧部署），我们做了以下几步来优化：</p>
<p>• 裁剪输入图像，只对车牌区域附近做检测（前面用传统方式做一次粗定位）；</p>
<p>• 减小模型输入尺寸，换成更小的 anchor 尺寸；</p>
<p>• 模型量化 + TensorRT 优化一波（这个后来才做，效果不错）；</p>
<p>优化之后，CTPN 模块的平均耗时控制在 300~500ms 左右，精度也远比传统方式高不少。</p>
<p><strong>4. 升级阶段二：CRNN + CTC 字符识别方案</strong></p>
<p>字符区域搞定之后，接下来就是让系统“读”出字符了。我们最开始也试过一些轻量级的字符分类网络，比如把每个字符框提出来后单独做分类（Softmax + CNN），但发现效果也不稳定：字符框切得不准就识别错误，而且这种方式对字符的前后顺序毫无理解能力。</p>
<p>所以最终我们上了比较经典的一套组合：<strong>CRNN + CTC</strong>。</p>
<p><strong>4.1 CRNN 是啥？</strong></p>
<p>简单说，CRNN（Convolutional Recurrent Neural Network）是个三段式结构：</p>
<ol>
<li>
<p><strong>CNN 卷积层</strong>：提取图像特征；</p>
</li>
<li>
<p><strong>RNN 结构（我们用的是双向 LSTM）</strong>：处理特征序列，理解前后语境；</p>
</li>
<li>
<p><strong>全连接层 + CTC 输出</strong>：生成字符预测结果。</p>
</li>
</ol>
<p>这种结构特别适合处理「一整行字符」的图像，也就是那种你不需要逐个分割字符，而是直接把一张字符区域图喂进去，它就能一口气输出整个字符串的方案。非常适合车牌识别场景。</p>
<p><strong>4.2 为什么要用 CTC？</strong></p>
<p>CTC（Connectionist Temporal Classification）最牛的地方就是<strong>不要求字符和位置一一对齐</strong>。也就是说，我们训练的时候只需要提供整张图片对应的文字标签，比如：</p>
<img src="http://img.geyuxu.com/image-2025040201.png" title="" alt="" width="296">
<p>标签：鲁N Y97L0</p>
<p>CTC 会自己在训练中学会怎么对齐字符和图像上的位置，不需要你提前标出每个字符在哪儿。对我们这种实际数据标注难度高的项目太友好了。</p>
<p><strong>4.3 模型训练的一些事</strong></p>
<p>我们训练用的数据主要来自我们自己采集的监控视频截图，用脚本定期抓取画面，然后人工标注车牌文字。清洗过程还是挺繁琐的：</p>
<p>• 把模糊图、反光图去掉；</p>
<p>• 对图片做标准化处理，比如统一宽高比；</p>
<p>• 加了一些图像增强操作，比如旋转、模糊、噪声、色偏，提升模型鲁棒性。</p>
<p>训练过程中也踩过一些坑，比如：</p>
<p>• 序列长度不够长，CTC 输出容易塌缩（输出成重复字符）；</p>
<p>• 字符集设计不完善，漏掉了新能源车的“D”“F”前缀；</p>
<p>• 数据分布不均，造成某些字符识别率偏低；</p>
<p>不过整体来说，模型在验证集上的准确率很快就拉到了 95% 左右，最关键的是——在一些传统方法完全识别不出来的场景，它居然能读出来！像那种模糊不清但人眼还能猜的图，它也能成功识别，算是给我们打了一针强心剂。</p>
<p><strong>5. 数据准备与增强实践</strong></p>
<p>说句实话，模型训练靠的不是花里胡哨的网络结构，真的靠的是<strong>数据质量</strong>。我们这个车牌识别模型能跑得还不错，80%功劳都得归到数据处理这一步上。</p>
<p><strong>5.1 数据从哪来？</strong></p>
<p>我们最初的数据来源是监控视频截图。停车场每辆车进出时摄像头都会抓拍画面，我们写了个脚本，定期从存储系统里抽取图片，带时间戳的那种。</p>
<p>不过这些原始图都不能直接拿来训练，需要经过一轮又一轮清洗。我们干了这些事：</p>
<p>• <strong>图像裁剪</strong>：只保留有车牌的部分，背景太大的图直接舍弃；</p>
<p>• <strong>质量筛选</strong>：模糊、曝光过度、反光太强的图直接扔掉；</p>
<p>• <strong>人工标注</strong>：用一个简单的图像标注工具，人肉输入每张图的真实车牌号；</p>
<p>• <strong>字符集整理</strong>：收集所有可能的字符，建立一套车牌字符字典（包括新能源前缀、军牌、省份简称等等）；</p>
<p>标注过程真的挺磨人的，不过好在只要首批数据标得够准，后面可以用模型做预标注，再人工纠正，就轻松多了。</p>
<p><strong>5.2 图像增强操作（真的有用）</strong></p>
<p>为了让模型能扛住各种“车牌奇葩状态”，我们给训练图做了一大堆增强：</p>
<p>• <strong>旋转</strong>：±15° 以内轻微旋转，模拟歪着进来的车；</p>
<p>• <strong>亮度变化</strong>：随机调亮/调暗，模拟白天和夜晚；</p>
<p>• <strong>模糊处理</strong>：加一点点高斯模糊，模拟镜头虚焦；</p>
<p>• <strong>添加噪声</strong>：模拟雨天、脏污；</p>
<p>• <strong>色调变化</strong>：HSV 色彩空间做扰动，模拟白平衡偏差；</p>
<p>这些增强操作真的不是为了凑热闹——我们一开始模型在夜间图表现特别差，后来特地加了一批“夜间风格”的增强图，再训练一次之后明显效果提升了。</p>
<p>而且有些问题增强也解决不了，比如遮挡、反光那些，我们后来干脆拉了一批「问题图」单独训练，变成模型的专项强化练习（笑）。</p>
<p><strong>5.3 数据分布也很重要</strong></p>
<p>一开始我们犯了个低级错误：数据集中上海车牌（沪A、沪B）占了大头，导致模型总是喜欢猜“沪”。后来我们调整了数据分布比例，让不同省份、不同类型的车牌在训练集里更均匀，这才缓过来。</p>
<p><strong>6. 模型部署与系统集成</strong></p>
<p>模型训好了，只能算半成事。真正要上线用，还得把模型变成一个随时能被系统“叫醒”、快速响应的服务，这部分其实我们也花了不少时间。</p>
<p><strong>6.1 用 Flask 封一层接口</strong></p>
<p>我们一开始选的是最直接的方式：<strong>Flask + TensorFlow（1.x）原生 Session</strong> 来做部署。没用什么 fancy 的部署框架，主要是为了轻量和方便调试，接口结构大概就这样：</p>
<p>• /predict：接收图片（base64 或 multipart），调用模型推理，返回识别结果；</p>
<p>• /ping：健康检查；</p>
<p>• /reload（内部用）：重新加载模型，方便后面热更新。</p>
<p>每次请求进来就走一套流程：图像预处理 → CTPN → CRNN+CTC → 后处理输出字符串。</p>
<p>虽然有点原始，但胜在简单可靠，后来部署到线下场景也挺稳定的。</p>
<p><strong>6.2 模型加载和推理效率优化</strong></p>
<p>说实话，TensorFlow 1.x 真不太友好。最开始我们每个请求都建 Session，推理时间能飙到 2~3 秒，完全不能用。后来换成<strong>全局加载模型</strong> + 线程锁管理 Session，推理时间立马压到了 500ms 以内。</p>
<p>还有几点优化小心得：</p>
<p>• <strong>模型冻结（freeze_graph）</strong>：把训练好的 ckpt 转成 pb 文件，推理加载更快；</p>
<p>• <strong>Batch 尺寸优化</strong>：我们评估时 batch_size 固定为 1，避免不必要的内存开销；</p>
<p>• <strong>图像 resize 尺寸对齐</strong>：输入图统一为固定高宽，避免每次动态 reshape；</p>
<p>• <strong>预处理和后处理放主线程处理</strong>，只把纯模型推理部分用锁保护，提升并发能力；</p>
<p>这些小改动，虽然不难，但每一条都能救你一口性能。</p>
<p><strong>6.3 系统联动：识别 + 计费 + 放行</strong></p>
<p>模型不是孤岛，它得和停车场管理系统打配合。我们这边做了几个联动：</p>
<p>• <strong>入场识别</strong>：摄像头拍照，调用接口识别车牌，记录入场时间；</p>
<p>• <strong>出场识别 + 计费</strong>：再次识别后查数据库计算停留时长、费用；</p>
<p>• <strong>放行控制</strong>：识别+扣费成功后，下发开闸信号；</p>
<p>• <strong>失败兜底</strong>：识别失败或多次识别结果不一致，会转人工审核；</p>
<p>为了防止“卡顿堵车”，我们整个流程控制在 1.5 秒以内，其中模型推理时间不能超过 700ms，剩下的时间给数据查库、业务逻辑和网络请求。</p>
<p><strong>6.4 部署环境</strong></p>
<p>最早几家门店我们用的是一台小型边缘服务器（i5 + 8GB RAM 没有 GPU），压测下来勉强够用。后面上线门店多了，我们换成了轻量级 Docker 服务部署在局域网网关设备上，响应时间更稳，维护也方便。</p>
<p><strong>7. 实战成效与经验总结</strong></p>
<p>系统上线那天其实我们还是挺紧张的，尤其是第一家门店，设备一接好，路口刚好就排着三四辆车等着进出，全靠我们模型不给我们“添堵”。</p>
<p><strong>7.1 系统上线表现</strong></p>
<p>我们系统最终在实际场景中跑得比预期还要稳一些，具体几个关键指标：</p>
<p>• <strong>识别准确率</strong>：白天场景稳定在 <strong>96%+</strong>，夜间略低，但也保持在 <strong>93%左右</strong>；</p>
<p>• <strong>平均识别时延</strong>：单张图片识别时间在 <strong>600~800ms</strong> 之间（包含全部流程）；</p>
<p>• <strong>日均识别量</strong>：单店约 <strong>500~1000</strong> 次识别，高峰能到 <strong>2000+</strong>；</p>
<p>• <strong>上线门店数</strong>：最终部署到 <strong>30+</strong> 个停车场，基本没出过重大事故。</p>
<p>更关键的是，原本高峰时段门口排队的情况缓解了不少，整体通行效率提升差不多在 <strong>40% 左右</strong>，人工干预大幅减少。我们现场运维的同事说，之前门卫经常抓狂写错车牌、算错钱，现在每天轻松很多（笑）。</p>
<p><strong>7.2 遇到的坑（踩过才知道）</strong></p>
<p>虽然结果不错，但中间也踩了不少坑，这里随便列几个，大家可以避避：</p>
<p>• <strong>模型没做字符合法性校验</strong>，一开始竟然识别出“1A2B3C4”这种根本不存在的车牌号，后来加了正则规则和置信度筛选才缓解；</p>
<p>• <strong>图片预处理太“干净”</strong>，前期训练图像质量偏高，结果一上线就被现实毒打，后来特地加了一批“脏数据”做鲁棒性提升；</p>
<p>• <strong>多线程并发 Session 崩溃</strong>，用 Flask 时没加锁导致多线程 Session 冲突，线上一度频繁报错，后来老老实实加了锁管理；</p>
<p>• <strong>字符集不统一</strong>，有的标注是“沪A12345”，有的是“沪 A12345”，训练时没注意，结果输出格式不一致，系统识别失败；</p>
<p>这些问题不是模型的问题，是我们“业务落地”经验不够造成的——你得时刻记得这个系统不是跑 demo 的，是要真干活的。</p>
<p><strong>7.3 总结一下：</strong></p>
<p>整个项目做完下来，我自己最大的体会是：</p>
<blockquote>
<p>OCR 项目从来不是纯模型问题，而是</p>
<p><strong>数据、业务、部署、系统联动</strong></p>
</blockquote>
<p>从传统方法到深度学习，看上去像是“技术升级”，但其实更像是一次「认知升级」：你开始关注更多系统层面的事情，比如服务性能、接口设计、用户体验、甚至运维和日志。</p>
<p>当然，我们这套也不完美，还有很多可以优化的地方，比如后面版本我们也在尝试：</p>
<p>• 用更轻量的模型（比如 MobileNet+CRNN）做前端部署；</p>
<p>• 用 ONNX 或 TensorRT 做跨平台部署；</p>
<p>• 引入日志追踪和自动告警系统，提升系统可维护性；</p>
<p>这些就是后话了，有机会再分享。</p> </article>   </div> </article> </main> <footer data-astro-cid-sz7xmlte>
&copy; 2025 All rights reserved.
</footer>  </body></html>