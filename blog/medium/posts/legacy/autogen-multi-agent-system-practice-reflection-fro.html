<!DOCTYPE html>
<html lang="en">
<head>
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">
    <title>AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant</title>
    <style>
        body { font-family: Georgia, serif; max-width: 700px; margin: 2rem auto; padding: 0 1rem; line-height: 1.7; color: #333; }
        h1 { font-size: 2rem; margin-bottom: 0.5rem; }
        h2 { font-size: 1.4rem; margin-top: 2rem; }
        pre { background: #f4f4f4; padding: 1rem; overflow-x: auto; border-radius: 4px; }
        code { font-family: Menlo, Monaco, monospace; font-size: 0.9em; }
        p code { background: #f4f4f4; padding: 0.2em 0.4em; border-radius: 3px; }
        img { max-width: 100%; }
        blockquote { border-left: 3px solid #ddd; margin-left: 0; padding-left: 1rem; color: #666; }
        ul { padding-left: 1.5rem; }
        hr { border: none; border-top: 1px solid #ddd; margin: 2rem 0; }
        a { color: #1a8917; }
    </style>
</head>
<body>
<hr>
<h2>date: 2025-07-24
tags: [ai]
legacy: true</h2>
<h1>AutoGen Multi-Agent System Practice Reflection From Heavy-Weight Contextual Programming to Lightweight AI Assistant</h1>
<p>My core objective was to address a key pain point of current AI code assistants: they are often &quot;one-shot&quot; and lack a continuous focus on code quality and subsequent optimization. I wanted my system to simulate a miniature development team.</p>
<h3>1.1. System Design: A Trinity of AI Developers</h3>
<p>I designed three highly specialized agents:</p>
<ol>
<li><strong>CoderAgent:</strong> Responsible for generating the initial Python code based on user requirements. Its core duty is to implement functionality quickly.</li>
<li><strong>QualityAnalyzerAgent:</strong> Responsible for reviewing the code generated by <code>CoderAgent</code>. It uses static analysis tools (like <code>pylint</code>) to check for style issues, potential errors, and non-standard practices, then provides specific modification suggestions.</li>
<li><strong>OptimizerAgent:</strong> After the code is functionally correct and meets quality standards, this agent examines it from a higher level, suggesting improvements related to algorithmic efficiency, code structure, and readability.</li>
</ol>
<p>To enable these three agents to collaborate &quot;intelligently,&quot; I chose AutoGen&#39;s powerful <code>GroupChat</code> mode. By setting <code>speaker_selection_method</code> to <code>&quot;auto&quot;</code>, I expected the system to act like a project manager, automatically selecting the most appropriate agent to speak based on the current conversation context.</p>
<h3>1.2. Technical Implementation: Assembling the Team with AutoGen</h3>
<p>Here is the core code snippet for the system setup:</p>
<blockquote><code>import autogen</code><br>
<code></code><br>
<code># Configure the LLM</code><br>
<code>config_list = autogen.config_list_from_json(...) </code><br>
<code>llm_config = {&quot;config_list&quot;: config_list}</code><br>
<code></code><br>
<code># 1. Define the agents</code><br>
<code>coder = autogen.AssistantAgent(</code><br>
<code># ... (39 more lines)</code></blockquote>
<p><em>Full code available in the <a href="https://github.com/geyuxu">GitHub repository</a>.</em></p><p>With the <code>speaker_selection_method=&quot;auto&quot;</code> setting, my ideal workflow was: <code>UserProxy</code> -&gt; <code>CoderAgent</code> -&gt; <code>QualityAnalyzerAgent</code> -&gt; <code>OptimizerAgent</code> -&gt; <code>UserProxy</code>. It looked perfect, didn&#39;t it? However, reality delivered a harsh lesson.</p>
<h2>2. The &quot;Heaviness&quot; in Practice: When Idealism Meets Reality</h2>
<p>Once the system was running, I quickly felt a persistent sense of &#39;heaviness.&#39; This feeling wasn&#39;t from a single issue but a combination of several factors.</p>
<h3>2.1. Interaction Latency and the Efficiency Black Hole</h3>
<p>For a simple Fibonacci function, the entire process took several minutes. Each handoff between agents is a complete LLM call. The <code>GroupChat</code>&#39;s process for deciding the next speaker also requires an LLM inference of its own. This meant that completing one simple task could involve 5-10, or even more, LLM calls.</p>
<p>In my daily development work, I need code completions and suggestions in seconds, not the result of an AI team &quot;holding a meeting&quot; that I have to wait for after making a cup of coffee. This high latency is fatal for high-frequency, real-time development assistance scenarios.</p>
<h3>2.2. Uncontrollable &quot;Emergent Intelligence&quot;</h3>
<p><code>speaker_selection_method=&quot;auto&quot;</code> is a double-edged sword. It did introduce &#39;intelligence,&#39; but it also brought chaos. I observed several typical problems:</p>
<ul>
<li><strong>Dialogue Loops:</strong> <code>CoderAgent</code> and <code>QualityAnalyzerAgent</code> could get stuck in a back-and-forth &#39;tug-of-war,&#39; with one making changes and the other finding new issues, preventing the process from ever reaching the optimization stage.</li>
<li><strong>Incorrect Scheduling:</strong> Sometimes, right after <code>CoderAgent</code> finished writing the code, <code>OptimizerAgent</code> would &#39;jump the gun&#39; and start talking about optimization, skipping the quality analysis step and disrupting the intended workflow.</li>
<li><strong>Premature Termination:</strong> The system might hand control back to the <code>UserProxy</code> and consider the task complete without sufficient optimization.</li>
</ul>
<p>This unpredictability turned a tool that was supposed to boost efficiency into a &#39;black box&#39; that required careful guidance and observation.</p>
<h3>2.3. Complex State Management and Context Passing</h3>
<p>One of the core challenges of a multi-agent system is state management. In this experiment, the &#39;state&#39; was the piece of code being iterated on. Ideally, <code>QualityAnalyzerAgent</code> should analyze the latest code from <code>CoderAgent</code>.</p>
<p>But the state of a <code>GroupChat</code> is maintained through an ever-growing message history. As the number of conversation rounds increases, the context window expands rapidly. This not only increases token costs but can also cause subsequent agents to &#39;lose focus&#39; due to information overload, ignoring critical code versions or modification suggestions. I had to meticulously craft prompts, repeatedly reminding agents to &quot;please focus on the code in the previous turn&#39;s message,&quot; which was a burden in itself.</p>
<h3>2.4. High Configuration and Debugging Costs</h3>
<p>Building this system required me to spend a significant amount of time on &#39;meta-work&#39;:</p>
<ul>
<li><strong>Prompt Engineering:</strong> Writing precise <code>system_message</code> for each agent to define its role, capabilities, and communication style.</li>
<li><strong>Flow Design:</strong> Thinking about how to design termination conditions and guide the conversation flow.</li>
<li><strong>Debugging:</strong> When the system didn&#39;t behave as expected, I had to read the entire conversation history to guess whether the problem was with an agent&#39;s prompt or the selector&#39;s decision logic. This debugging difficulty is far greater than with traditional code.</li>
</ul>
<p>These upfront investment and subsequent maintenance costs are clearly disproportionate for solving a problem at the level of &#39;writing a Fibonacci function.&#39;</p>
<h2>3. Reflection: Which Scenarios Truly Require the &quot;Heavy Artillery&quot;?</h2>
<p>This failed attempt was not without value; it gave me a deeper understanding of the nature and application boundaries of multi-agent systems.</p>
<p><strong>The core strengths of multi-agent systems lie in:</strong></p>
<ul>
<li><strong>Specialization and Modularity:</strong> The ability to break down a large, ambiguous task and assign parts to &#39;experts&#39; in different fields, achieving a separation of concerns.</li>
<li><strong>Simulating Complex Workflows:</strong> They are excellent for simulating real-world processes that require multi-role collaboration, such as product development or scientific research.</li>
<li><strong>&#39;Emergence&#39; and Creativity:</strong> Free-form discussions between agents can sometimes lead to unexpected and creative solutions.</li>
</ul>
<p><strong>So, what scenarios are suitable for this kind of &#39;heavyweight&#39; system?</strong></p>
<ol>
<li><strong>Exploratory and Research Tasks:</strong> For example, &quot;Investigate the latest advancements in autonomous driving technology and generate an analysis report including a technical summary, key players, and future trends.&quot; Such tasks lack a fixed process, require multiple complex steps like information gathering, integration, and analysis, and have a certain demand for creativity in the final output.</li>
<li><strong>End-to-End Automation Projects:</strong> For example, &quot;Automatically generate a project skeleton, write core code, and configure deployment scripts based on a user requirements document.&quot; These tasks have long cycles, multiple steps, and can be executed asynchronously. A multi-agent system can act like an autonomous project team, working silently in the background.</li>
<li><strong>Complex Decision-Making and Simulation:</strong> For example, simulating a market environment where &#39;Consumer Agents,&#39; &#39;Competitor Agents,&#39; and &#39;Marketing Agents&#39; interact to predict the effectiveness of a marketing strategy.</li>
</ol>
<p><strong>And for the following scenarios, we should decisively opt for a &#39;lightweight&#39; approach:</strong></p>
<ul>
<li><strong>High-frequency, real-time interactive tasks:</strong> Such as code completion, real-time Q&amp;A, or text polishing.</li>
<li><strong>Deterministic, linear tasks:</strong> If a task can be clearly broken down into A-&gt;B-&gt;C steps, then forcing it into a free-discussion <code>GroupChat</code> is like using a sledgehammer to crack a nut.</li>
<li><strong>Scenarios that are extremely sensitive to latency and cost.</strong></li>
</ul>
<h2>4. Returning to Simplicity: A Blueprint for Lightweight AI Assistants</h2>
<p>Since the heavyweight multi-agent system wasn&#39;t suitable for my daily development needs, what is a better alternative? The answer is to return to simplicity, leveraging other patterns provided by AutoGen or shifting our mindset.</p>
<h3>4.1. Solution 1: Two-Stage Agent Pipeline (Sequential Pipeline)</h3>
<p>If your process is deterministic, like &#39;code first, then review,&#39; you can organize the agents in a sequential manner. AutoGen&#39;s <code>register_nested_chats</code> feature is perfect for this scenario.</p>
<blockquote><code># This is a conceptual example to demonstrate how to build a sequential pipeline.</code><br>
<code># After the CoderAgent completes its task, its result is automatically passed </code><br>
<code># as input to the QualityAnalyzerAgent.</code><br>
<code></code><br>
<code># Assuming CoderAgent and QualityAnalyzerAgent are already defined</code><br>
<code></code><br>
<code># Nested chat setup</code><br>
<code>review_chat = autogen.GroupChat(</code><br>
<code># ... (13 more lines)</code></blockquote>
<p><em>Full code available in the <a href="https://github.com/geyuxu">GitHub repository</a>.</em></p><p>In this pattern, the control flow is a deterministic <code>User -&gt; Coder -&gt; QualityAnalyzer</code>. It retains the advantage of agent specialization but eliminates the unpredictability and high coordination cost of the auto-selecting <code>GroupChat</code>.</p>
<h3>4.2. Solution 2: Single Agent with Tools</h3>
<p>This is a more mainstream and practical paradigm for building AI assistants today, and it&#39;s in the same vein as OpenAI&#39;s Function Calling/Tool Use.</p>
<p><strong>The core idea is:</strong> Instead of creating multiple agents to converse with each other, create one &#39;omnipotent&#39; <code>AssistantAgent</code> and encapsulate capabilities like &#39;quality analysis&#39; and &#39;code optimization&#39; as <strong>tools</strong> it can call.</p>
<blockquote><code>import pylint.lint</code><br>
<code>import io</code><br>
<code>from pylint.reporters.text import TextReporter</code><br>
<code></code><br>
<code># 1. Define the tool function</code><br>
<code>def lint_code(code: str) -&gt; str:</code><br>
<code>    &quot;&quot;&quot;Runs pylint on the given Python code and returns the report.&quot;&quot;&quot;</code><br>
<code>    pylint_opts = [&#039;--disable=all&#039;, &#039;--enable=E,W&#039;]</code><br>
<code># ... (27 more lines)</code></blockquote>
<p><em>Full code available in the <a href="https://github.com/geyuxu">GitHub repository</a>.</em></p><p><strong>The advantages of this pattern are overwhelming:</strong></p>
<ul>
<li><strong>Low Latency:</strong> No communication overhead between multiple agents.</li>
<li><strong>High Controllability:</strong> The flow is driven by the LLM&#39;s decision to call a tool, which is more predictable than a free-form conversation between agents.</li>
<li><strong>Easy to Extend and Maintain:</strong> Adding new capabilities only requires adding a new tool function, not designing a new agent and its complex interaction logic.</li>
</ul>
<h2>Conclusion: Finding the Balance Between Complexity and Practicality</h2>
<p>My journey from ambitious design to pragmatic retreat taught me a profound lesson: <strong>the first principle of technology selection is always &#39;fitness for purpose.&#39;</strong> Multi-agent systems are a powerful and fascinating paradigm, but they are not a silver bullet for every problem. To chase a &#39;cool-looking&#39; architecture while ignoring real-world efficiency, cost, and controllability is a classic case of technical self-indulgence.</p>
<p>For those of us building AI applications, our goal shouldn&#39;t be to build the most complex system, but the one that best solves the problem at hand. Within a powerful framework like AutoGen, <code>GroupChat</code> is just one of many tools. Learning to make wise choices between &#39;multi-agent collaboration,&#39; &#39;sequential pipelines,&#39; and &#39;single-agent + tools&#39; based on the nature of the task is the hallmark of a mature AI engineer.</p>
<p>In the future, collaboration between humans and AI, and between AI and AI, will undoubtedly deepen. Our task is to maintain a clear head amidst the constant emergence of new technologies and find that optimal balance point between technology and value.</p>

</body>
</html>