<!DOCTYPE html><html lang="zh" data-astro-cid-bvzihdzo> <head><!-- Global Metadata --><meta charset="utf-8"><!--<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">--><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"><link rel="shortcut icon" href="/favicon.png" type="image/png"><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" title="Ge Yuxu • AI &#38; Engineering" href="https://geyuxu.com/rss.xml"><meta name="generator" content="Astro v5.5.6"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><!-- Canonical URL --><link rel="canonical" href="https://geyuxu.com/blog/ai/autogen%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%AE%9E%E8%B7%B5%E5%8F%8D%E6%80%9D%E4%BB%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BC%96%E7%A8%8B%E7%9A%84%E9%87%8D%E8%A3%85%E4%B8%8A%E9%98%B5%E5%88%B0%E8%BD%BB%E9%87%8F%E7%BA%A7ai%E5%8A%A9%E6%89%8B%E7%9A%84%E5%9B%9E%E5%BD%92/"><!-- Primary Meta Tags --><title>AutoGen多智能体实践反思：从&quot;上下文编程&quot;的重装上阵到轻量级AI助手的回归</title><meta name="title" content="AutoGen多智能体实践反思：从&#34;上下文编程&#34;的重装上阵到轻量级AI助手的回归"><meta name="description"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://geyuxu.com/blog/ai/autogen%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%AE%9E%E8%B7%B5%E5%8F%8D%E6%80%9D%E4%BB%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BC%96%E7%A8%8B%E7%9A%84%E9%87%8D%E8%A3%85%E4%B8%8A%E9%98%B5%E5%88%B0%E8%BD%BB%E9%87%8F%E7%BA%A7ai%E5%8A%A9%E6%89%8B%E7%9A%84%E5%9B%9E%E5%BD%92/"><meta property="og:title" content="AutoGen多智能体实践反思：从&#34;上下文编程&#34;的重装上阵到轻量级AI助手的回归"><meta property="og:description"><meta property="og:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://geyuxu.com/blog/ai/autogen%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%AE%9E%E8%B7%B5%E5%8F%8D%E6%80%9D%E4%BB%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BC%96%E7%A8%8B%E7%9A%84%E9%87%8D%E8%A3%85%E4%B8%8A%E9%98%B5%E5%88%B0%E8%BD%BB%E9%87%8F%E7%BA%A7ai%E5%8A%A9%E6%89%8B%E7%9A%84%E5%9B%9E%E5%BD%92/"><meta property="twitter:title" content="AutoGen多智能体实践反思：从&#34;上下文编程&#34;的重装上阵到轻量级AI助手的回归"><meta property="twitter:description"><meta property="twitter:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><script src="/js/jquery-3.7.1.min.js"></script><script is:global>
	window.addEventListener('DOMContentLoaded', () => {
		$('.toc ol').css({
		'list-style': 'none',   // 隐藏 1. 2. 3.
		'margin': 0,
		'padding-left': 0,       // 可按需调整
		});
		$('.toc ol > li').css({
		'list-style': 'none',   // 隐藏 1. 2. 3.
		'padding-left': 10  
		});
        $('.sidebar').append($('.toc'));
      });
	</script><style>:root{--accent: #2337ff;--accent-dark: #000d8a;--black: 15, 18, 25;--gray: 96, 115, 159;--gray-light: 229, 233, 240;--gray-dark: 34, 41, 57;--gray-gradient: rgba(var(--gray-light), 50%), #fff;--box-shadow: 0 2px 6px rgba(var(--gray), 25%), 0 8px 24px rgba(var(--gray), 33%), 0 16px 32px rgba(var(--gray), 33%)}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-regular.woff) format("woff");font-weight:400;font-style:normal;font-display:swap}@font-face{font-family:Atkinson;src:url(/fonts/atkinson-bold.woff) format("woff");font-weight:700;font-style:normal;font-display:swap}body{font-family:Atkinson,sans-serif;margin:0;padding:0;text-align:left;background:linear-gradient(var(--gray-gradient)) no-repeat;background-size:100% 600px;word-wrap:break-word;overflow-wrap:break-word;color:rgb(var(--gray-dark));font-size:20px;line-height:1.7}main{width:960px;max-width:calc(100% - 2em);margin:auto;padding:3em 1em}h1,h2,h3,h4,h5,h6{margin:0 0 .5rem;color:rgb(var(--black));line-height:1.2}h1{font-size:3.052em}h2{font-size:2.441em}h3{font-size:1.953em}h4{font-size:1.563em}h5{font-size:1.25em}strong,b{font-weight:700}a,a:hover{color:var(--accent)}p{margin-bottom:1em}.prose p{margin-bottom:2em}textarea{width:100%;font-size:16px}input{font-size:16px}table{width:100%;border-collapse:collapse}th,td{border:1px solid rgba(var(--gray-light));padding:8px;text-align:left}th{background-color:rgba(var(--gray-light),.5)}img{max-width:100%;height:auto;border-radius:8px}code{padding:2px 5px;background-color:rgb(var(--gray-light));border-radius:2px}pre{padding:1.5em;border-radius:8px}pre>code{all:unset}blockquote{border-left:4px solid var(--accent);padding:0 0 0 20px;margin:0;font-size:1.333em}hr{border:none;border-top:1px solid rgb(var(--gray-light))}@media (max-width: 720px){body{font-size:18px}main{padding:1em}}.sr-only{border:0;padding:0;margin:0;position:absolute!important;height:1px;width:1px;overflow:hidden;clip:rect(1px 1px 1px 1px);clip:rect(1px,1px,1px,1px);clip-path:inset(50%);white-space:nowrap}.title_li{list-style:none}.title_li>a,.title_li_num>a,.toc-link,.series-list>li>a,.series_title>a{color:#7a888e}.content{max-width:960px;margin:0 auto;padding:2rem 1rem;font-family:-apple-system,BlinkMacSystemFont,Segoe UI,Roboto,Helvetica Neue,Arial,sans-serif;font-size:1.05rem;line-height:1.75;color:#333}.content h1,.content h2,.content h3{font-weight:600;margin-top:2rem;margin-bottom:1rem;line-height:1.3}.content p{margin-bottom:1.25rem}.content a{color:var(--accent, #0070f3);text-decoration:underline}.content img{max-width:100%;border-radius:6px;margin:1.5rem 0}.content pre,.content code{font-family:Menlo,Monaco,Consolas,Courier New,monospace;font-size:.9em;border-radius:4px}.content pre{padding:1em;overflow-x:auto}article.prose{font-size:var(--fs-base);line-height:1.7}@media (max-width: 640px){nav>div,nav>h2{font-size:.6em}ul,ol{padding-left:20px}main,.content-wrapper{padding-left:0;width:350px;max-width:60350px0px;margin:0 auto}img,table,pre{max-width:100%}table,pre{overflow-x:auto}.content{margin:0;padding:0;border:0;max-width:3350px00px;font-size:11px}h1{font-size:1.3rem}h2{font-size:1.2rem}h3{font-size:1.1rem}h4{font-size:1rem}h5{font-size:.9rem}}
a[data-astro-cid-eimmu3lg]{display:inline-block;text-decoration:none}a[data-astro-cid-eimmu3lg].active{font-weight:bolder;text-decoration:underline}header[data-astro-cid-3ef6ksr2]{margin:0;padding:0 1em;background:#fff;box-shadow:0 2px 8px rgba(var(--black),5%)}h2[data-astro-cid-3ef6ksr2]{margin:0;font-size:1em}h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2],h2[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none}nav[data-astro-cid-3ef6ksr2]{display:flex;align-items:center;justify-content:space-between}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{padding:1em .5em;color:var(--black);border-bottom:4px solid transparent;text-decoration:none}nav[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2].active{text-decoration:none;border-bottom-color:var(--accent)}.social-links[data-astro-cid-3ef6ksr2],.social-links[data-astro-cid-3ef6ksr2] a[data-astro-cid-3ef6ksr2]{display:flex}@media (max-width: 720px){.social-links[data-astro-cid-3ef6ksr2]{display:none}}footer[data-astro-cid-sz7xmlte]{padding:2em 1em 6em;background:linear-gradient(var(--gray-gradient)) no-repeat;color:rgb(var(--gray));text-align:center}.social-links[data-astro-cid-sz7xmlte]{display:flex;justify-content:center;gap:1em;margin-top:1em}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]{text-decoration:none;color:rgb(var(--gray))}.social-links[data-astro-cid-sz7xmlte] a[data-astro-cid-sz7xmlte]:hover{color:rgb(var(--gray-dark))}
.statement[data-astro-cid-uffxixac]{font-size:10px;color:gray}@media (max-width: 640px){.statement[data-astro-cid-uffxixac]{font-size:6px;color:gray}}
main[data-astro-cid-bvzihdzo].page{display:grid;grid-template-columns:260px minmax(0,1fr);width:100%;margin:0}aside[data-astro-cid-bvzihdzo].sidebar{box-sizing:border-box;width:260px;padding:2rem 1rem;font-size:.95rem;position:sticky;top:4rem;align-self:start}.sidebar[data-astro-cid-bvzihdzo] .meta[data-astro-cid-bvzihdzo] p[data-astro-cid-bvzihdzo]{margin:.25rem 0}nav[data-astro-cid-bvzihdzo].toc li[data-astro-cid-bvzihdzo]{margin:.35rem 0 .35rem 1rem}nav[data-astro-cid-bvzihdzo].toc a[data-astro-cid-bvzihdzo]{color:var(--gray-dark,#444);text-decoration:none}nav[data-astro-cid-bvzihdzo].toc a[data-astro-cid-bvzihdzo]:hover{text-decoration:underline}article[data-astro-cid-bvzihdzo].prose{max-width:85rem;width:100%;margin:0 auto;padding:2rem 1rem}@media (max-width: 768px){main[data-astro-cid-bvzihdzo].page{grid-template-columns:1fr}aside[data-astro-cid-bvzihdzo].sidebar{position:static;width:100%;padding:1rem}article[data-astro-cid-bvzihdzo].prose{max-width:100%;padding:1rem}}.series-list[data-astro-cid-bvzihdzo]{list-style:none;margin:0;padding-left:10px}.series-list[data-astro-cid-bvzihdzo]{list-style:none;margin:0;padding-left:10px;max-height:calc(16em + .5rem);overflow-y:auto}.series-list[data-astro-cid-bvzihdzo]::-webkit-scrollbar{width:6px}.series-list[data-astro-cid-bvzihdzo]::-webkit-scrollbar-thumb{background:#0003;border-radius:3px}
</style></head> <body data-astro-cid-bvzihdzo> <header data-astro-cid-3ef6ksr2> <nav data-astro-cid-3ef6ksr2> <!--<h2><a href="/">{SITE_TITLE}</a></h2>--> <h2 data-astro-cid-3ef6ksr2><a style="padding-left:0;color:blue;" href="/" data-astro-cid-3ef6ksr2>Ge Yuxu<br data-astro-cid-3ef6ksr2>AI & Engineering</a></h2> <div class="internal-links" data-astro-cid-3ef6ksr2> <a href="/" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Home </a>  <a href="/blog/1" class="active" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Blog </a>  <a href="/series" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Series </a>  <a href="/projects" data-astro-cid-3ef6ksr2="true" data-astro-cid-eimmu3lg> Projects </a>  </div> <div class="social-links" data-astro-cid-3ef6ksr2> <a href="https://github.com/geyuxu" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Go to Ge Yuxu's GitHub repo</span> <svg viewBox="0 0 16 16" aria-hidden="true" width="32" height="32" data-astro-cid-3ef6ksr2><path fill="currentColor" d="M8 0C3.58 0 0 3.58 0 8c0 3.54 2.29 6.53 5.47 7.59.4.07.55-.17.55-.38 0-.19-.01-.82-.01-1.49-2.01.37-2.53-.49-2.69-.94-.09-.23-.48-.94-.82-1.13-.28-.15-.68-.52-.01-.53.63-.01 1.08.58 1.23.82.72 1.21 1.87.87 2.33.66.07-.52.28-.87.51-1.07-1.78-.2-3.64-.89-3.64-3.95 0-.87.31-1.59.82-2.15-.08-.2-.36-1.02.08-2.12 0 0 .67-.21 2.2.82.64-.18 1.32-.27 2-.27.68 0 1.36.09 2 .27 1.53-1.04 2.2-.82 2.2-.82.44 1.1.16 1.92.08 2.12.51.56.82 1.27.82 2.15 0 3.07-1.87 3.75-3.65 3.95.29.25.54.73.54 1.48 0 1.07-.01 1.93-.01 2.2 0 .21.15.46.55.38A8.012 8.012 0 0 0 16 8c0-4.42-3.58-8-8-8z" data-astro-cid-3ef6ksr2></path></svg> </a> <a href="https://www.linkedin.com/in/geyuxu/" target="_blank" data-astro-cid-3ef6ksr2> <span class="sr-only" data-astro-cid-3ef6ksr2>Go to Ge Yuxu's LinkedIn profile</span> <svg viewBox="0 0 24 24" width="32" height="32" aria-hidden="true" xmlns="http://www.w3.org/2000/svg" data-astro-cid-3ef6ksr2> <path fill="currentColor" d="M20.447 20.452H17.2v-5.569c0-1.328-.025-3.039-1.852-3.039-1.853 0-2.136 1.447-2.136 2.942v5.666h-3.248V9h3.122v1.561h.045c.435-.823 1.498-1.688 3.083-1.688 3.295 0 3.903 2.17 3.903 4.989v6.59zM5.337 7.433a1.882 1.882 0 110-3.764 1.882 1.882 0 010 3.764zm1.626 13.019H3.708V9h3.255v11.452zM22.225 0H1.771C.792 0 0 .774 0 1.729v20.542C0 23.226.792 24 1.771 24h20.451C23.2 24 24 23.226 24 22.271V1.729C24 .774 23.2 0 22.222 0z" data-astro-cid-3ef6ksr2></path> </svg> </a> </div> </nav> <!-- Microsoft Clarity --> <script type="text/javascript">
		(function(c,l,a,r,i,t,y){
			c[a]=c[a]||function(){(c[a].q=c[a].q||[]).push(arguments)};
			t=l.createElement(r);t.async=1;t.src="https://www.clarity.ms/tag/"+i;
			y=l.getElementsByTagName(r)[0];y.parentNode.insertBefore(t,y);
		})(window, document, "clarity", "script", "rc2w96osp6");
	</script> </header>  <main class="page" data-astro-cid-bvzihdzo> <!-- 左侧栏 --> <aside class="sidebar" data-astro-cid-bvzihdzo> <div class="meta" data-astro-cid-bvzihdzo> <b data-astro-cid-bvzihdzo>AutoGen多智能体实践反思：从&quot;上下文编程&quot;的重装上阵到轻量级AI助手的回归</b> <p data-astro-cid-bvzihdzo><time datetime="2025-07-24T00:00:00.000Z"> 2025/07/24 08:00:00 </time></p>   </div> <hr data-astro-cid-bvzihdzo> <br data-astro-cid-bvzihdzo> </aside> <!-- 右侧正文区域（flex 居中） --> <div class="content-wrapper" data-astro-cid-bvzihdzo> <article class="prose" data-astro-cid-bvzihdzo>  <article class="content"> <nav class="toc"><ol class="toc-level toc-level-1"><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#引言当多智能体的浪潮涌来">引言：当多智能体的浪潮涌来</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#一我的实验上下文编程多智能体系统的构想与实践">一、我的实验：“上下文编程”多智能体系统的构想与实践</a><ol class="toc-level toc-level-2"><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#1-系统设计三位一体的ai开发团队">1. 系统设计：三位一体的AI开发团队</a></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#2-技术实现用autogen组建团队">2. 技术实现：用AutoGen组建团队</a></li></ol></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#二实践中的重当理想照进现实">二、实践中的”重”：当理想照进现实</a><ol class="toc-level toc-level-2"><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#1-交互延迟与效率黑洞">1. 交互延迟与效率黑洞</a></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#2-不可控的智能涌现">2. 不可控的”智能涌现”</a></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#3-复杂的状态管理与上下文传递">3. 复杂的状态管理与上下文传递</a></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#4-高昂的配置与调试成本">4. 高昂的配置与调试成本</a></li></ol></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#三反思什么场景真正需要重装上阵">三、反思：什么场景真正需要”重装上阵”？</a></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#四回归简单轻量级ai助手的构建思路">四、回归简单：轻量级AI助手的构建思路</a><ol class="toc-level toc-level-2"><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#方案一两阶段智能体流水线-sequential-pipeline">方案一：两阶段智能体流水线 (Sequential Pipeline)</a></li><li class="toc-item toc-item-h3"><a class="toc-link toc-link-h3" href="#方案二单智能体--工具-single-agent-with-tools">方案二：单智能体 + 工具 (Single Agent with Tools)</a></li></ol></li><li class="toc-item toc-item-h2"><a class="toc-link toc-link-h2" href="#结论在复杂性与实用性之间寻找平衡">结论：在复杂性与实用性之间寻找平衡</a></li></ol></nav><h1 id="autogen多智能体实践反思从上下文编程的重装上阵到轻量级ai助手的回归"><a aria-hidden="true" tabindex="-1" href="#autogen多智能体实践反思从上下文编程的重装上阵到轻量级ai助手的回归"><span class="icon icon-link"></span></a>AutoGen多智能体实践反思：从”上下文编程”的重装上阵到轻量级AI助手的回归</h1>
<h2 id="引言当多智能体的浪潮涌来"><a aria-hidden="true" tabindex="-1" href="#引言当多智能体的浪潮涌来"><span class="icon icon-link"></span></a>引言：当多智能体的浪潮涌来</h2>
<p>近来，以AutoGen为代表的多智能体（Multi-Agent）框架无疑是AI领域最炙手可热的话题之一。它描绘了一幅激动人心的蓝图：一群各司其职的AI智能体，像一个高效的人类团队一样协同工作，自动完成复杂的任务。作为一名热衷于探索AI工程实践的开发者，我被这个想法深深吸引。</p>
<p>为了将这一范式应用于日常开发，我设计并实现了一个名为”上下文编程”的多智能体系统。我的设想是，通过一个包含代码生成、质量分析和代码优化的智能体团队，打造一个能真正理解编程上下文、交付高质量代码的AI编程伙伴。然而，经过一天的实践，我得出了一个略带苦涩但宝贵的结论：<strong>对于许多日常开发需求，精心设计的多智能体系统可能过于”重量级”，其带来的开销甚至超过了收益。</strong></p>
<p>这篇博客将分享我从构想、实践到反思的全过程，深入探讨AutoGen多智能体系统的优缺点、适用场景，并提出更轻量、更实用的替代方案。希望我的真实体验，能为同样走在AI应用探索路上的你提供一些参考。</p>
<h2 id="一我的实验上下文编程多智能体系统的构想与实践"><a aria-hidden="true" tabindex="-1" href="#一我的实验上下文编程多智能体系统的构想与实践"><span class="icon icon-link"></span></a>一、我的实验：“上下文编程”多智能体系统的构想与实践</h2>
<p>我的核心目标是解决当前AI代码助手的一个痛点：它们通常是”一次性”的，缺乏对代码质量和后续优化的持续关注。我希望我的系统能模拟一个微型的开发小组。</p>
<h3 id="1-系统设计三位一体的ai开发团队"><a aria-hidden="true" tabindex="-1" href="#1-系统设计三位一体的ai开发团队"><span class="icon icon-link"></span></a>1. 系统设计：三位一体的AI开发团队</h3>
<p>我设计了三个高度专业化的智能体：</p>
<ol>
<li><strong>CoderAgent (编码工程师):</strong> 负责根据用户需求生成初始的Python代码。它的核心职责是快速实现功能。</li>
<li><strong>QualityAnalyzerAgent (质量分析师):</strong> 负责审查<code>CoderAgent</code>生成的代码。它会使用静态分析工具（如<code>pylint</code>）检查代码的风格、潜在错误和不规范的写法，并提出具体的修改建议。</li>
<li><strong>OptimizerAgent (性能优化师):</strong> 在代码功能正确、质量达标后，它会从更高层面审视代码，提出关于算法效率、代码结构、可读性等方面的优化建议。</li>
</ol>
<p>为了让这三个智能体能”智能地”协同工作，我选择了AutoGen中强大的 <code>GroupChat</code> 模式，并特别使用了<code>SelectorGroupChat</code>，期望它能像一个项目经理，根据当前的对话上下文，自动选择最合适的智能体发言。</p>
<h3 id="2-技术实现用autogen组建团队"><a aria-hidden="true" tabindex="-1" href="#2-技术实现用autogen组建团队"><span class="icon icon-link"></span></a>2. 技术实现：用AutoGen组建团队</h3>
<p>以下是系统设置的核心代码片段：</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">import</span><span style="color:#E1E4E8"> autogen</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 配置LLM</span></span>
<span class="line"><span style="color:#E1E4E8">config_list </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.config_list_from_json(</span><span style="color:#79B8FF">...</span><span style="color:#E1E4E8">) </span></span>
<span class="line"><span style="color:#E1E4E8">llm_config </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> {</span><span style="color:#9ECBFF">"config_list"</span><span style="color:#E1E4E8">: config_list}</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 1. 定义智能体</span></span>
<span class="line"><span style="color:#E1E4E8">coder </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.AssistantAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"CoderAgent"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    system_message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"You are a helpful AI assistant that writes Python code to solve tasks. Return the code in a markdown code block."</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    llm_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_config,</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">quality_analyzer </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.AssistantAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"QualityAnalyzerAgent"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    system_message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"You are a quality assurance expert. You review the given Python code for style, errors, and best practices. Suggest specific improvements."</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    llm_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_config,</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">optimizer </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.AssistantAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"OptimizerAgent"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    system_message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"You are a performance optimization expert. You analyze the Python code for performance bottlenecks and suggest refactoring for better efficiency and readability."</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    llm_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_config,</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">user_proxy </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.UserProxyAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"UserProxy"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    human_input_mode</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"TERMINATE"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    code_execution_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">{</span><span style="color:#9ECBFF">"work_dir"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"coding"</span><span style="color:#E1E4E8">},</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 2. 设置SelectorGroupChat</span></span>
<span class="line"><span style="color:#6A737D"># 使用 "auto" 模式，让LLM来决定下一个发言者</span></span>
<span class="line"><span style="color:#E1E4E8">groupchat </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.GroupChat(</span></span>
<span class="line"><span style="color:#FFAB70">    agents</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[user_proxy, coder, quality_analyzer, optimizer],</span></span>
<span class="line"><span style="color:#FFAB70">    messages</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[],</span></span>
<span class="line"><span style="color:#FFAB70">    max_round</span><span style="color:#F97583">=</span><span style="color:#79B8FF">15</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    speaker_selection_method</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"auto"</span><span style="color:#E1E4E8"> </span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">manager </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.GroupChatManager(</span><span style="color:#FFAB70">groupchat</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">groupchat, </span><span style="color:#FFAB70">llm_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_config)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 3. 启动任务</span></span>
<span class="line"><span style="color:#E1E4E8">user_proxy.initiate_chat(</span></span>
<span class="line"><span style="color:#E1E4E8">    manager,</span></span>
<span class="line"><span style="color:#FFAB70">    message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"Write a Python function to find the nth Fibonacci number, then analyze and optimize it."</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span></code></pre>
<p>在<code>speaker_selection_method="auto"</code>的设置下，我期待的理想工作流是：<code>UserProxy</code> -> <code>CoderAgent</code> -> <code>QualityAnalyzerAgent</code> -> <code>OptimizerAgent</code> -> <code>UserProxy</code>。看起来很完美，不是吗？然而，现实很快给了我沉重一击。</p>
<h2 id="二实践中的重当理想照进现实"><a aria-hidden="true" tabindex="-1" href="#二实践中的重当理想照进现实"><span class="icon icon-link"></span></a>二、实践中的”重”：当理想照进现实</h2>
<p>系统跑起来后，我很快就感受到了那种挥之不去的”沉重感”。这种感觉并非来自单一问题，而是多个因素叠加的结果。</p>
<h3 id="1-交互延迟与效率黑洞"><a aria-hidden="true" tabindex="-1" href="#1-交互延迟与效率黑洞"><span class="icon icon-link"></span></a>1. 交互延迟与效率黑洞</h3>
<p>对于一个简单的斐波那契函数，整个流程下来耗时数分钟。每一次智能体之间的交接，都是一次完整的LLM调用。<code>SelectorGroupChat</code>为了决定下一个发言者，本身也需要一次LLM推理。这意味着，完成一个简单任务，背后可能有5-10次甚至更多的LLM调用。</p>
<p>在日常开发中，我需要的是秒级的代码补全和建议，而不是泡杯咖啡等待AI团队”开会讨论”的结果。这种高延迟对于高频、即时的开发辅助场景是致命的。</p>
<h3 id="2-不可控的智能涌现"><a aria-hidden="true" tabindex="-1" href="#2-不可控的智能涌现"><span class="icon icon-link"></span></a>2. 不可控的”智能涌现”</h3>
<p><code>speaker_selection_method="auto"</code> 是一把双刃剑。它确实带来了”智能”，但也带来了混乱。我观察到了几种典型的问题：</p>
<ul>
<li><strong>对话循环：</strong> <code>CoderAgent</code> 和 <code>QualityAnalyzerAgent</code> 之间可能来回”拉扯”，一个修改，一个又挑出新问题，迟迟无法进入优化阶段。</li>
<li><strong>错误调度：</strong> 有时，在<code>CoderAgent</code>刚写完代码后，<code>OptimizerAgent</code>会”抢话”，跳过质量分析环节，直接开始谈优化，打乱了预设的流程。</li>
<li><strong>过早终止：</strong> 系统可能在没有充分优化的情况下，过早地将控制权交还给<code>UserProxy</code>，并认为任务已完成。</li>
</ul>
<p>这种不可预测性，让本应是提效工具的系统，变成了一个需要小心翼翼引导和观察的”黑箱”。</p>
<h3 id="3-复杂的状态管理与上下文传递"><a aria-hidden="true" tabindex="-1" href="#3-复杂的状态管理与上下文传递"><span class="icon icon-link"></span></a>3. 复杂的状态管理与上下文传递</h3>
<p>多智能体系统的核心挑战之一是状态管理。在这个实验中，“状态”就是那段正在被迭代的代码。理想情况下，<code>QualityAnalyzerAgent</code>应该基于<code>CoderAgent</code>的最新代码进行分析。</p>
<p>但<code>GroupChat</code>的状态是通过不断增长的消息历史来维护的。当对话轮次增多，上下文窗口会迅速膨胀，不仅增加了token成本，还可能因为信息过载导致后续的Agent”注意力不集中”，忽略了关键的代码版本或修改建议。我必须精心设计Prompt，反复提醒Agent”请关注上一轮发言中的代码”，这本身就是一种负担。</p>
<h3 id="4-高昂的配置与调试成本"><a aria-hidden="true" tabindex="-1" href="#4-高昂的配置与调试成本"><span class="icon icon-link"></span></a>4. 高昂的配置与调试成本</h3>
<p>构建这个系统，我花费了大量时间在”元工作”（meta-work）上：</p>
<ul>
<li><strong>Prompt Engineering:</strong> 为每个Agent编写精确的<code>system_message</code>，定义它们的角色、能力边界和沟通风格。</li>
<li><strong>流程设计：</strong> 思考如何设计终止条件、如何引导对话流向。</li>
<li><strong>调试：</strong> 当系统行为不符合预期时，我需要通读整个对话历史，猜测是哪个Agent的Prompt出了问题，还是<code>Selector</code>的决策逻辑有误。这种调试难度远高于传统代码。</li>
</ul>
<p>这些前期投入和后期维护的成本，对于解决一个”写斐波那契函数”级别的问题来说，显然是不成比例的。</p>
<h2 id="三反思什么场景真正需要重装上阵"><a aria-hidden="true" tabindex="-1" href="#三反思什么场景真正需要重装上阵"><span class="icon icon-link"></span></a>三、反思：什么场景真正需要”重装上阵”？</h2>
<p>这次失败的尝试并非毫无价值，它让我更深刻地理解了多智能体系统的本质和适用边界。</p>
<p><strong>多智能体系统的核心优势在于：</strong></p>
<ul>
<li><strong>专业分工与模块化：</strong> 能将一个庞大、模糊的任务分解给不同领域的”专家”，实现关注点分离。</li>
<li><strong>模拟复杂工作流：</strong> 非常适合模拟真实世界中需要多角色协作的流程，如产品研发、科学研究等。</li>
<li><strong>“涌现”与创造力：</strong> Agent间的自由讨论有时能碰撞出意想不到的、富有创造力的解决方案。</li>
</ul>
<p><strong>那么，什么场景适合使用这种”重量级”的系统？</strong></p>
<ol>
<li><strong>探索性与研究性任务：</strong> 例如，“调研自动驾驶技术的最新进展，并生成一份包含技术摘要、主要玩家和未来趋势的分析报告”。这类任务没有固定流程，需要信息搜集、整合、分析等多个复杂步骤，且对最终结果的创造性有一定要求。</li>
<li><strong>端到端的自动化项目：</strong> 例如，“根据用户需求文档，自动生成项目框架、编写核心代码、配置部署脚本”。这类任务周期长、步骤多、异步执行，多智能体系统可以像一个自主项目团队一样，在后台默默推进。</li>
<li><strong>复杂决策与模拟：</strong> 例如，模拟一个市场环境，让”消费者Agent”、“竞争对手Agent”和”营销Agent”互动，以预测某个营销策略的效果。</li>
</ol>
<p><strong>而对于以下场景，我们应该果断选择”轻装简行”：</strong></p>
<ul>
<li><strong>高频次的实时交互任务：</strong> 如代码补全、实时问答、文本润色。</li>
<li><strong>流程确定、线性的任务：</strong> 如果一个任务可以被清晰地分解为A->B->C的步骤，那么强制使用自由讨论式的<code>GroupChat</code>就是杀鸡用牛刀。</li>
<li><strong>对延迟和成本极其敏感的场景。</strong></li>
</ul>
<h2 id="四回归简单轻量级ai助手的构建思路"><a aria-hidden="true" tabindex="-1" href="#四回归简单轻量级ai助手的构建思路"><span class="icon icon-link"></span></a>四、回归简单：轻量级AI助手的构建思路</h2>
<p>既然重量级的多智能体系统不适合我的日常开发需求，那么什么是更好的替代方案？答案是回归简单，利用AutoGen提供的其他模式，或者转变思路。</p>
<h3 id="方案一两阶段智能体流水线-sequential-pipeline"><a aria-hidden="true" tabindex="-1" href="#方案一两阶段智能体流水线-sequential-pipeline"><span class="icon icon-link"></span></a>方案一：两阶段智能体流水线 (Sequential Pipeline)</h3>
<p>如果你的流程是确定的，比如”先编码，后审查”，那么完全可以用有序的方式组织Agent。AutoGen的<code>register_nested_chats</code>功能非常适合这个场景。</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#6A737D"># 这是一个概念性示例，演示如何构建一个有序的流水线</span></span>
<span class="line"><span style="color:#6A737D"># CoderAgent完成任务后，其结果会自动作为QualityAnalyzerAgent的输入</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 假设已经定义了 CoderAgent 和 QualityAnalyzerAgent</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 嵌套聊天设置</span></span>
<span class="line"><span style="color:#E1E4E8">review_chat </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.GroupChat(</span></span>
<span class="line"><span style="color:#FFAB70">    agents</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[quality_analyzer, user_proxy],</span></span>
<span class="line"><span style="color:#FFAB70">    messages</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">[],</span></span>
<span class="line"><span style="color:#FFAB70">    max_round</span><span style="color:#F97583">=</span><span style="color:#79B8FF">2</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    speaker_selection_method</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"manual"</span><span style="color:#6A737D"> # 或者其他可控方式</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 注册嵌套聊天，形成流水线</span></span>
<span class="line"><span style="color:#E1E4E8">coder.register_nested_chats(</span></span>
<span class="line"><span style="color:#E1E4E8">    [{</span><span style="color:#9ECBFF">"recipient"</span><span style="color:#E1E4E8">: quality_analyzer, </span><span style="color:#9ECBFF">"message"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"Please review the following code."</span><span style="color:#E1E4E8">, </span><span style="color:#9ECBFF">"summary_method"</span><span style="color:#E1E4E8">: </span><span style="color:#9ECBFF">"last_msg"</span><span style="color:#E1E4E8">}],</span></span>
<span class="line"><span style="color:#FFAB70">    trigger</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">user_proxy,</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">user_proxy.initiate_chat(coder, </span><span style="color:#FFAB70">message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"Write a Python function for quick sort."</span><span style="color:#E1E4E8">)</span></span></code></pre>
<p>这种模式下，控制流是确定的 <code>User -> Coder -> QualityAnalyzer</code>。它保留了Agent专业分工的优点，但消除了<code>SelectorGroupChat</code>的不可预测性和高昂的协调成本。</p>
<h3 id="方案二单智能体--工具-single-agent-with-tools"><a aria-hidden="true" tabindex="-1" href="#方案二单智能体--工具-single-agent-with-tools"><span class="icon icon-link"></span></a>方案二：单智能体 + 工具 (Single Agent with Tools)</h3>
<p>这是目前业界在构建AI助手时更为主流和实用的范式，也与OpenAI的Function Calling/Tool Use一脉相承。</p>
<p><strong>核心思想是：<strong>与其创建多个Agent进行对话，不如创建一个”全能”的<code>AssistantAgent</code>，并将”质量分析”、“代码优化”等能力封装成它可以调用的</strong>工具</strong>。</p>
<pre class="astro-code github-dark" style="background-color:#24292e;color:#e1e4e8; overflow-x: auto;" tabindex="0" data-language="python"><code><span class="line"><span style="color:#F97583">import</span><span style="color:#E1E4E8"> pylint.lint</span></span>
<span class="line"><span style="color:#F97583">import</span><span style="color:#E1E4E8"> io</span></span>
<span class="line"><span style="color:#F97583">from</span><span style="color:#E1E4E8"> pylint.reporters.text </span><span style="color:#F97583">import</span><span style="color:#E1E4E8"> TextReporter</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 1. 定义工具函数</span></span>
<span class="line"><span style="color:#F97583">def</span><span style="color:#B392F0"> lint_code</span><span style="color:#E1E4E8">(code: </span><span style="color:#79B8FF">str</span><span style="color:#E1E4E8">) -> </span><span style="color:#79B8FF">str</span><span style="color:#E1E4E8">:</span></span>
<span class="line"><span style="color:#9ECBFF">    """Runs pylint on the given Python code and returns the report."""</span></span>
<span class="line"><span style="color:#E1E4E8">    pylint_opts </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> [</span><span style="color:#9ECBFF">'--disable=all'</span><span style="color:#E1E4E8">, </span><span style="color:#9ECBFF">'--enable=E,W'</span><span style="color:#E1E4E8">]</span></span>
<span class="line"><span style="color:#E1E4E8">    reporter </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> TextReporter(io.StringIO())</span></span>
<span class="line"><span style="color:#E1E4E8">    pylint.lint.Run([io.StringIO(code)], </span><span style="color:#FFAB70">reporter</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">reporter, </span><span style="color:#FFAB70">exit</span><span style="color:#F97583">=</span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">, </span><span style="color:#FFAB70">args</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">pylint_opts)</span></span>
<span class="line"><span style="color:#F97583">    return</span><span style="color:#E1E4E8"> reporter.out.getvalue()</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 2. 创建一个具备工具调用能力的Agent</span></span>
<span class="line"><span style="color:#E1E4E8">super_assistant </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.AssistantAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"SuperAssistant"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    system_message</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"You are a super-assistant for Python development. You can write code and use tools to check its quality."</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    llm_config</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">llm_config,</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 3. 创建UserProxyAgent并注册工具</span></span>
<span class="line"><span style="color:#E1E4E8">user_proxy </span><span style="color:#F97583">=</span><span style="color:#E1E4E8"> autogen.UserProxyAgent(</span></span>
<span class="line"><span style="color:#FFAB70">    name</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"UserProxy"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    human_input_mode</span><span style="color:#F97583">=</span><span style="color:#9ECBFF">"TERMINATE"</span><span style="color:#E1E4E8">,</span></span>
<span class="line"><span style="color:#FFAB70">    code_execution_config</span><span style="color:#F97583">=</span><span style="color:#79B8FF">False</span><span style="color:#E1E4E8">, </span><span style="color:#6A737D"># 我们不执行代码，只调用工具</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#E1E4E8">user_proxy.register_function(</span></span>
<span class="line"><span style="color:#FFAB70">    function_map</span><span style="color:#F97583">=</span><span style="color:#E1E4E8">{</span></span>
<span class="line"><span style="color:#9ECBFF">        "lint_code"</span><span style="color:#E1E4E8">: lint_code</span></span>
<span class="line"><span style="color:#E1E4E8">    }</span></span>
<span class="line"><span style="color:#E1E4E8">)</span></span>
<span class="line"></span>
<span class="line"><span style="color:#6A737D"># 4. 让Agent使用工具</span></span>
<span class="line"><span style="color:#6A737D"># 在LLM的Prompt中，它会被告知有lint_code这个工具可用</span></span>
<span class="line"><span style="color:#6A737D"># LLM会决定在合适的时机生成调用该工具的请求</span></span></code></pre>
<p><strong>这种模式的优势是压倒性的：</strong></p>
<ul>
<li><strong>低延迟：</strong> 没有多Agent间的通信开销。</li>
<li><strong>高可控：</strong> 流程由LLM调用工具的决策驱动，比Agent间的自由对话更可预测。</li>
<li><strong>易于扩展和维护：</strong> 增加新能力只需添加新的工具函数，而不是设计一个新的Agent和复杂的交互逻辑。</li>
</ul>
<h2 id="结论在复杂性与实用性之间寻找平衡"><a aria-hidden="true" tabindex="-1" href="#结论在复杂性与实用性之间寻找平衡"><span class="icon icon-link"></span></a>结论：在复杂性与实用性之间寻找平衡</h2>
<p>我这次从雄心勃勃到回归务实的旅程，让我深刻体会到：<strong>技术选型的第一原则永远是”恰如其分”</strong>。多智能体系统是一个强大而迷人的范式，但它不是解决所有问题的银弹。为了追求”看起来很酷”的架构而忽视了真实场景下的效率、成本和可控性，是典型的技术自嗨。</p>
<p>对于AI应用的构建者而言，我们的目标不应是构建最复杂的系统，而是构建最能解决问题的系统。在AutoGen这样的强大框架中，<code>GroupChat</code>只是众多工具之一。学会根据任务的性质，在”多智能体协作”、“有序流水线”和”单智能体+工具”之间做出明智的选择，才是一名成熟AI工程师的标志。</p>
<p>未来，人与AI的协作、AI与AI的协作，必将更加深入。而我们的任务，就是在不断涌现的新技术中，保持清醒的头脑，找到那个连接技术与价值的最佳平衡点。</p> </article> <html lang="en" data-astro-cid-uffxixac> <head><!-- Global Metadata --><meta charset="utf-8"><!--<meta http-equiv="Content-Security-Policy" content="upgrade-insecure-requests">--><meta name="viewport" content="width=device-width,initial-scale=1"><link rel="stylesheet" href="https://cdn.jsdelivr.net/npm/katex@0.15.2/dist/katex.min.css"><link rel="shortcut icon" href="/favicon.png" type="image/png"><link rel="sitemap" href="/sitemap-index.xml"><link rel="alternate" type="application/rss+xml" title="Ge Yuxu • AI &#38; Engineering" href="https://geyuxu.com/rss.xml"><meta name="generator" content="Astro v5.5.6"><!-- Font preloads --><link rel="preload" href="/fonts/atkinson-regular.woff" as="font" type="font/woff" crossorigin><link rel="preload" href="/fonts/atkinson-bold.woff" as="font" type="font/woff" crossorigin><!-- Canonical URL --><link rel="canonical" href="https://geyuxu.com/blog/ai/autogen%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%AE%9E%E8%B7%B5%E5%8F%8D%E6%80%9D%E4%BB%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BC%96%E7%A8%8B%E7%9A%84%E9%87%8D%E8%A3%85%E4%B8%8A%E9%98%B5%E5%88%B0%E8%BD%BB%E9%87%8F%E7%BA%A7ai%E5%8A%A9%E6%89%8B%E7%9A%84%E5%9B%9E%E5%BD%92/"><!-- Primary Meta Tags --><title>Ge Yuxu • AI &amp; Engineering</title><meta name="title" content="Ge Yuxu • AI &#38; Engineering"><meta name="description" content="Welcome to my blog!"><!-- Open Graph / Facebook --><meta property="og:type" content="website"><meta property="og:url" content="https://geyuxu.com/blog/ai/autogen%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%AE%9E%E8%B7%B5%E5%8F%8D%E6%80%9D%E4%BB%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BC%96%E7%A8%8B%E7%9A%84%E9%87%8D%E8%A3%85%E4%B8%8A%E9%98%B5%E5%88%B0%E8%BD%BB%E9%87%8F%E7%BA%A7ai%E5%8A%A9%E6%89%8B%E7%9A%84%E5%9B%9E%E5%BD%92/"><meta property="og:title" content="Ge Yuxu • AI &#38; Engineering"><meta property="og:description" content="Welcome to my blog!"><meta property="og:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><!-- Twitter --><meta property="twitter:card" content="summary_large_image"><meta property="twitter:url" content="https://geyuxu.com/blog/ai/autogen%E5%A4%9A%E6%99%BA%E8%83%BD%E4%BD%93%E5%AE%9E%E8%B7%B5%E5%8F%8D%E6%80%9D%E4%BB%8E%E4%B8%8A%E4%B8%8B%E6%96%87%E7%BC%96%E7%A8%8B%E7%9A%84%E9%87%8D%E8%A3%85%E4%B8%8A%E9%98%B5%E5%88%B0%E8%BD%BB%E9%87%8F%E7%BA%A7ai%E5%8A%A9%E6%89%8B%E7%9A%84%E5%9B%9E%E5%BD%92/"><meta property="twitter:title" content="Ge Yuxu • AI &#38; Engineering"><meta property="twitter:description" content="Welcome to my blog!"><meta property="twitter:image" content="https://geyuxu.com/blog-placeholder-1.jpg"><script src="/js/jquery-3.7.1.min.js"></script></head> <body data-astro-cid-uffxixac>  <div class="statement" data-astro-cid-uffxixac> <blockquote data-astro-cid-uffxixac> <p data-astro-cid-uffxixac><strong data-astro-cid-uffxixac>脱敏说明</strong>：本文所有出现的表名、字段名、接口地址、变量名、IP地址及示例数据等均非真实，
    仅用于阐述技术思路与实现步骤，示例代码亦非公司真实代码。
    示例方案亦非公司真实完整方案，仅为本人记忆总结，用于技术学习探讨。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;文中所示任何标识符并不对应实际生产环境中的名称或编号。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;示例&nbsp;SQL、脚本、代码及数据等均为演示用途，不含真实业务数据，也不具备直接运行或复现的完整上下文。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;读者若需在实际项目中参考本文方案，请结合自身业务场景及数据安全规范，使用符合内部命名和权限控制的配置。</p> <p data-astro-cid-uffxixac><strong data-astro-cid-uffxixac>版权声明</strong>：本文版权归原作者所有，未经作者事先书面许可，任何单位或个人不得以任何方式复制、转载、摘编或用于商业用途。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;若需非商业性引用或转载本文内容，请务必注明出处并保持内容完整。<br data-astro-cid-uffxixac>
&nbsp;&nbsp;&nbsp;&nbsp;•&nbsp;对因商业使用、篡改或不当引用本文内容所产生的法律纠纷，作者保留追究法律责任的权利。<br data-astro-cid-uffxixac><br data-astro-cid-uffxixac> <em data-astro-cid-uffxixac>Copyright&nbsp;©&nbsp;1989–Present&nbsp;Ge&nbsp;Yuxu.&nbsp;All&nbsp;Rights&nbsp;Reserved.</em></p> </blockquote> </div></body></html>  </article> </div> </main> <footer data-astro-cid-sz7xmlte>
&copy; 2025 All rights reserved.
</footer>  </body></html>